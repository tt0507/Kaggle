{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to use machine learning to create a model that predicts which passengers survived the Titanic shipwreck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_full_data = pd.read_csv('data/train.csv')\n",
    "test_full_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes represents the following information:\n",
    "* **Survived**: 0 if the passenger did not survive, 1 if passenger did survive.\n",
    "* **Pclass**: passenger class\n",
    "* **SibSp**: # of siblings & spouses of the passenger aboard the Titanic.\n",
    "* **Parch**: # of children & parents of the passenger aboard the Titanic.\n",
    "* **Ticket**: ticket id\n",
    "* **Fare**: price paid (in pounds)\n",
    "* **Cabin**: passenger's cabin number\n",
    "* **Embarked**: where the passenger embarked the Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_full_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataset we see that there are null values for *Age*, *Cabin*, and *Embarked*. For *Age*, the null values will be replaced by the median of the column. *Cabin* will be dropped as the NaN values can not be filled with arbituary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_full_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Insight into Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create pivot tables to get useful insight in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.395408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.117887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fare\n",
       "Survived           \n",
       "1         48.395408\n",
       "0         22.117887"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_data[['Fare', 'Survived']].groupby(['Survived']).mean().sort_values(by='Fare', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows the passengers who survived payed a higher price for the fare. To get more insight into the difference between passengers who survived and didn't survive, we look at *Pclass*, *Sex*, *SibSp*, and *Parch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.154687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.662183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.675550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fare\n",
       "Pclass           \n",
       "1       84.154687\n",
       "2       20.662183\n",
       "3       13.675550"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_data[['Pclass', 'Fare']].groupby(['Pclass']).mean().sort_values(by='Fare', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survived\n",
       "Pclass          \n",
       "1       0.629630\n",
       "2       0.472826\n",
       "3       0.242363"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_data[['Pclass', 'Survived']].groupby(['Pclass']).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first table describes the mean price for the three *Pclass* and the chance the passenger survived. The tables shows that *Pclass* with 1 has the highest price meaning that the passengers had better rooms or services, and another evidence that the chance of surviving increased with passengers paying higher fare prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survived\n",
       "Sex             \n",
       "female  0.742038\n",
       "male    0.188908"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_data[['Sex', 'Survived']].groupby(['Sex']).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pivot table shows that female had a higher chance of surviving than male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.553734</td>\n",
       "      <td>0.329690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.464912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SibSp     Parch\n",
       "Survived                    \n",
       "0         0.553734  0.329690\n",
       "1         0.473684  0.464912"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_data[['Survived', 'SibSp', 'Parch']].groupby(['Survived']).mean().sort_values(by='SibSp', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table shows that passengers with more siblings and spouses had a smaller chance of surviving. On the other hand, passengers with more parents onboard had a higher chance of surviving. Since *SibSp* and *Parch* both represent the amount of family onboard, we create one column called *NumFamily* which is the sum of the two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>NumFamily</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  NumFamily  \n",
       "0      0         A/5 21171   7.2500   NaN        S          1  \n",
       "1      0          PC 17599  71.2833   C85        C          1  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S          0  \n",
       "3      0            113803  53.1000  C123        S          1  \n",
       "4      0            373450   8.0500   NaN        S          0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_data['NumFamily'] = train_full_data['SibSp'] + train_full_data['Parch']\n",
    "train_full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumFamily</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.578431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.303538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Survived\n",
       "NumFamily          \n",
       "3          0.724138\n",
       "2          0.578431\n",
       "1          0.552795\n",
       "6          0.333333\n",
       "0          0.303538\n",
       "4          0.200000\n",
       "5          0.136364\n",
       "7          0.000000\n",
       "10         0.000000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_data[['NumFamily', 'Survived']].groupby(['NumFamily']).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above we can see that there is no clear trend between the number of family onboard the ship and the chance of the passenger surviving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better understanding of the relationship between variables, we plot visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7feb77e788b0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train_full_data['Age'], kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows that most people on the ship are younger than 40 years old. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7feb77eaa340>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAE9CAYAAACyU3u7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeXhU5fn/8fczS2ayh4RFIKyi7CQoiIgL4oJaRSsqWtdqq6215aetba1aqdVWW7q49YtaW9RSl7rihqKIuyLIIquAICQiZCeZJLOe3x9nCMREIctkJpPP67pyMeeZk8OdEO489znPYizLQkRERERERJKLI94BiIiIiIiISPtTsSciIiIiIpKEVOyJiIiIiIgkIRV7IiIiIiIiSUjFnoiIiIiISBJSsSciIiIiIpKEXPEOoC26d+9uDRw4MN5hiEg7WrZsWallWT3iHUdbKDeJJCflJxFJRN+Wmzp1sTdw4ECWLl0a7zBEpB0ZY76IdwxtpdwkkpyUn0QkEX1bbtIwThERERERkSSkYk9ERERERCQJqdgTERERERFJQp16zp5IZxEMBikqKqK+vj7eoSQMr9dLfn4+brc73qGISJRylU35SSR2lGdarzW5ScWeSAcoKioiMzOTgQMHYoyJdzhxZ1kWZWVlFBUVMWjQoHiHIyJRylXKTyKxpjzTOq3NTRrGKdIB6uvrycvLU1KLMsaQl5enu3oiCUa5SvlJJNaUZ1qntblJxZ5IB1FSa0zfD5HEpP+b+h6IxJr+j7VOa75vKvYk5vz1fnZW+tj0VSU7KmvZWVXL5pIadu2uJxyx4h1el3H77bczcuRIxowZQ2FhIR999FG8QxKJu5JSP9uKayn+qo5dpfVs/7KWXaX11PhC8Q6ty3I6nRQWFjJq1CjOPfdcamtrv/HcWbNmMXv27A6MTqSD+MqhcjvsWgdVRbB7B5Rthppd8Y4sacSiXzR//nzuuOOOdogOMjIy2uU6mrMnMRUKBlm2rYIf/GcFtYEwXreDO6eP4cVVO1i+rYLHrzySIT0z4x1m0vvggw948cUX+eSTT/B4PJSWlhIIBOIdlkhclZb5ueEPa1i/sRqASePzOP3kg7jxj2u4dMYAzpvWl8wMLdDR0VJTU1mxYgUAF154IXPmzOG6666Lc1QiHai2DFY9AQtvhkgI0rvDOf+Gl39hv3/x85DVO74xdnJt6ReFQiFcruZLqGnTpjFt2rT2DLXN9GRPYqrcV8/MJ1dTGwgDUB+MMGv+Gi4+cgClNQF+/fSnVNSq6Ii1HTt20L17dzweDwDdu3enT58+LFu2jOOOO47DDz+cqVOnsmPHDkKhEOPHj2fx4sUA3HDDDdx4441xjF6k/YXDEV56/auGQg/gvY/L8NWGGJCfxr8f+4LqGj3di7djjjmGTZs2AfDII48wZswYCgoKuPjii5uc++CDDzJ+/HgKCgqYPn16wxPB//3vf4waNYqCggKOPfZYANasWcMRRxxBYWEhY8aMYePGjR33RYnsT6AWFt5kF3oAvlJ441YY/wMo2QDv3w0hf3xj7OS+qV80cOBASktLAVi6dCmTJ08G7FEEF198MZMmTeLiiy/myCOPZM2aNQ3Xmzx5MkuXLmXu3Llcc801VFVVMWDAACKRCAA+n49+/foRDAbZvHkzp5xyCocffjjHHHMM69evB2DLli1MnDiR0aNHc9NNN7Xb16piT2IqFIGSmsYJqaI2iMdt/+ht3FVDMBSJR2hdysknn8z27ds59NBDufrqq3nrrbcIBoP89Kc/5amnnmLZsmVcfvnl3HjjjbhcLubOncuPf/xjXn/9dRYsWMAtt9wS7y9BpF35AxE++7ymSfvW7bX06uEFYGepOlPxFAqFeOWVVxg9ejRr1qzhtttuY9GiRaxcuZK77rqryflnn302H3/8MStXrmT48OE89NBDANx66628+uqrrFy5kvnz5wMwZ84cZs6cyYoVK1i6dCn5+fkd+rWJfKv6SoiEG7eVbIDsfvbrHSsh+M3Dm2X/musX7c/atWt5/fXXeeyxx5gxYwZPPvkkYBeOO3bsYNy4cQ3nZmdnU1hY2HDdF198kalTp+J2u7nyyiu55557WLZsGbNnz+bqq68GYObMmfz4xz/m008/pXfv9ntyq2JPYsrjhJF9shq1HdIzg1277U7UicN7ke7RaOJYy8jIYNmyZTzwwAP06NGDGTNmcP/997N69WpOOukkCgsLue222ygqKgJg5MiRXHzxxZx++un861//IiUlJc5fgUj7Skt1cfykHk3aDx/TjQ2bq0lxG/J7p8YhMqmrq6OwsJBx48bRv39/rrjiChYtWsS5555L9+7dAcjNzW3yeatXr+aYY45h9OjRzJs3r+Gu+6RJk7jssst48MEHCYftDvTEiRP5wx/+wJ133skXX3xBaqr+rSWBpOaCN6dx25AToWip/XrUdPBkd3xcSaS5ftHcuXO/9XOmTZvWkCvOO+88nnrqKQCefPJJzjnnnCbnz5gxgyeeeAKAxx9/nBkzZlBTU8P777/PueeeS2FhIVdddRU7duwA4L333uOCCy4AaHb0Qmuply0xlZedyQMXjeVXz6zm460VjO2fww2nDuem51YzraA3vz51qIq9DuJ0Opk8eTKTJ09m9OjR3HfffYwcOZIPPvig2fM//fRTcnJy2LVLk8ElOY0dlc3lFwzg6ZeK8aQ4uez8/qzftJucLDd/+M1IsjM1Xy8e9p2z1xKXXXYZzz33HAUFBcydO7dhKPqcOXP46KOPeOmllzj88MNZtmwZ3/ve95gwYQIvvfQSp512Gvfffz9Tpkxp569EpJXSusMlz8MLP4PSjXDoKXDUNfC/y2DS/4MRZ4FDz2va6uv9oocffhiXy9Uw9PLrWxykp6c3vO7bty95eXmsWrWKJ554gjlz5jS5/rRp0/jNb35DeXk5y5YtY8qUKfh8PnJycr4xx8VildKY9rKNMVuBaiAMhCzLGmeMyQWeAAYCW4HzLMuqMPZXdxdwGlALXGZZ1iexjE86Rt/cDO6bMQp/GFKcBsvh4qHLxpHmdpLhVWeqI2zYsAGHw8EhhxwCwIoVKxg+fDivvfYaH3zwARMnTiQYDPLZZ58xcuRInnnmGcrLy3n77bc5/fTTWbJkCTk5Ofv5WzoP5SYByMv1cMHZ+XznpIMAyMxwUVcX4fSTetMtR0+zE8mUKVP47ne/y3XXXUdeXh7l5eVNnu5VV1fTu3dvgsEg8+bNo2/fvgBs3ryZCRMmMGHCBF555RW2b99OVVUVgwcP5mc/+xnbtm1j1apVCVPsKT8Jbg/0KYQLHgcrAq40sMJwxevgzQa3N94RdnrN9YsGDBhAXV0dy5Yt49RTT+Xpp5/+1mvMmDGDP/3pT1RVVTFmzJgm72dkZDB+/HhmzpzJ6aefjtPpJCsri0GDBvG///2Pc889F8uyWLVqFQUFBUyaNInHH3+ciy66iHnz5rXb19oRtwWOtyyr0LKsPQNZfw28YVnWIcAb0WOAU4FDoh9XAv/XAbFJB8nOzKBnTgY5mel0S/fQM9OrQq8D1dTUcOmllzJixAjGjBnD2rVrufXWW3nqqaf41a9+RUFBAYWFhbz//vuUlpby61//mn/+858ceuihXHPNNcycOTPeX0IsKDcJqV4XvXp46dXDS1qqi7zcFBV6CWjkyJHceOONHHfccRQUFDS7Oufvf/97JkyYwKRJkxg2bFhD+/XXX8/o0aMZNWoURx11FAUFBTz55JOMGjWKwsJCVq9ezSWXXNKRX86BUH4SyOoD2fmQngsZPSCzlwq9dtJcv2jWrFnccsstzJw5k3HjxuF0Or/1Gueccw6PP/4455133jeeM2PGDP7zn/8wY8aMhrZ58+bx0EMPUVBQwMiRI3n++ecBuOuuu7jvvvsYPXo0xcXF7fOFAsayYrfPWfTu1DjLskr3adsATLYsa4cxpjew2LKsocaY+6OvH/v6ed90/XHjxllLly6NWfwi7WXdunUMHz483mEknOa+L8aYZft0cGJCuUmkecpVeyk/icSG8kzbtDQ3xfrJngW8ZoxZZoy5MtrWa58k9BXQK/q6L7B9n88tirY1Yoy50hiz1BiztKSkJFZxi0hyU24SkUSl/CQi7SbWK2McbVlWsTGmJ7DQGLN+3zcty7KMMS16tGhZ1gPAA2DfnWq/UEWkC1FuEpFEpfwkIu0mpk/2LMsqjv65C3gWOALYGR2CQPTPPUv9FQP99vn0/GibiEi7Um4SkUSl/CQi7SlmxZ4xJt0Yk7nnNXAysBqYD1waPe1S4Pno6/nAJcZ2JFD1bWPORURaQ7lJRBKV8pOItLdYDuPsBTwb3S/CBfzXsqwFxpiPgSeNMVcAXwB7lrB5GXvp4E3Yywd/P4axiUjXpdwkIolK+UlE2lXMij3Lsj4HCpppLwNOaKbdAn4Sq3hEREC5SUQSl/KTiLS3jthnT0Q6ucWLF3P66afHOwwR6QIWLFjA0KFDGTJkCHfccUe8wxGRJNVVco2KPREREUkI4XCYn/zkJ7zyyiusXbuWxx57jLVr18Y7LBFJMl0p16jYE0lAzy0vZtIdixj065eYdMcinlve9sXVtm7dyrBhw7jssss49NBDufDCC3n99deZNGkShxxyCEuWLGHJkiVMnDiRsWPHctRRR7Fhw4Ym1/H5fFx++eUcccQRjB07lueff76Zv01EuoLXFu9k+uUfcsy0t5h++Ye8tnhnm663ZMkShgwZwuDBg0lJSeH8889XjhHp4mLRJ+pKuUbFnkiCeW55MTc88ynFlXVYQHFlHTc882m7JLdNmzbx85//nPXr17N+/Xr++9//8u677zJ79mz+8Ic/MGzYMN555x2WL1/Orbfeym9+85sm17j99tuZMmUKS5Ys4c033+T666/H5/O1OTYR6VxeW7yTO+/9jJ0lfiwLdpb4ufPez9pU8BUXF9Ov396dBPLz8yku1k4CIl1VrPpEXSnXqNgTSTB/fnUDdcFwo7a6YJg/v9r0KVtLDRo0iNGjR+NwOBg5ciQnnHACxhhGjx7N1q1bqaqq4txzz2XUqFFce+21rFmzpsk1XnvtNe644w4KCwuZPHky9fX1bNu2rc2xiUjncv8jW/D7I43a/P4I9z+yJU4RiUiyiWWfqKuI5dYLItIKX1bWtai9JTweT8Nrh8PRcOxwOAiFQtx8880cf/zxPPvss2zdupXJkyc3uYZlWTz99NMMHTq0zfGISOe1q9TfovYD0bdvX7Zv395wXFRURN++fVt9PRHp3GLVJ+pKuUZP9kQSTJ+c1Ba1t6eqqqqGZDd37txmz5k6dSr33HMP9orfsHz58pjHJSKJp2d3T4vaD8T48ePZuHEjW7ZsIRAI8PjjjzNt2rRWX09EOrdY9Ym6Uq5RsSeSYK6fOpRUt7NRW6rbyfVTY/8k7Ze//CU33HADY8eOJRQKNXvOzTffTDAYZMyYMYwcOZKbb7455nGJSOK56pJBeDyNuxEej4OrLhnU6mu6XC7uvfdepk6dyvDhwznvvPMYOXJkW0MVkU4qVn2irpRrzJ67853RuHHjrKVLl8Y7DJH9WrduHcOHDz/g859bXsyfX93Al5V19MlJ5fqpQzlrbPINL2ju+2KMWWZZ1rg4hdQulJuks2pprnpt8U7uf2QLu0r99Ozu4apLBnHy5F4xjLDjKD+JxIb6RG3T0tykOXsiCeissX27dCITkc7h5Mm9kqa4E5HEpD5R22gYp4iIiIiISBJSsSciIiIiIpKEVOyJiIiIiIgkIRV7IiIiIiIiSUjFnoiIiIiISBJSsSfSRdx9990MHz6cCy+8MCbXnzVrFrNnz47JtUWk67j88svp2bMno0aNincoIpKkulKeUbEn0kX84x//YOHChcybNy/eoYiIfKPLLruMBQsWxDsMEUliXSnPaJ89kUS06kl441aoKoLsfDjhtzDmvFZf7kc/+hGff/45p556Kueffz6bN29m9erVBINBZs2axZlnnsncuXN57rnn8Pl8bNy4kV/84hcEAgEeffRRPB4PL7/8Mrm5uTz44IM88MADBAIBhgwZwqOPPkpaWlqjv2/z5s385Cc/oaSkhLS0NB588EGGDRvW1u+KiCSYWGyqfuyxx7J169b2CVBEOr927hNB18ozerInkmhWPQkv/AyqtgOW/ecLP7PbW2nOnDn06dOHN998E5/Px5QpU1iyZAlvvvkm119/PT6fD4DVq1fzzDPP8PHHH3PjjTeSlpbG8uXLmThxIo888ggAZ599Nh9//DErV65k+PDhPPTQQ03+viuvvJJ77rmHZcuWMXv2bK6++upWxy4iiem1xTu5897P2Fnix7JgZ4mfO+/9jNcW74x3aCKSLGLQJ+pq9GRPJNG8cSsE6xq3Bevs9jbeyQJ47bXXmD9/fsP8uvr6erZt2wbA8ccfT2ZmJpmZmWRnZ3PGGWcAMHr0aFatWgXYBeFNN91EZWUlNTU1TJ06tdH1a2pqeP/99zn33HMb2vx+f5vjFpHEcv8jW/D7I43a/P4I9z+ypc1P90REgJj3iboCFXsiiaaqqGXtLWRZFk8//TRDhw5t1P7RRx/h8Xgajh0OR8Oxw+EgFAoB9jj35557joKCAubOncvixYsbXScSiZCTk8OKFSvaJV4RSUy7Spu/ifNN7SIiLRbjPlFXoGGcIokmO79l7S00depU7rnnHizLAmD58uUt+vzq6mp69+5NMBhsdrGXrKwsBg0axP/+9z/ALi5XrlzZ9sBFJKH07O5pUbuISIvFuE/UFajYE0k0J/wW3KmN29ypdns7uPnmmwkGg4wZM4aRI0dy8803t+jzf//73zNhwgQmTZr0jYuuzJs3j4ceeoiCggJGjhzJ888/3x6hi0gCueqSQXg8jbsRHo+Dqy4Z1KbrXnDBBUycOJENGzaQn5/f7LxgEekiYtQn6kp5xuy5u98ZjRs3zlq6dGm8wxDZr3Xr1jF8+PAD/4QYrDyViJr7vhhjllmWNS5OIbUL5SbprFqaq2KxGmeiUH4SiQ31idqmpblJc/ZEEtGY87p0IhORzuHkyb2SprgTkQSlPlGbaBiniIiIiIhIElKxJyIiIiIikoRU7Il0kM48PzYW9P0QERHpmtQHaJ3WfN9U7Il0AK/XS1lZmZJblGVZlJWV4fV64x2KiIiIdCD1iVqntX0nLdAi0gHy8/MpKiqipKQk3qEkDK/XS36+9skRERHpStQnar3W9J1U7Il0ALfbzaBBbdt7SkQk2W3fvp1LLrmEnTt3YozhyiuvZObMmfEOS0TakfpEHUvFnoiIiCQEl8vFX/7yFw477DCqq6s5/PDDOemkkxgxYkS8QxMR6ZRU7ImIiEirVFdXU1FeTigUwuVy0S03l8zMzFZfr3fv3vTu3RuAzMxMhg8fTnFxsYo9EZFWUrEnIiIiLVZdXU1pSUnDIguhUIjS6BycthR8e2zdupXly5czYcKENl9LRKSr0mqcIiIi0mIV5eVNVtOzLIuK8vI2X7umpobp06fz97//naysrDZfT0Skq1KxJyIiIi0WCoVa1H6ggsEg06dP58ILL+Tss89u07VERLo6FXsiIiLSYi5X8zNBvqn9QFiWxRVXXMHw4cO57rrrWn0dERGxqdgTERGRFuuWm4sxplGbMYZuubmtvuZ7773Ho48+yqJFiygsLKSwsJCXX365raGKiHRZWqBFREREWmzPIiztuRrn0Ucf3WQeoIiItF7Mn+wZY5zGmOXGmBejx4OMMR8ZYzYZY54wxqRE2z3R403R9wfGOjYR6bqUm0TaLjMzk/4DBjD44IPpP2BAu6zCKcpPItJ+OmIY50xg3T7HdwJ/syxrCFABXBFtvwKoiLb/LXqeiEisKDeJSKJSfhKRdhHTYs8Ykw98B/hn9NgAU4Cnoqc8DJwVfX1m9Jjo+yeYr08GEBFpB8pNIpKolJ9EpD3F+sne34FfApHocR5QaVnWnnWZi4C+0dd9ge0A0feroueLiLQ35SYRSVTKTyLSbmJW7BljTgd2WZa1rJ2ve6UxZqkxZmlJSUl7XlpEugDlJhFJVMpPItLeYvlkbxIwzRizFXgcewjCXUCOMWbPKqD5QHH0dTHQDyD6fjZQ9vWLWpb1gGVZ4yzLGtejR48Yhi8iSUq5SUQSlfKTiLSrmBV7lmXdYFlWvmVZA4HzgUWWZV0IvAmcEz3tUuD56Ov50WOi7y+ytP6yiLQz5SaRxFVfX88RRxxBQUEBI0eO5JZbbol3SB1K+UlE2ls8NlX/FXCdMWYT9rjyh6LtDwF50fbrgF/HITYR6bqUm0TizOPxsGjRIlauXMmKFStYsGABH374YbzDSgTKTyLSKh2yqbplWYuBxdHXnwNHNHNOPXBuR8QjIgLKTSJtVfzYC2y46a/Ubd9Bar/eDL3tOvpecEarr2eMISMjA4BgMEgwGKSrLi6p/CQi7SEeT/ZERESkkyt+7AU+/dFN1G37EiyLum1f8umPbqL4sRfadN1wOExhYSE9e/bkpJNOYsKECe0UsYhI16NiT0RERFpsw01/JVxb36gtXFvPhpv+2qbrOp1OVqxYQVFREUuWLGH16tVtup6ISFemYk9ERERarG77jha1t1ROTg7HH388CxYsaJfriYh0RSr2REREpMVS+/VuUfuBKCkpobKyEoC6ujoWLlzIsGHDWn09EZGuTsWeiIiItNjQ267DmeZt1OZM8zL0tutafc0dO3Zw/PHHM2bMGMaPH89JJ53E6aef3tZQRUS6rA5ZjVNERESSy55VN9tzNc4xY8awfPny9gpRRKTLU7EnIiIirdL3gjPaVNyJiEhsaRiniIiIiIhIElKxJyIiIiIikoRU7ImIiEgDy7LiHULc6XsgIslCxZ6IiIgA4PV6KSsr69LFjmVZlJWV4fV693+yiEiC0wItIiIiAkB+fj5FRUWUlJTEO5S48nq95OfnxzsMEZE2U7EnIiIiALjdbgYNGhTvMEREpJ1oGKeIiIiIiEgSUrEnIiIiIiKShFTsiYiIiIiIJCEVeyIiIiIiIklIxZ6IiIiIiEgSUrEnIiIiIiKShFTsiYiIiIiIJCEVeyIiIiIiIklIxZ6IiIiIiEgSUrEnIiIiIiKShFTsiYiIiIiIJCEVeyIiIiIiIklIxZ6IiIiIiEgSUrEnIiIiIiKShFTsiYiIiIiIJCEVeyIiIiIiIklIxZ6IiIiIiEgSUrEnIiIiIiKShFTsiYiIiIiIJCEVeyIiIiIiIklIxZ6IiIiIiEgSUrEnIiIiIiKShFTsiYiIiIiIJCEVeyIiIiIiIklIxZ6IiIiIiEgSUrEnIiIiIiKShGJW7BljvMaYJcaYlcaYNcaY30XbBxljPjLGbDLGPGGMSYm2e6LHm6LvD4xVbCLSdSk3iUiiUn4SkfYWyyd7fmCKZVkFQCFwijHmSOBO4G+WZQ0BKoAroudfAVRE2/8WPU9EpL0pN4lIolJ+EpF2FbNiz7LVRA/d0Q8LmAI8FW1/GDgr+vrM6DHR908wxphYxSciXZNyk4gkKuUnEWlvMZ2zZ4xxGmNWALuAhcBmoNKyrFD0lCKgb/R1X2A7QPT9KiAvlvGJSNek3CQiiUr5SUTaU0yLPcuywpZlFQL5wBHAsLZe0xhzpTFmqTFmaUlJSZtjFJGuR7lJRBKV8pOItKcOWY3TsqxK4E1gIpBjjHFF38oHiqOvi4F+ANH3s4GyZq71gGVZ4yzLGtejR4+Yxy4iyUu5SUQSlfKTiLSHWK7G2cMYkxN9nQqcBKzDTlznRE+7FHg++np+9Jjo+4ssy7JiFZ+IdE3KTSKSqJSfRKS9ufZ/Sqv1Bh42xjixi8onLct60RizFnjcGHMbsBx4KHr+Q8CjxphNQDlwfgxjE5GuS7lJRBKV8pOItKuYFXuWZa0CxjbT/jn2GPSvt9cD58YqHhERUG4SkcSl/CQi7a1D5uyJiIiIiIhIx1KxJyIiIiIikoRU7ImIiIiIiCQhFXsiIiIiIiJJSMWeiIiIiIhIElKxJyIiIiIikoRU7ImIiIiIiCShAyr2jO0iY8xvo8f9jTFN9nsREeloyk8ikoiUm0QkERzok71/ABOBC6LH1cB9MYlIRKRllJ9EJBEpN4lI3LkO8LwJlmUdZoxZDmBZVoUxJiWGcUlzArXgTKGiPkIwEsFlHORm7PPPEAqCFQJ36t42fw0EfOBwgnFAOAgOB6T36Pj4pU0CoQiVdQEMkOl143U74x1SolB+irNgMEIkYmEMVPvCgEVWphu3y76faFkW9f4IKW4HTqcBIBy2qNwdAAwej8HvtwDIzHCR4tYMg86msipAOAIupyE7yx3vcBKFclO8WRYE68DlobQ2RMSy8LgcZKfu888Q9IMBXJ69bXUVEAqAyw2RCETC4EqB1G4d/iVI29QFQlT7QxgM3dLcuJxd7/fLgRZ7QWOME7AAjDE9gEjMopLGaiug6CP45BEieYcSHnUZ33vsC1LdTu46v5BBuV5M9Q547y7w7YIjr4aew+1EtfBm2PYBnPNveH0WbHkLeo2Esx+EHsPsIlASXmVtgOeWF/O31zcSCkf4wTGDueyogXRLV78B5ae4CYctdpXW899niqisCnDmqX1YuaaSp174kh9eNJATj+1JJGLx7kdlvPNhGQWjsjllSi+8HgefrKrkL/+3kSu+N5DS8gCPP7cdy4KLz+3PGSf3VsHQSViWxbbiOm6dvY4Nm2sYMyKbm68bRu9e3niHlgiUm+LJVwrrX4INLxMecDS1/adx5twNFOTncOf0MfTyRqDyC3j3b2CccPS10K0/1JbBc1fbReKJs+Dl62Hnahh0LJz1f5CdH++vTA5Quc/P3W9s4rEl28j0urj59BFMGdaTTG/X+v1yoOXt3cCzQE9jzO3Au8AfYhaV7BUJw7r58N8ZsP4lHO/9je5PTOOeM/ryaXEVl8/9mEhNCdx/DHz8IKx9Hv41Fb5cAWuehZWPwYSrYOFv7UIPYOcaePQsOxFKp7Cl1MesF9ZSVRfEFwhz1xsb+WRbRbzDShTKT3FSURng+zOX8ezLX/Lme6X8v5tWccjgTLrnpvDXOZuo2h3gX499wR33fMZ7H5fxj9AbNyEAACAASURBVH9/zu9mr2N3dYgbbl9DaqqTtDQn/5y3lRpfGF9tmDkPb2HTlpp4f2lygMorg/xi1qds2Gz/m61aW8XNd66lsioQ58gSgnJTvPir4Y1b4YWfwWcLcC68ib5vXsusE/uweEMJd76ynsjuYphzNKx6Alb+F+ZMgqpieOkX8PliOPZ6eOr7dqEHsOVteOZKqC2P65cmByYSsXhp1Q7mvr8VfyhCaU2AmY+voKTaH+/QOtwBFXuWZc0Dfgn8EdgBnGVZ1v9iGZhE1ZbBB/c0bqv8grxIGVmpLlJTnLD9I3vIwb7e+zvRm4lw0BjY+k7j92t2QUAdqs5i4dqdTdrmr/ySUFg3iZWf4ueTTyup8YUbtb342g6OntAdgEDQ4oVXdzR6f9nKSvyBCJYFw4ZksmxlZZPrLnpnV+yClnbl94fZsbO+Udv6jdUEglacIkocyk1x5K+BFfMaNTk/f4Pxfeyhmk4nmCX/hEho7wnhAKz4Lziig97cqVD9VePrfvGefZ4kvBp/iAVrvmrS/tHnXa9Y3+8wzugQhDWWZQ0D1sc+JGnEOMCd3rTd5SEUtnA7HeDJaPp+Sgak5tqvq4rsIZsl+/zzudPsD+kUDhvQdJ7A+IG5XXLs+b6Un+IrLbXpMPBUr5NAwL4J4XY78HgcBEN7C0KHA9xue97el1/Vc9JxPZtco2BUTowilvaWkuIgM91FtW9vp7l3L2/D3MyuSrkpzowBl7fxTW2Hk0j0GUf3dC+WJ5smP6XebMjYJyelpNvrHuzR/VC7XyYJLzXFSWG/HN7bVNaofXifrDhFFD/7/Ym1LCsMbDDG9O+AeOTr0rvDyb9vlFzC/Y9ioy8VA1w/dSjmoNF2AtrD5YHjfwMDj7HbP/w/OPVOSMuz33enwtkPQKo6VJ3F2H45fGd074bjSQfnccqog+IYUWJQfoqvEYdm0a/P3gWhUlIcnP2dvrzxzi5OOLoHWZkufnDRoEafc9YpvfGmOLnwnH6s/Ww3+X1SOfLw3Ib3jxqXy/hCLYLQWWRnupn1y+GkRgv/zAwXv7t+ON2yu9acmK9Tboozbw5MvqFRU/1hP+SlDdX0zPQw/bC+OA6/tPGCK+k9YPS5MO5y+/XSf8Fps/feGE/Lg+kPNS4GJWG5nQ4uPWogo/tmA3b9f9GE/gzI7XoPOoxl7X+ohTHmbWAssARouMVhWda02IW2f+PGjbOWLl0azxA6hr8GanbCZ69i5Q0hdFABXwbT8bpd5KS68bid9rDML963/xx6CqT3Ardn73DNlHR7/l+wzk5cqTmNV+2UhFdZG8AXCGNZFmkpLnKTdHEWY8wyy7LGteD8hMtPXSY3AWUVAVauqaSyKsjEcXk4nYZIxCIt1UlWppvdNUF27vKzdGUFI4dm0T8/lZysFGp8IWrrQoRCFm63g3DY/l2U6nVqcZZOxh8IU10Toq4+TFr038/lSs6nHy3JT4mYm6AL5ae6CqjcBlvexso/An/2YHYE00j3OMlL9+AkYveRNi20h24ePAUyetl9pdqyxn2nUL09YiotD5wHurahJIKyGj++QBiXw5DhcZGVmpy/X74tNx1osXdcc+2WZb3VxtjapMskLJEupBXFXsLlJ+UmkeTUwmIv4XITKD+JJKNvy00HdHsi3olJ2q6yNsD28loWbyihsH8OI3tnkZvh2f8ndiX1u2F3Max7EXqNgPwjIEP7ESY65afOLRy2KK8M8M6H9urAx0zoTm63lC4/5+vrSsv9fLi0HF9tmOOO6k5etxTc2o8woSk3dX7lvgBrv9zN8m0VHDe0B/1z08hJS85RNa1WWwalG+Hzt2DQMdBj6N5pQ5IQDqjYM8YcCdwDDAdSACfgsyyr681y7IQCoQjzV3zJb+evaWg7+7C+3HL6SLLTkvNxdotZlr2s8hMX7m0bdJy9P2G6klYiU37q3MoqAlz2s6XsrrYX+HjwP1t5+J5x9Oyum1F7lJX7ufLny9lVai8Z/sB/tvDw3ePI76Oh+IlMualzq6oL8IeX1/HUsiIA/rLwM2adMYLvTRhASpIOU24xvw8+/Ae8Pds+XgxMuhaO/UXziwdKXBzoT+u9wAXARiAV+AFwX6yCkvZVWRfgLws/a9T2zCfF+AKhb/iMLshXAm/Maty25S2o1152nYDyUyf2yhtfNRR6ANU1IV5euONbPqPrWbqysqHQA/D7I/znqW0Egtp6JcEpN3ViPn+4odDb468LP6OyTlsvNPDvhvfubtz24b32PoeSMA741oRlWZsAp2VZYcuy/g2cEruwpL35Q+EmbZEDmK/ZdVgQamajzbAK4s5A+anzqqtvmptqm2nryvyBpt+Per+9WJMkNuWmzqu5PlIgHGnYwlgArMZ7FUL0WN+kRHKgxV6tMSYFWGGM+ZMx5toWfK7EWabHzWVHDWzUNnFwLukpWlGqQVoeTPxp47YewzTuvHNQfurEpk3tjdu1d36e22U485Q+cYwo8Uw8PK/RnoYOB1w4vT+elKb7HEpCUW7qxNJSXEw6uHEf4JKJA8n0avpLg5R0GDOjcduoc7SPc4I50NU4BwA7scecXwtkA/+I3rGKG60odeDKfQHe31zKS6t2cMSgXM4o6EN3LdDSWG05FC+DFfOg12gYexFk9op3VF1OK1bjTLj8pNx04PyBMLtK/Dz+bBEWFhd8tx+9enhJSVGfeI9wOMKu0gBPPF+Ezxdkxln96HNQarOb2ktstXA1zoTLTaD81BKlNX5eXLmDj7aUcdro3kwakkduuvpOjfhK4bMFsPE1OPgEGPYde49o6VCt3nrBGNPfsqxtMYusjZSwWs4fDJPicmCMVrr7RkE/ON327XPpcAfamUrk/KTc1HKhkD3/LFn3Z2sP4XCESAStwhlHB5KfEjk3gfJTS1mWRSAUsfc0lm8WrAe3N95RdFnflpv29xvjuX0u8nS7RiVx4XE7Vejtj9ujQq9zUH5KIi6XQ4XefjidDhV6nYNyUxIxxqjQOxAq9BLW/n5r7FsVDI5lICIiLaT8JCKJSLlJRBLG/lbosL7htXS0kB/qKsCZAmm58Y6m/UXC9sacGHus9/6ePvrK7BWfUruBSxucdlHKTwmioipAJAI5WS6czuR78lRdEyQQiJCe7sLr+fY7/PX1YXy1IVJSnGRmaBGsLkq5KVH4ayDgA3cqeJNwe8NQINo3dO1/QTnLsreZAkjrrhFMXcj+fhMVGGN2Y9+lSo2+JnpsaWPQDuIrhffvhdX/g5z+cNpfoPsh9ryyZFBbARtehnf/ahezJ9wCA45qPjGH6uGrNbDgl1CzCw67FMZ9X6tmdk3KT3FWVx9iw6Ya7vnnZqp9Iaaf3pdTju9FdlZy5KZIxOLLr+r465xNbNnm4+gJeXz/goHk5jR/g6msIsA/523hg4/LOWRwBtdeNYTevbwaOt/1KDclguqvYOFvYcvb0PdwOOUOyOkX76jaj68UljxoLyqX1RtO/TP0HA6uZhaQqa+Cz9+CN28HKwLH/QqGnAipOR0ft3S4by32LMvSIOV4C/nhg/vgvb/Zx1VF8K+T4ZqlkHlQfGNrLztXw/NX7z1+bAZc/WHzxZ6vDP59CoSjm5ou+j14MmH8D8ChH9euRPkp/ioqg8y8cSXh6N7e9/xzM7k5bk46LjlWsa2oCvKTG1ZSVm7nm2df3kF9fYRrfzSEtNTGvz59tSH+fv9G3nyvFIDS8nK2bFvJ/bMPI6+bRh90JcpNCaC2Ap69Cj5fbB+vfxHKN8MlL0BGj7iG1i7CIVg+D966wz6u2g7/mgo/Ww5ZzWxdU7EVnrx47/HTV8AVC6HfER0SrsSXnuEmurpKWP21+d3+aqhM2IW+WiYchE8ebtq+5tnmz/9y+d5Cb49Vj9vfJxHpUJ98WtlQ6O3x0us7qfEF4xNQO/PVhhoKvT3efK+EurrmNzl/+4PSRm1f7fI3e66IxFiobm+ht8eudRCsjUs47a6uAj59onFbqN7+Gpuz6smmbcsftYd2StJTsZfoXCnQbUDT9mTZw8Thgp4jm7b3HN78+c0NwcgdolWgROIgv3dqk7aB+amkJMlm316Ps8m0lj4HpWIcTYdlGmM4qFfjPORyGe0XKBIPxgEZXxth4E6zp4okA5cXug1s2t7cUz2AniOatvUatf/1ESQp6LdQokvtBqfNBu8+46on/NhuTwbGwNjvQfdD97blj4cBRzd/flY+jDpn73FGT5hyE6SkxzZOEWliYL80Jo7bu2BUrx4evje9HylJsj1AeqqTKy8e1HDs9Tj49U8PbXbOXrdsN7+ZObShuDMGrv7+YDLSk6PwFelU0nrAmfftXdvAOOA7f0meOWreTDj5tsbrFRRe1LTA3eOQk6DP2L3HvUbCyO/GNkZJGN+6qXqi6zIbg4bDUFsCVcX2f+zU7OQp9vao2WV/OFz2U8tve3JZW24PYfDvhsw+dsGnu1NJ40A3VU9kXSY3AZVVAXbXhKivD5OX60m6+Wk1vhA1vhBlFQF69fCQnenC/Q17bvkDYaprQuws8ZOXm0Jmuov0NK3ImUyUnzqRQC3UV9p9p6ze9k1zT0a8o2o/kYi9uubuL+1+oTfn21dr95XYH5Zl95vSk2DuojT4ttyk30KdgdNpL8aSLAuyNCejp/1xINJyk3P7CZFOKCc7hZzs5Crw9pWR7iIj3cVBPfc/VNyT4sST66R7bjOr4YlIx0pJsz++aWhjZ+dwQGYv++NApPdQgddFqdhLBOGgvcdcJGzPPYvTNgK764L4/CEsIC3FSU5atAPnK7Un/jpc9t4szgT6sfHX2AvWgL0qZzLdtRNJAFW7g/gDEZwOyMpy43Z1/BDNYCjSEIc3xUFOdgpOp6EuuqedZUFaqjOhnqKFwxaVuwOEQhYpbgfdvmG7BhFppWCd/eTOsuypHN7suIRR7gtQFwjhdBgyvC4yPO69e9qFA/Y8wQO9md1R6irtxWqMAW83rXuQ5BLnN2NXFfDZe5/M/4k9PLH/kXDOvzv8TlS5z89tL63j2eXFWBacOuog/vDdUXQL7rKX6/1yuZ2szv4n9J9gTw6ON18ZvDMbPn7QPh53BRz7S0jXnnsi7aGkzM9v71zLp+t2k5Pl5oaZh3LYmG6kejtuHlowGGHVuipu+uNaqmtCdM9NYfas0fTIS+HJ+cU89sx2wmGLU044iB9fOighnjKGQhE2bK7h5jvWsqvUz6D+afzxplHNLmgjIq1QW2Gv5P3WnfbN6BHfhdP+1OGL15VU+/nxf5ax9IsKXA7DVccN5qpjBpG1+zN44iJ7y4O8IXD+f6HH0A6N7RvVlMALP4PPXgF3Opz0O3sthGSZzyhNJMcs+s6svsoupmrL7eNtH8KrN+19WtVBPtlWyTOfFDeswvvK6q+oLI8mhC+X2401u+w98BJlm4PiZfDhP+wno+EgfDQHipbEOyqRpOCrDXH3Pzfz6Tp7P+jK3UFu/ONaanyhDo2jqjrITX+wCz2A0vIA9/5rM1u21fLwE9sIBC3CEXhp4Vd8sKy8Q2P7JpW7g1z/u0/ZVeoHYMu2Wmb9eR2VVYH9fKaIHJCq7fD6LfbTKSsCa56GT5+yR0h1kEAowtz3t7D0iwoAQhGL+97cjLu+DP57nl3oAZRtgicutPtQ8RYO2jfIN7xsP30M1MBLP7efQkrSUrEXb1XFEPla52nb+/YTvw704eayJm1ugnbxua9gnV2gJoLPXm3atuHljo9DJAnV14dZtabx//VQyKKkzN+hcfj9Eaq/VmB63E6Wrqhocu4HH5cTCEaatHe0+voIu6sbx7x+YzWhcOddEE0koXzxftO2Ta916D56dcEwH29tmociwXp70ZR9lW60C61481fD5kVN279c0fGxSIdRsRdvWX3A8bUhUflH2I/WO9CJI5pO8HU4PZD/tYV9XF7wZnVQVPtxyInNtJ3U8XGIJCGv18moYZmN2pwOOnzxEa/XSV5u46GZTpfhsDFNhxwdMbZbQmz74PU6yExvPEvikMEZOJ1aNVikXfSf0LRt8PH2XnodJCPFyYnDm87Fc6V4my6olzt47zYQ8ZSSAQOPadree0zHxyIdJma/FY0x/Ywxbxpj1hpj1hhjZkbbc40xC40xG6N/dou2G2PM3caYTcaYVcaYw2IVW0LxZsPZD4InWkD1LoRT/mjvodKBhvbK5NqTDiHV7cTjcvCj4waTlpMH0+7du8F5ajc475HGe/7FU/4RcNhl9v45xgFjL4H+R8U7Kklwyk0HJj3Nxc9+OIRDD7YXPcpId3LLL4Y3KWJiLSfLzV9mjaZ/vj3fbeiQDK65fDCDB6Yz48y+OJ0GY+CEY3swaUJizNfNznLzx5tG0i3H7tz17e3ld9cPp1sCzCeUxKb8dIByBsBxv9q7Sfqhp0LB+U1vnseQ0+lg+mH5TD8sH6fDkJ3q5k/TxxDy5tlz9DJ72ydm94MZ/0mMlTBdKXDkj2Hw5OixF076feItICPtKmb77BljegO9Lcv6xBiTCSwDzgIuA8oty7rDGPNroJtlWb8yxpwG/BQ4DZgA3GVZVjO3bvZKmr1iQn6oK4dwCNypHT7BeI+6YJjquiAWkOV1kZoS7dTVlECozk6qqbl2skgU9bvtMecQ19W4pP3Eeh8r5aaWqagM4A9EcDkNWZnuhk3DO1p5RYBwxMLtMg2LsNTWhfD5wlhYpHqdZGYkwJ3zqHA4QkVVkGDQwpPioFuOG6P9QDs95acE4veBv8qes5eSHrf9h2vqg/gCYQyQk5ZCisthzx30lULYD06PXeg54j/qoEFteXQ1Tqfdb0rpuCeiEhtx2WfPsqwdwI7o62pjzDqgL3AmMDl62sPAYuBX0fZHLLv6/NAYk2OM6R29TnJzefbeAYqjVLeT1OY2C85IgLtR38SblTjDSqVTUG5qmUTZMiC3mc3a01JdpKUm5qLSTqdD++1Jiyk/tYAn3f6Iswyvmwzv1240OZwHvv9dPKTlAtqvuKvokNsMxpiBwFjgI6DXPknoK2DP/4a+wPZ9Pq0o2iYiEhPKTSKSqJSfRKQ9xLzYM8ZkAE8D/8+yrN37vhe9E9WicaTGmCuNMUuNMUtLSrRUrIi0jnKTiCQq5ScRaS8xLfaMMW7sZDXPsqxnos07o2PS94xN37PxSDHQb59Pz4+2NWJZ1gOWZY2zLGtcjx4JPLxQRBKWcpOIJCrlJxFpT7FcjdMADwHrLMv66z5vzQcujb6+FHh+n/ZLoitLHQlUdYkx5yLSoZSbRCRRKT+JSHuL5cz2ScDFwKfGmD27Nf4GuAN40hhzBfAFcF70vZexV5PaBNQC349hbCLSdSk3iUiiUn4SkXYVy9U43wW+aZ3pE5o53wJ+Eqt4RERAuUlEEpfyk4i0twTa9ENERERERETai4o9ERERERGRJKRiT0REREREJAmp2BMREREREUlCKvZERERERESSkIo9ERERERGRJKRiT0REREREJAmp2BMREREREUlCKvak9SIRCPnjHcU3C9XbMYpIlxMIRAiHrXiH0axQKEIwpNwk0iWFQxAOxDuK5lmW3XeSpOKKdwDSSVV/BUvnQul6OPwy6F0Aqd3iHZWttgy+eA8+fQryx8OYGZDRM95RiUgHqKoOsnbDbl5+/SsOGZzBd07qTV63lHiHBUAwGGFXqZ/Hnt1OMGRxwXfzOainF6/HGe/QRCTWwiHYXQwf3Af+3TDxGsgdBCnp8Y7M5iuBtc/D52/BsO/AkBMhvXu8o5J2oGJPWq5mJ/z7VCj/3D5e8yycNccuqhxxflgc8sPHD8Gbt9vHa5+HNc/B955Q0hJJcqFQhIWLd/L3BzYD8OZ7pSx8axd33V5Abk78C76y8gCX/HQpfr/9VG/Bop08cu84BuSnxTkyEYk53y6YMwn81fbxqifgyreg95j4xgVQWwHPXwOfLbCP182H8T+AE38Hnoz4xiZtpmGc0nK7v9xb6O3x3t/tJ2rxVldp3zXbV/FSCNTEJx4R6TBV1SEee7aoUduWbbXsrg7GKaLGFr61s6HQAwiHLZ6aX0QkkpjDTUWkHX326t5CD8CKwHt3JcawyaBvb6G3xycPQ6C6+fOlU1GxJy3nbOYOucsLxnR8LF9nALe3mXYNkxJJdsZASkrTX2tOZwLkJsCb2jQPNdcmIknI3cwT/JR0EqIrbhz2x76cKdidKunsEuAnTDqdjJ72XLg9jLEf9SfCMMnUPJjy28ZtI85MnDHxIhIzOVlufnzpoEZt4wtzyExPjBkLk4/qQU62u+E4LdXJ9O/0xeFQh0ok6Q2eDFl99x67U2HSTHDFf4g5KRkw7orGbcdcD97s+MQj7SoxfgNK55LeA85/DLZ/CKUbYfgZkNm7TZes8AWoDYRxGEjzOMlOTYFIGHylEKy1k2JqN3B5vv1CTpc9sbj3u7BhAfQdC70LIS23TfG1mb/a/ggH7cIzEQpjkSTjcBgOL+jGo/eN450PSzl4YDojDs0iJ7v1nSl/IEJ1TRB/IEKqx0m3HDfGGHZXB6mrD2MAr9dJVqZ7v9fK65bC3LsP5/0lZQRCEY49snvcF48Jhy0qdweprw/j8TjIynCRkqKnjSLtLrMX/HARbHod6nfDiDMgvVebLlla46cuEMbtNGR63aR7XPaw0LoKCNbbTxPTe+x/PQVvFky+AUaeBV+8DwdPgdyD7b5XPNVVQMBnv05JT5yFADuZLlHsRSIWpT4/u+tCpKc4yTB+MoMl9n8CT0by3bnwldqFhTGQkgnpeY3fD/igvso+x5sNaXng3H9HpZGMHnaR1w7Kavxc/9QqFq3fhTFw9ti+3HzGCHKqPoP/nG0vCOPJgnPnwsCj91/wpebYHweNbpf42qy2Aj76B7zzV4iEoM9hcMFjkHlQvCOTBLC7OkhtbZhQOILH4wQL6v1h0tNc5CbIKpLtpbYujK82hK82RGa6i+wsNy5X405IeUWAmtoQnhQHaalOMjNalpvS01wM6u9iUP+2P82v94f5cGk5t/99PXX1EXr18PC3348hM8PF7H9s5K33SwE44Zge/L+rhtBtP0Wlw2Honuth2il92hxbe/miqJZrf7uKsvIA6WlOfvfLERw2OlsFn0DQD/UVUF+F5cmkmgx21RsyvG6yvC7SUpKsC1mzyy7C3F77SVdqTqO3d9cFqfGHqAuGyfK66JHZzJSR/ck8CMZe1C7hflVVx/fnfsy6HdW4nYZfnDyUi8f3Im37O/D0D+y1CrL6wEXPQs9h+79geh6kH233sxKBrxRevA7WPW8fj/wunDZbN8tbIcn+pzZva5mPGQ98SEm1H4eBX0zux0Upb5L19i1wzM/t5W+T5W5BzS54/EIoWmIfD54C0x+w7+wABGph3Qsw/xr7KZM3Gy5+DvoeFreQX12zk0XrdwH2Fi9Pf1LMTZN7wNOX24Ue2MsUP/V9+MlHbX6K2OFqdsBbf9p7/OUn8N7dcOIt+y9cJalVVgW464FNLHy7BIBB/dP49U+H8tMbV3JQTw933VZAj7zk+Bmpqw+z6N1d/Pm+jYTDFpnpLu66fQyHHpzZcM6u0np++puVFO+wFyw467Q+/PDCgWRntfBmVDupqQlx61/WEQjaC6jsLPHzxHNFjBmR3VDoAbzxTgknHNODYyf2iEucrVVRGWDWn9dRVm7v+eWrDfPbO9fy3znj6Z6rYq9LC4eheAn8dwYEfBiXF+v0f3L36p4sWFfO32YUcMLwXnjdSfJzUrkdHj4dKrbaxxN+BMf9qmFUUGVtgH8s3syD73yOZUHfnFSeuOpI8rvFZyXdWn+Ivyz8jHU77AVUgmGLP76ynssLvPDU5faIKLAX1Hvmh3Dxs52vSNry9t5CD+yV30ecaRd90iJJP2evqjbAb59fTUm1vfl3xII/vbmd6oOn2Yt2vD3bXsExWaydv7fQA/h8EWx9d+9xfSW8MNMu9MB+wvfslVBT0rFxRgXDET7YXNr0jUgYSjY0bquvsocldDY71zZtK/po79AE6bK2FdU1FHpgrxz5xru7mHxUd7YV1THv6e0Egsmx+XaNL8Rf/rGxYaPzal+I2/++gYpKu9Co94f59+NfNBR6AM+9/CUlZf64xAv2k8g9hd4elgWfrKpocu4nn1Z1VFjtJhyx+PyLxnmoti5MfX1y/MxJG9SWwNM/3Pt7KlRP9oJr+OnEPALhCNc/tYqqusRY5bbNArXw5m17Cz2Aj+bYN8+jymoCPPC2XegBFFfWceeC9fj8oY6NNao2GGbFtqZ914jft7fQ2+OrVXafqrPZ8nbTts/f6vg4kkDSF3v+UIRNu5p2qktq/PZjeoDdRU3e75QiEXubga8r/mTv62Bd02V+yzbZSwDHgdvp4NTRzTypc7ohf1zjtoxe8R8/3hrNPTU95BR7aKp0aZu+aLolyBfba+nVwx4etPHzGurrO+Ev6WbU14cJhhoXTlu31zZsO1DvD7N5S9Ncva24tklbR0lLc5Ke1vjJhctlOO6opk/wjj0yr0lbonO7DGNGNM5D3XLcpHqT5GmNtF4kDNU7GrfVV5LmtPNRbSCMP5gcuYlgbfM3ZffZYmp7RdM8tOGrauri9D3I9Lg4fmjPRm0OAw5PZtM1CgYe3fKpOomgualCw6d1fBxJIOmLvUyvm5NHNJ4Am5bipHeGsZ9yuTz2JNRk4HBAwflN2/d95J2SYY/h3tfBJ8R1OOGRg/O48tjBeFwOMjwubjh1GM6MPDjn33sLvu6HwkVP7x2O2pm4vPCdv9pzIx1OGDUdRp1tv5YubXxBtyY7lhx5eC5rNuwG4MRjepKRICtJtlVamovcnMYdjqPG59rzFIHMdDdTjm78/9vpgBGHxu+mSHaWm7/eOoY+B9nF99hR2Vx0Tn9GDs3ikvP64/E4SPU6+MGFAzh4YOfbeNjtdnDtVYcwapj9Pe6fn8qs64fjVGoSl6fpDdfuh7C92r45k98tldRkZmneYwAAIABJREFUmbPnzbEXJtmXw9Vos/OhB2Xi/toWLqeO6k2WNz5FlMft5IfHDubU0QfhMNAjw8Ociw4n5M215+jlRfu1/Y+Es+bEf5G61sg72F6t1J1mf0yaCXmD4x1Vp2Qsq/Nu5jpu3Dhr6dJmnmR9TWm1nztfXc8rn35F/9w0/nj6IIZ/8jtSSlbDGXfBQWOa35utM6qtgFWPw7t/tZPV5N/Yd0f2TDSORKB8Mzx/NexcA4OPtye8ZsV3HlxdIEx1vT0kJDvVjWfPPABfGYQD9teS0QkLPYA1z8GaZ+xJ2e40e2hC0dL/z955hzdZrn/8k72bdE9K2XtPQcCFR9woiiguXLjQ4x4/j0ePetxbQY9bFFyIG0GmypAle5UCbaG7Sdrs9f7+eNqmIYUWKBRKPtfFBX3yvsmbt+TOc6/vDePebz29os2ITCZbLUnSwMaPPH5pqm1yugKsXmflzffzcLoDXHxOBr26xfHES1u56Jx0rhibhSWudYi0BIMS+XtdPPv6NvL2OBnSP4G7b+lIUkI40GSz+5j+dQE/zSvGYlFx7+RO9OhqQqdtuU2lJElYbX5CkoRKJcdco7rp9QapdooSLpNRieYEFDSpqPRy+0N/M/7iNuRk66mo8DHzu0KefKAbGWknYBXFMeBksk/YC+H7KZC/DDIHYDv7Fa75pgSNSs7z4/qQk6hHdjzM120OnOWirWfd56KK6LyXIWtA3Ww8jz/I+kIbj367kZIqDxf3y+SuMzuRaGzZnuoqjx93jZJ5gl6NQlGTw3GUiuysUnNiOnoAvzwoRO1qs3lbvge5Gsb8t2Wv6zjlYLbppHD2AJzeAE5fAIVMRqJGElk9ueLEzBQ1RtAP7kqQqFHabGCj5KoQx6n0QnI3xtGj4C94f3TkWs9xcOEboG6Z5u7jmZNqM4VQC7bZ/UiShNGoxOkKIoXAZFS0SkVEW5WfQCCETqvAoI+2TV5fEIcziEwG8WZV69lMHodUWH3ccPdqymsEWkAMoP/qvSGkJLUOYaDm5mSzT7htovVDoaFabsTtC6JWyrHoW0cQKgKfS4jByRQHDC6XO7yEJAmTRoWuFdrn44rl02DOg5Fr5zwPQ29pmes5zjmYbWolOfjGMWiUYv5ILapWLHuvUInI1MHQn3j9JScsCe2g3SjYVdNYrIuHMx6NOXoxACHHX3/EwomYIToULI0oa2rUilZ/D44XLHEq7r+9Mw8/vZFQTdv2pCvbYtTH7n+MGuqNHzAhWmNaLWp9o9/LSS2cyTup6DEW/non3DuZ0B56Xnzwc2I0yEnj7J0s+INBSqt8fLu2EKVCzkV9M0g2alAqWrA901UBRRtgz5/Q90ooXCl+7nUJxLeLmmUTQW0Zp0IDUuDELEswJMO4D8C+V2RcU7q1zoxyjBiNYLX7WLfRzsatVZw2PInsTH2ThpEfLfz+IOWVfuYsKKZH1zjizWrmLS4lp42eoQMTSLAcOHtRW8Ypl4FSKcfnDyFDhsWsDJdSHecoFDL697Lw1XtDyNvjJCtdh8WsQt9AxjVGjNaM0+unyO5l1ppCsuJ1jO6eenhz9Jr1osogb4nYO/S8GLb9As5S6HOlaL1RHcQxdZQK4T2lFgJeQDrxKrlMqTDp10hnz5hy8HNiNEjMorcyiu1e/vHqElw+oRD19qJc5t49kjRzC/Vf+Jzwx6uw9HW45H8w+1ZR/w+w7HW45F1R0tiQWIktX8yL0Zhg2BT4+V6o2Alth4nnMmc166XaXT52lDr4enUhPTLiGNMznSRTM0XxDEkn3oybGDGaEXuVn2df386ff1UAMHN2If+8pSMXnpOOStkyzlFJmY9r7lxF144mMtN13POvDXWPdWxn4JUnexPfgMNnr/Lz5feFzPppL8/+Xy+++XEvi5eWYY5Tce+tnRjUN75ZHaZgUKLC6uOHuUU4HH7GnpdJSpIGrebIM3A6nQKdTlGnABsjxsnI5qJqLn9nWd1ohf/9vouvbjml+fYAh4qzAr66Hnb/Dtf/Ah+eC/YC8dgfr8LNiyCtV/R5wYDQY/hmEnQ8E9L7wW//EkH37hfDOc81v/6BswLyl8K2OdD5bGg7vPn2O8aUmIPXDJwY4ccYTUKSJD5dtqfO0QOocgf47u99LXdRnioxr0auBEubsKNXy8JnwNXAnD1nhXD0ClfCqf8UA9UrdorH9iyF724XYjTNRDAY4tfNJYybtoyZKwt47LtNXPfRX1Q4Wm7GV4wYrQm3J1jn6NXywYzdVFW1zJyqQCDEjFkF+HwhzhqZzBezI0fw5O5yHnDG3+btVXz8RT7DByexZFk5C/4oIxiCSpuf/3t2M/bq5n1PVpuP66as4sMZe/jqh31cffsq9hWfgDNHY8Q4DrG7fbw8dzv1JSx2lTvJK48ejXPM8FYJRy+5q9j71Dp6IERLFv4XvA1cn6scpl8sju85Dr67NSzWsvEbWDEVAr7o8w4XTzUsfBq+mAh/T4cvr4H5T4i9X4zjhpiz14qQJPCHouflBRpYO6bUzvBraJbfgQZ9Bn3C0QOQycG9n2O3+3dxTDNR6fLx5oLciLWNe6uwulrJ0NgYMVqYhrTAxMe/ZUTCJCBQM+NPJpMRDEVfRwNLSJLEoj/LAOjSwciaDbb9HocdedXNeq3L11RSVc+BDAYlPvsmH5+vlcw5ixGjBZGkhvdJgYYMwLGidr8kVwjnLurxAA3aTp8TXJVgyYbSzdGGd8dc4Ug2F75qWPNx5Nrfn4GvBR3lGFHEnL1WhFwu47phOWjqlUTp1Qou7te85Y6HhMYI/a8VxspRBhn9Ih8fcS/oGhCLkSsguUv43/sPU0/r3cxz6mRR886ABtdixIhx6Oh0Cvr3NkesXTWuTYv17KmUciaMzUKhkLF4aRmXnp8Z8XibTF2DipQymYz+vcXIlMIiN53bR8/Xa9vG0KzXqpBHGyKhUhozUDFiHCkWvZq7zuwcsZZp0dEpxdRCVwRozZA5UDhsqd0jSxllMhj5gGhx2Z/amXTVxeFZe/XJHAjq5rRPsthG6QQg1rPXykiL0zL3nyP5eOlulAo51wxtS0pL1ZyDMEanPwrtRwmBlnEfwI7foGgt9L0KUno0PBrCmAKXfgDTx8KqD+Hcl+CXB0S0KC4Dxr7TrD1wCQY194zuzF0z/65b65dtwaJrxcpjMWIcQyxxKp64vzu/ryhn/eYqRo9KoWtHEypVy8Uc01O0fPrWQGb9uJeUJA1Tn+vLj/OKyMk2cPZpqQcUaBncP54RQxP5dWEJL/27N9t2VpO7y4lCIWPShLZRw+OPlEH94om3qLDaRKWBSinj6nHZqNWxeG2MGM1BnzZmfrzzVKYv30PbRD2X9M8iuSX3ToYkmDATtnwHufPhhnnw9wxwlMDgm8DStuHzdPFin/XNjbB3DYy4D/58VQTc03rBqAejg+dHgsYIg26C5W+H1wZMAnULOsoxojhp5uydbNT+Xo+rGVWhEMjl0f8+4PFBMejU7xJyyKGgUJVS60Gf3Pj5h4jd7WdPhZPZa/fSI9PMqM7JMZnlFuCkm2N1EhIKScgbyFa1FJIk1dnKpl5bVbUftyeIQi5DAvyBECqlHINegV7XvHFUSZIor/Qxb0kpDkeA885KIylRgybm7B1zYvapdXO82Sbg0PdOAY9offF7RJZPCoq5ymr90VECd1aIAP72udDxLMgcAIbYeK9jTWzOXgvg8QepcvuRgDitEp26gVvtLBPKSQpVsys1HldOXi1yOaFgkICjFLkkEVRo0JgOYhDkCiG9e4ww61T0zrLQO+sgoyBixGgFVNp8BIMSKqUMizk6e+VyB3C5RT9YnFHV7Bmk420zVWsvK61e/AERKEuwqA+adYwzqY5ZCapMJiM5UcOVY9sck9eLEaPF8DrC/V66BFDuZ59CQSFCEgqJDNXBRjcdBsebbQKEc+dzidFNIN73wWYlK7VgSj821wbCset4lvgT47gk5uwdBWwuHzP+yufNBbkEQhLXDsth8qgOJBhqjJYkQfl2+Oo6UY+d3gfGfdhwfXUrwu91w97VqL+bDPYClO1PI3jRVBTmjJa+tBgxTgpCIYndBS4ef34zu/JddOlo5MkHupOZHi7rsdl9vPfZbn6cV4xWI+eWa9pz1shkTMbWXdJcVuHlhbe2s2xVJQnxau6/rRN9ephb/fuOEeO4wVkOvz0B6z4XLSBnPQHdLwo7dH4PFPwFsydD1V7ocCZc/DaY0lr2uo82jjLY9hP89m/wVguVzdFPtP73HaPZiNWAHAV2ljl4bs42nL4g3kCId5fksSKvnuS4sww+v1w4egBF62DmleID3YqReWyoZlwWlhDOWwRzHsLrtB30vBgxYjQPNruf+5/YwK58FwDbch08+t9NWO1C2VaSJBYvK2f2L0UEAhIOZ5CXpu6gtLx1jyBxOAN88Nlulq6sRJKgotLHo//djNMVU7uMEeOYEArChm9g7Seiv8xthR+mgKM4fIzbCp+PE44ewM75MO+xhkcQtCZcFfDDXeL9hwKwfqZQvAzE1MJjNI2Ys3cUmL+lNGrtl43F+IM1UroBD1h3Rx5QthWCR2FDJUlChvdoGEOvUxihJo52kJxlov+uHopdi5Hvt9ZacXj9WF3NON8mRoxDxOMNUlIWaWdydznx+0Xpotsd5PflFVHnrVl/dAIyLncAe5Wf5u4dDwYl7FV+PJ6mOWsOZ4DV+41QCAYl8veeHLYpEAhhq/LjjY1yiNFS+Jyw/efo9T31ZvNWF4m+/frkLTo6Mv/BgNjf+N3N/9yequhxUgcjf2n0Wu5v4bLOVo7d7cfujjm2R0KsjPMoMKRdAm8v2hmxNqxDIipFjW+tUIsmWWe9TJ65jejd249QSEImO8wePFclbJ8Dqz4AUwac9ThYckBxhCMLQiGRnZv/H7DmQd+J0OOig9eQA3JDohiuXm9mTCi9DyFFAyIooWAzj1Y4OEd0nxvBHwySX+HmuTlbKXf4uH54DiM6JWHRN6z0FyPG0UKtlmOOU2KvN8g8I02LUiH+32s0Cvr0iGP56shNRLfODSurBUNSg2MBGiMYDLG32MM7n+RRUennkvMyGDogoVl64GxVPuYuKmXeolJy2ui54aoc0lK0Bz1Hp5XTpYMxalB5Zlq0ap0kSUjSse3tOdz73BSsdh+zfy7iz5UVdO9k5JrxbUlKiAlTxTjGqPSQPVQ4b/VJ7xv+tzFFzN2tP7M3vS8oG1CXPJI9hLMcVn8EW3+CjL5izEFcM/TA+d1QvkMMHfe7YPjd0GYo6MwHP6/+PaglcwBo4qLXj/HeKRgKoWhmsbxaHN4AW4qqeGXedgD+Oboz3dPjMGhirsuhErtjR4FeWWbGDcjimzWFSBKc1S2F0d3rCY3ok+DyT2HmBBHdMSTB5R8Lhcka3P4Ae61uPlq6G5NWycShOcTrVGhU8qZ9sEIh2PKDKIOoZdciuP2vI6/zdpbCe2cIgwiwdzX4nTD0VuHMHYCgKo7gBW+h/vmfwtAltEc679VIkRaPXRjDVR9AYkfoe+VRrUt3egMUWt18vHQX8QY1E4e2JdWkbdaNXIXDzwVv/oGrJmq+Jt/KW1f247zesV7FGMcWS5yKpx7qwSPPbKLaESDBouKph7oTXzMqQKGQcd7odP5aa2XtBjtyOVx6XiZtMvQRz1Np9TH/91K25ToYc2YqHdsZ0OmUqJs4RqHS5ueGf67BXSMCs3FrFf+6tyujR6UcUcDF7w/x9fd7+eiLfAC27KhmzQYb777Un8T4AwdXzHFqbru+PbsLXOzKd6FWybjlmvbodOFNU60i5g9ziygr8zL2vAwy03UY9Efva7TS6mPuohJydzu5YHQa7XMMzdpD6HIHePvDPH6ZXwLA1h3VrN9SxStP9ib+AGMnYsQ4KiiUMPAGyFsiMllyBQy5DeKzw8doLXDhG/DzfcJxSuwA574Y6Sy5bVC2TThrKV2h9xV4tUmoFPKmfa/7nDD/yfCg8H1rIH8ZXPN95Ky7w8FRs3cK1mSp9iyF636GnOEHPy8uA065E1a8LZy5NoNh6G2grufkuipEP+OmWZAzArqMOTrKmzXYXD62Flfz5aoCuqfHcVHfzGYfVbHX6ubyd5bVzYVflreMOXeNpEtabKzDoRJz9o4CCQYN/zq/O/eMFkM69WpFZBZHoYSsgXDbcmGwVHqRFavnxBVUuBjz+h8EQ+J/+Wcr8vnyllOYs7GICYPbkhp38Eg17krhMNXHYxd9gkfqPLkbKOla9QH0Hn9QY6jWm/B1O59A+5EQ8CIpdajM+13L7j+FE1zLmk/ghrlHbmQPwK5yJxe++Qc1t5nPV+Tz690jSWns/h4CawusdY5eLR8v28PwjrHsXoxji1Ipp2e3OD59ayBebwitVo4lTh3hYCVY1Dz1UA/cniByOeh1SoyG8FeF1ebj/ic2sG2nKJ2as7CEKTd1IBSS6NPDQnZm4w7QttzqOkevlm9+3MeQ/gmY4w7fmXG5A2zcVhWxVlLmxWb3HdTZA0hP1fHSE73w+kKolXJ0OkVEprHS6uPGe9ZQUSlKsX/8rZg3/9uXPj0aicofJpU2H3f937q6/so5C0p47N6ujB6Z0mzBKLc7yNxFkW0HubucuD1B4pvlFWLEOASMKTB+uggey5WgNoK2XvZKY4SelwhhlqBX7J3q7w0kCXYugK+vD6+t+YSSi75hQQFc0CedxMbGKXkdsG5G5FrpFuEEHin71oFCE3b2AFZMg8z+B599Z0qDEf+EIbeIyiilNjLT6HeLOXdLXhQ/r/8SOp4Nl7wD+oQjv+79CIYk5m4u4YGv1wMwi718vbqQ6TcOadZxVTNX5lO/wl+SxNrjF/Rottc4WYj17B0l4nQqMiw6Miy6hjf0CpX4ACe0E+MF6g0W9wWCTFucV+foAVS5AyzcWsqynZVcNm0ZZdWN9PfVloruj+4IZp+4KkUWL28BjH0Xzn4KajeJxpSDZvVqUWuNKM0ZKBPbRTt6znJY8kLkmnVXdH9jM+HyBXhzYS71bjNWl5+F20pZX2ijwtE8PZQNGb9kkwa1Mvbxi3HsUSnlJCVoyEzXkRivQaGIdhzMcSrSUrSkJGkjHD0Ae7W/ztGr5YvZhSQlaLjpnjXk7Wl8U2QxRzt0iQkqVKrDc2L8gRCl5R4WLy3nrJEpvPnfPmSkhQM2Om3TyppSkrS0ydCTmqKNKindmuuoc/RAbDw+nLkHhzOw/9M0C5VWX52jV8snX+SzPc9BabmXYLBpvdIHRQZmU+TvVyEHpfI4lJ+PcXJgSARLtshmaRsoU1TphaMTnxMdBHaWwe8vRa5V5KJ1l/DKb9t54Ov12Brrm5fJokdhyeRiT3W4OMtg5yKoKoSJ38DASeHH4jKbtHdCnwiWNmLPuH9JqccOy96OXMud2zwOagNUOn28vTA3Ym1rcTV7rW427rM3fo+bSKYl2gHOitc3cGSMxojtNo9HgkFU8mjBAqVCTiAkkV/poqTK08CJ9dDGwdlPCsNYS/vTwZx5eNfkrYalr8P/zoA5D8P0S4TQTL+rQamBc5498giSTNZwrXlTDOHhvBwylA1EyP1BiYdnbeDBb9ZjdR650WqXZGBQTjhObtQouXd0Z/QNzV6MEeMERKGQEaqJmkz/qgCX++AOUGaajn49wxkxnU7BLde0P+xh5MUlHq6cvJLn39rBs69v57k3t/PwlC4AjDkjFYPhyD9rDTlASoWMozXStKHsnUIhY/tOBxNvWxkltHM4WOJU3HNrp4j3MPGy7KNamhojxlEj6G94vyCXI0kS87eWRlXZRKFPhHNfIuJDMWyKGAVxODjL4Zub4NOL4NeH4cMxYi+WNVC81rA7GtRrODRkDb/vo2ScZNBgO5HLF+TSt5fy8dLduLxHHgS7sE8GWfFhhy8rXscFvY/h/MBWxFGz6DKZ7APgfKBUkqSeNWsJwBdADrAbuFySJKtM1BC9BpwLuIDrJElac7Su7XhHrYDJw9KZva4Yb0BEb5ONGga1jee/P28BCIu9HIzETnDnati7RgzYjM8+/OHt3mpY+kbk2h+vws2LYNRDjYqzNAl9IpzxL/j0Qupy9yndhXjNUUCnVjDljE78uqkYf1C8XrpZS7f0ODbtq2LTvirsHj/xhiMrtUwyapg6cQD5FS4qnT56ZplJOsLnjHFkxOzT4aPVKOjTw8y6Tfa6tQlj2/DbElEOqNM13hsTb1Hz5EPd2VfsodLqo2snE/ENZPuagtcb5KMv8vF4w5mugr1ubHY/n709CLNZhbkZhF86tjOSkaatE3FRyOHGiTlHzTGKN6vo3tnE5u3VdWsTxmbxy4ISXO4gn31TwN03dzzo4PfGUCjkDOobzxf/G8y2HQ5ysvUkxqtjzl4LErNNR4DaCMPviizjTOtNYcBMlacUhbwJwRm5AtqNhCnrYN9aSO4CxrSGs4xNwVUBeQvDP0shkX286G2RxTQ0Q4uKzgIj7xdjKGrpOU7cj6NAgkHNff/ozK3Tw//V+mdbqHB68QZCvL1oJ1cMzkZ/hEIqKXFavr1tONuKRWl+l7S4Zu8LPFk4mhb9I+BN4JN6aw8B8yVJelYmkz1U8/ODwBigU82fIcDUmr9PTpRqMgww/5buzNpsR68zMLBdIv83ewMhCQblxJNkbIKzoFCJUoi4ZhACkUIRKpoABNzCmDSHSlUtmf3g1uWi5jypA3QcDcaj12Scnahn/r2nMWtNIWqFnGEdEnnwmw11j/sCzVAqhXD4mrOWPcYR8xEx+3RY6HUKbru+Pdt3VlNU4mFQ33i27Khm6cpK1CoZ11+Rg1bTeNlkvFlNvPnIgx6hkITDER1F9vqCtG3TfCU/ifFqpj7fjz//Kqe03Mc/Tk8h+SiqVsZb1Dz7WE9W/W0ld5eDQX0T+HujrW4MRpXDX5dNPRIMeiUGvZKM1IP0DMU4lnxEzDYdHjqzcM6u+R4pdx7ehG4UJp7CrTPyALh6SDbGpjggGqP4E9/2yK/J30AVlrdK7GuaS4tAqYF+E6HNEKEg2naYyBzWDqNvZuRyGad2TOLnKSP4ft1e0s06OqUamTJjLQC+YIhQM43TSTZpSDYdvT3gycJRc/YkSVoik8ly9lu+CDit5t8fA4sQBusi4BNJDFtaLpPJLDKZLF2SpKKjdX3HOxpTIlmyMqbk7MNtbk+RXM75vTK468zO9Mu2NN5k3Nyo9KIpeuf88Fqvy4VBbE40JqGgdda/mvd5D4BWpSA7Qc8dp3fk100lXDptWV2vZE6inviYgEqrJGafDp84k4qMVIlQSCIzXUdOtp5Km587b+zAqFOSSLA0n1pkU9DplFx5aRZ/rgzPB9TrFAzo0/wSI4nxai78x7FT0U2wqDn7tFQG94vn5nvXsK8kXLp55dg2aJrgVMc4sYjZpiPEkgMqPbI2Q/CnDMTp1HDNKTkMykmgY4oRk/bY2ifi0kQPoi0/vDb0tiPTT2gIfQJkDxF/jgEmrYruGSpyEvW8tTCXx7/fVPfY6G6p6FWx6oDjiWP920itZ4SKgdp5BJlAQb3jCmvWTl6DpVCBOQPMGeiA9sDklMMsI2gO9AlC2Wnt57B7MXQ6R6hiHW4d+3GGsiar99r4vny9ppCuaSauH94uVjJwchGzT00k3qKOkOb/x+nNp157OHTIMfL2c32Z8W0BljgVV1+WfcydzqOJwaDk5Sf78MlXe3A4g1x1aRuys2JCBScRMdvUVDQG0LSDhHaYgD6J0Ce7+RUpm4wxFSb9KtQyy7YJnYOcU4983vFxgl6jZNKp7Ug0ali8vYwRnZIY2y8Ts7712N/WQIu53pIkSTKZ7JDzvDKZ7GbgZoDs7OxGjo7RrKgN0O8qMUBdYwLV0akHbyniDWrO75PBaV1T0Cjl4b5ITxX4HKJvUWsRfY/HcGhpjGPP4dinmG1qOYwGJdlZOu6+qSMKpQyNWo6iKX3NJwgqpZysDB333dqJUAi0NeqioZCE1e7D4Qii0ynQ6xRR6qkxWhexvdMJiNooRF78blCbxD6iFZFo1HDtsBwuH5SFTqVEUduz7bKKvVPQCxrzUW3JiXFwjvW3QkltiYFMJksHagf87AXqq3Bk1axFIUnSu8C7AAMHDmyeouATDUcpBH0i+6dPjpjP1xSCIYlKpxd/UEKtlDetlyzghdya+TVBnyjrvOoryD6l1Tk+ETX9nioxQ3D+E6Jv0ZAE1/8CSZ1b7gJjHC2OyD7FbBM4XQFc7iAyRDaqqSMP6lPl8OP1hpDJwGRUoVE3bt/KK73c/X/r2V0gRhWMHpXCXTd1wNIMPYHHE2p15P3cW+zmjofWUWH1IZPBpAk5jLsgE5Mx5vC1MmJ7pyMlGABXeXhO3eGI1QW84LaKweYqPeibUCrutsFf78KiZ4TwnDFF7CESOx766x/HKOQyjJp62TxnOcx5CDZ8JX5O6gzX/nDkc55jHBbHOvT5PXBtzb+vBb6rt36NTDAUsJ/UNecHo2y7kO59pQe8dxaUbBCGp4n4g0HW5ls5/40/GPbsAq763wr2VDRhFovbCrNvFY4egN8Fs24SH+haAh4xE2/Rs7DiHaguFsbNVQG7lsDcx8TAU2dFxFP7g0H2Wt28tXAH7/2eR7Hdc8jCAy5vgLwyBy/N3caMv/IprW5kNEU9bC4f+2xuiu0enPvLBXvsMP/fwtED8X5//Ke4HzFaGzH7dATY7D5ef28n4yYt57IbV/DJl/nYq/yNn1iPSpuP/7y0lbHXLWfC5JXMWVBMtePgz+EPhPjq+8I6Rw9g3uJSCva5I46z2nz8tqSUaR/nsSPPgcMZwO8PUlTi4eMv9vDld4WUV3ijbI/V5mPRn2W8/WEeW7ZXNXo9B3pfP/9WzLuf5LG7wInL1TRZcq8vRHmll+JSD1Zb5BiYaoefV9/JpcIq1iUJ3v98Nw7noV9fjOOemG06Evwe2LMU3hkh9k7TL4nsoWv389iBAAAgAElEQVQKnirY9C28NRhe6Q5fXweOkiacZ4eFT4cVxh2l8PP9wgmsf0zxRvjtCSFO5ygT684y8ZrzHhfKoPXPATEAvmwb/PYkrJ0unvsQsbv8rCuw8ewvW/hlQ9GhzRd2lon7WF0k9n/1qdgZdvQAyreLWYCB5pnBF+PQOJqjF2YgGoqTZDJZIfA48CzwpUwmuwHYA1xec/jPCOngXIR88PVRT3gy4SwXzoU+MTJr5iiFL66CipphlrZ8+Hw83LJY1IU3gUqnn0kfr6SqZg7WtpJq7p75N+9fN4iEg40DCHiFglR9qvaBVM/RtObDgv9A57OFcf1hClzwhqhV//NVcczS12HwLXDGY6AV/X5Fdi//eGUJbr94rrcW5vLLXSNJMze9D2hHqYNLpi6tE1dpm6jn68nDGu25K3d4uffLv1m8vRyVQsbkUR244dR2WGqFWVwVYSNdS9k2cT9inLDE7NPh4XIHcLtrSwYjvz5WrLHy07xiQFQPfPpVPkP6x9O3Z9NKlvz+EF9+V8iyVZUAuN1BXnhrB/17WTAZD9z/4fWG2LYzOmC1c7eTXt3ELD+r3ccr7+ygcwcTOdkGvv15HyMGJ5CVpefaO1fj84lgzidf5fPRawNIShR2w17l4+lXt7J8tQjufD6rgAfv6MyYM1NRKpsWK620+bjr0XV1A9I//bqA15/uQ79eB78vLneA35dX8OLUHbjdQTq2M/DcYz1JTRZ20ecLRTi4tZRX+kiPKWuesMRs02ESCorva5kMDPuVC3psMPOK8JDxonXw3R1w2cdNy85BTcB7cng/kLcIFr8AZ/8HVAf5vDXkEJZvD+8hJAn2LIOtP0LOcOE4/XQPjHkevr0Fdi0Wx/35Klw8TQjj1fb7Ff0NH58fvqbkriJ71kSVT38wxJxNRREK5KM6J/Pq+L6Nj5yyFcCM8VCySbT1nP8qdBkj2n0AyrZEn1O8Tqi4K1tXxcWJwFHL7EmSNEGSpHRJklSSJGVJkvS+JEkVkiSdKUlSJ0mSzpIkqbLmWEmSpNslSeogSVIvSZJWHa3rOq7xOWHX7/DZOJG9W/NpZAYp6BdGoj7VRQ1L+x4Aly9Y5+jVsrbARiDYyIgBlS667KDNYCH5C+Ia7IWQNUjM3/v7M+g7UdSoL3878rxV74FPzI4KhkJ88MeuOkcPwOryM3dT04OT1R4/L83dVufoAeypcNXNZjkQgWCIL1YWsHi7yE76gxJvLMil0FovI2BKixah6Xp+qxGmOVmJ2adDp6zCy4tv7+Dm+9by/JvbKSsPBzz8/hB//lURdc7Kv5ueAXe6gqxeZ4ta357nOOh5Br2C0SMjN3cyGQzoHXam3K4gl5yXyaq/rbw3fRdqtZzUFC1ffb+3ztEDsNn9EaqeLneoztGr5f0Zu7FXNz17tq/YXefogdiX/W/6rkazng5ngKdf3YrbLWxj7i4nb7y/E2dNVtBoVDJyaKSin1YjJz21ZcVyYhwZMdt0GLitsG4GfHQeTL8Udi4UWa9aPFVhR6+WghWil6yplG2LDvzu/l308h8McxtR8lmfLueF5/Y5y0FrFnuKhf+F3N9gyM2iiqrW0atl4dPgrqmmclWK4Hr9ayrbKoLuTcTm8vHS3Mg95eLtZdEVTvvjscMvDwhHD8Q9+PZmsV5Lzojooe69LgNNCwoNnsS0ng72ZiIQap65aoeFowQ+uVCk6yty4ce7IH95+HGFKtrhMqaK+vPGCPiguhi9IohpvzkzvbPMKBvo+7O6fDi8NRsSuRIueVd8gNUG6HgWnPsSyGqeS4aoh5/3mLj2fWvhq2sh5I82dPWMkwQRjmavzDjm3NCFcW1dYC+ILltogJAEgQbKPp3eIDtLHVidDZcNuP1Blu2M3qCuza+3udMnwnU/QXofYYz7XgmnPxKOXu2P3yvKV0s2Q1VR9BdMjBiHSTAkITXT7KJDxV7l5/HnNzN3USklZV5+W1LGI89swmoXny2VSs7QgdGKdwN6Ny1qbrP78PmD9O1pjnqsU7toISi3O4i9ykcoJCGTyejZNY4JY7MwxynJTNfy6N1dIoaNyxUyHnlmE6vW2Sgu9fL1D3v5YW4RXTpGP3cgUM8+1bvfarWcu27qwDOP9KCqOkCltWnlSA19pQQCEmUVXiqsB95slpZ7o87dtLUKj0c4fxq1gqsvb8sFZ6dh0Cvo2M7AG8/0wWw6cMGO1eajYK+LvUVubPZYOVWMZkKSDqmdpNnZtxa+u10Ew4vWwfSxIhBeizYuOvuWNRAUTdAr8DlFFVNi++jH2g6LGlweDIaodPpw+2ruh0wO4z+FtF7C0ekzAQZeL9ZBOERbfxBBcdse0fIy86rw4/UJBcSmCWrueT2nrMu5QvVToRTX24S9hwQRQfJa3P4gu8udVHsOEJDye2DvfnGFUFDsfWoxpsAVMyChvVBzH/kgdB4T7QDW4nWI6y7dLJ4nGCtHb05izl4N5Q4vnyzdzX1frmfRttIDOghHle1zw71htaz5OPyhNSTDVd+IOTIApnSYMAP0jTQaS5IwgG8MIP6X2/nf5R3qhrK3TzLw2hX9SKg3pN3m8vHT+n3c9PEq7vliHbml1UheB3w9CbqcA+M+hLbD4fPLwV9zbaEgbPxmv9cNiSjViHsj13tdVmdklXI5k05th0ohIzVOw/sXpdD1+/PR/28YvNITlrwgFJ0OglmnYsqZnSLWUuM0xBvUnPnyYt5amNug0dKrlZzeNVodalC7eptWhUo4ehNnwR2r4NwXD1wiEQrC3pXwel+Yegq81gu2/3pImdc6gn4RJWvJL9AYxwUOZ4At26t47vVtfPJlPuWVx76E2OsNsn5zZKZ8y47qiKzYyKGJXHh2GjIZKBQyxl+USfucxscDWG0+HnlmE1dOXsnIU5LoX5OR02jkTLmpA/H1RigEgxJ7i9089+Y2HnhyEz/NK6bC6uWN93ficAZ46M4u3HhVDr8uKuWvtZV159nsfqqqI6PVC/4sp08PCwpFePNh0Cs4dXA4W6bXKejdXUSi77utE5u3V3PzvWu5+vZVTL5/LaXljX+2M9N1Udm2S87P5OVpO5h09xoqDvD7TE3SRlwbQL9eFnS6cGl/gkXNlBs78vnUQbzyn9506xyHStWwKE6lzcf9T25kwuSVjL/5L/71/OaoPsCm4nQF8HpjtikGIqi5+DnRtrHvb5FFO5YEPLD648g1SYItP4R/1iXAxNnC6QBI6QYXvdV4CafPBZu/h1d7wd+fw9lPhwO92afAqAdBHbZxlU4fHyzdzfUf/sXj32+kyO4Gez7M/w8MvhkufU/s476+PhzIDgUjrxXEd3/1Pmg/KnJ9+F0iAA1gSBQOFED2UBhwrehFfHeUuN7N34vrPwgWnZrJp3WIWOufHc+mfVWc9uIiFmwpxRdoIFql1os9YH0U6kjxFY0JOv1DOKC3LoeR94prbgivEzZ8Ca/2hLdPgTcHhbOGh4rfE5lhjAG04OiF44kKp5fJ01ezardwKmb/vZdHzu3KdcPaoW5iX0az0JA6U1JXsfEv3iCaXZO7wqRfhDGTKyPHAPhcIpOm3S867iwTKXafA/X27xkY9PDz+AfxJXRBq1KQJHeAtQxUBjAmszyvgts/X1t3+u87ytlwb2+UjlL49dHw8xqSw9EnhVqoLW2fE/2elDo472UoWI6r19VUJfTC61KiD3lIMmrIMMiZO2UYe8sqSF76eGREbtmbMOC6Ro1yz4w4fppyKp8s3UOiUc3ZPdJ4eNZ6ppzZkZGdklmzx0qnVBNmnQpDTWZTIZdxcd9MNhTa+X7dPnQqBfee3YX0uJqNWdAPXgcOtFRaPRD0ozJq0OvVmHUqCAbBXQHIxO/BVQ6zbhalq7Xnf38n3HkKqNKjrjkYkqhweMkrdxKvV5Fs0oq+SUeJELgp+Au6ngc9LxX3V9e65JpjNI0NW+zc/8TGup9/mFvEuy/2JyH+2PU9yBUyTEYl1Y6ww2TQK1Cr5ZRXeln0ZxlWu58Jl7Th+ivbgiTDYAj39QWDEi53AK1GEZFxA1i2urLOkXz0mU1cd0Vb7pncEYNeSHjbqwN4vSFMRiUOZ4Cb7llT57ht2lbFy0/0Iitdx9c/7uOHueHI8tWXheXlzXHRPX8ZqVocDj+vPdWbeYtLSUvRcPqpKbg9QcoqvBj0CixmNU880J0//ionPUXLvMVhAYR9JR4+mpnPXTd3QKM+sOpoYryaqc/35ZcFJeQXujhteDLbcqvx+yWeuL8bO/IcWO1+khLUEeqhJqOSZx7pwX9f34bN7qdfTzO3Xd++7p46nAGCQanuepVKGXKZrO69VlX78flDGA1KtBoFC34vY+uOcMnZmvV21m60ccapDQevbFU+Kq0+bFUBsjN1xJvVuNwBNm2r5svvCkmIV3P9FW2JMynRaBSoVbHY8UmHowTeO0NkZECIhFz7I7QbceyuQa6C5C7R68ldRaljyUYRdM0ZAZOXCudKqYkcA+CtBmSg2S/T77HDj3eLDNrvL0G/iSLwa0oXfWeSJHrX1AY8KjPvLtnJtMV5AKwrtLNydyW/Xd8WRdHfYi9QS86p4jsdxN/7D10H4dSNehhyRkLlTqoH3olDm0bA5kGvUZFo1EBGX6HsKUnw/R3hxEAoIK67/WkRzuj+qJVyxvXPomuqiVlr99IpxciAnHju/WIdz4ztRUqchpW7K+mYYiTBoA6Po9KY4B/PiN//nqViL3jx1PBICb8HAh6q0WGtdAMhdCEDRp0CnVpZ45DZxO/OkAjemrLQ2uC2t0oIAl77fXT/JYDPDe5Kkcm1tBVOvNYsWol+fxGse8S+se1w8bvWxkpHY84eotyv1tGrZeqinYztl0my6Rj2P2T0EUZg9x/iZ0tbOOV2yF8GM64IH5feByZ+E/4QBP2ErHtg4TPI3RWEBt8K2UOQ1zhIkhRCZt1Vd7py51xSds5FumM1srWzRFROocb+jzdwtj+HrHg9j1/QnZfnbqfaG8DtD7LFJqfXuS8KgyKFhKN54ZsiqxgKipr5IbfA5tlho5UzElJ7wMvdIGsQzoG380t5Ko9+vBxvIERWvI7pNwwhRyqk3cdjyLn8U2Tl26Lviy0fkjpFr9fDqFXRI8PMw+d25fHvNzH+nWWMH9QGtULBuGnLAJDL4J2rB3J6l2RcviBObwAJeGRMZx4+pyMgw6yWodWrhRrWqvcgbxH6nFEYu46B2bfgzR6Bb/h9hEIa2DQL+bI3QKkhdOa/kaf3gar9VK99jgOKueRXurjorT/qeihHd0/hrYvbov7ySiisKZHY/buIcGX0B50Z2p8ejk7GaPXYqvx8NDNyE1Bc6iV/n+uYOntmk4oH7+zM489tJhgS017uu60TwaDEzfeupbSmf2/61wV88Gp/OuSEN00VVh+/zC9m6cpKenY1cdmFWSQnhsuntmwLOyCVNj8vT8vl4jHpXDu+LZPuXk15pY/Thydx48R2APzr3m588mU+6zeL6O17n+3myQe7s2R5Rd11DO5noV222ORUVftRKmRccXEWM2cXAqDTKbhncifmLS7h5/kljB6ZzCkDE7n/iQ0U7HWjVMq49dr2nDkymXsfX0+vbmb02uivy7w9Tjye0EGdPYCkBA1Xj8tmyfIyXnsnF4crwAv/6sVDT2/EahNVBwP7WHj8vm6YjEpsVWL8ROf2Rj58tT+BoIRSKScpQYPDGWDbzmo++7oAnU7BlZe04effitmV7+KWa9rRPkeP1ebnpbd3sKfQxalDk5h8TTu27IjOuGzLdTTo7Nnsfp5/cztLlosyd5NByUdvDGDnbicPPBkOPPy+vJw3nunLLwuKufKSNhG/1xgnAcWbwo5eLYufEyWLxyo4KVfAwEkiGF4pHC3aDIGswbB8Gix5Tqwte1M4a2c/I75LAbxOQqWbkS95HkmmQDrtIeRJnescpJDfjby+yuTa6fD3Z0h3b0L26//Bxq9FNuv819Akd+GaHmriZBm8tKSIYEhiV7kLp8xI3JDJsGKaeA5NHIx5QQSwA14hcjfmefjgnLAI3uDJwhH66FzocDrWoQ/x1movHyxfRkgSrTfvXzuQ5F2LRd/exK+h3h4PEBlPf+OlnPEGNSM6J9M9w8TdX6zjxbnb+M9FPVmeV8Ej3wrhFoNawazbhtElLU6I4PhcItB/6fsiqC2Ti32JWi/2QL+/DKVbMPS4BFNCe/jpHpy9ryXU9ypCPjksewP5+i/AnElozEvINcboss2KHQ3XwEuSKCGdPjZ8zqiHRWbzf6eL5AZA3kIY85xQf+94BqT0rBMFPBmJOXsIJ2B/lC0xkNeQLNShnGXCCMSli164BU9FHle0TkRUapy9YHUpindHCccCkOctInjFF9D1HAA8kgpNh7OQ2wtEJKhyl/hAKtSi4ReovOxb/rNWy+xvFiNJMLp7Km9d1Z9rPvgLAFdIBd0vFGUF9kIRidJaRCRp5wKhTGVKgwlfCCOj0tdkHVXQ+RzYPofqf/TmwalhIZVCq5uHZ21g6kgvFlcFMp9TqDnVF6FRaiAxsszgYGiUCuL1aryBEBf0yWDieyvqHgtJ8MisDXx3x3Ben7+DL1YVIElwRuckXjhNQ+L0M2HIrTDsDhGF2zFX3M/85VC0FgZcg+bXR5HLZdD/auQ/h8tT5TMnEJqyDnnb4bDnz/AFJXaI7lkEHN4Az/+6NUIsZ97mUmTnJYcdvVrWz4Tel8PHF8BFb0Kfqw55tmKMExN5TUnk/igbMlpHEZVKzpB+CXz1/lCKSz2kJmuIMylZscZa52CByOB9NHMPj9zdFZ1WgcPhZ+pHecxZIBTp1m+2s26TnWce6UFignAMThuexJxFJQztL4JTK9ZYOXNECq+8k0t5pY/hgxM549QUJt+3lmpngMQENY/d05WpH+WxLdeBVqvAZFDwv5f7U1buRauRYzGrsZhVFJV4mP5NPkgSwwcncdGYdGx2P+mpWixxKkaeksznswrR65R8MGMPBXtFVj4QkHjj/Z0MH5xQt3bZhZko5FBfy+rUoYmoVE3/XbRrY6CkzMNF52Qwe86+OkcPYNU6G3sKXWjUcu799waqqgPEW1T83z+78tHMPVRVB3j1qd4Ul3q469H1dectW1nBG8/05c5H1/Hgfzby6VsDueOhddhqBGC+n1OEJU7JOWek8evCSGn2M05teMhxWYW3ztEDqHYGWLfJzo/ziiOOc7qCbN5exZr1NlasqeTNZ/oe0yBEjBZG0UCQQ6E6cF/W0cKUJsoFq4pAqQJDishuLXs98ri/P4PTHqlz9oLWPSg+GA2ShAyQ5c4leOsKFMkiuBxQ6lCb20BcBiS0g6J1hEwZyNxW4egptXD5pzD3/5AVrCBDruD6QXfQ5sLx3Dl7NwDVMhNxpz0kguHOcrF30ieJrOPa6VCZC4ld4OZF4nFjMujihSNjyYai9ewLxvPesvC+aH2hnff/2MU9mjzUtj1ihmD7M2Dn/PB7tWQ3Tc+hBplMhtMbRKNU0CHFyKOzw0Edpy/Iv3/YzLTx3THPulYEoWVy0XuY0U+Mkjj3JeFUfTBG9B4C8j1/wqn/hLbDMCz+N15zOsiCyGvV2auLkH90DtIdq5AZUyOVSzuPaVjl1FkmSobrO4drPoZ2p4Ydvbr1T2DgDcKRvnmx2P+epMR2jIBBreSMLpFfeveM7ky8vgW+tAxJop48o68QX5GIHG9QS72IRyh/WZ2jV4tixdsEnCJb6ZQbKBnzHr+PmsFDwVv5tsfrlFy7lKC9JguV1ps1zkS+XV9Wp50yb3MJuaUOBrdLoH9bCx1SjCJ1b84S9eFxGaDWE3RVUmTpy6uq63mqegy7PTo8ITmkdBXvRWeGC9+AUQ9i9SmimoE3F1XhM2SJH2y7hUrVwBuEsUvtCZd/0mjdeX10agVTzuzIw+d2RaWQ492v3rzc6cUXCDFzZUHde12wvZyf8+VIOaNg2RuiDLPG0atjx1zIHACAaut3yPcfQwEEt80RNfldzhPRu3ajRI9lAz1+voCYLRj1HCiiG7M1pnBp6Ip3RPlCjJOCOJOKm6/Jidg75bTRk5F+7KX1dToFKUkaenc3k5qsRadVEgxGN/cHgxJSjYqA0x2MKH0E2LStGk+9Xj+DXs6sDwZx+3Up3H5dCt98MIisdC1La1QxL7swk+ff3E61UwRGKip9vDxtB1dcnIVaLefOGzpgMKhIjFfTtZMYrWAxq7DafNjsXq68OJlrxllom6nA4fDRJlNHUoIGpVJOThsdrzzZi66dTOTuilb9LCn3EmdSEQhKVFh9/Pv+7rTL1mMxqxh/URa9usY1GHw+EEmJaqa92I+unYyUlkVn/PeVeHh3+u66MlWrzc8Lb23niouz2FPoYunKCr6oyU7W4vNLrPzbSo8ucbjcQYpLPXX3v5ZZP+2jbZaOeyZ3JDlRTXqqlsfu6UpGWsObwfoOfC1Wux9zA8PaTUYlbneQ/EI3TncjKn4xWhfJ3YQARy1yBZz+aHQrybHAmCKqo1K61wxMb0A0RpKoUziRJGSr3otUswwFhQNWQ2XIQsm1fzK7x+s8FLyV30d8Rtl5HyJt+0Uc0ONi2DRLKHvWnK9b8RpDEt0kGtRMGNwGo1Yp9jMJ7YWCuSkNFErcpbnsyryAp6RJvG4/lSK3nJApXRynixfv57qfYMhkNpdH99auzbfhjq8pX/XYhHBctwvE3iPnVCGoJzt4xUF9Egwapk3sz00j2jWocVBkc+Oz7hWOHogKr5Xvi35IXQL8dK/I+tU4enWsmwGdzgZAs3Emcs9+ont+N0F7sRgZkT1U/N/peZnQR2io/FIKRVdQ+V1RQjlATUKixq6vmHZSi77EMnuINPYLl/Vh5W4r6wpsnNMzjZwkQ8tk9/ZD0icQGH4fqm9vCC8md8FvSKW2C0XWgEBLSJ9EUKZECajlCj5ZU8Lr88V8vpmr4Iwu1bw4thsJMjkkdmD53ugPwcZ9dp69tBdxWhVJxobLc8pCRsZ8sBabS5z/8Yp9zJnchw4+N6hrNqTGFBhxHwnOAHr1Vly+sAEe0SkJfVyCqE/fOEt8OOVy0TztLBeG97yXDumeJRg03DC8HeUOH93STWwpCpeJndk1hUJrtPO4bK+f8YmdUefNF3LMKl3YwQKRnas1FAkdCEqwvxkNmDJRxWXA2KniXIXmgL2GFkWA8X0SWV8YbiTWquQEFDoYertwOmsZ9ZAwmCCMqvzwPraSJFFW7WVLcTU6lYL2SQaSGplDGKPl6dzeyKdvDeK3xSVkpOkYOiCBBMvxkT3p08NMvEVVl6GSy+Gay7PrSh5lMjAaFNirwk6AQg7KetnKnDY6ivYV1ilful3VZGRmMWxQAkuWVaBQyOocvVryC9106Whi5juDiTc3/HlQKMBs9OBxOxCuiwOL0YhCHs60Gw0qBvVLoKrax5ABCXz7U7gkTamUkZWuY+jAeH6aV4JKKWfe4hImXNIGo17J8tWVyOUyjIamfx51WiXdOsXRNkuPRq1g9frwxkellNG3h5kX3oyUQi8u9RJX04dXsNdFYgOZM3Ocsm5Qe0K8uk6xs5bMdB2SBBf+I51Rw5IAGZY4VYNZY4B2bfVoNXI83rAnq9XIuWFiDstWV9atd+5gxKhXsq9ElLodSd+evcpHWYWPohIPnTsYscSp0GiavlmN0QIYU2DSHNj2K1QVihlwcdH96S2BT2FENuBGVH+FRz8Fu40lKNehpiaObmrgWuuJjMjk8Ojs7fy2RQSsZq6CO87oyO19L0W38ClI6CDKBffDYt/C17eOxayr6e+Pujg3hfJMxkxbV6ck/uFKFXNu7UfExGRzFgy9jYG2ILA74ilGd0/F2CZVVGhtrGnrSekuFMMr82Dt5zD6iabdrBpS4rTcfkZHKp0+4rRKqjxhuztuQBaW/J+iTyrZCPE54ChuWN1Ul1A3niKU0g2QRWWZQhqT6Lu8YoYYOaE2RvdP1iGD7hfD+i/qvYZFvP+cEWFnVKESWcV5j4mfTemH5PzWx+sPUunysXGvnXSzjgyLlgTDibV3ijl7NSQaNZzTM41zeqY1fvAxpMIVYIW3B0PG/0jC1pk447tgbXcBXreOTrVjWiydMaf3FQM2AdRGHKc8gIQGDeAJBnn/98h67gXbSnGFupNwxefw52ucNUjLe8siX/u8Xum0TzrQB67meXKr6hw9ELPqpi0v4+mLU4nYkijVxKs8fHp1T+6ZvYP8ShejOiXx2DkdMCr8cOWXQj7ZnC16Fdd+Kvr0zn2xyQPjI15OISfNrOWD6wbx/JxtrCuwMbJTEref0Ylie3RG7Zz2GtSb19ScrIXT/w/m1hOjOfWfsOlb0FoInfcSQV0KiuQuYvYOEGw7AkWbweJYrbnRyKY85GFMWhX+s9vw+TorySYNj52egrq6AEbcA73GCWWz1O6QO0+8tlIDZz912L0QRXYPF775B+UOESXsmmbi0xuGNDp4PkbLotcpyWmjrOtZO57QaQK8+2Iffv6tBKstwMXnphFnCBEKhZDL5cQZFdx+fTueeW1H3TkTLslCrwt/3buc1REjDiRJwuGo5sE7uuB0bsbjCZKYoKaiMhzd7trJRJxRGSFosj8atYxyd2S2zu12kJAY3fMaZ1Iz8dI2VFT6+GNFOcmJGqbc1AGFQsaZp6YwYkgSBfvc3HFjB35dWMKmci+XnJdJxmHOtNPrlAzqF8+Dd3Tm6x/3EmdUcvukDmg1CpISNRSVhPuE2mXr67KAXl+IKy/JZu7i0jqxnOwsHe2yDWzb6WDCJVloNQomjG3Dx1/mI0lCUXTKTR1JsKhRKuUkxjf+ebfZfTz3WE8+/bqAikovZ41MIS1ZS7xZzefTBrNmgxWTQYVKJePpV4UNPH90Gjrt4W2mqqr9TPt4V53AjkIh441n+tC7ewtkiGIcGsZUGHBNS19FFNaAit3Zk+iUOpiE/DlY00ewN/LcYnsAACAASURBVPEUEoN60qkpW+w2nrhV74VHBpizcHY8n9p8UiAk1Tl6tXzwxy6uGTIC3dlPQdF64WDsWRpxjDpnKO0OsnfyomTqstKIkVFWl5/FedVcnrxfabVaT5LWzmuXdOLJX/dQ7Qkwrl8qY3sno/Duhet/hsKVQoylMg82fyf0Es7612H192uUClKMGr69bTj/+WkzhVY3l/bPZPzANqi2NpBpyxoMf70rgtBqgxCUq1VmlyuEYumKqcIhPOUOvB4XOsNLIpgPePrfALoalc6mXK9MJsRXdBbInS8c3GF3ivXLPhR7Mutusb78LSjdIjK9g2487PaXHaUOLp26tK5SbEzPNJ4Z26vxwfPHEbKWmtvUHAwcOFBatap1zxAtd3iZ+N4K3P4gQ9rFU1btZ8mOMn6881S6pYsP3sKtJSTLq0n15KH0VKLvMIxAwI9OHkKuj6c0oOeMl3/Hsd+gzD8fGEWmWQeucqwhHdNXFTN1cR7BkMSk4e24aWR7TFollU4fFQ4vFr0ak1aJSRuOVM1YsZuHv42UyB0/MIunxvYKKzfVYstH+uYmKgbfT8iYimbvcsy538HIB+DTCyG1l6iz9znhwteEGEkz4PIFcHqDmLRKtCoFNpePr1YVsGhbGcigW4qe2zrZSPjuajjr39BjLCBBdQnsWyNq0jUmJGc5MlMa6JNwBCRwlBGoLkOmUKEwJKA0JaM9gOx5g2ycRXDDLKwdL0blLse87Uu44vNI+WJnOZTvEDMH2w4DfTKoDt058wdDPPfLVt77I9LpnzaxP+f0PD4isbXIZLLVkiQNbOnrOBJOBtsE4HA4KCstRa/XAzI8HjcarZaUlBTkcjkBv5+SMju+gIZNW6vo1N6EJU6F3REgwaIW/7ZbsdsiS3vMZguJSYlUVfsJBENUVPr49wtb2VPoomsnE08+0I2MNB02u49qZ4BQEOJMSuLrZTz9fj8F+dEDhttkZ6NSRUbbq6r9PP3qVrp1iqNPDzP2aj+zf97HlJs6cst9azDolaQmaygocjNySBK3TWpPnLGBiP0hEgpJ2Kv8KJQy4owqJEliT6GLV9/NBWTIZHDDhLY8/9Z2kpM0PDKlCxazGqvdx4YtVeh1CtpnG6h2+NHplBgNCkxGFaXlHqodASqsPlKTNVjiVJjjmr4xqaj08tBTGxkxNJk4k5K/1lo5fXgSZ41MQVZTU+z2BLD+P3tnHR5XtXbx3znjmkxc65a6lxq0UIOWQrFCocXdXS5c9OJwuTgtTtELlOLWQoW6uyZtk8ZlMm7nzPfHTmYynRr6waXreXhoTubM7Dk5s2ev/a53LWeYdZsaaVNoJjfbtF/X08NBRVWA0y9amnCsQxsL/36gJ46DEPr/DxyZn/4aqHIFOPrRH+iUbaNrrpXiWh8rdjew6LZjyU0RqqNX5hczqjVYatai1Woxt+pDJOjFbDSC0U65X8eQRxODzS16DT/cdDRZZk1TfEIU5twL6z4QLRdjHoAuJ+KTLbgCYeq8ITKsBlJMutj6IBhWuGPWej5alShHfOzU7pw+oHXymylZQHjpyzT0vgz0Ziw7v8Tiq4DsLvDd3ZDTXURUGWxwxhuJ0tpfAVdAOPqmmnVC6eathR8fElnKUVVEK6hhWDZDuHEWDhTrt4Zd4jGFR4EkEw26kKxZYM3C5QsieWuIuCrRmFORTSmY7RnCC+FwEPIJEyB/vWitce4RzuWnvZbosOqpFhvmShAKBohNiV/QS9rgC3HpWytZVpLYPjPnhmNEe9OfCAebm45U9v7kSLfouX5UJy6duZLddUJ+WJRrS6jGdMm1c8rzGzBodbx99nAcH03FUL5S/LLVEOynz+SKobk8Orc0ds7YonQschg0VrBl4wAuPtrC5AHCrtxm1GHSa9hY3siZLy3BHYwgS3D7CUVCh24QX+rHFuXg+GYbDU3VPb1G5tJj2icTPYCQD6l0CRmlp8aPWTLjFsaVcdMBKtb/ZmTPrNdi1sdv9VSznov6WLjQtgwifug0BlmTA1cuFZIDbdPiwuQQvYdNkFIKYv+2agBDHm5LJrIkxeIcfhbajUSj0ZOxfIbogTzt1WSbYUtGU//B4J///C2gqFHKnMkVzYrGX5ABeARH0ASj0Ygsy3i9cdc3h8OB3LSDKskyJoNEKFDDwN6pLFnt5vHnd6Cqogfw3RcHoNdZkKTGWHVPkiS0TVlWdpuYZ9JSDTzzUC8UJYpOKwnC4wxxz+ObWblWEMX2bSw8eV/PmMxRlmVsdjtuV7y/1m63x8bWEpFIlNJyPz8tS/xCd3vCGI0aautD1DZVFhcsreXic9r8FpcPWZYSCKokSRTmGXnw9k4EAwGMJhNIGp68tycGg4ytiWBmpBkYOTQ+V2RmJG4AZWUYSbUrZKYbsFq0h7+QakJqip57b+3K6+/upro2yCnj8+jdPTVG9EBIUk05WvJyfn3/qD+Q3Jde7wyh7qcn9AiO4HBgN2q5cFhbnv9xJ+v3inaJSX3zE9YCo7plM+6pBfQsyOa5E/PQvz4afbO7aN/zMB99D+O6ZvD1ptrYOZcNzSNF8oM2HWxNqqPjH4Xj/glIYEojhJZ5W6q45t3VhJUoBq3MjGn9GdI+Ha1GxqDTcPmI9ny6tpxw0z2eZtFzdOcDqJjcFei2fELWlk/ix9qNgPzeQva4d1WLx1b+ZmTPbtRBS/GCwQ5Dr4OtX4l+urZHi4pe7ynCdEbWiBYYS4YIrW9Cy9nHbjYQNeXjsmSh02owHcLJOAl6s6jkbZwlHFhz+wivBOs+aydrFnQa87Pf876IKKL9ZV80+v9a/X9HyN6fHJIkMbhDOp9dPYyPVpbRJcfGcUXZCT10uSkmPr5iCCt3N5Be/Ak0Ez2APYswKH7OytxF37M78eWOAINytRyV7iU16gLiPWVGnSahMlXnCXLLh+twN1UE1Sg89OVmJvTMjZG9TKuBr649mlmry3AHIkweUEhOygGkTWaH0KA3tjAY6DMVbPliwlCbKo86M3Sf9OsuXAtEo1HCiope2/Te3JVIM0YiNU/q39vh8p+Ee1ULhBUVbzCCxaDdP3mFhCrnz4bZAUUTRCaRRr9/56kDwB0I4wspSAjyeqg8SKNOw/lD2vD1hribnk4jMaro50tkj+AImqHRaMgvKMDjdqMoCja7Ha1Wm/B7e0oKBqMRt1fiiRc2xAxN/H6FFWsaiEaj9OmRTVTxARKyxsRPy+o5YVRewmvt26e4frMrRvQAdu7y8vXcSs6aVIgsS2g0GtLS0jCbzfh8PsxmM0ajEc1+HART7Fomjs3l2VeKE47lZhvJzTImuGaedXJhjIT+FghHVDFeWUJRFJxOZ7zS2QCOtDTSHClJJNXjjSDLxHL39oVer0H/cxdSTdBoJPKyTdx4eUfCkejP6ktUFBVnYxg1CgaDfFgV0BS7jqwMQ4IxzITROdh+w+t8BH8vmPRaLh7ejsHt0/l2YxXDOmYwoE1aQg9dlt3AN9cfzZ7KGtIW3ZcYI7HqdVKHXc+/jopyYqfWLCmPcEIHI13U7RjUfcLBDTbxXxMaXAFu+e+6GJELRlRu/GAtX1wzjKymHN8Ch5nvbjiG95eXYjfqRNTXAbwRRF6cUTidN2PgJfFcu2akFPws9/JDQVGjKGo0vr5oLIUXhwlDFBDSzAu+jZPeJgTCCsGwgs2o2+9GkyRJpPwaA0RLhjDy63G6WDdpD1/t5PSFCIRVNLLwd9AcYiPMYdZx1sBWPPjl5tixNIueAscfb5L2a3CE7P0FYDfq6JGfQo/8A/cv5KaYmNDdALPXJf0uGlVx1K3iqC33cVRuL9iwS0wSJ/7noK+rRKPsqk3MaVGjIpewGbIskZNi5PIR+wmE3xfWbDj/a/jhAaGr7n4q9DpLkLvLF8GiZ4VEcfBVYP1teifrPEG+2lDBop11jO2Ww8jOWdi3fZ04qQddsOR5Ib9oMj+pdQd5c8kuftpRx9AO6Uwb3Gb/JjW+etHF/WsyhX6mc1mdJ8j9n2/is3UVWPQabju+C+N75u2/EbwFinLtvHJuf174cSdmvYZbxnUhw/rnkkgdwV8LkiSh1WpJdezfiAhAq9Wi1Wqpb/QluXeuWt/IeZMLuej61aI/S5JYu8nJ9Mf6HPK1d+5Kds/cusODokRjCwyNRoPFYsFisRz0uTQamXHH5mA0aPj8u0ryc4xcMq0tGWkGHr6zO9/Oq2LTVjdjR2TTvcieFAz/S+D1RSgt9/PfT8tId+g5dUI+aamaJEmrs6EBm80WI3seb5itOzy89WEpZpPMRWe3JT/XmJT15/crBEIKNosW7SE2gw4Eg0GD4Weoxv2BCKvWNfLwM1tpcIYZ1NfBHdd2IT3t4PNMukPP84/05uWZJZSU+hh9TBbjRmYfCWo/gl8Fh0XP8I6ZDO+4/4gRk05LqzQtrQwWWLA9+QGyhvTlTzDeV8f4tLYwf52Ih+ow6KCvG1bU2CZ5M2o8QZQWbVNGnYY26RZuHddl39OTYckQ0Qzf3yMcLwdfKQggCIOc5S+Do72IQvgFHgf7Q7UrwLvL9rCj2sOUQa3onWvCNP/xONEDIdfcs1i4kjahotHPM3N3sL3KzaQ++Yzrnkvavr1tzdnMWuNBjFgOAfnnr7uqXAGueXc1S0vqybYb+PcZvenb2nHQ9hutRub0fgWYdBr+u7KU1mlmbh7b+YCmhX9WHCF7fzYEPYJ8RNUWjkTy4TWWyrIIDW12bmyCqqrIWV1FpEPxPEGysromWg7vBxa9ljHdspm1Ok6M0i167E07ydFolIgaPWDVa79ILYTx/xZulcbUeE5PZmeY8KTQVP9Ct0l8deJ5JQ0YU3BGtNzy4TrmbBEN1l+ur+SBk7oxJepOzhwJuGLXw+kLcfOHa/lhq8hsWbm7gQ17G3nyjN6kNu9G+RuhdLEID9UahYQjq2ssjPX3gqKofLiyjE/WiL+JKxDhjlkbGNg2/ZBkz27ScVxRNn1bO9DIkpBoHMERHCZUNUpDY4hQKIpeL5Nq16JGQXeYRMJs0pKRpo/JIUGYjxh0IV58rBezv64ColxxXi9MhhBw8M/S0YMzeOWdRJvv8aNzYkQsHFHRaqQE6eHBkGrXMXFsLiOGZqLXSbGKWZpDz+STCghHor+YfASDCi5PBEWJxnIAi3d7ufyWNbHHfPF9JR+/OjDp3H376ot3+7j2zvim3pIV9bzz4kBysuILlsrqADPeKqF4j49jh2UwYUzuH9L75vYo3PGvDbEswqWrGnj57RKuvbgDxkOYt+RkGbnxik4Egwo264GdQo/gCPYLv1P0i0mS2EDV6MVa4HDWTsZUsS6qWBs/ptGJfrSjroCaLaLNZPiNQqoYPXjeilGnoXO2ja1VcSfwfq0dGJrnSlUF1MNf62gNYv12ygyhgGppZNJqsOhdk7S/PH/XUy2qhho9mNKo8Uc57cXF7KkXxO6zdRV8dXk/ikLu5HNbxH7VuAOc/uJiyppipZbvaqDaHeTKER3i3xO+OiHBXD0TUgqFT4KjjbiuvyPcgTD3fLqRpU29d1WuIOe/vpz5t4w8pNeCw6JnyqBWjO+Zi0Er/7K2nf9n/PVG/L8MX72w3F/0jKh49ZkqPhAGuwjktOXtP8S0JbK7waQZUCfsu12p3dhRo9KtdDWGPfMgtzds/ozops8InfYGje4A5c4ANe4APfJTSbfqkJGo9YbYUuHixjGd0cky322uokOWlYcmdiJ98ztUd5jEh2trqXYHOX9oW/Y2+PGGInTPSyHbbthvX0wMevP+SZGmiXx4awVpk7Vi5+Zw5I2eKvjwItg1X5CvY+9C1+2sGNFrxqPfbOWsa08SYfLN0QqSjKfvZXywuIxx3XOQiHLR8HaY9Vq+WF8BwNwtNfjDCrF9pJrN8M7k+BO/OgauWvGbaeUP+DZDCj9srU46vnJ3Ax0Os1n4/yU/8gj+0lDVKDt3ebn1fhG0+8BtXflmbiPbSzwcf1w2XTrYDiltdKToeObBXnw9txIk0MgSPbvaUaJawsFqThsv7l+frwZLej7uOjcaj4vGlRuxdGqDMTcLfXoqwZp6/HvKsepM3H9LF6bP3E0orHLWpAK0Gom1G50Egipfz63ilJF22lhDuFZtIKVvN7SpdozZyVE1zZBlEUmwLyRJQq+T8AcVPJ4IqhrFaNAcliGJ1xfh+/nVPPPyTgJBle5d7Nx/W1fen52Yl9foilBTH4rJTpthtlhZuc6JxaQjK9OA0SBz1QXteP393Xi8CqFwlIVLazntRNFTXNcQ4qrb11BZLSSR24s9NLoiXDy1TVL177dGeaU/IXQeRFi8168ckuwBmIyaX+zoeQR/Y3hr4PMbYcunMOZfkNEJ1n8AGZ2bWkUOUe3SaKH32WLN4a8XuQyFA4W75YInxEZwWjtY9LRwumw7Uhi41W4VgebZ3cCWjS8UocEbprjGw0tT+3HvZxtZXepkUJs07jm+DWmbZkL7kSKfzpgKvc4U0QU6kxizPe/g49xf7hwIkhaNJpI2c4Z4X4dCwy545wyhtjI54JTp+O39Y0SvGY/NLeXlUdcib/4sftBgg7y+RJe/gtJ5Av6IlXsmduOleTtZvkvkPL+zdA9TBrUiy2YERRFGNl/fJs4vXw0l84Vfgu33dcL3hxQWF9clHAtGVOo8QbLth3ZV1shScoXyL4QjZO/PhIYSUSlKKYDup8Fr4+KhoKveEB8Iex4RRcUTjGDRa5N31bUGyO0BO+cQ1eig06nMnF/D2X0upFNGV2zFX6B0HEttu1PZVAEvz1/DTzvFB6Bbnp0Xz+mLVpa56p1VrNzjxG7UcsPoTtwwqj2GylU4PhpLzbgXmPzqWkpqvbx/yVFc8ubK2A5WhlXPp1cOIc8cTSzPK2GRtaK3xg1QAH8oghIFa/NOibsCPpgm3JX0Fhj7sJAIHGiSA4gEYdFzguiBmOy+/QfGDqOTsmLaZVjwGzKxXr4IFj5FNOyjvvflvLAyxMtLN/H8jzuYMa0/V7y9kjtO6IrVqOX95aWYdBrk5gpBJCishltCVWDTpzDsusP7W/9CmPUaBrZJY0lxopFEj/yDXJ8jOIJfCWdjmDse3Eh1bZB/3d6VR5/bxo4SIfH+bl41N1zWgZPG5aLRyHi8ESQJLObErxdZlrCYtRiNWjZtczH8qAzqGsJ8+nUFF04pIKp6kYD09By+mltN7+B2Nk6+AlQVjdlE0fSHsI8YSs1bn7Djn08SDYfJnHAs/3nmIUKygelvlbBmQyNFney88Hoxk0alo/nxe+bf9mBsDN2e/icZk0/CnGpJ6CXZX/9bJKISDKnodTI6nYzLHeaL7yqZ8fYuQiGV/r1S+eeNRaTtJ/euJRpdYR57Li4R27DFxWvv7mZAbwc//hQ3frDbtLjcCp3aZeLxeAj4/UQlAw0uDXc+tA5/QOWmKzqyYEktOp3Mg3d057q71qKqkNYiTsHjicSIXjO+nFPJmZMKMKT9vkQqJ8uIJCWKRrp2tmEyHpFjHsHvhGgUNn8Gm2dD+2MFcXr7tPjv17wNF3wD1iwCYQV/WMFu1CX3aslayOkFy6eLNZgtF777p1DtlCwQztyDLhdVKOdumHUx1O0U53Y+AU54gvqAjrNeX09pg58cu5H7T+rGwycXYd42G9tbU2HyTJg+Qox56iyYMSIWQUB2Nzj7Q0ECW26Gh/0QDog1UIvql69JJmpuXjvV7RCkrb5YGL2d/oZwodQeZH7y1cPsK2MRUvgb4P2p5Fy1OuFhkgTpVj2h9HYYL/4RFv1HjLPP2fDN7UjFP6Jd+TrVw1/hztmlPHpaT56Zu53luxpwmPXxtZO/Hla+njiGgFOM/XcmewadTM+CFOZvi8+52r84gfs5ODID/5mwuynorvPxImdObeFQFnTB1q9o9Id4/sedXPD6Cp74bmuyS1BjmWigXfce0uq3sL9+DP8alYlfk4LaczLeCdP5Z/UITnxtK0SJEb0zBxRy89jO3DV7I7d+tI7LRrTnwmFtcQUi3PPZJhzRBhwfTARvLVVqKiW1Xib0zMUdjFDRIreu1hPi9YU7CK+aKfJNwkHw1EDddqjdBvU7wVNNKKJQ7vQze005by3eRXGNB7/XDT88KIgeCEnGZ1eLCagFqlwBvlxfwSsLi9ld5yUQCMDuBUmXU6reyAXDRDZZls3Asut68eFxbsxrXkVRo/hG3EPlMY+xKpDPp5ucsfGvLWukVZqFOz9Zz5kDCpEkuHlsZyGTVCJCLjLselFt1bSYKPYxePk9oNPITB3chqPapTX9LHH1sR3IS/1rNQsfwV8L4YhKRVUArVbCbtfFiF4z3v6olDpnmDUbnNz1yCbue3wz23Z6CLTo73U2hrjtgQ289GYJC5bU8eBTW9m8zcWYkdkgaXE4Mqio1TPt6jXk6AIU3/IAqCrG/Gy6/fAxs2tbc/vjO1mYNpgecz5Aa7NQ8/lcGr/8nhfeKGbuwhpGDMlk1pd7sdu0TB6XQd37sxPGueWOJ6jdU8+n31TQ6Arh80fYs9dHabmfsvIAeyv8BIMKtXVBNm518d4nZaxa76S2Pki9M8RzrxUTConS1Yq1Tt7/tIxwOF7KanSF2V7s4e2P9rByXQP1zhBl5ckuuOs2NdK3Zyo6rVgEXX9pB57+Vy9Wr3eycp2LiGJCb3DgD+qZ+WEZ/oB4jQ8/28vIoZksXFrHuk2NHNUvjdYFZnp3E32/je4wRqPMTVd0pDA/PiekO/Q/25Hzl8Bm1XLzlR0xGMTSon0bC1ee1+6AJjJHcAS/GpEA7Jwr/l00UfSvtUR9MTTupcoV4MEvNnPRGyt4c/Eu6r2hxMftWQRvjBc5dYufg7dPhRMeFfLIgZfAhKdgw8cw72HY/VOc6I17SBitzbqEvB9vYtbkLMZ0TqPSFeC699eQEdiF7asrRX7wroViLTf0GrHOCbaQRVZtFO9j0dPgLBWE0FUO9SXx9ZOvAV8gSKihDHXlG6hr3iHkLCfiroaPLhTvFUSl870pglw1IxpFcVWgrJqJsuJNlMZyscYs2yeCIxJAG3LTp1DMKb0LU1l/Y28e7rgF3cb/ErVkwNiHhCNm5Yb4eq1yHa2MPhp8IW79aB2XHN0ejSxx98Suor8tHBCy2PFPCslsS5j3Mbz5HZBi0vOvk3vQPlP0b1v0Gp48ozf2Q7S//K/gyAz8Z0KbYeL/qpJIIpqgagxMX1DMc3PFJLNqTwNrSp08f3Zf0iwGoQNf9goMvFjsNEVV2PQppk0fMmzELeCtI6wEGd/BQK3XEZvsUs06TulbwFkzlqA0hXwu2FHLWxcM4vN15VS5gnFpTlRBa07hzQsGUucJsqXCzcvnDuDzdeW8uVj0z+x1KajaMph+jJA2Vm2Cjy4Q5E1ngkkv4ikYxdkvr6CkyQDmqe+3s+K6XqLZd1/U7QSHyJ6pcgU499VlbKkUk+TDX23h4yuG0KP7aYn2w4Cc25NpbQsZ0CaN7qlh7J9MRSpbLn75/V0ETp/Fxd/LaGWZ587uy5nTxfuXJYgSJawIJ6rvrjuaTLsRo+KBzd+KsPWgW/RHnvEmvHcWZHZBaTWUP0KAlGkz8PzZ/fCHImhkGatRG6+M/gw0+kIEIiqydHiuVEfw94VOK1OQa6KiOhDfpW0BrVYiGFS46vZ4z8uSVQ2888IA8nMF6fD5FWRZ4t5bRDWsZLeXWV+Wc9qEfKwWLU5XGFmWOWZIBjarBmeV2IgqfOhOHninkY1bRYTChi0uSmvTOfWmy9l99+NEPB6ab12tTuLk4/Po1tnOj+saaXXfI3TVNLLtrMuINLpRPF5UReHx50twucOMH5XDfU9sYct2MZ8MHZDOTVd25Ks5VUx/K55JecnUNmRnJkt91qxvxOdXSNHJRCIq85fU8sgz22K/Hzsyi0umtk2qdvXrlUpaqp63XxzA7jIvAb/KedfEXZSHDEhj2KAMnnl5B3de3wVvk3OpJAmFGcCmbS4umdqWNIeetFQ9FVUBHvj3FtZtaqSoo43br+nMky9up2SPj+su6ZDkZvp7wGLWMmZENoP7pxOJqBgNmoRoicNFOKzicoeJIkLhj5DFIzggtEaR97b5M9HPtr+1k6ThojdWxCIYVu5uoKIxwA2jO4l+LV+9yIob+Q+RZxvywKo3obEc2o8Q8siQD7pOFL173qZWivx+Qvo46zJAVE8ydnzLvdN+Yu52sUkdbQ4eUCOoqW2oPX8pCyskPIEIo85dSua829Dt+Fo8xlUuiOTK1+DiuSJaYM794n1ZMmDKh+gs2eheGoo+0GTktCCb6MVzE/sNQVTMWpipKK4KNNOPFkQQwORAvXQBctujYfu38fP0FmRTCjOmtWHZrnpGFUbRvzoKXE2ZgAabqErOPE1IUk96Fj68QPxOEps8FY0BWqebmXfzCNLMetGnt2wGLH5W/H2GXifyi7+9E6XTeFRTBn8E5SpMM/P+pYPxhxT0Wjkh+/DnoN4bJKxE0cjSX8ao5W9V2Wv0h3EHfvtsjGBYocEbIrJPs4I7ED5oFkcoolLvDRGKNJ3naA3H3QPbv4O+08Qk1gxrNmr743jxx50Jz7GkuJ5A886yJEHP08W/3z5d7OyYUqHzOLFT9O5kdE8VMWTe2Tw0WKVHngWbQctR7dL5ZmNljOiBWJh8vq6c4R0zMek0RHVm6DUFIkFSbDb+M2c713+wlse/3cqZ0xdzVLt0+hSKjrbzelsx7PxayB23fQur3xRED4Qk4fPr0QadMaIHQjs9p9hHtM3RiRdJkiAj7vRZXOOJET2AthkWyiurCXY7AwZcIh5vsAmnUUsmaRYDQztkYAnVxIkegKqQtugBzu+TwppSJz/tqGVE50yybAa656WwsdyFXiNTmGamQ7ZNVPXclfDxRaI/MOyDZdNRXRU0TJvHhlEzWd3wx+0QpVn05DvM5KQYfxHRq3YHuPb9NRz10BwmPLOQn3bU4g9FDn3iMyEOHQAAIABJREFUEfwuUPwBQnUNqEpy3tivRajeScSdWIlTgkHxeuED/81DDY2E3aL53pGq4+E7u5GXbaSyOkCf7okOspdObcvCpbUJxxQlyvfz4/2lOp3EeWe2ZvpbJVx9+1q+n1/DHdd2JhqFtz4sZcply7nurnXodTKqLZXsKScBoO/SKUb0mjH3pzpsx4m5wppu49zJrdFoJFLtWgpyTVx9x1pefHMXdzxXzrPztLR9Rkg500cNY0OJ2OSa/XUFldWBGNED+Gl5HduLPcxfkvhe3ptVSuf2yT2xA/ukYjaLxUJ9Q4iX3owTRJNJg1mrYgh6ePaB7jia+vsG9HEw7YxWWMxa8rJNtG9l5cUW5wEsWl5P21ZmgiGVJ1/awWkTRC/P5JMKmNN0TYcMSKddawtpqSJk/c6HNrJ2YyPRKGza5ubBp7Zy5/VdeP7h3qzf7KLR/cfkQhkNGjLTDeRmm34R0XN7Inz9QxXnXLmCUy9Yyn9m7MDZGDr0iUfwuyAajdLgC8Vkg78lfMEIDb5QkgmR0xfCEzzw/eoPiTWXqkbFd37n46H3ObDxY1FxarkhldubkDk7RvSa8d6yPbia14OSRsg1qzbAGycKaWOnceBoBRXrREvNM31gzUzR29dtkiA2HUfD2vcTBxf2od+7mC65NhwWPVFzJuT2gkAjNfnHMemdvdwwazv//KqEUTO2Uj78YVHZ0uhEdl7ZCrHWcFXAT/+JR1J5a+Grm5Hrtgki1wxPFWpjBeT3TRyHySGczpugrvtvnOgBZBXRWLMX70mvCLIMwsnzrPfB6CDDZuCEHrlIO+bEiR6Ije4174hq5sZZQv7qaIOa148Sn4FgRKXAYcJh1lPgMAuZ6e7FIow96BbE77u7UPIHUDvtRxZ2/SdV4YO7Jf+WyLAaKEwzk203/iKit7vOy7RXlzHowTmcOX0JWyvd4j78k+NvsV3mDoRZV9bIsz/swKCVuXlMZ9plWjDpf/3br3YFeOHHnawudXJcURZTBrbCpNews9rDE99uI6SoXHNcR7rl2RMy2WrcAV5eWMLS4nqGdczgvCFtyDCaoNtJ0O5o0FngisWw8RPhLNVlPI2kYtZpEyx99Ro5vtMuSaLnbckL8QEueAJ6TIaPL4ZmslO3k7SPJ+M5cw6vnT+An3bUYtAm3/TpVgNmvczHVwxBMpph9H3Q4wzqPCFW7o5LK9UovPDjTi49uh0W1UWn2u+gtqlHxZoFDYmOefjq0USTJ/Jvt7k4ceItaOp2QMk8oQk/4XERdN4Ed4v+u8sGZ3NJlyBpy26FTcAxt8LwG8R1MDkSslfUUGKzMQAhL6YmGdX2Kg/nDm5DulXPzf9dR5pZz+On98JubHGPlMxPegp5y+d8WjCAu7/Zyo2jO9G/dVrSY/5s8AUjPP7NVn5schutcgW58I3lLLjl2N/kM3EEPw/+skq2/+t53Ou3kHf6CeSdPRFDxq+/j0INjdT9sISSp99An5lOlweux9yukFCdk5J/v0r9whVkjj2a1pdNwZAVl9GEnS4aFq9m5+Mvo7Vb6Xz/9Vg6tibXHOKxyzKIakP0vqYDW4p9bN/lZcSQTLIzDbz7cWnSGDJaWO5Ho3DvY5txe8VneN2mRmZ/Xc6xw7J4/b34HPHurDI6trPS9vLLaJufg0anQaOREmIbLBYtEtD5mXtJHzcSTaqJmc/3J6rCY8/tSBjD0rWNXDm5O/nXXojtnLN44HExzhS7jgZX8jy0baebtNTEjRuXR8Fk0nDj5R154fVi/AGFoQPTmTQ+P6FvOtAUDp6TZeCJa/Kon/EGGyevI2vCsbz/xOl4dTYMejnBzEYFAoFkdz9FiSJJEnX1IbIzDTz3cC/WbGxk1XonY0ZkMWJIRkyaGQ6rbN2ZGEVRVuHHH1C4+o616HUyE8b8vj0xvxXq6oMJ1dEvvquiQxsrp4zPP+LQ+QejwRdizqYq3l1eSqHDxA2jO1HgMP9qSbCqRilr8PPkd1spbfBz1oBCjivKRpYllpXU8/KCYlJMOm4a25k26eZ4Ri6wt8HPU3O2sbPaw6Q+BYzvmYtWTsF11D/RRnxYDFrMly1G3vQJUkYnaDscp2JLGoPDoo+HfetMYq21qUn27a2Fz66Ba9fDzEnxvrqyFfDNHXD0LTDlA6jftV8JomzNYnC7dKYOboPGZhK9ePW7mLe9nr3OuKzbF1J4cbmTe4ffhj6rg/ACaK7G6S2imtgSNVuR9cnESC1fg+bUV+C9s6F6E9jzRc9ey7EF4htmzhNeYhE9eW2Okwzbdm4a/TKtJgbQoYI5M8EIUA0kbrQBovJpED4B0YZdKMc/TpmhI1fN3EGrNDPTp/UjvbkXLhKCDR8lP8XW73igfgKfrNnJzIvSKUj7fZ3MfwvUeYJc8fYqNpaLa7Kj2sN5ry3j06uGkmk7tMnL/yf+Fiu7HdUezn55aeznhdtrmXvjCFql/7q3X+cJcmELacCaUie7an3cMLojJz+/KFYpW7Szjs+vHkb3ppy8Bl+Ia99bw6Kmfrk1pU62VLh44qQOpDw3CJSmXUydGS76XjTuAraIyj/GF3Hbx+tjY7h2VMc4IVFV2PJ58kCjkWR5pK+OXKOCyWSmY1Yb/GGVmUt3xyxzs2wGTumbz6dry7l85krevmgQZkcGtB9BZI8z6SX8YYV+hTZyv7gyrp/PKoKC/smWupld0OrN2E1aXP44eZs2pDUaezqc/nqTG6dGEL0WDcY98lNik8iFPXSkvTU6boNc/ANcvli87j6QHG2SAt1dfa/g/Y2i4jGpTz5Hd8qk3hvilfP6o5EkHBZ9YqxETs+k5/Vl9WZNpeibPKbz/rN8/mzwhiIs3J5YuQgrUcoafOSk/LknrP81BKpqWXLcOfiKBQFxLl1LoLKWTndfhcb46/4W9fOWsWryNbGfa79byDHrv2T1eTfTMF9s/DiXrcO9aQc9X3oAXYpYEDWu2czyiZcknrfhKzbe/DDVn3wXO97q0rM498Gb0NlFxevkE/L5/LtK6psCyPNzjRzVP77YCAbVGNFrRiQSTaqiAaze4KT/2W3RX3sB0VCIaacX8tp7e2K/v2xaW8rDKh9WFNFjnpuzT0mlMM9MTV0woU8wBquN0pGTeeqBXQSDKhqNxLUXdyASSSZZQwem43InjnNQXwc6rcQJo3IYflQ6URWMRhlbi8Bwo1Fm4thcPvh0L9dNzmDPJdfhWrUxdp19O3bT9am70NkSF2s2i5aTj89NiJFo19qCyy2iGrp0tJGZbsBo1JCfa+KE43IwGTUJQecajZQUSm63aQkEVCKRKEP6p2I0/DVcLtduakw6tnBpHccfl43V8vfor/kzQFGjfLGugjs/EQ68K3c3MG9bDd9cd3QsGPyXotYT5KTnFtLgC8ee+/6TutG7MJWL34z3kM3bVsMPN42I9aRXuwOc+sIiKl0iXHzVHidOf4jju+Uw6qn4edk2A59fcwOZNrHha/KFOHtQK95eKuYQWYJ7TuwWl+AFXbBzTuIgo1FRifLuMz+VLoWMjoKMFQyEDiOFDDLYRIpye6NkFqGUNHLBa8t555JBZNmywJpFcO+upGvhCUVRiybC2yeJiAeALhMEmdo3SL3jGKLWLCRZE/d00BqQO42GtDYw7VNQgiDrhElLS1f03mfDkqchvy+L6ckVH8fVBPO21jD3xmPISUnu/Ze7ngjzHoiTUEkWzzX7SvFj5+PRpHfE4gkx+8ps9BqZdKs+Hnmj0UHhIFF1bQFfZh82bXShkSXaZfzCrL0/GCFFjRG9ZlQ0BvCHk79H/mz4nyd7oYjK64t2JRyLqFG+21TJhUNaga9W7FLoLE1l78OfxHwhJUkaMHvNXi45ul2CJBLg9UUlPHxqT7SyjD+ksGhnHbIkXCjdwQhztlTjP741KUpIVKRkrZA+/vAgnDoDdGb0WpkTeuQyqG0aa8sa6ZpnJ8tmiLsxyTK0HyN6/zI6iwpXxTrx4czuLiQKzdBbQW8mGgWLQUuKWWbWFUPYsNeF0xeiMM3M1e+sZlOFuLFX7G4g3yF2XvJSjRQ4TDFiCHDJ8HZkp5jh5BdEBdFgE7lz1izR1/bpNWKSzO8Hk6ajtWXy5dXDeGl+CfXeIBcMa0uHzKYPvPnAVY1Uk46PLh/CspJ6Ure+kJh3E43CilfhhMeSzlPNmYTO/Ybo0pcwNBYT6HUui72tWFe2h5vHdqZfaxEKfVBnpvQO0Pdc4YwKkNeHuqJpzH9jO3dNKKLVX2BnCkQGUM+CVMobK2PHJAlyj5i8/OGIOF0xoteMspmf0Pa680CnQ1XF/S3LMppDxa60QNjZyK5n30o4pnh91C9aScSZ+GVVOetbuj15B7oUGxGvj11Pi/tbYzETjURQgyGqv55PpLYBJAmt3UrE7WXPS+/S4dZLY2QvM13Pa0/3Y/M2N3qdTIe21gSnSpNJw+kT8zjlhFy0WpHJtmx1I3k5Rj75qiJhTP17OrDbhGpBthk4faKRkcOy2LLdRX6umSUr63n0ObFwK68OcuLoXNIcehwpOs6YmM8zrxTHnqtNoZmUVAPDh+XSsZOD0vIAPYrspKboCAQULj6nDe/PLsOgl7nivHbk55qZNrkVrQvMLFpeT+8eKYw5JivmeGlI23+Pht2mZ8ophRQWmGmfE2RVE9Frxt53PqPzAzcmkT2LWcuJY3PJzjQwf0kdHdpaOXpwBvc8ton+vVO57erOpDZl5B2IsKXa9dx7SxE337sej1dUIW+6vCMffr6Xfj1Tuf6yjgnk8M+Mzh2SqzA9u6b8Zcjq/woafCHeWpyoynH6w+yp95FljMZ7wvSWw7f5b0JJnTdG9Jrx1pLdSRb4wYjKoh21nNa/EIBad5BKVwCtLGHSaXAHI7y7dA99W4nvb5NOgxqNUuUOMmu1WIsBpJj13DSmM1MGtWJ7lYd+rR2kWVoQEr1F+Bwcc6vojZO1gsAZrGIt09JIJasrfgx4VBuZFoM498plKKXLaIhaqdC15oKXt8TM8xp9YRE7ABxXlM3DX23BGxJETZLgkqPbYbQYRfWvdKlw+3S0Ecqmcz+F2VcJg5ZO42DcI0gGC8olC5F++rcgUkOvR2PLFWOzHnjDOWTOQrloPoH6vby+MHHd6gsprN7j5PgeyWuAkDED5eIFaBf9B03EBwMvQtr8BSCJ6qE1B0mSYsQ6CZIE3U8RVdM9iwCIFJ3MLkNnnL7dzJjaj9S/iEmKVpZpnW5md1284uow6+L5iX9i/DVm/18BjQy5LaoVA9o4uGlMZzSyRGmDD9vOuaR+e42w3J34tCh760xCOtkC0WiUGk+QGndQkCOTDq1GQiNLCcROBFsn63fzUs3ITaIBjSxx7uDWTOqTT40nRIZVz0cry5AkmcCF89FYUkFVURQF486vhRtUE+wmHXaTjraZB9gJaTtUSDabJYedjhdNxae+DDNPEQ3ABjvO8S9x7xd7mFe8kZkXDqRrXgqZNiOD2+t4dq7ox2uJlkQmy27ko8uH8ObiXeyo9nLWwEJ6F6YiazTCPrfoxMQxOdqISUEJURe1srHSy5Z1uzi2cyY3jemEQac5sHba7xS9f03X1OQqp7U9l+wemWhWFyQ/PqVwv09j0GkgrQDPiDsIR8IYtBJ9AyrfXJWLwwi6w8mes6TD6HvhmFtAiaDozJiw89W1OaSYdfuVwh4K/lAEdzCChERGy92w3xE2o467JhSxo8bDjmoPBq3M3Sd2I8X4Pz8d/OmgMcXnJo3VQtcnbsdW1IHg3ioi4TDOaIRwOEx6ejpmsxkkCY1Gk3SfhOqdhJ0uIi4PhpxMtDYL+pzkPDlDdgaqL5BwTGu3xnaAZa0We5+utLr0LCRZQjbo8e8pR5eWSt5Fk2n31vOEwlEMegn37C+QWlS+JUki3WFg2KADkCGrhnNPz6ahvppwIIpeo+HU8bkEQhLHDc9kzgIhKz52WAbdu5jYs3s3KSkppDoc2G067DYdRqPMuVevxO+PV+/ysk3o9WIcWq3MuONyyM0x8fWcStq3tXLyuFzSm0hnaoqeLh3jMSVGg4YppxQyYUwu0WgUv1/h02/KKcwzMXxwBmNGZqPXyfuVD6qqGiPjqtuLf/deTDYr4/rbUAMykkZDtEUPpi4tBQ7w8c5IM3Dc8EwG9nNg0Mn4A1Eev7sHOq2E3X7ouUmjkejSwcbM5wfg9yuYjBpkGXp2S0Gvkw+Zgbg/RKNRlKbxy7J88OzU3xC5WUamnFLA+5+UoajQq1sKk07IQ/sXWFD9L0GnkUiz6qFK/DyxVx7nD22DGo1S4QpgW/kK1sWPQZeJMOY+oUQy2JIydEMRhQZfmCpXgHSrAbtR27ROSkS61UB0P61PLUmE2aDl5rGdGdwunQZfCLtJxyeryzDpZJZc1weHNgySzF6fzPbGxPvFYdHjsOjplpey70uINV+fc8QaqXa72CAffBVojEJp9OEFEGgEWy51415g6pvb8YcV3r5okKg62nNxtz2em99fww9bt8aeVpJI6KnPtBn46trhTJ9fjDsY4eLh7WibYQGdFlILxX8tkdsLpn4MUahRrSzZ2UCd183oojZkjH8Gg1ZKaFdJgLcWVIWgpKM6ZMQVUMi0tkVvb03Gms37uf77n2csZjOKoR3+0Q8jASYCSAPzhEOpMeXgsVjNsGbB5LeaQu9lVI2ZwqiFL64pJM2sR6P5+Z9tlz9MIKKgkSTS/yCTlAyrnufP7st5ry6nxhMkxaTjhXP6kfYXUBxI+zbG/pXQv3//6IoVKw75uL0NPmYu3c2ITllk243MWLCTt5eK3fRzB2Rzfac6Ui1G+PZOUUbvOAbGP5GQ+1Fa7+OUFxZR4w5iNWi5Z2JXBrdLZ0e1h9s/Xk95o1hAPXNWH4Z2SOeU5xexq4n9Z9oMfHbVsJhEzhOI8O2mSm7+cB2KGkWnkXj6zD6Maq0hOv9x9CtnQFRFaTuC6KTpaO2JgaDeYARvMIJZr8Fq3OcmW/EafL5P1tvkmdB5PPhqUIJedjWqPLWojs82CHlCxywr715yVEzSsLfBx8nPL4rtTI0qyuKRU3smfKBUNUqjP4yiqpj0GiyGQ9/s9d4QN32whrlb403C06f2Y1STVj8JrnKxq7VrAeT2hNH3CyfM6s0w7TMxMb4yGpxN8q6UArhozn7zWqLRKBWNAV78cSfn9bbSZuFNyDuaJGm5vcSumjXrkO/ht0SdJ8hT32/jo1V7ybAa+Nek7vRr5YhXan9n1LqD+MIKeo1wpTL9zoHLhwtJklZGo9H+/9/j+DU43LkpUFNH2asfYevblZT+PWhctpb1F91BsLIGY2Eug+a8hSYnA4/bjcfjQaPVkpmRgcFojC2+Q7UNbLr1Efa+OQuAnFPG0uPlB4mqUTZcfAeVs4TTWuqg3vT78FnK3pzF1n88ERtDz5cfJP+sE5H14svev6ecJWPOxbdTfK4yjhtCzzcfp7gabn14K87GMKl2Hf+6uSNF7S3obfHFXUuCoNUm3seRSITSPXsSzBj0ej05ubn4/FH8AUUQKCVAKOCMPa6goAC9Qcw9je4wL7xWzOffiaq0zaLlxcf70LogcYGpKArBkIpWK6HTJpPj/WH1eifX3ily6wB6FNl58B/dcKQkL4IURcHtduNsENVOu86AZ+5S1l9wK/lTT6bLQzez+7mZ7HioqX9akujz9pPkTBqDrE3+fDe6wixaXkdFdYBW+WYefGqLINUGmUfu7E6fHql/aL+aqqoEAgFqa2pQFAWrzUZaWtrPqi7/Gnh9Ebw+RYTXG2VSD4Pw/lH4O81Pm8sbWbxlN+M62THqtNz05V7mbq1FluDhCW2YYN6EWSvB3PuF+Ufvc8RmqCW+0bR6TwNTZizFH1bItht4eXJnOqVr+HKrh7u/LsHlj2DQCm8Ah1nPuP/Mj7V3dMuz88YFA2Nrk2pXgBkLipmxQEgQ7UYt71x8FEX2IHxyOZqd34MkE+59LuqIOzCkJH6nu/xhAmEFm0mHqeUGc8gLX94iDFha4splYrPa30Ak6GNzbYR751azYo+ojE3qnc8Dk7pjafrOXlvq5MzpS/CHxRx4zbEduOjodthbrNPCioonEEYFLDotxsP43q1xB5n80mKKm0ztDFqZz68eRsfs5Co4qiII6yeXQdVG1HbHUjn8IU5+q5goMPuKoQQVlROfWYinyf+hT6tUZkzrv19nyWBYobTBz4vzdnD78DTSPzo9LjftepKIUrAkbyz+nqhyBfjHrPXM31ZLx2wrT57Ri/aZVrS/gDT+XEQUlXpfCH9IwajTkGbRofuD5sVD4WBz0/882VPUKHvqvLy3opQ3F+1Gr5W57Jh26DQyD3whdjd+uG4Ibd8ZIshFM7qcCCc/D0Y7vlCE2z9ez+w15aSYdLxybn/eX1HKwu21dMmxcdeEruyp89A200a6RY/VqKPGHWRrpYuwEqV7vp0MqyG24KhyBRj1xLwEo5VueXZmn6RD+9rYhPEHR96DdujVaJoWCFWuAA9/tYXFO+vo0yqVuyZ0jWeshQPw+bWw9r3EizDkGhhzPwC7ar2MePzHpOu07I7jYjr8aDRKpStAudOP1aAj1axLkFf4QxFW73Fyy0frKHf6Gdsth/tO6n7gMn4Tdtd5OeaxxNdum2Hhv5cOJmPfc3318MFUkUvTjJQCQcLfmSw08+d/A1FFZL2gQk4PsGYTVhQavGFqPUEcZj02oxZfWOHEpxcyvFMGd3cqxTb3NuGoJetEn2OfqWIn71fuXgfCCo1+8drpFrGLuT/yFlFUXpy3k8e/jRsRaGSJ+TePJN/xx8gpQxGVRn8YvUYi5XAqm38Q/k6LqXAwSERRqK2tJRwOYzQasQUVlgybTKimnlYXT6bN/ddS40zsk23VunWMTLk2bGNBH1FN7/zQzWSceQLuqALRKKmpqVDTQLiiBkunthiy0gk3NBKsqsW1bispfbuhz0yL9eup4Qhb//lvih9PzKrqt/0nrrxvB1U18Z6wdIeelx/rSWa2kCUqioLP68XpdCJJEo60NIxGI5qmClc4EqGsrIx90fxeFEWhsqKCYDAxOzQrOxurNa5kqKsP4vEqOF0hcrONOFL1CSYpkUiEmpoa/D4fWq2WrKws9AbDQStTzsYQt9y3gU3b3AnHX3+mHx3aJKso/D4fFRWJ0tN0rYFVY87DV1zK8FWfYszPJlhRg3vjdlL6d0efkYbObsXZGMLtiaCqoq/OatHy9od7+PTbSh64vSu33reeft3tdMzTsrk0wqYdXmY80Zf0tF//GW1whnC5RYC8zaqNyUP3RSQcZs+ePQnHHA4HqQ7HH6I+APE3UVVhpPNnMmb5u8xPgYAPvbcSae79SJtngy0X56gneHJrOm+uqMaok/nxusHkPNs2sZ1i1L1NVTEttZ4gZ05fwo5qD+0zrbxzeh4ZC+9GU7maaLuRhI65k/kVGrrn20m36NHIMnWeIGvLnKSYdLTLtCYQkLIGH8Me+SFhnJcOb8PNaQvQfnNrwvHgOZ9h6CAce1U1yp56H3d/uoFtVR5Gd83mmmM7xtYdEXc12rdPgcr1Cc/Bme9ClxMA+GFrNee/tjzh152yrbxzcXyjPBQK0eALU1rvJctuIsUgk9JCtt3oD/Pl+goe+XoL/pDC1KNac8XI9iI66yD4cWs15+3z2id0z+HxM3ph3tdUzV0FLw0XruFNUNuP4r1Wd3PHV6Wc2CuXhyb1wBtSWFPqJM2ip22GhQyrAV8ogssfoc4bJMNqIMWko9YTZNxT87lmZBvODb6HofhbPJ1ORhP2Ytr4Hpz6KrQZetDxHxYCbtH36K8X/Yb7+DU0w+UPc8MHa/h+c9zpOd2i56vrhsfksr83fMEInlAEs24/BZf/Rxxsbvqf122FIwrLdtXz0jzRw+EPKzzy9VZeO28A2XYDVa4g1e4gbaMt4guiUdjxrTAJkWQMARe3DE2hnV1CMph59acSvlwvdpYrGgNsr17GrLNbk7nzc+h2MpBBps1Apm3/+umIoiYQPRDyT2nfcEvAULaIUOgiNFobDb4Q1723hsXFwtjlqw2V7Krz8v6FA7CHKmH1TFGV3JfsFU2M/dNs0JBpMySEsQ/rkI6+xWKpyh3g+01VFOXaqfUEWV5Sxwk9c2MTUqM/zHmvLSfUFDXx1YZK0i16/jG+a2J1SAkLGabWAEY7YSV5Y8EXiqDuR/ZKJJhI9ECYq+ibFl4Nu4QlsS0bOhyb8LDNFW6mzFiKJxhBluChST3okmvn6Sl9cPrCmCLbYdKLIvclEhQuo746Efgp/3I5gKJGWbW7gfNfX04woqKVJZ44oxdju+UkyVQb/WG+2lCZdP66MidGnYReq0lwb/2tUe8N8urCEmavLafAYea+id1om2H5Q3bGjqAFZJnKvXtjVaxAIIBsNNH25ovYesujeLYUE95HdgkQCgbRaDQoioK+VS59Z79IyROvkHXGCdQG4720NTU1ZNlTqfvoGwy5WejSU9E5UtA5UrB2aZ/0vGowiGfj9qTjikIC0QOoawglfKZDwSA1NfGqfVVlJQWFhUTqGyl/9zMyxo9AluWY9BHAZDbHyIMsy1gsliSyZzDEP5Mud5hlq+tp38ZMukPL+s1OijqlkJdtahqnQl1tLX6fUFVEIhEqKioobNUqiey1lCiqUQgEk5vsmwPU94XH40k6FtRpSOnfA19xKb5dZdh7dEafloqtW8fYYxqcIe56ZBNrNojKQIe2Fh65qztmS1MYuU7m3ze2wvfxJ/jeXE7PY4agv2o8avTXGwDUN4S48Z71bC8WY+/dPYX7b+2633iEYCg56sDr9aLVW1BU6XettPkDCtuLPTz7yk7c3ginn5jPccOzSLH/eRZVfwdowl7kJc/HjTUay0iddTaXn7+Md1bVEAirhMLhONFrXjttmg19poEs44h4eX5iHq+ucjKpyEb2p1NEODggrXkbvaeatP6PsWYMRE6MAAAgAElEQVSPylHt03GYNWTZjYzuun/n2H37/ABsuijaPQuTjkt7lkAT2avzBpk8fTFVLjG3vLl4N76gwj/GF1HW4GNliZOzOhyPoSXZk2SxgdyEztk2tLJEpEXbzuiu2aS0+J7WN5agK9tGflpnNPUlWIIV0PHYmNSx3Onn9hYGey8vLKFrnp1T+u7TkhL2iz7BJm8F735iL7whJckbAhAeFC2IHoBcPIdBQx8FoLjGSzCikm03MrZb/DoHwwrfb6rmhg/WEFGjGLQyH10+hB3VbmZedBQhXyNBb09W50/hxeVO7AaJ6049j0L/1l+fkRf0wLr34KtbxP2kt4p+xfx+SQ8NRJSYk3gz6rwhGn1hZAkseu3v6ipe7Qrw2LdbWbSjjt6FqfxjfFG84PInxt9gZScl3RgAS0vq6JqbglmvoXWmFW+3KVReuJIdU1dSPW0BkV5Tm6pG69C4ysinlquKvJzbO4VvNyZ+kMoa/Hj0GUQ6jiVUukrcuL46ETlQX5Lk5mTUaeiWl6hzNuk00HafjDkg1PF49CZBcAJhhcXFdfQqSOHMAQX0b+1ga6Ubc6Re7OQseFw4eQ6/SWipTQ44/tGEnLp0i4G3LxxEtzw7sgQju2Ty9Fl9YjKDaneAcCTK/O21nP7SYi55cwXekIIvpAh5gLsSR7iKd6a0pVdBXPv+47Ya6r1Bgk3yBby18NPT8MYEEThat5NUk5aOWYm75BcNb4fDrAdPjbAMrt+F2rgXVQlCWrvEi9HScrjLhKTeABAuXzf/d11MnqBG4eGvt5Bm0XP37I386/PNSPl94K2mhuFtXzeFonc+sPYdQc5q3AGCkf3noIUiKlUuPzd8sJZgk8NfRI1y+8fr95u1aNZr6ZqXrHVPs+qZPr+EGndwvxP8b4FQROWVhSU8+8NOSuv9LN5Zx6kvLKLe+/tkWUWj0aQcpSMQUFU16dr4gwEcQ8XmXP45J6OxWcjQGUkPRcmS9di1erSyhoDTRaC8imBpBbYenenz/tOE9yMJ8qsRCs89hVBdA6HqOiL+AIHyKjxbiglUVKME4393rdVCwXmnJj6BLKM36pKkknk5Rpr3MKLRKC63WxA2qxWLxYIkSQQbXWz9xxNsuvFBNl7xT9J1RvRNclGTyURmZmZMGihJEja7HZvdjiRJaLRacnJzkZvcfL2+CIqqMrC3Gb1cT8hfRVF7FYtJIhCM4HL/H3vnHSBFmW79X1V1TjM9OTAMcYAhZ5CMCAqIYiSoqKCYI6ZdWcO6mNewRkwogq6KAQysKEEkpyEPaYAZJvekzt2Vvj8KZmhh793g99377e75C2o6VFd3v/2e5znPOTK+ehkNF1Z7i7xJ13VkWSEcltF1vVmiWF1VRWVFBcFgEI9LYurkxA1XVoaVzHQbsj9IpLSCxm17iJyoIlpVi9V8JtkxyQqR0gpEi5mk3l3P+n5v393YTPQADh8NEY2qmCSB+x7bgzkWxPfbRyl76hXq1myi9PEXCDzzHHb1TMJ/CrKsUdcQJxD867lkobDCDz/VNBM9gKI9TWzbdaazMoDZfOb2TTKZWbepnoOHg/jqY2e516+DxiaZ2x8qYt/BAGXlEf74xmG27mz47+/4D+L/h4ys/wlIumw4XJ8OTUGqP0y620rbNCd2s0jTuc9SMbOIozO2Uzt1uWEkoivUVldQ2hjDZTMzZ4CNwkxrM9E7BeHID3TPtNAl20NxZROapuMLxjjmC1HeEKExnPiblOm24rEnbuRdLidKwYQzzl/seG7zvwNRhZpAjKEd0riyXy4FmS42H6ujJhDlolfXMW/5EY62nYrc82pjH5Dc2ohWOM0sLtlh5r3r+pOXYsciiVw9sDWzh7fDLAlGNcxfQQXpXL8+hcGvH2LCJwE2Cj2JqBhF5UAlrcQ63rmsLa1OU+98u7uScNCPfMoZOFAN38+FBRNg+QPgr6Rfm5Qz5hxvGdket0UyMvkqdxJvrKS6MURctCVmNAOkdaKs0fjOTu6de1ZDlMaIzIOf72omszFF4+UfD9Izz8vMBVv4ZFcD+92DmPLhIVYfqGXprhomvHMAX+Z/09UL1xmh9H8lQzYSV1AjTbD8wZbCQTxouH0Gz9y7S4JAwS/kqxZJJKpoLNxQSm0gfnYS/CugMRzn3k938unWE5Q3RvhmdyUz39+CL/h/aT3Ufj2Xz3/5zp7VLNK/jfeMLkphtofyxijzr+7L0Zogx5KuYu7rB1A0nWSHmcXX/4ZCLQQ/Pt4cWyC1GYZn0p+YObQtQzumYTGJSILApqP1pEhRTF/ciDLxRTRNQfz+t1D0kfFkrfrDlMXNM2GpLitvXd2Hx5btY3tZEwPbeHl4QhfqZT/J457GvPoPoERQel5FrP14VNmYi5MEgc+v7USb4E5SyhbS0HsYdRcMRSjf1uIW9eUtxqDxtE8M2aPFDfYWUiaJAgUemQ8uzQFzO2RzEn/eXMrx+giX92tFQyjOtuONrNhnENpQXOXJ74o5p30qaYFibJ9OwxqopJ+3De9O+oBrlunsrfDTJdvD9/uqMYkCozqlkXP0W8RVTxhf3tpiOLGJtJs3smjWQBZvLmVfhZ/JvXPpkOHii21lDMsVSNv4J8zn3IwYrDbC4K9aYgSW/vQMSBb08c8h7PncCJwfPdcYBv8FNF3nWF1igLSOUfkprgowsiAdde9SJPW0HxFdhy3vQHYvQ7uvxIwqpTMdVYdjdSEeW7aXo74QE7pnc8Owdgnzi3WhGAs3HGd4x/RmS+hTCMdV4oqGL2BIU2oCMYYXpJPmtHD3mAK2HK3nWF0YQYDpA/Mprgzw5k8lrD3k4+0Z/ZpnAX5NNEbifFVUkXDMH1U40RD5py21T4esqlQ3xfhgw3EUTWPGOW3I8tgMs5z/AADpLNJCi9VK9MQhOv7udmy5GZgaAmw6bwaR4+UgCLS981qcd19H7Y/r2TN7LrosY0py0//bd3H1KECIyZhVDXRQzRKS2ULpq4vQVIV2d1yHf8c+No27Fi0aQ3I56b/0TVLO6YNwknSljBhA4R9/y9E/vY/J7aTLUw/gtijMe6ATjzx/kMPHQrRt7eDxewtwizHAKOBYLHYicQcffVmFxSJy0flZiFqUEwu/BKBu5UaKJt9M+7m3kXfeUASTdNYZsKSkJDxuN+Eo7CkO8/2aUrp19tClwE1KkkSgqaV4Fo1EkEQ/suzh2dcOsW5zPRazwDVXtOa84V5iEYMk+IMab35wlNnXtCHVa6a6qqq5s1dbU0NWVhZDBqby/GPd+Wp5Jfmt7Fx0fg7biurJ9gpYdhfh0KKEj57AnpeF2ZtEmt1OoyajKAo2mw2xPoCuqgxatQhLmves7/fho6EzjoXCKotPZhQKsSh1KxK7FNVffk+3P/4GWdHw+2UQwGk3YbNJNDbF+XRZOSvW1JCdYePu2R3Iy3U0yx5jMZXDR0Ns29VA6YnIGc99qCTIkP6pVNVE2barkc4dXeTlOHA5JZKSkmhqMoipyWQC0c2f3i0iEFR489nepP0VV9J/Flt3NqD+Yo/z9YoqBvZJ+VUdRRua4mzcVs+2okZGDkmjexcPSf+LZgP/pyFaPejZPRHqEnMrBW8+PVoFmDsiDVPcz/O1/fngm30A5Kc6+GjmLYjhCFM+rW72LbimfyZ3jc4l2mcWTT1mEdbNOPUQKeWrqQiL/OabXbxwZS/8UZnZH2xl28l4p8m9c5k7sbDZJTvFaeGzGwfx8NJ9HK8LMaFbJhO6ZRGWR+HsfyPS9gVgsqIMu586Sw6n3A6cVokfbiwk/cT3eHw7qDt3Mj53ZxZvKkXTDUv9S98/yI2DZjF95v2kOU2GG+ZpBWWHxcSQHJHPp+VjttjwmGTEn38Pigx9ribcWMPD6x0UlRnnXhuMMevPxSy/cyi5h5dh/vZu3DE/5+b2oXDq20x8v4S6UJy+OVas658nmj8SObMb9nXPImx5y3hS30Go2UfatCV8e8cw3lpbgi8Y47ohbQCBpbvKGZQaJX3zqxzt9wj1SgSX1Una7L14f34c2873we6l6YJXeX9NkLvGdOSSPq3OaogSVzSjqH8a/FGF9Yd91IXipDqtvLMhcd8QkVXWHK5nygA39aEYiqpjEkXD2CcehqpdRi5hzA8DbzZGZ04j0DWBKC+sOMicviZStV8Ut+uOoOsatf4oG07GlA1un0q628pzV/Rk+lsbaQjLWCSRh8Z35uPNpSzaVEppfZiHLuj8q+5lTiEqa6z9RWzV/soAkfjZiew/jFgQGo8b6jN3lrHndWcb+9J/EP/yZE/RdMZ1zeL7fdVsLKkHYHKvHAa0sjMk2YRsi1OjOJm7YHtzRaMxLHPf5/v4YHIGqafn0x1bC8fWcmX/S7jizQ34gnGsJpHnLumCpXwTNRd9yFd76jlaV8rUrnNo4ynA/dNjRhTBni9g0GzjcSKN5Pz8KM/ltSHSuzuOmlW49q7nW/el1MqjuOzGC5EE2FweZ9U6H7+ZcJIkWmRSS95C2vwGAN6dH5PU7TKEYXNazlHXYPsHRoBmcmuINMCYR40uX8gH8QBEgyQ3lVOXMYjL5m9ujlD4eEsZ86/uS0PkzA5PcWUT3fc/ZoS2AzQcI/WbmfxmxEJ+873CzSPbc9PCbdQEYrw/oxet0jqi3bqFhlAMMVSD7kwjHLdjNcM1A1sTVzVMosjO8iYO1IR4b0MdH02bS7JaZ7Ty60uMnL3h96Pfvp2wZkIRzNjzR4LNQ5MsojQEcdutyJoOqoJXiuCWYzwzuTN2q4X2aU7qQnF2VwSaq7cpLgsxawoWu9ewWpbMhk6/4AJjcVr/J6M7anXTWHgVYbOX9Yd9lNSGONEQ4Y01Jaiqzr3jOmEzSwQiMjtKG/hw43GS7GYGt0ttltkCtE93IokCV7+7if2VBiG3mkSW3TaUgiw3n940mJiiIasa24838MASQ+Kxr9JPTNHwBaKknaZDj8lqs+jVH5UREEh1Wv6ukFuLJJLndSREZ8Bfd+P6R1HjjzP2xZ+af0AWbSrl+7uHk596ZijsvzPS0tKoq6tD13UkSSIt2Us4LxtP53YE9h/mwMPPG0QPQNc5+uJ75F17KQceeAZdNro5SlOA3TMfYMB373LknnnULDUyo1LPG0KXJ+8jdcQAtJjM/geextW5PQO+fovtU+8iXltP0TVzGLJhCbZT7p0uB/ZLxtB74kh0IGY1ocsKVbfcz5PPPYqYnIzW1ETpHfeSPf8PgNGVC4RMXHfHVmTF+IR++V0lC//UB0ual1iVUaH1F+2n6Io7GFb8PQ2CSlZ2NhaLBVVVm7uccjyOjsS3P9by+gLDiGH5ymp6dUvi4bsKzrh+sXgUJWpj3WZjfY/LOm8vOs6gvj2xW0zY7G6+/K6S71fXUFUT5fcPdCYzK4tYTCMUUbHbBPwhEUlU6dnVTYe2DiRRQFE0fPUxVq0P0CG3PVcONnPslYUcf/Mj0HXc3TvRf+l8hJRUdF0gEhPp/9V8dI+HxpCCVY1jtxlkNhLVCIYULr4gi+QkE326JyOKAkV7GknymFFVHbfLhCBJiFYL3qH9sHUpILb/IObMdFSrjW3bGti1vxGzSaBzBw8FHVzU1sU5cixERVWUiqooN92/g0Wv9Sc1xYqmacRiKm98UEJDo8z10/JZvipRlTJySBrrtvh49Nni5mOTx+dw49VtSfZ6QXSjajrhiMLcp4pp8hsbsm9+qCY7y4bbaWreOKqqTjyuYbOJNDbJaLqO3SbhsP9924zc7DMlUa1zWhxXfw34AzLPvHKQtRuNtXr5qmqmX5rHdVPz/xPxcBqEUb+Byp1QdxhEE+rIh1GtXm4enoaLKqpCdj7Y3EIAjteFeWnlEQa1TWkmegAfbKlm6sC21HS8l5ve2UVEVkl2mJl/9VWcqArzh0t68MHG44TjKg+N78J7647xze5KvthRzlWDWpPiNAiCKeKjYOWtzO8+gbg7D0/pYkx1E3l6n5dBrW7mnMF3oevwRXEIR4XK5JNsL1UIkrHyJoSyjcb/d36Ed+w8hrW/iPdPxkuE4iov/FSO2ypwffU8aDPMKJybbRBuADmEGPThjTQipXVAeGOE0YEC2PoO1tlrOVCdSIaiskYkrmBedstJV3GgfDtpG37P9f3vYvXREJcXmJHefwXnhpfRb1qHUDgJ+s+CcK0xBuPORow1kW5J4v5ROeiahizZWFHsY9cJP2+uaWDBjOeo88W5dfF2GsIyNrPIi1c8yLDhDyKiomomnp7swmG3YYnWE2/SUWxpRGQVMzIePYRVsPHQ+M50z3aR6bZyoiFCTBOobIogCMaokcduJifJxnmdUwjJOkfrIvTOcVIfjPL6qsO4JAWHy8X07i4cgmxkF9aXGPvQb+4x3O67XgwYBnVf7ajgq6IKrunWnlR3ltGlPAm1YDwR3cL4l9fiCxp70jSXha9vH0ZBhovldw5H1jRiisY3uyqaMxSX7axgzrhONIXjCV4EEVnFJAjEFJWw/I+5eIqCcQ6nzgcMVZ7l13YKrt1vmA+eUv1sfQdm/2yMLf2D+Jcnew2hOFe/s4nZIzrw5MXdsIoKzgOfk/TmBYYuOq0jgct+TNBhgxHEroq5Zz5g1W4+rR7Q/GbHFI05n+9n9T0jmfrOtuYFbvFmWDBlAiPzlhvZKeWbQb3eIBfxEGxfgFvXae5NiRID755JWaOdR1eWEoorXNEvjxuGZzUHe0vxIGx7J+F0xL1LYMwjhrb8lN7c7ICBN8KSWYbpTK/pRhfsw0uMbtXUP6Me30iJ3vmMDf+bP5Vw++gO7D7RxMTObhqiOkt2+uiW44GViXEM+A4xoJWDT6e3xWZX8Z+UK360rYqB3SqxSWZEV2tCnra8svIwW45tpVfrZO4eU0BlY4RMj43VB2qoDca557wCJEFBX/sCQv3JjCxNhdVPohdezKSFx2mb5uSpyV2prY/xh+8OUhuIMX1ALue0T+HIiRpGJVdj3/omkzw5+HvfzOyvjhGK6zxzaTesZhMf3zCQsoYIYrtx0Ko77FhoELuJL6KXb0VY8xT0uw4OLKes3ZXc90UJ24/vpG++l5en9Oa+z3ZypDbElzsrmDmsLdX+GG//XIJVEnnjqr78eUsp95/fiTfWlLD5aB3dc5N4dFJXqpsizUTv1GfmhR8O8vhFXfnTysMs2XaCdLeVOeM6cWnfVvx5SxmCYEgGHlt6iCcmdyPdZaW8McJrqw4TV40u2bKiCn4oruGRC7syuF0qrr8xOiHZYeGxi7py6Wvrm2dHZwzOP6sd9j+DJdtPJFQKY4rGBxuO8fCEwv9nJg//m3FK+qgqCtk5OYg6hA6UsGXaDJq27AJRZPiOZRze99oZ9w0dLcPkdhKvrW8+FjxwFDUSayZ6AHUr1hG5eTrB4hIO/Oa55uPeIX3p8uyD7Lz2fqInqkA9KXvWNBobGghHIzRv1SIynpRUerz7FKF4DFkIYnZC97efxOQ+Zc6i8cnSE81EDyAcUVm1vo5z33mKzRNmNh/Pv2MGMVFHkRVqa2rIzMrCV1tLOBwmKzsbQRQJBDUWLUnMHyza04Si0iwVlSSJSCSCJJnYvfvMGbr9h0JMGGPkT9XWGcP8u/b5icU1zCYVs9lKtEln9/4gn3x1AqtV5LqpbUhPFnGZNUxOidHnWBgxOAtBtCGXlXD8jcXNjx/YfYAjz8wnfdwwdky/h4HblhEyOflo0XHWbamjoJ2Lm2a0xSSG8Hg8mMQQiiwzboSXrbuCvPDmEaZdkofdJvDw3Z0QRZHqUJje2//Cuu1+dhxVGXyBl4IObv74/gnGjsrkkvEZCKLAsu9r+cNLB7DbJK6+vDUd27p47+PjBEMqdY1xkjwSTU1NyPE4D92eT1mFSkVVjFuvb8eSr8sxSSIzrmxNssfMvY8kmlJ8+V0F11yRx4HDEZ5//RC+hjhjhqVz07XtuO/R3ciKjssp8dbCYwzsm0LPwiQ0TWf5qmp27G5kUN8U2uY7mfvkXs7pn8rN17Y761zgX0Pb1g4G9E5m8w6jQ5KeamHapXlYzL/ehioSVZuJ3il8uqycyyfl/ofsnUKkAT6eBmMeRU0vJKSZeXeLj5de3Iquw/XntKFv3pnXan9VkP5tU884fqQuyts/H2t2qmwMy/z2i928dU1/Jr3yM/6osQYt2ljKohsGsqGkjvpQnINVQfrmn+wGhX1w6HuSD33f8sCla7l+yvccrg0x57sybGaRqwblk3daXJRJCcFJoncK4ro/MvyGSxI271keGxMKnLDuB2PEo3ASlG6EJTPRO56PNuYRqNmPULmjhegBqHHELW8zY9CNrDlcz8h8G0ebNL7d6yPJIrQQvZMwl29m5rleruzpxaPUG/4DgHBwuZHtZ08Gawq4MuGHxxB8BzF3Go95wGzq6msIOfJYe8iHKIg8MqkrMU1i7ld7m2cao7LGPZ/uYvmdwxj+7GruG9WKGwabMJVuQlzzJOga5mH3cVDoREhKosYvs2xXKd1zk/A4bMz6cDt5XjvzJnejS7abHq2S2V/p54HRrZD6KCQXvYHuSkYYfQPi7vmoopmHBk9GPLgcLbcv4sczoP6IIemd9mdYdLkRXbH9ferzzmNbWYDPtp8g02Nj8Q2DmL+uhN9e+jlpq++Hmn0o7cehj3mEj3fWJxArXzDO8t0VXNAjh98t3cPqA7UUZLr5zfguDGhbx+aj9bhsJo7UBFi2s5I54zrhsEgcqg4yf20JqU4L0we25unlxdQEYjxzWU86Z7n+ZjfNFKeFpy/tweyF21A0HUGARycVkvR3FrT+S8QCsOYZEnJIgjVG06jLxH/4Yf/lyV5M0SjxhXlgyS423dGdzKXTjdbyKfgOkWTRSXFaEmaWRndKw362bKWul/DdJ4kubB67mbLGWEIlC+DFdT569LmalLJN0GOKQfTAaMUKEuinta1NDuKKzrS3NjVvkL/bU8WXtwwhx2M1bI3VuHE/Tp/NOHmOV31uvK6GY4Yccc3TLe6iAkb2XrCa+PQvMS25HktTGdLYkWe8PpMo0DnNysejw7iLXkSxp3PnDfcSNHHmTFt6J8zlm8j4/AbiI+fy8AUX8/CyA7RPc2Cu2ATf3k7s5gPc/9ku1p9swx+pDXHMF2be5G58tu0E53bJZPbCbSzfU8W++3ohVO8645x0fwVxFVYdqEXRdCa/sZGobOh8fresmPnTezLMXoLlwynNLzdpz2c8e+WPDHt9P9Pf2cLXtw3hmb8cYG+Fn1E3F+D84EKDdAPs+hjhmq+Ma1a0GN+srcxauJ8D1QZB21BSx2+/3M2tozpwzyc76Z2XRGNEJtJYzdxzbCCY2FlTzdWD8pn94XYu79eK+8d14sfial7+8RDndztz2LxzlpuPt5TxwamqYl2YOz8u4tPZg/liezmT++Sy/kgdqw/Wct9nu3jush5c8NLa5nnAb3ZX8eHMgXyzp4obF25l1ZyRfzPZA2iX5uTHe0dQ1hAh1Wkh2WEm+Vd25DSfRSpilsT/EL2TODU7Fo1EiMViSNsPsP2yW0+/ATXfribzojEE9rTMuggmE+7CDmhKouwlfexQQocTQ5ABLN4kjr20IOFYw7ptdJ5nKAK8g3sj2lq+22d7fyS7jaZYlJAcAxkigGKWSLdZUVUVVdXP6pgoSQLec3ozYve31K3bhqt7J8TMVBrkls1PJBwmHA7jcrvRNY3q6mpsjvSzdqtlRScnJxd/UyOxaBS3243ZbCMYqj7jtoUFLioqKhCAe2a3ZfnK6pOdKAFfbS0ZmZnU+uL8/o8tXa17H9nF+y/3pfKZl8m/dTqq3UwsHsbl1gif5do27dhL+gUjUENhlJjCG++V8JdVBrEsPRHhwOEgC17uTWVFebNsNBwO07UghQ5tXLy+4Ci9uiURDKn89snd3HpdO75Y6Wf1ekMqtHq9j/NHZ5KdZefeR3bz9MOFhCMq731kVLEDQYXnXz/Ei0/0INljptEv0yrLSiAQwOl0ojuMDa/FHGPVeh+BoMpDd3ZCFAQWLSmjR2ES0WiiBEmSBGRZ595HdjXLKZd9X0WSx8zIIels29nA8MFp3PZgEcu+r2Tx6/159b0jrN1oFB7Wb6nn/FGZXHR+Du9/UorbZWL2NW2x/I3RLt4kC7+7t5DGpjiRmEpmmo0U76+7Ngm0+Ik0v+5/AweDvwv+Cqg9AH++Ct8dZYx4aV3z7y7Aos2lXDtk+BlZwxMKU4xZstMgiQLdc5PYX+lPOJ7psbNiX3Uz0QNDUvnZthOM6ZLJp9vKGNT+NOIonuU3zplKfTjONe9tbn4/v9ldycp7R4Icg2iDUTj+JUQTZkHn2zuGseVoHVLcT58MgYyvr2kmX6gKLJkJ8SDqmEcxvTsGMrsaozm/gCAIXNs3lWm29bgOfkE0tZCHb7uVqKAYKqXTzyFvALaiBdh+/iPytM8NE739Sw3vgNVPwYZX4dpvjO7OyX2c4DuIHgtQ2flOikqCDGybym+/3MN3eypZNWckR2oTC17huNpsoPXdAT+39BARFrXMYwsfT6XzrUW8tNXH62uOALCyuIYV+6qZM7Yzty7ezl1/3sVLU3px66LtmE0iE9OceD4c2/LF2fURXPU50rtjYc+nMPVjxDeHt4wV7f3C2Pf2vQ7WvYhaMJ7tJ/zkmoM8MdSGZraz5tgJruifz2Wf7uL2wU8xdoKXd7f68OyJNhvqnI78NCe//WJ3sxvn7vImblu8nZem9OaqdzZx57kd+WxbOUt3VpDsMHN53zwueX198/2XFlWwcOYALn1jA1Pnb2TlvSPI8Pxta5NJEhncLpWfHxhFWX2EHK8dj82EzfxrUinBcIn/JcR/rgj1L7+8Wc0ibVIdPHVJdzR7CtUT3iM86O6EC5eiN/HRdT3p0SoJu1nigq4ZPDahAHe0EsY9aczaubPg/KdRBTP5KYkyE6/dzNmcoUUBBMkCY59IdBWye43MuNNx/pOsOszB2SgAACAASURBVOhL6IToOsz/6QiRgM8wYNn0BvSfmXi/nlMM1yhXBnQYA2kF8O44OK3ypXnyDPMTqxvJYkMs2wT+CtraQrRPb5HUCQLcMKwdzrrduD+7Ag7/gGn3RzjfG02yGITJ81tCy1Pbw8QXYP3LAFh2LWJMGwt5KXamDsynttdtRLtNQdZpJnqnsO14AxaTxMsrD/PTwVouPelE5VMdyB3O/8VFNKGnFqBqOkM7pLG7tC7hBwdAjQZxbHkl8X7hemy+3bRPd6FoGr5QnO2ljQxom4L14LIWogfGIlz0kVGFijYSU7RmoncK+ysD5HrtOCwSD08sJI0mBq2/gYz3BpPxbn9G7X+EdClIhwwXJxoirD9Sx7xvi/lqZwXdc5PO6Jqd1ymF5Wdx4zzRGOaDmQPom+/lpR8MV8QNR+oIxpRmonfqtl8WlTOqUwa6DpuP1vP3wCSJZHhs9M330ibN+asTPYCLe+fgOY2AOiwSVw3K/9Wf5/9XiKKIw+HAYbORIppxd2lPj7fn4Wjfuvk2geIj5N8yndY3T8PkceHq3I7+372DGo3R79NXSR7UC8lhJ2PSGLq+/jgm75mmP6Yk91kjRQRBIH3cMHovegFLqrf5nLwpKQnOlZLJhCRJhEKJ82bhcBhN06jz+agoL+PSidlYrS3387hNDB+cisnlxNW5PbkzLiGc5aXhtCq30+UiGjXmXN1ud/OMGHqY66a0Tni+QX1TsFoEqiorCAQCRCIRfLW1BIIhxp6TzIiBXgQBrFaRm2a0we1Q0VQVVVURBJ1kj4k5N7fHqUVJNlmQZfhmReJ3UNMMgmVJcrNx2FQ8+sksw1iMpH7dz5iZyJww2ri+AGkZzcHwpxCLa8iy3Ez0TkFVQlxwriHPj0Q1XltgqBm6dvawZkPiTMiK1dX065kMQElpmB/WJv4djK5nh7ZOLp2Qg8lknGNFeTmVFRVUV1XhdFqZfH42e4r92CwSv5m3l43b6jlyLMj4MYnFqOGD0jh8NHTG3NzGbfVcNjGHP/ymK8+/doi4rKNpsKfYT1VNovR/xU819OttfKbWbqwjEPr7ZlqSk8y0ae2kS0fPr070AOx2ibEjEjPYpl+ah8f1L1///tuRnAeeVnDlh6SJfpbO6MDkHi0O4zFFw2OSWTDdcHL22ExcPziXy/vk0D81wswhbfDYTLRNc7Jgelfs0erm2btT+KVh2ymIAngdJt68qi9pp48XuLKgx9SE28bH/IG3fz6aQNyjssZf9lZB/WH4Ux8oXQ/tRiU+yTm3I4iG++eErumcr6wi472BUL3X+LsgoOqa0cFrPwa97oghMzy61nA9t582l2t2QJ9rsGx7C9fyO6FkNbYtr+FYfBFOIY7/wrdbbp83EAbfCtsXGHfd8R5y9ynorQcjZ/WmZtzrKJk90SONiXFggLD3c9on6cz9ag8mSaRPay8xxZC/D2qXknDbDLcV68lu+OX98mDnYn4Jf0Rm8ebEiJV9lX4yPUbxTwfWHfZR0RTlwkIvri2vJFZIok1GxzSnj5F3HK5vIXqncPgHaNUPPDk0dbqCPp4AhV9PIv39IWS+05eJgT+TZzcyf2tVB0//3MALa8p5bdVhruzXCtNpRT+TKFCQ4TyrG2eK08zHNw6iMSyzdKdx3VYW13C8PvF3KxBT2FHWSLccD8GYgu/vNKZzWE1kJdnp3zaF3GT7r++abnXByAcTCxtJeZDb55962H/5lS3VaWXJjQOoCimUNsTQ8VLqvYbzJvTAu+w6yChEkkQ6LZvMgoF3oiS1xVG+DtfSx9HHPYHQ+QLoPBG96TjClnexrHuRp6/4hvuBtYfr6JTp5oULW5Em+mif7kqortw1piPxzF7USxIpDpuhv244ZlQ7snvAnTth35eQNwgyuuAqPnN4320zI+5faljpbp4PF70Cl71ntHSzehgWtad/+TK6woDZsOUtg9AOvoMYFuzjn4fMLoia0lzSTPvmej6+7GN+PK5wPGRiYs8cvBYN9zfPJJ5EzI+5fAscWQEXPA1pnaB6Nyx/qEU66s7Cbrfx6rQ+XL9gC+UNEe4eMYMLBAGPzZRQuXNapFP9SL4qquAPk7uzeHMpQVWkqusNZAerMe3/ojnXpzpowWMz0SXbRWbSmUO3JklCt7g4g29bXMQUFYdZInaSICqqjmY608UTk7VZamFGJdVpoe60RSDNZSHTbWPVnJEk2yVY96kxy3Dq7kf+grfv9Tw+aShrD/t44uTAustiwiqofHNdR17f3EBVSGVmbw/ZYiNdsj3srUisdBZkuLnnzzvZV9VyvG2ak7hypiuT0yI1Sxw6nS1c9X8Y6S4rf7l7OF8VVaCoGpf0afXfZjH+O0EQBGwqWM1W1LgMVjOC3UavD55n+xW3Eavy0fHRO2jSVbLum0X+vTNRdZ2wWcTlchMvr6bXRy8iiiIhRcanxvHkpNP52Qc5Mu91dFWlzS1XEffV0+6ua9n/QMv3OnX0YKzZ6XR/8wks6anNYejBYBBd08jNzSUWi6HpOo6T3SFBEM50VdVbYghMup8P/tSH71fXYrGIjB6ait0qA0ZxTJIk0jMyqKmuRlEUrFYrLpeLWFMAu8WOXFqJcHI+NRoJMbiPl45P9eCnjfUUdnLRrXMSdqtK7S+IQywaRCyrZZpzH7e9MgHBakFTQ0QjLQ6OkiTy1tPdqX3zfdaMeYWUYf3pteQ1sjLPXE9yM20EvyxBrm8kerwcKS8DSZKI+3z0eOsPHHzkJeK+BnKnTSJ15ECUcASTx4UgCaSlWKiqaSGziqKdNd9PFAQiJztqHpeJSKTlNYmigHpapIVkEptN2Zr8Ml06uFi3ObGA1r2zh4ljMnE4TAgCNNS3FH80TaO+ro7WrTJ45N4u/PGNQwSCxnqs6xidw0w723c10KGtixHnpJ5VytixnYumgMwDv9+b8JPTJs9BQ0NiBd5iEVFPSnrb5juw/orzdr8G3C4zt89qz6hh6RTtbmTIwDTatXb+zd3HfwvYUmDWCgjVIjWVUqCHmNdLJdedxSvrqpjaNxtPuJShmx/ik/NuQ7el4D7yKba1QYTe1zDnnExmD22NWLmd1E23oMtRFk55mzuXnWBfpZ9BbVO5qFcOkiSS7DDTeFKCaDWJzBrWDrtZxGExGZvpUJ2hXDqyEnpeCUPvgv3LoMtEBE8+HlvJGafvskqw6kmjsPv9XLj0HUOW6TsMbYcZxO2UUZvJAt0vg+Pr4MA3hjnL+OdQTQ6ki1+HpFaYhJOfDTVumI5ctQQOrUBDROt+BbogYj5lrHIKdYcR4gHm7svlrit+pLVLRTq+Dj691iBGgOxpDa36s2/Ya1z18h4kUeCZCQ8zynqW30pPDv6osRh8VVTOiII0tpc2IIoCD5zfmWf/coANJXUUZnt4eEJh87rROdMJ0lkKraKIy2o6wzH8FMFqlWxv3rvJqo5msp3ZIZKsRidUiRozeYKYmLuY3hnSu8CNq7FpGtafH2shsbqOY9PLmPtewzsz+vHtrio+PDl7l+62kSSG+XpmZ145qRq4fVAKZiVIx0xXwmiMRRJJspuZMn9jwl6zINNNKHZmoclhMRGVNaOo8CuPr/wqSOsAt242CLorC7pcaEh6/wn871qB/y9AjfjZXh7gijc2cOX8jcxeuI30JBdV6UNg4kvoF72KEgtB9R5SvrmBjMVjcK15BE5sQgjXwWvngBpHcGUbFYpAJVmfTODl/vVsuncgH05tTyepirSGnXxyfQ/mTSpg1tA2fDp7ED8frmPgk6u5adF2fIGo0W2bPwLWvQifXQ9f3Qa9roLWg8CWRN823gRLXodF4vqhbbFWbTcOaIoRY7B6HnS9BHZ/RkxRaRI9zZbFNaqT+Mi5cNduuKMIht6FYnah2Tzw3niEA99C9yuMx2s4RvqCwVyWUc49I3JZs/cEXxedQLUln3EdBUcylG8zNPzHf4a9X7aQHbMddexTlIXNXL9gCwerg4TiKk+sKEPTdX53YdeEgvhvJxRyvC5EYbaHDI+VxohhdJNkM/P4ylrmu2/l0LSNbDr3E27Z4EIWrdw3Kpcb2jWQ69AYXdBSwUqym+nUOhP/4AdBOq0CmFFIjTWfan+Ue0bnk+42k51kY/OxeoJtzmt2RgWMSIeeU6H4G0hujZcmXrqojRGHgTGA+9KU3rTy2sn02LAKKtaaojOukaV2F6qm8czyA8QUDatJ5PkreuKxaLQqfodHrIt5OWcF5+x9BK/HyT3nFZCfemojDTOHtiXVZeHGEW2xnhz49dhMPHtZD3KS7WScRpQ8dhOTeubw4/5qruyXlzCf8L8FJkkkO8nOTSPac9vojuQk288q7fx3haaqSE4bdfEoNbEwNUoM8+CeqKpC9zefYMj2pZhSvcjxOIF4FJ8So0GNE4tGidY1sn3yzRx/6X1MqcnIJhFVVWmQY7gvH8ewomUM2bGMVrOuJFRSRuq5gxm8ahH5N0+nx9tP0uHBm/h54KX81GMCTdv2oCoK5SdOUF9XR0NDAydOnMBitRqzZiYTWiSK25aoaPDY7ajhlpnfeCxCPFLNpLFuJo31Imh+rIqGGoki+4PEqn2I4Sg5ubm0zs8nKzsbk8mEGIqwadgUtl00G5fWslBEIw2keSPcNCOfAZ0k4pHas0tFRRFdVTl2/+85csUsHLKfaKRlI+ByuxE0nePX3U7ZU4YCoH7tFornzOPSCTlkprd8rwrau+hdaHQbRKsFszcZTdOw2mygaVQt+QtdX3iY/kvnY/Ymcfytj0EQGLL1S0xClPtv65hwjpPH5yBKYkJWIIBk9vDld1V07+IhI9XCpRfmALBpWz0Xjk3stF02MZefNvoQBOjTI4nx52XQqX1LR2T00DQKOrjIyrTjcZsTcgyb3xtZRhIF3l50lANHDHI+uF8KPQqTMEki+w40UdDeTU1tlKrqGN4kC1Mnt2pet3Ozbcya3oYObV20zm1Zay4cm0VqipUxIxI3ItMuyePHtTVkpFm584YOv6qL5q+F5CQLQwekcdvMDvTulvyfHL9fItpgZPa+NRreuwC+nYPdncJNA9OYf2lbHhjqRazZh3D8Z9K/mELGR2Oxb34FoXIXlK7HvmAMGeYoaVYdoWwjYsVWOnw3lQ8mutl0d19emNyBhlCM8vowy24bwt3ndeT20R349KbBPP1dMec8tYonvy2mPhCGn56FhRcbSqKFF0PRIhh0M2R0wWxzcM3gNrhOc67OSbJxTvu0ljm9SIPhWbBjIfS9xhjZyCgEqwtV1agNxKjVPagXvwl374dbNkHhRaiiBb1qD7x/IUKsyehggTHHt+BClMJLaOp3Jw/+2MjWspARefULiGYbS/f4GPVmMYf8EmxbYGQGA7gyEQffwrKDYS5feJCGsIwvGOfGTw8TE2zoA29ueSDJgjb+eVZWmGjltZPhttEQlkl3W9F1mPvlHkZ3zmDxrEFcM7gNT3yzD03X+eTqTnRqWI3QaYIhEz2FlHZ4k5K4bXSHhPMd1zWLXeVNuKwmrh6QzfCCdGxmkS9219HY747EWIekPMMvorIIWg82xo1G/aZFOefKgIkvGeTFlYlDlJFqi/klRH85pXVh3v7ZIO3JDjPPXd6TdJeFzjue4NnUZTybuoxOO54gw23l+ct7kewwvq9mSWDe5G6YJZHpA1tzqhHYymvnwQs607t1MrbT5n3bpjlpk+rgcG2QhycW4v47xl/+n8HsMNRzo+fCgBsMZeE/CeH/5/yrfv366Vu3nhlEfjqqGgKMfXk9/kgL22/ltfPqtN50lKooCZqxmwTaLxmbmIfX5ULI7AarnzT+ffEbRju/ao/hzuTJQWmqQPF2RK05gKliK2rbkZg8mRTX68z8uDghuPzxSYVcU/007Pwo8QRv3wZmJ+gq4ZiMLFr5sVSj2h9lcLtUfjxQw42tqwxJaXJrI/tv1ycowx+kRvfy1toSMj02OmV5mPftfhojMtMHtj65+EmEojJJWgPim8NADhsVlnNuB0FAaziO2m4UWjyG9fMZhC5ZhORtjUVuRHzjHMPABiCrO4FLP8Z18HOEFXPBbIfxz0F6Z/RwPWR0QS9Zg16+jYbuM3lxS5g1R4Pce14BA9qmoms6iq5TUhuiXbqTIzVBvthRzujOGfRolczBaj898rykuyyU+EJMfnV98xD3mC4ZPD25C6mrHqA+ZxRKWieE5NYEYwr+iEyW14WsKMTiCm1sIdTi5UhJ2eh5A/BrNgTJjCLH2VAaok9+Cu+vP4am6dw3JBlLyfcIcsSoDp7YalyfdiOhajcxT1sa7XkE4zoumwmPzYQkGmHnAHrxtwgfJ8pJuP4vxI+up7HHLAKygMtqxmM/GfAZaTTkDWocbEnI1hQQjCH1UEzBYjIqbB67maZwnFBcJRhVcNlMeJ1mbCaJ2kCMdUfqiCsqwzqmn+yyCLhspl/dXOV/EoIgbNN1vd//9Hn8M/hb1qaYr4GgrtDkT+zuppltmM1mBK+HaDSKqqo0NSbmoWWYrPzUeRy6pjG6ZDWWrDQURSHuD2B1OlHiMkIkitLop+brVVgyUkkdMQAEgd03zcX3w7rmx7K3zmHgTx9RHU1UFrjdbpKsDpQmP7qsoCkKgstBVJExIxDYtBPvgJ6EJbBpAmgasihgTnZjjivUrdxA1Rcr6PjwrRx64hXqVm7E07uQ7q89jrN9axRFAV3n+EvvU/zQszg7tSNj0rm0vmkastWE2enAIpnYPvlmvAN60ubu6xCddnw+H5FIC8nMcCchxuL83P8S5LoGcqZPomDeHHA7MZlNyJW1HHniVZL6dceel832q+6l9czLyZt1BdaMVPyalfLqOBazQJpNofrZP2H2uMiZeiGmzFREtxOzxYJS18j2qXdR/9NmwJDHDtnwGWqGl3ggiFXVESUzcWcS5ZVRUlIsuBwSZknBbLEQi8VQZBm7w4ksG/OHCGCWZOKKiaI9fn5YXcu0y1oRj+sU7WmkXy8vTofEui11DB+YRrJHwGTSiMtmIlENSRKw2yTcLglBEBAEAUVROFFWlkD6nC4XVqsVRbUQl43bOewiSR4LiqLR6JcJh1XsdgmPy4TZLBAKa4QjCnFZw2k3Ncspa3xRIlENs0nAZpVI8Vpo8suUVYTZU+ynd7dkvMlmYjENh8NESrL5X2pO999lfaLuiCGBPB0F49BHz0WIh6HxGHjbwnvnJ86jjXgAavYbM2jnPQ79b4BIPUrVHuLu1ogWB+ZwNQ3uzuw4XsexhihjOmdgs1r46Ugjjy/bR+i0cZYvbhpI7y9HGTLBU5DMqHfsIoQdJxFC0TiKZOer4jAIGPuKKj9X6t9Rl9ydqDUNqxIgZc+7aCN/i6RGENc8TVOny/ku2IFX1xxDEOCeMQWM7pKBSRSJxqJ4tUbEl7obhimZPWDYPdB0Ai3qRys4nxXHdV79uZyXpvQk165hqSlC/PDiZrWVXHgJgVFP8tgP5Xy1s4oMt5W3L8uni60eSYmgpHbire1B6sMyF/bIZt53xcRklXvHFlCQ5cauBHApDYj+MtS0znx9KMaakgCTe+eSn+pg94kmBrRNIcVp5sf9tdy0aFtz1/2uMR25vm8K7tWP4Gs3Cd3bBndyKnZ/KToquHPYH3RgtZhRVI2VxTX0yE2iQ4bLuD5mO+FImMP1CnmpTt5cc4TO6Tau7mZDKv4K0Z5sSGMPrTBIXVYPKN8Kmd3BYgc5ClY3ij0VHRGzSQQlhrb6KcSf/9jyXpqsMPMHwmW78He8mJACbquJFKcFkyQaXd1TZjhWD3GLMarQGJYJxBScFmN/5rCa8AViRGWVqKLisJjISbYTV1R8wTgri2vwOsz0yfciK9rJPZf57/I6+N+O/2pt+pcne8d9QUY8t+aM46vnjECMNfHHNeWE4zqvne/C9PPzxtBG4cWQ2xuC1ciijTopDc2ahMNqJlmKGS38nR8Rum0fljW/x1z0QfPjxsc9w0rH+dz00Z6E55vUM4fn05ZhXvd84oncshmOr4UVjxgf6Mxu1F20kAd/qGf1gRpmD2/HHYNTsfzwMCF3PpaID6n1AKqzRjL9w2IqmiIsmjWIGz7Yyvlds3BaTaw+UMN1Q9owvjCNoCyQRiPy1vepL7iSovIABekOciLFuNr0oyoo49nzPqaeUwiYU9lXVosqmOien0FS+RoCskitsxOzlhxj6bUdSRFDCNV7IbsnhHxUWfPR5Bgpm57GtucjEE3UX7OKSFIHFE1n89F68lOdZCfZcEg61y3czq4TLZvbR8Z35Or+WZiUMFTsIJDWC7+YzM4TjWQn2cjyWElvKKLE2ok5n++nxh9j0bR2tNEr0YLVCHn9UW1pfLm7hie/288NQ9txY1835pIVxiKU0QV6TqPBnMEjS/diMplIdVrZUVrP05f2JCKrZLitpLutxE4uCtuPN5Cf6iTTY0VVDRnWsboQJb4Qg9ulGhbEegB2LMS86VUw25FHzkV3pGJZfInhfHrbVmRHOg0hmbiqYTNJpLmtRGWV8oYIb60tQRQEbhjejpyk/2TPnY5/l81UPBCiLtCUQFwAkq12nFYbwXCYgCaTnZVFIBhEVVVMkoQ9riLXGFENgigi2e2YklxY01MIHjzGTz0n0OOdJ3F36cCGEVPR4oZEx9W5HQO+fYeVv5xdAUaWrKI6nngeHrcHS20DRVfPIbD7AJLLSZen70cNRTj60nuo4ShDt35JxcdfE62qxeRyEqv2UfDwrVR+/hf2z3mSLs89RM13axAEgeQhfQjuOUhg9wEGrf4IKdmNruuUvfw+aRNGodkMMiHGFYLb95A+6Tz8u/ZT/dlfKJh3D4qmEY/Hsdts6LpOsKoWqyhx5A+vYk5Npu1tMwjsLsaU5MbephWi14PsDxLYvIuiqXehRaLkXn0xbe+6DnvHNsiKgqZp2GxWtGgc33erKbq6JcbG0S6PQSs+wJKbiaIoKIqCFIoQOV5B3NdAUs8u4HGih8Icmfc6Jz74kg6P3k7ezCuIaypmiwVJktDqmlhdOJbUc8+h85NzkLweAnGjEOgyWzE77Mi6RkNjI4JgQRBULBYzbpcLBAFJMvIIFUUhHo+jn+w06rqOgJEtGo1EMJnNmM1mJElClmV8tbXE43EcTicpKSlUVFSgKgrpGRm4XC4j6kLTQBAQRRFRFFEUhWAwSCwaxelyYbfbz5qF+O+Mf5f1iWPrYcEFiceS8tBnfI3QcNTIv80fYnR0dnxoKGt6TYfkVoZEUZQMowlHCljd1MsWZry3hdK6MD/ePZhZC4soOrkXkESBj2b25atdNc0W+qcw7+JCpu29KdFNU5SI3LoTtryNfcuroMqo7cdQNeoFbl9axo6yRt6+ph9tUmy8sqqErCQ7tYEoU/rn0salk/Z2H3BlsnnUYu7+upxxXTPRdFi+p4o3r+5LlttMSNbJE2sJHV5PVcoADtSE6ZnrIqNyNaZuF3GgSeKNNSXMm9CGiKxTdKyWZI+L9hkenEe+IeRoxQE5gwe+K+fzG/tSH5KpaAhR2MpLStN+TFYHlYqbu74pZ+vxJjx2E4tnDSLJbiIcV9lR2kj3Vkl4bCacks7YP21IcKb8bFYferVOojYssK20gV55yaiazq4TTRRkuvFYRZIa9rJDac3DS4txWyXevTyflKb9CJoMOb2J2TN4/Ov9rDtSx60j2zOhow1t9xLcFevxtxmLpfM4/IKH2xbvoCDThcUksqfCz8tTeuMLRslOspPqshKIytT4Y+wub6JrjscgULox87e3wk9TOM7Adql47WZsSgOsfgrT3s/Ak4sy/o9wYjOmH35ndB5nfE3Ekoo/KqNqOnaLhNdhwR+VOVQd5P31x8hJtjXn9v4rFZL+WfxXa9O/DqX9K4irGq289oSIgR6tkrDrETIXnsNj5z5DfXp/GmMx9nZ5lF1VEc51uWm1+ys8Kx/EnNMb5fz3GPvaWkZ3yuCxi7qSOnouSBasegTTzoUJz2dZ8weG33imPer47lmgdk08mNsXJAm+vc/QOJvtNPaaTRQb947pyJX98uidYyPkO8S2TvdTFtAxJwsMThVIt+s8MrEQq0UkxWlmyc2DeffnYzSEYyye1oEkKYYQr2XL0TA92+eyJfVKbn1jf/NTzx6Sxw2tbQx9ZTtvXzWL7lYXl8zf0nydMj1H+fzm0TRFZNYcrOWyHik49n6EsOllo6XsL0e74Dk+qfXw6tpSPrn6PnrW7gZ0rILKoYYI09/ehKLpjC3M5PZzOxI1icyd0JX31h/l292GMcL8dWVM6J5JxvK7+D/snXeYFFXWh9+q6hwm5wjDkHPOICAqmDEgYs66CObP1dU1Z12zGDDngAqKAgaULDmnYWCAyamnc6qq748aBpoZ1F0DMtb7PD7S1dXd93b1nLrnnnN+B6OVXQMHMfGlBWTEW2kIROic6eTRCT0493nN0H18QXvafnMV4r5lSKCFuy/7jrV7Irj8UYblGDCufBkWNsrMb/4cdszHdMY7zFpfSYd0B8l2M1vKPfzr842MaJ/CjEW7+Pq6ERRVeZn8yvImZbGTe2Ry8/Eduf+LzcxpFFMxiAKvXdyfjHgzL1cM55wTxxOOKryyxsMtw5LpYEsGfy1Br4tSt4BV8WGK+vEKNmQ5nYgicMJTPzapZH2yeh/f3DAyJg0zEIni9kfxhaM4zAYSTQpGJagVeB9i2GRFpdYXwheMYjUZcFoMP9uIvdYbwheKIokidrP0hwiz6Pw6BIsJa9TazNmzJyeyfMjZWAty6frCPfg3FWGUJOrn/ogtLwshP5s1k68n6vbS7dm7qJz9HXVLVjFwzqtY8rLo98nzGBLjKHrwhSZHD8C7tRjPph0kHzOQ2gXLm44nDOiBKEmIohgTDbJFZDb96z94NmwDIPWE4SSM7I8lJ4OUE48h6vaCJJIx+RSiZi2yLIWj+HbtJeX44fTJzyKuZ2fSTxlDxGIigEKGlgexoQAAIABJREFUDEZZIVrnIhoMErGayL3mPMqrq5Cj2lgls0TmqWNp8HoI56bR4cEbcXs8MdHNlNRUnOmpeDdux19UQvc7plAZ8iF2ykdVVfyRIKnEUe1pwNqjPd2m38vma+9GtJixdWxLZVUV4XAYSZJITk7GZDWTfPwIur/+CJun3I3s9eEv3kugtIKow0ptg4us7Gyqw/VEU+MQ0hMoD3rJToxj9ysfUfL8O6SdOIqUM46ntPKA6EtcXBwOs4mox0dgTynGtBTKaqqaah+9+Mm226ivdxEJhzGZBaKRKAG/D7vdTtm+fSSnpGC32ykvKyPS2FdRFEWysrOJRqOUlx9Qh7bZbKSkpFBTXY3T6cRgMBAMBnHV1+NwOGhwufB6PFit1qb3EgQBVVEwGI1UV1U1Ceb4fD4SEhJISEyMqTuMRqNNjiaCgOLyINmtSNbm9Y/7+yeCVqcoGQ5vmxRFafpPFEUkSdIXckeKaAjsSTG17AAUHqs1WZ89FU5+UhNwUSKaOJyvCixOTTZ+3XvQ6SToe5FWujL8RpIGXc308/ryysJiyl3BJkcPtPvYw/N2cvv4Ts2cvUH5cVDVKcbZiw64BtVdjm3Zk9oBZwauHpcRlSzcd1o3Smp99MywscsVZmTHVMKhAIVpyQiiRMRgouH0t4k4c0k2pjHjwkxeWFBEepyV964YpPWVjKh8sb6cSX1SeLW6Gy98ekAN+ekzj2FQxMCZ05cy//oR1AeDnPzCqqY2Rt2y43jxvNOo8YaZv6aUu47NJHnuFNL3LKKzLVlL4bxwFnx/LzmlK3l+0nzGvOKja2Y8TouB77dVc+fnmkjMhUPacN7APEJR+M/EXjz5zQ5WlWi1yM8u3MvjExxc+sZazuqbzU+76vjnzA1kJ1ip8oQ4d0Au5w/syAVPaFkcP1zVmZT3TzwQIY3LwnzpN8zdVEGtL8LIPCOWL69F2vG19vSWWUQqL8XV62ZWlNQRisqYDCJr97p46ced1PrCbKvwaKrg68v49+zNTd/RreM6cmrPbC57YyWbGxVY4ywGPvvHUFaXBCnmfE447UpqvFGmz23gmfEnki7cBdXbaIhKbKlyYTaIRBWViKzQKd3J5nI35834qekzPllVypfThpF2UB9igm4tgyoa1IROjHat/MnavDQpFJFxBbTMKrvZQKLN2JS5dSiqqpVJeUMyFqOWhfW7C7P8wbR6Z6/KHWLGhf248aN1bCx1M6BtEg+c3p30NY9A0EX8nKuQp+7kn7N2MHeLli/8+Hx4/JSRnNrpVAxbPydl3Quc2XMib64o58QemYzrngnH3YfgqYoVRwGIBjFJIvef1o0n5m8noiicP6gN/rDM1+FOjJz8NXGeIrAkQmIbqN6uFbR2OB7fsNt5YZ3Ki5+voTDNwcMTulPSoNA2PpcByiYGb34TJbs/9Y7JVKtm2qQqPDFvO4t31nBMxzQm9s8lmQaSv7wMca8mNXts4XFE2j/LXV/FFjAv2uXhilE21v1rDGEVvlxXFuMQV7pDvLN8DzurvSTaTFw7Ih/r9MehYBQNw28nGFeAogqc2ybC5UNzqQlL7D17LhajhDskE6z3c0zHVIIRhcmD8llTUk/bVDu7a3xMHpDPid0y+XRtKTurvQiecpQe51CVdSwPfryRQERhV42WUra4qBZvRKXGGybNaSZfqELcd9AOX8SP9N293DruGa4YWUC2wQMzX4m9JqWrMCoh3rpkAHW+MGUNAW4/sTNRWcFkkNhR5aWkxsfdszfFSEjPXl/O9WM7MG/zAVn3qKLy0FdbeeLsnny4upIPVx94rlemjbTJcwmFw1hs6aRtmYVz/k1a6qY9hYazP2WvmtPk6IGmaPbByr3cdJyWSx+MyCzYVs11768lFFWItxp567wu9Nj0iKbi1XEc2JKIyAouf5hAWObfszbx/bZqjJLAv0/uymm9sltMTaj2hLjsjRWs26cpHp7SM4s7Turys6Iptd4QsqKSYDP9/o1D/+4oCjazhYjTidfr1ZQwExNRg2E8G7fj2biddv93JdG6BlaedhVqo6Kjs0dHur9wLytOuYIN/7iL/p9Pp/zjr1hzwY0M/Oo10k8eTbC8CtkXaPaRUa+fHq88yJrzbqBhxQaShven433Xs+Wfj9Lh/htRHVYUwGww4lu9mYaVG3B0bkfu5RNJm3QS1e4G1IoKEixmTKKTcGUtpsQ4yp54jVBtHe1vvwZbfjYoKlGPj6Ujz8WSk06XJ+/AnJ1Kw3fL2HjVnaiRCMakBAbOfY1Q2xzkg9pIqKpKWI4Sb7VpipCq2iyNta62lrT0dLxp8fT66Fm84SBCVCDe4cQYCCGoKtGyKtJNVgRJQhnUi5EbviJc7yJcVYtFFYiKIunp6fga3Mh12t+E87ghDFs7mz3PvknpO7MQjUb2Pf4qbadeSDQaJRRqXPg2XotATS2Vn88HoM1Nl9IQjVV2c7vdxGfnMGzl55gzU/FHQs1EbtweNw7RAAE/NZ8vwNm1A0mdC1Dr3cQbzfj9fiRRbHLOtJ+OgruhAfGQqNt+hdRoNEpNzYGyBFEUyUxPx+QJYLA5kGWZ6qoqLZUWiI+PJy4+/sD8GmloaCAuPr7J2YtGozFOp8Nuh83FVHz4Fe3/9Q+sOVptSbjWhRIOEzAIuDweVFXFbDaTnpGBoQWHT5ZlvB4PtbWa8IwkSWRmZGKyHN42RTw+ZJ8fyWLGmNBchVbnNxD2gb8Wzv0IZk+Dhj2a8zbseq2Nk7tUEz854xV4/yKtRQNoCoLnfqil8239QiuLyGpsBdV1AtlpnbjpuA5sKa9v9pGBsExmvIUrRhTw9rIS4ixG7jg2m9TNr0Gn8dDhePDXoDiz2WPpRMrOmVq9fcfxeEb8m1u+rODbrSsYVpjCbeM7sdMVpntilD6uhUglc1C6nE6VcwyyIFGZ0Ic7Z21md81uJvTJ5tTe2STaTFz02k+U1Pq1GvqhbYkIFl5cvK9pjIIAszbVMaxzDktuHYWsKDwwf0+TowewsdTNypJ6nv52B+cMyKNHjhnDV1+j9jqf2r5TidrSUBQV8/iXsBkFwiGJOdOyEAXN6Y2zGOmdm0DvvAS6ZsWxdq+L9DgLW8rd3HtqV9bsdTFzdSkWg8iSXW7uPa0r6XEWTntucWOrMW3t9N22avrmJyIrKsPbpxC3a05sKqy7DHXde8y+9hqiskKyWN/k6O3HuO5NMobczMyrh7C53E0oonD/6d2JRhW84SjPfb8TXzjCw3O3xbzuyW92cFyXjCZHD8AdjPLc90Wc3COLmxaX8fyBSgKKPFlIFy1BVWRCioUv1hXzzk97UFVol2rnhfP6srUiVuWz2htiS5mbtI6Nzl7ABcumw48Pa8GTxDZw9pvw42Nak/qs3mCJIxDRekK7/GGu+2AtW8o92E0SMy7qT//8RKQWdAX21Qc456VllLoCSKLAdce25/xB+YfdLJcVtamVW7Ld1GIboT+bVr16cwcirCip59r31jB5YD4fXjmY+0/rhtdVAzu/0U5SFfyKkblbYuWsH1lQRn2PywCwVK6iS4p2U11a3KiCZrSiGu0obUbEvE7uczGiOY6J/XP5cupwXruoP9WeEDd/vA5JFFCCDbBrgSYJbDBCUlu4+CvI6Il9xdNc0aaKp05tw2Nn9mDaB2t57vvtSNu/Rnr7dChbS3nOOKZ9soWRjy7ghg/Xcf7gfFKdZj5etY8Vu+rIKv+2ydEDEIrmIexZSm5juwi7SeLlC/px4ZA2vPRjMZsrfeyo9LKnPtjs+6vzhXFajLy/Yi+1QYG68+ZRPPYV7l6qMPSRHzn+6UVsqomwaI+fy95YxeQZK5i9vpw1e+q59ZMNjO6UxoMTupOXZOWrjRVc+vpKZq8vx2qWyEu20ys3kVcu6EvyorsRP7qQaDRCfQsyuGaDiEkStUJaf22z5wV/NchRKhqCbK30ajWVh/4WDEn855vtTPtgLQ9/vY1Tn1tMjS/M/XM2k5dkIyPOHNNncT/+sIx0yB9qnS/cotBI24xELptdzZCXS7DKPpzzbzyg9uWrIX7uVNo7m/eNsZskFEWlyh2kxhvihg/WNbVZaAhEmPZpEdVtToLPr4HNn+P1h3ht8W5Of34JV7+zmon985jYP5eIrPLvWZvwBCPNPkOWFT5cuafJ0QOYta6MtXtdLX7n/lCUZcW1nDdjOac8u5iXFxa3eJ7O/05odykLu42j5pm3SfCESBYMCJEoNfMWNp0jADsffbnJ0QPwrN+GEoliTk9B9vpijquNevmWzDQKbros5vOMyYkkDuqNLT+b/p9O55it80g7aRRrzr2ecFk1kbIq9tzzHCW3Pk64eB+hyhq6P3837e+4FvfKjVS8NpNUk5UEs5WK59/lh67jUCMRFg08g11Pv07q2GGUvvU5i/qexpKhZxOpa6Dt1AtpWLGB5cdegEWGTVdrjh5ApM7FuktvBfcBBWO7wUhiUKb08Vcp/+BLwpW1hKqbLwwVRWmqT2sIBbDbbCSFFfw/rmTJkLP5rmAUO+59FiIym6fdy9KR57Lp+vtQQmFWjLuUPbc9QZrZhlrvofblj1jefwIrhk/CM2chGCQEUaL/7JdRIhGKH3mJXU+/3qx9AoBiNBDXvZP2/cY5WxRHURQZyWpm3xuftOiAG41G/MvXsajnSWy9+SFWjL+EzdfeQ/XXP1J09V04Q3JzFVRocTygpXUeisFoxLV4NT+2H0OksgaXy9Xk6IHm1CmK0swR2x9Zi9Q3EKpz4aqri3E6vT4flnZ5VM76hmVjLyBYUY17/VZWTriaxYPPpPyx10gx2xAEgVAohLfR8TsUVVWbHL39c6uprSFYU4cSaW7PguVVbLj6Thb2OYXVk2/Av3tfs3N0fgOKrC2cf3gIxtwBF83RxCJ8VVobJ9CifvUlBxw90KIoy56Dbo393Co2QFKB9u9qLbPIbjGSn2Qn6xBl7SuHtyEj3sr1Yzvww43DmH2GgxN23I1z+RPahri7FIoXIHhKMQoKQvtj4cLZqI407Ese4eERBv5vdA5TRhcy8cVlrNi2F+mHh5A+v4powM02Wy8ufXs9ox9bwGPztnPL8R0JywrPL9iJJAi8ubSEksZeyaoKryzaRb0/3CT8kp1g5YMrBjOoIJkZi3ZR3hBiU5k3JrVyP3W+MFaTxENfbUU2xVF9yU8UD7yHqV9WMuihBUyYvpzakMT76+o4d8ZKLn9zJev3NfD2shKe+76IqWPac8WIAgrTnLy6eBeXv7mS1XtcKKrmPEzsn8v/ndCJh+du4+wXlyEKQjNFzSp3kLxkrbWW02LA5K9oNk7BXY5BFFi3z02lJ6J9zwdjsBA0xPGPd1Zz+6cbueeLzUx4fglhRVtrnNQjE6MoxLQMA631RUt2qNYXxtaC0q8zLoGxb+zlum+91PgivL18T1McZWe1j5cXFtM7t3l0zmyUCEdlKt1Bor5aaGwYD2jK9z8+Bint4c1ToLaIOl+Ih7/ayinPLuLfszZx18ldGdg2CV9Y5tr31sQosO/HE4xw9+xNlLo02y0rKo/P206FO9jimqjBH2bm6n2c8cISzpq+hC/Wl+MONLdhfzat29kLRnjymx1sr/Tyz5kbOPvFpdzx+UYybUpMLxWlhbLFYERBbVR39LYZy9JS7WKNO6hBtsGZgnrGDJSx90PH8cinvgAjbka02DE0OifTf9jJhyv3clK3NEaEFpDwyUTY8DF882+YeTmq2QmzpmhGdf2HJH98BsdJq9ha3sC++gCTutqJW/0cAHXD7uSaWWUsKqojLCusKqnn5o/Xc+3o9gBUuQNYKlY0m4tQupLTemUDcNPxHfl41T5u+Xg9L/5YzDkvLWNjaQOn9MyKcWoEAU7qkcXCHVo/kx1VXr6tSWT2+nJmriklqqgICFgMIle8tYptlR721Pm554stCAgkO0zc9ulGvKEot36ygaXFtYRlhZ921XHLx+uxmyUem7eNT1ftJWLXvtPUwE7OGRDbWyvRZsRsELnjpM7srfcTTu0B5thd3FCfy3luWR2PfL0N0ZGKZ+htMc+rPc6h0qewes+B6ICsqDz//U5Gd0rjyW92sLXCw7SRsdLE2QlWEmzGZr2BzumfS5LdGNMjaEi7ZOxmIyt312vRwYgP5EP+wKu2YJM0Jc2D5zehdzbFNV5OfW4xpa5AkzjNfnbV+FCc2vVjxSu46ip5YM4W9tUH2FTm5h/vrubsfrlYjCKyotLQgrMXlhXW7m1odnz9Phez1pYSOMRY1/nDTH5lOVvKPVS4gzw6dxvzNle0uFDT+e8J17vZOO1egnvLKX7oRZb0O40fCscgurwU3fdc03lqVEYJNt+IUYIhBJMRU2pSU6pm0ogBiOYDqSXxfbsxeMG7ZJ45jjbXXsCwZR9jydJUaE0piUTq3Wy56UGC5dV0vP8Gfhp3CbufeZO9Mz5k0YDTie/blVB1HWvOvY7Sd2ex7bbHWHXS5VgU2PX4DOJ7d6Fh5QYi9Q3E9e6CGo1S9OALROpchCqq2XLTgzi7dcCSnY4SCBL1eGPSSgG8m3eyvxGL0WjEUF7H4t6nUHT/82y8+k5WnzMNyWhopmZpdzgINqa/RiIRhHCUqMvDmsk3ECrXmu0mjxzA6knTqPh0HqGKaipmzmXTtXdTcMMllH/wJTvuehp/UQk77nlGc2bKq9hw2T+JVtURLK1kxcmXa0UnwO4X3sNiaV4fYrTbKbz9amzt8qiYORfbIeM0mUzIbh+LBkzA2bkQm8EYE40TBAFzMMLWWx+NeV3VF9/h7NyOmm8Ws/bc6zAGmy8q7EYT0iFtHSRJwiBJxMcfUAUURJEEo5ltt2qtN6I+P+Fw8/eLRqNYTLHjT3A4kOtcbJx6D2UfziHUguMVUWQs2en4i0qINnhYcsxk6pesJlhaya4nZrDvhXexNb5vMNQ8sgktO67hcBjvjt2Ea2Kd/XBdA+su/SflH3xBuLqOmnkLWT7uEkKVzfsP6vyP1O7QBFZKlmjK4a8er6lIuvYe6KMWDaEqLSxiI0FNjh+gzTAoX68tKDJ7N52SGm9n5tWDuXpkASd0y+DtS/oxsmMagiBgNUqkSj5Sv7ocacccGHaDlhY65ybY+AnCrGvJWf0odkccvH0GwtLnENe8Scpbo7mok8L7K7RI2/gODszrtTKbuhH3MumdIjaVuQlFFeZtruTFH3dy4WDtnu8KRNh+SG9dgF3VPgY3NnV/4PRu3P7pBu77cgvPfb+Tk59dhMUocWbf7JjXWI0SvXMT2Fru0e7HIZVZu+Cxedubeg6nx5lZu6+Bu2dvYU+dn60VHq55dzVjuqRT6Qly9TuriMgqF7yq3YNDUa1v4AsLdpKbZOOWj9ezodRNisOMrKhEZYVTembFjCMv2Uac1cj5g/NZVlyLp/PEWGdOEIj0uZhLXl/J/M2V1KhxBHtfEvMeyrjH+KGolrKGA/cgbyjKRyv30i07nps/Xo8/LHNS91g13uHtU7AYpRgVTICLhrQhL9kW0zvxgsH5rCqpp94fwReMUlLbvAXZ9goPKU5zTM+9wjQHBSk2lu+q4/wZy6krLWr2Oqo2a8KGgLr8RRZvr+D1JbupdIdYVlzHlW+v4vqxHQAt8ynagjMQjMjN+i4DFFV5WVrc3OZsr/Jy88fr2VPnZ3etn6nvr2naRDiStOo0zpYiNTurfVpLBdCENEbfid0IPXPiY6Ielw3KIGHb68g9JlFeMJEFi7dz49gOdMqIdTQkZxoMvgYGXIJkjJW/t5sNXDu6Pd9uqeLc7g4c85+JHUxtkaY0VB0bArcuf4quxw0BICSrTVK3oaTOrNsXm465q8ZHcuMfTrUvTLDPmVjWvR9zjqvNOLpY4rh2dCH98pO4+6DcaoBnvi/i7YJkZlzYj9cb1SrPH5zP99uqqHSHEATonZfIl+vLWX5Q8+6eOfEsLKpplsk6b3MlA9sms7HUzeKimmYh7KIqb1O65AeryrlgwumkrXmVhqDC0HbJPDShOzPXlJIRb2Ha6Pb4wzLbKjx8fNUQImaB8KXfI/3wAJK3Ale3i9hs6E2KU2LNXhdLdtZR6hxKn/O+I2Hvt4jZvdhj7oi3hV4r/nAUS2OO9sw1Zdx3XAbKCXl8tsVDmxQ7kwfm8eQ323n38oG8sGAnxdU+Tu2VxQndMkiwmXnvikHU+8IYJJFAOMqklw/UQdVGzWRaEzXJ50bUwmPZ7VZ485KBLC6qQQCGFKZQ4Q5y+2cbKW8I4g/JZMRZqHAfMK6DC5IxV6zSHjjS2FQZGx2QFZVVJfV0THdSXO0jqYXUAqvJwMk9Mpl/UEoqwMC2ydw1ayPjemRiPajH1E+76mJSWgFmri7lhK6ZxNuOrlz1vyJKKIRvW/PeUIG9ZVotHJAydhjW3Eza3XIFq86c0nSOJTsdc0YKBruVrq8+zI57nyVxaF96vfYwpqQDu5+mxHiShvYlvm83BElCNMaae0t2Go7O7TCnpVD73dKmzwVQZRn/rn3sfDS2b5R30w4itS4kuw0lHEFsTLNLHNiL6nmLms2n9rulxPXuSrC0EoPDhiktmXDVgQhO6nHD8GzcRkr3jiiiwLZ7nomJYvqLSnAtXUN8r874TWYiAlitVqw2GxWNtWoWs5nqr37AaLM2RQ0BbAV5NKyKFcpy/bSeTg/dAkD1nAXkXXZ2szFXz1kAgkC4uo5wZQ2mtGSsuZn4Nu4gq3MBLpcLWZa1mrhIhK33PU+Xx/6JrSAPkzMeo8FIIBLGiIA1LBOurED2+dl84wN0fepOUjq2JWQyIjlsWFQB2eVG9jZfDCjhCIIo0rBiA0owTGZWFg0uF4qqYpeh8p3ZpI0bSXJqMl6fD6PBQGJSEpLBgDMuDnujCIuowpqJU/Gs1+4zpa/PJOvOa2g4xOEzGY34tu4mqW0WEUHAjIBv6TqCikrZ+18gh8K0GT+CQ3MTzJIB3/bdAAgGCdnjjXm+4qM5ZFx6Jj7A4XC02Hdwf33ewY6gxWSm9tsliKOHYMk80CpHCQapmR/7W/MXlbQYNdX5H6na0vKx/RLwjnQaRt6DM6MQwZEG3qoD5/W7FFbOgOE3alEWf63WG9ieHPN2GQk2bjy+I1FZxXKoQJk1BUbcrG2EtxkK398f87RQvRW1eEHM/RVVwbLsSbqn3cJngKyqmmiMEsUjOJr6+O3nh+3VnNu4uewORBjTKS2m760kCuQm2bh6ZDvapjiQVW3Tu+njVHhi/jZuOb4Tj53Vg09WlZJgM3LR0DY89W0RUUUlzmLAYTaQGW/lp107m147oG1ys3uxqsKSolq6Z8ezuKiWioZgs82lH7dXc+VILVL64cq9HNMxlbV7XYQVheuO7UBeso0fttXQPSeOy4cXUFLtJc1p5p3LBhExRAhfPB/TwodAUajrfz0rKix0zHDyyepSTuudzeqCq2hfMJ6kmpUIbYYjGizU7my+jvaF5KaWBYuKarhvbAYFCRKLSgL0zktgXLcM3lqym0+vGcqT32zHHYxy6dC29MxJIN5qZM7U4dT4wjjNBraUaxvWAFsqPHTMcCIKxARhju+awebyBj64cjALtlWR4jDTKdNJIKLwj3dW4wvLyIkdQTLGbrIXjtFahgFqfA5LimPLAVz+COHGNlkFqfamllcH47QYObZTOq8t2d10zGwQyU6w8ti8bQxrn0pcY/2eqqp8tHJvs/f4bG0p3XOat+X4M/lLRfYEQThBEIRtgiAUCYJw6299v/Q4S0zvFYBxXdNxOp1w8ddabnneIJKtBmZc2J/bxndiXLcMXjyvD+cNaotp1C0oJzxCQmom868fyeUjCki0t5CjK4qaUEgLtEt18PV1I0hxmGP7wIH21y22UBAqmUhxaue+usZD/ZDbNVW2YC2Zh6Q+xFkNRKIqDrOBS4YWUB/fFfnYezQFLEcanrGP8n1NHOe8tIyiKm9MVGk/UVmlIRDh3i82c2afHB45szvbKjy899Me7Qd9Zk+MksCOKi/dsg/8YCvdIfJb6O+Wn2yjstFZ6ZDuJCchtj9Xos3YFC5PspuQIj5cJ75EKLkLsqLSv20iT5zVk5uO68CXG8pw+bWw/qVvrGRHdZBhL+/mKdu1vNnmQS5flcPraxqaUhiKq73M3eFl/Pv1lPeYwjXLkpj49g6yEqzNvrtzBuQ11eP1yIknak7g1FwfT08oxG6SuOi1FXy8qpTTnltCfrKdZyb1ZvLAfFIbC4JTHGbapztpm6KlShycRnHznFKCkz/XetBIRtSOJyKc+DjziwOcNX0Ji4pq+HFHNWe+sASrydB0k3nq2x08dU4veubEYxAFRrZP4YkTUklY9rCWOjz2XrbWNc//zkvSdvHevWIQCfaWnbFh7VO5dnQhTrOBNKeZu0/pyqo99cRZjRgPWYDtn9PBtE9zYDb+pUzGn8rvaZ+M8XFknH5czDHJYcfWJpc+7/yHwT+8S9tpFyFaLSSPHMjg798h8+zxtLv1KoYs/ABHp3YM+vZt4np0pPdbj9Pvk+ex5mW1+FmSxdzM0QMwp6UwcN4b5F09CcnRsv0STc1/S4LRgDE5Ac+GbTg6FmBtm4N/9z6cXdo3O9fRpZDAnlLyr54MVgsDvnqV+L7dEM0m0k4cReFtV7Ph8ttZM+4ShOp61INSC/cje7ysPuMaKh+ZQWpCIjazhZpqLePAbrHikEzULliGJScjRsBICYUxHFLLZUxKQAlotsnepT0kJDb7PGe39rjXaRtihoQ4ksaPod1bL+BJyqZmdx02WzwORxKezfsof38OgZJSVp5+Nd6tO1nc5xR2Tb2P8Bc/UvnoDBb3P71pTv5d+5BsFn7sfDx178xGqqrn+9xhqIpC7mUTY7+3ru2J1LtRo1HMmWmgKKj1bpwOB+L6ItafOYWtNz7Aj11PoOjKO4kPKaSkpmotOxoVPI1GI2azGaXBg3/ngVqdfa9+hLG2Qes/KAgYDAY3czImAAAet0lEQVQyMjNR3D5WjL2AtSdewa5/3M1Pw86havZ31Da2mqia9S1iZR0Os7XpdUlmG3unv4fsD5B31bkILdTj2drlo0giCYmJWK3WZs9DY41eZiZGk3bfs1ks2PwhSp5+E3N6SuzJooglNzP2kNWCaPn7ik393msn2o1qJgamdD+LPfkT2HfhTxRNmIMntRfY0+HyBTD0Ouh2Jlw6D/KHwJmvwpCpWs3eVYuh08na5vohGESxuaMHmnBd55O0dZrJ0Ty9UFW0hf0hqJKJglTtc95f78Y36AZQVewGJSYqBNrapNQVICvewuB2KZzaO5vzBuVhM0m0Sbbx1Dm9eGf5Hs59ZTkCCjZT83FGZZX1pS7eXb6HG49rzz0nd+Lz1ftYXFRDpwwnz03uQzgqs6vGF7N2qvIEyWth7ZSXbKPSrW2npDjNh14C2qc7m9YKSXYTogAvntcHSRBxByOc3iub/0zsycVD2vL6ot3U+SM8Pm879325mc821jPuIy8vpf2LlzPuZOIchY01mkgJQEmtj/u+rWDyfAOuvtMQP70cVrzM2M4ZMRE6QYAz+mbz3VbNwe+YEUfIlMBVBbX8Z0IH6nxaVtCLC7X002O7pPPk2T05tks6iY31a2lxFrpkxpGbZMMTjDbpGISiCm8vLeGl8/uRk2jFapS4YHA+Z/XL4cOf9nHBjOWs39fAp2tKmfjiMsJRBXcwiqyoPLWkhvozPtT60xksWu/kzqfAho+0huT9LqG4JnZTTRA04ZjeuQm8dH4/kh3Na4QtRol/jC5kQu9szAaRdql2nj23NzMW7aJ9mjPGQRQEgW5ZzZ26bllHvqb4LxPZEwRBAp4DxgL7gBWCIMxSVXXzz7/y8CTZTXx45SD+OXMDu2v9jO+ewdQx7bEaIxBpVDa0p4IgkGKCy4YVEFEUzE2KPE6MQOpvmJfdbKBDuhNVtsGof8HMg+pocvqhWhNQc/oj7juQfhk55nailmQeOL0bry/ZzVeuHM64chlx5et46qyRXPLWOryhKBajyONn9cJhlnjr0gHEWwy8sbKBYW3PYuCVZ6MoKk/8UM1ry7QbfZbTiFkSGFaYzKKiA7vr5w/KZ+7GCqKKSn6yjZs/3sCUUYXMuz6bzWVudlR5iMjajszxXTNYt9fF8l11FFV76ZThZFBBEsuKtYhfQYqd8d0ymPjSMk7snkmyw8SEPtnM2VCOLyxjNUo8OKE7rywsRhIF7jqpA2qymZtnFzH/kx8QBDi9VzbHdknn+g/WMmV0IbKiMKwwhUVFNUQVhXapDp5eWAaAw2xgxkX9uP59rcn5qE5pPPL1ViYNzCUiyyzeWcsTEzqhqgovX9CPj1bto8wV4JSeWbj8mtJo9+x4+uYnMuyRHzhvYB6XDrXiDUWbnLeGQITdNT6sJumwhbZZCVamjCpk+g87iSoqYUXAn9gJy/mfgSIjGC1giee0XgGmL9jJ0sZ0jnir1udlUEEyS3fWsnavi9s/28gVIwoYXpiCTYwS79sFxz8IOf0QbCmcPUDmw1X7mnLIx3ZOp1duPP3a9NI2FQ5Dkt3EZcPbckLXDPa5AsxcXcqSoho+vGpws02M/GQbJ3bP5MsNWvQkJ9HKNaMKW74x/w34ve2TZDVTeOtVKKEI5R9/ha0gl+7P3oUpMxXRagFUDE47Bru2IEga1o/4/j0QDFIzUY7fgiUjlawzxhEsq2LnQy82pcKJVgvWNtl0uGMKqydd13R+4uA+GJx2+n82na23P872+5+j/2cvUv/TWhIH9KJ67kLql2q7tOknjyZpaF8cnQqQg2Hcy9bh3rCVPu8/hSBJuFZvZOWEawhX1SLaLJhSkii89Spqvz8gwGTOSsNWkId3SzF5l59D8cMvYXDayb3yHGRfgPIPvsR20igKplxI2Udz6PzorWy74z8ogSBVX/9I9+fvZu0FN6NGowgGA50fuYU9L3+AOTONvAdvR7Y5iO/fnYYVG7Qxnz4WBBHvlp2knTgKQ34enguncMHt2wkEZDLTLdxxg50Hn9pGnNPAnZeMpG12OnULV7DnlQ/peM91rL34/6iYOReANlMvpOqrHwFIOXYoDSs34OzRkexJp7DqnKmkHDccg91G5hnHY8lKo2rOApzdO5B+0hjWnHcDks1K1yf/xYar7yRYWkH/WS9hzUjBs66xMbGqUvPdUroYDS1GzADM6Sn0efc//HTy5YTKqpBsViJVdSQV5JGUlARozlYkGCZr4omUffBlU9Q5efQgLBlp7H7mTVRZZvno82hz7QW0vflyJLsVub6B+D5dGb7qcyzZmrPd5toL2P2M1o7ImJRA1//cjiUro6m9Q0sIgoDFaiUtLp7A3gpqPvua9Y++TPb5p2FMjF0omdOS6fnqw6w4+XItnVmS6P7sXRgSjuzO+ZHij1g7YU+DSR/AvNsh2AADrkRsfxxxgpOwnIxVEA4sjOOzYcydWr2e4fD3n/8aayLkD9bSRgdcqdUCNhLKGYIhfxjEZYFbWwsgmYgOvZF2phSuHV3IF+vKOHbcqfS7eARW927uO6Uzd8zeQkRWSbKbeOD07gQjMk+e0wuzQeTlhTs5q28O1xxTSCgqc+/szXzXKHyWn+wgP9nWTNn9/MH5vLt8D5IAbaQaUr68k3+OfoBrRw9j0U4XFa4AOQlW1uypZ+qY9uyt81Nc4+OHbdXMvGYI326pZHdjit/gdskkWI3sqvExZXQhUVlhyqhCHpyzlaiikuIw8c9xnbh15gacZgNTxxRilESueWc1m8rcmCSRKaMLUYEZC4u5//TutEmxk5tkZenOWm4Y25EPV+7lgW9LAe2ePqZTGtN/2IkkCvTISeDZ74q4+5SuGKvWgRIl1P8qjJLAu5cN4t2f9hCMyExq3CQvdQUY1y2DWl+Yi19fwV0nd2F4uoXtlZ4mzYF99QGCYfln1yXHdExlXLcMvtpYgSBAICLTr20in14zFNACGVaTgeuO68CE55fww3Zto69dqh272UCq00y1J8T7a2sobkjk9rEf0C3LqaW412yHs9+CzB6I9jT+fYqTidOXNgnqTB3dnowEC9PP7/uzyuQpDjO3je/E+YPz2V3rZ/oPxVS6g3x01eCD/AWNcd0z+WDl3ianvHdeAsM7/BYv4vfhL9NnTxCEwcBdqqoe3/j4nwCqqj54uNf8ql4xQJ0vRFRWcVoaG1wfKQIuTQ1pyyytAWVOP4iEiRqtyMU/IlZvRew+AbcpnfKQiRSHieIqLxlOE8lWgYjaWCyvCNQHZOKsRhRVxR2I4LQaMUki4aiC3SwQCcvYzRL+sIwnJGv506KCPypgMhmZv7mSlbvrGd8jg+7Z8fhCMnaTRJUnSL0/QkGKnaiiIgoCRkmg1hci1WlhV40PgyCQHm9BEgQURcZoMOANRQlFFaxGCX84SlRR2VTmZkT7FF5ZVMypvXIwSdoNwheKsqnMTY+ceKo9QXZW+7jt09h0q/9M7MXz3xexo8rLV9OGYzdKrCipZ3OZm/MG5eEKRKj2hChMc/DMtztYUVLPlFGFDGuv7QIbRYFgKITJIOHxBYiLcyKJAiW1fvxhmQ7pDsJRFW8oQnGNj/u+2NKUOvnZP4aQEWdhWXEd32+rYlTHNIYWJjdF9A6HNxTBE4yiKCpWk6FZrR9oQinV3pBm2IATumWS6jRT6Q4y9b01rCypp02yjacn9aZLZpzWVLQFqj0hqj1BrEatfUKLEefD0BCI4AlGqPOFyYizkGg3tSg4U+8L0xCMEIzIJNvNP6va+XvyV+xj9d/ap19rm6L+ANEGL4JBwpya9HsO+b9CVVVC5dVUfD4f2esn88wTQBAQjAbCVbWUffQVcd07kjSiP6GqWsxpKYSr64h6vDg6tUOVoyCIqJEIcjCEIIqIBgNhjxfJZMLgsKGEwghGIxgkog1uDDabdn4ghMFpA5MJQVUJ7qug5MX3sOZmknvxGVo6o9GIEg7j31GC5LRja5tLuLYeU2K89nkGEWQV98btOLsUIogiCCBazKhRmWB5NSSnIKsCAZcPj2LChY2M5V9hzUrD1jYHY1I8oslE/bI1WDLTEE1GIvmFTLxqJeHIgftk985xjBmexpMvFTHxpAwmDxaQlCh7X/uE1HEjcHYooGHNJuwd2uLdspONU+8hZdRAOj9yK2pUBklENJuQvX5URSHi8WLNSkf2+vFu34W1IBej3UakwU3U7WPX029Q8Ymmkpd+6li6Pn0H0Xo3u597G0OCk/wrJmHJSUf8mbYGqiwTqq5D9geQrBaMKYlIxuaRkVB1HQ2rNlK/fC3pJ43C1jYPVIWS6e9pQkGKQttpF1Ew7SJMKc2joqCJuURcbsJ1DViy0jGnJSH8yg0KRZYJV9URLKvElBSPISEOU2JzJ04OBonUuQlVVGNKS8aY4MTgaJ6N8EfwV7NPf9jaSVXBV63935oIhiMYOfXVQtUmKP4epWAU4aTO1KsOUgUX8uYvEIP1iD3PpkJJIKBI2E0Gimu8FCRbMUgSKppwkaKCJxglzmJAVMKEwmFsFiuqKBKSBRxmCb8/iM0s4ZclbW1lMWASAVFrBfDJqn3srvVz7oA80uPMhGUFuwFSXWu1puFpXdgdsGMxSVgJYQ5U4bPns7HcTbLDTJzFoN1vVQVRlHD5wwiN6yxXIIIkCKzYVcfwDqnMWV/GsV0yMBlE4q1Gaj0hSur9dMuOxxOI8NayEj5cGStO9NFVg7lgxk8YRIFPrhmCzSTx9cYKfKEoZ/TNoaTWj6yopMeZueOzTbgCYe48uSv5SVZEQcApRbCEalAMVrY2mMhNdiCjld9IgkCbFDu+UJRARGZVST0PfbW1Schu4c2jEEX4ckM5G0vdnNEnhy5ZTpLsP792cPnD+MMyAmAzG4i3NrdN/nCUKneIL9aXk5VgYXj7FJLsZrZXepjy7hp2VnvplZvAM5N6x7SyOpiIrFDvC1PhDpJkN+G0GFv8rMNR5wvT4A8TiMikOs2HXRPWekPU+7TrmmAzthgx/CM4KpqqC4JwJnCCqqqXNT4+HxioquqUQ867ArgCIC8vr29JScmfPtY/E6UxcTkqy0QDbnbUhnho/m66ZMXTKzee937aQ5zFhC8U4fGze5EW9/MOSbnLz0nPLOL2EzvTNSueORsqeOrbHfx02xjS4ixEogoINFv8R2XlsI7HfvzhKGWuAG8s2U28zcS5A/KwGkUCEQWDJGAUBR6Zu5X5m6tIdZoprvZx/uA8KhtCzF5fHvNelw5ry546P/M3V/LspN58uqaUQETm6XN6k3KQ0yHLCnWNufhJNmOMbG4wImOSxMNG4zzBCNe8s5qFO2KLbO89tSvnD26jzVtRMBxmN/r3pt4XJiwrSIImcPN37TH1V1tMwa+zT3832wSgRKOIBgOh6loi3gBlb31K+eff0PPl+9l+9zOIRgOy10fe5eeQOm4kBlvLaXwA4QYPG6+5EzkUpuO/pxKqrmP1xKl0n34vWWecgKqqKKEw0iFy/KqioKrqL0Y86+rDfLuoih07vZw4NoP8dCPmsA8BEIwS1d8vZevND2NKTiRcU0+ovIqu237ivGlrY97HZBJ58Lau3HjXBrp2jOOMk7J4++MSJk3IY9zojJhzw3UNKKEQkt2GMe6AoJMSiQIqYgsO137ql61hyfBzYo5ZstMZuuwTLBmpWkN0NAGWPxo5ECTi8gAqxvg4JNvP32daM381+6SvnVpGVhQkUcQTDBMMy2wsdfPo3G1MHpSHyx9h2a46LEYRs0Hk/tO6E/8LPWfVPT8hfHgeyqnTkeOyMC58BCq3wIWfgyNN60coSlr7iYP4NWunhkCEoioP76/YS6eMOE7qkYlJEghGtfTTcFTh9k83sKPKh90sUVTl5ZlJfXjym+0xdYQAj57Zg6e/28HeugCf/WMIt36ygexEK0+c3ZN464E5hqIyDYEIoiDERN5UVSUUVX42i6fKHeTEpxdR7Y2t4J01ZSg9crS68T9z7VTjCSGrKkZJ+EXHsjXTqpqqq6r6EvASaLtTR3g4fzj7HRWTaMATsvN/n29ka4WHpcV1HNs5jSmj25ObaMNmkn7V7oEkiigq3PDh+qZj/dskYmzMOzYeppfaLxkrAJvJQGGak7tP6RbjYO3f/610B/l0TRnBiNIkV2ySJI7vltHM2RvQNom5myoQBchOtPLjjmoSrKZmcr6SJB424vRLKYd2k4ExndKbOXsDCw4Ukv9Zxgr4r6JzOn89/m62CWiKJplTk6ld8JXW7gBYNeEaCm+7hpTRg5FsVozJ8Ujmn7dPBpsVR8cCdtz7LFWff9N0PL5XF0BL9TvU0QPN2fk12yJJiSbOOjkHRVEPsk9aNEj2B6hfsIJQWRWhMq0WRZAk7A4jNquEP3BANKZ3t3h27NIWWL27x7P4p1qKSwKkJTcfmymp5dTClmooD8WSm4VgNMaIzqSMHoLBqY35z3Dy9iNZLS02Tdc5evi72af9SrVOi4lAOMi176/FG4py+2ebmDwwj5uO60iKw4zdLP2iowcgxGWCrxrxndMPiF0MnnJAHfwwKay/Zu0UbzXSNz+J3rmJLW5O76z2smB77DrFahQZ2TE1xtkTBU0norIhRLLdhDsQZWuFh3irsZmQntkgkeZsvkYSBOEX1042s4Ehhcl8vrbsoPcTST8o2PBnrp1S/qSso6OZv5LaQimQe9DjnMZjOo0kO8xMP68vXRuLPXfX+kmxm8lOsP7qMHGS3cSblwykTbIW5u6dm8CTE3uR+CuM3a/lcJG0BKuRNy4e0NRfZ3C7ZC4Y3IYh7VK4bFhbzAYRm0li2phCar0hghGZx87qySer9pGbaOP1S/q3mBr5W8Z5cs9Mzu6Xg0EUiLMauP+0bmT8QnRU52+Jbp9+gZRRg2gz7UJEs4lIg5eIy40xMR5LVtovOnqgOUD5V51L5tnjQRQxJifS663HMP3O6a0t2SfJZqX9nVNIG38MCALmjFT6znwep03g8bu7k5mu2YSeXeO5dHIbPv2ylGOHpzKwbxLLV9dx8aR8Cts6mr3vb8GYFE//z6ZjbmyXkXLccDo+cGNTHaeOTiO6bfoFEmxG3rikPzmJWmbBjipNpTI70fqztVoxWJO0Jt32VE0wptNJMHRai319/1cOt3ZKdZh55IwexFuNSKLAGX1y6JmbwJUj2nF813REAVIcJh49syefrS0lO9HK05N688KCnfTJS+CJs3v9+nn+ChxmA7eN78zwxrKZjDgLr17U/79KidT5c/krpXEagO3AGDRDtQI4V1XVTYd7za+ti2lt1HpDRGQVgyT8bOHr4VBVlVpvmKiiYjL8uWFvRVGp9YWQVbAYxCYD5A9F8TYWzZoNIsGogiCAURQJRRUkUfjDasa8oQi+kIwgQILVhOkw0U2dP4e/WpoU/Pf26e9qm6I+f1MLB2NiHJLlv18IRRo8moy+KGBMTmixtuyPIlzv1tQ6RQFTahKiJKGqKvWuCLKiYjQIqKrW7sRoFIlGFVQVnHYD5haaBf9W9tfaoSharV0L9Ws6fy5/Nfukr51+HdraI4ysqpgl8X/LpJGjWisJVdEU2K1/3t9jOKrg8odRAbtJwtEo9+8ORAhEtHo3k0EkGFGQRC2yFooqmAzi77pJfjAuf5hgVEESIMlujunVrPPnc1SkcaqqGhUEYQowF5CAV3/OWP2d+a3FnoIgHLGwtygKLRa12swGbAe1yfgzlzQOsxGHWd+R0jk8un36dRjstt8ceTLGOzHGN5dp/zMwJcbBIeqPgiCQlHhkUqwFScKSceSV3HT+uui26dch/h4bxpIBnOm/fN4fgMkgtqjJEGc1EneEImq/Z7RQ54/lL+PsAaiqOgeYc6THoaOjo3Moun3S0dH5K6LbJh0dnZ9Dz1fT0dHR0dHR0dHR0dFphejOno6Ojo6Ojo6Ojo6OTitEd/Z0dHR0dHR0dHR0dHRaIbqzp6Ojo6Ojo6Ojo6Oj0wrRnT0dHR0dHR0dHR0dHZ1WiO7s6ejo6Ojo6Ojo6OjotEJ0Z09HR0dHR0dHR0dHR6cVIqiqeqTH8D8jCEI1UPIrTk0Bav7g4RxJWvv8oPXPUZ/fAfJVVT2qO0n/F7YJ9Gt/tKPP7+jmv53f38k+6df+6Ka1zw9a/xx/l7XTUe3s/VoEQVipqmq/Iz2OP4rWPj9o/XPU5/f3pbV/N/r8jm70+f19ae3fjT6/o5/WPsffa356GqeOjo6Ojo6Ojo6Ojk4rRHf2dHR0dHR0dHR0dHR0WiF/F2fvpSM9gD+Y1j4/aP1z1Of396W1fzf6/I5u9Pn9fWnt340+v6Of1j7H32V+f4uaPR0dHR0dHR0dHR0dnb8bf5fIno6Ojo6Ojo6Ojo6Ozt+KVu/sCYJwgiAI2wRBKBIE4dYjPZ7fiiAIuYIgfC8IwmZBEDYJgjCt8XiSIAjzBUHY0fj/xCM91t+CIAiSIAhrBEH4ovFxW0EQljdexw8EQTAd6TH+rwiCkCAIwseCIGwVBGGLIAiDW9P1EwTh+sbf5kZBEN4TBMHSmq7f74Vum45OWrNtAt0+tYZr+FtpbbYJdPvUGn7bum36369fq3b2BEGQgOeAcUAXYJIgCF2O7Kh+M1HgRlVVuwCDgH80zulW4FtVVdsD3zY+PpqZBmw56PHDwH9UVS0E6oFLj8iofh+eAr5WVbUT0BNtnq3i+gmCkA1MBfqpqtoNkIBzaF3X7zej26ajmtZsm0C3T63hGv7PtFLbBLp9ag2/bd02/Y/Xr1U7e8AAoEhV1WJVVcPA+8CpR3hMvwlVVctVVV3d+G8P2o89G21ebzSe9gZw2pEZ4W9HEIQc4ETglcbHAjAa+LjxlKN2foIgxAMjgBkAqqqGVVV10YquH2AArIIgGAAbUE4ruX6/I7ptOgppzbYJdPvU+PzRPr/fSquzTaDbp8ZTjtr56bYJ+A3za+3OXjaw96DH+xqPtQoEQWgD9AaWA+mqqpY3PlUBpB+hYf0ePAncAiiNj5MBl6qq0cbHR/N1bAtUA681plq8IgiCnVZy/VRVLQUeA/agGaoGYBWt5/r9Xui26eikNdsm0O0THP3X8LfSqm0T6PbpSAzsd0C3Tb/h+rV2Z6/VIgiCA/gEuE5VVffBz6maxOpRKbMqCMJJQJWqqquO9Fj+IAxAH+AFVVV7Az4OSTs4yq9fItpOW1sgC7ADJxzRQen8qei26ahGt086rRrdPh216LbpN9Danb1SIPegxzmNx45qBEEwohmrd1RVndl4uFL4//bu3kWuOgrj+PcxcQtJESKiC74sgkR8AWEbY1KEaCWioou6qATRP8FGO5EUNoIIdqbRQnzFIKIEDKKNikYR40thFBdcFAOCjQoei3vjK8E1M+y985vvp9mduXfhXM7wwJk5dzZZ7I8vAt8NVd+EdgM3JvmKbn1kH92e9vb+o22Y7T6uAWtV9U7/+Hm6AGulf9cBx6vq+6r6FXiRrqet9G9azKbZ03o2gfkEs9/DSTWZTWA+Mdu9NJsm6F/rw957wCX9t9ks0N3seGjgmibS72A/CXxaVY/+5dAhYH//+37g5c2ubRqq6oGqOr+qluj69UZV3QkcAVb602b5+taBb5Ls7J+6FjhGI/2jW0G4OslZ/Wv15PU10b8pMptmTOvZBOZTf84sX980NJdNYD71p83y9ZlNE1xf8/9UPcn1dHvMW4CDVXVg4JImkmQP8BbwMX/uZT9It3v+LHAh8DVwW1WdGKTIKUmyF7i/qm5IcjHdu1U7gKPAXVX185D1na4kV9HdQL0AfAncQ/fGSxP9S/IQcDvdt58dBe6j2zNvon/TYjbNrlazCcwnGujhpFrLJjCfaOC1bTadfv+aH/YkSZIkaR61vsYpSZIkSXPJYU+SJEmSGuSwJ0mSJEkNctiTJEmSpAY57EmSJElSgxz2NBpJbk5SSS4duhZJOslskjRGZpM2wmFPY7IKvN3/lKSxMJskjZHZpP/ksKdRSLIN2APcC9zRP3dGkieSfJbkcJJXk6z0x5aTvJnk/SSvJ1kcsHxJjTKbJI2R2aSNctjTWNwEvFZVXwA/JFkGbgGWgMuAu4FdAEnOBB4HVqpqGTgIHBiiaEnNM5skjZHZpA3ZOnQBUm8VeKz//Zn+8Vbguar6DVhPcqQ/vhO4AjicBGAL8O3mlitpTphNksbIbNKGOOxpcEl2APuAK5MUXQgV8NKp/gT4pKp2bVKJkuaQ2SRpjMwm/R+ucWoMVoCnquqiqlqqqguA48AJ4NZ+B/1cYG9//ufAOUn+WE9IcvkQhUtqmtkkaYzMJm2Yw57GYJV/vxv1AnAesAYcA54GPgB+rKpf6ILukSQfAR8C12xeuZLmhNkkaYzMJm1YqmroGqRTSrKtqn5KcjbwLrC7qtaHrkvSfDObJI2R2aR/8p49jd0rSbYDC8DDBpakkTCbJI2R2aS/8ZM9SZIkSWqQ9+xJkiRJUoMc9iRJkiSpQQ57kiRJktQghz1JkiRJapDDniRJkiQ1yGFPkiRJkhr0OwSXEK70TKxJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.scatterplot(x = \"Age\", y = \"Fare\", hue=\"Sex\", data = train_full_data)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.scatterplot(x = \"Age\", y = \"Fare\", hue=\"Pclass\", palette=\"coolwarm\", data = train_full_data)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.scatterplot(x = \"Age\", y = \"Fare\", hue=\"Survived\", data = train_full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three graphs shows the same information we found using pivot tables visually. Passengers who survived typically paid higher prices for the fare, more females paid prices over 200 pounds for the fare than male did, and *Pclass* with one also had higher prices than the other *Pclass*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/seaborn/axisgrid.py:728: UserWarning: Using the barplot function without specifying `order` is likely to produce an incorrect plot.\n",
      "  warnings.warn(warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7feb78b21a00>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 440x648 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embark = sns.FacetGrid(train_full_data, row='Embarked', col='Survived')\n",
    "embark.map(sns.barplot, 'Sex', 'Fare')\n",
    "embark.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that survived passengers embarking from S and C paid higher fares, but from Q we do not see such trend. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two new columns *Honorifics* and *LetterTicket*. *Honorifics* checks if honorifics are included in each passenger's name and is classified into five categories: Mr, Mrs, Miss, Master and other. *LetterTicket* checks if letters are included in the ticket. 1 if letter is included, 0 if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "honorifics = []\n",
    "\n",
    "for x in range(len(train_full_data['Name'])):\n",
    "    match = re.findall(\"([A-Za-z]+)\\.\", train_full_data['Name'].iloc[x])\n",
    "\n",
    "    if match[0] in ['Mr', 'Mrs', 'Miss', 'Master']:\n",
    "        honorifics.append(match[0])\n",
    "    else:\n",
    "        honorifics.append(\"Other\")\n",
    "        \n",
    "train_full_data['Honorifics'] = honorifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "LetterTicket = []\n",
    "\n",
    "for x in range(len(train_full_data['Ticket'])):\n",
    "    match = re.search(\"[A-Z]+\", train_full_data['Ticket'].iloc[x])\n",
    "\n",
    "    if match:\n",
    "        LetterTicket.append(1)\n",
    "    else:\n",
    "        LetterTicket.append(0)\n",
    "        \n",
    "train_full_data['LetterTicket'] = LetterTicket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      "PassengerId     891 non-null int64\n",
      "Survived        891 non-null int64\n",
      "Pclass          891 non-null int64\n",
      "Name            891 non-null object\n",
      "Sex             891 non-null object\n",
      "Age             714 non-null float64\n",
      "SibSp           891 non-null int64\n",
      "Parch           891 non-null int64\n",
      "Ticket          891 non-null object\n",
      "Fare            891 non-null float64\n",
      "Cabin           204 non-null object\n",
      "Embarked        889 non-null object\n",
      "NumFamily       891 non-null int64\n",
      "Honorifics      891 non-null object\n",
      "LetterTicket    891 non-null int64\n",
      "dtypes: float64(2), int64(7), object(6)\n",
      "memory usage: 104.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# check if there are 891 entries for new columns\n",
    "train_full_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop columns that are not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      "Survived        891 non-null int64\n",
      "Pclass          891 non-null int64\n",
      "Sex             891 non-null object\n",
      "Age             714 non-null float64\n",
      "Fare            891 non-null float64\n",
      "Embarked        889 non-null object\n",
      "NumFamily       891 non-null int64\n",
      "Honorifics      891 non-null object\n",
      "LetterTicket    891 non-null int64\n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data = train_full_data.drop(columns=['SibSp', 'Parch', 'Cabin', 'Name', 'Ticket', 'PassengerId'])\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Embarked* column has two Null values. We check where the null values are located and drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61, 829]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['Embarked'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      "Survived        889 non-null int64\n",
      "Pclass          889 non-null int64\n",
      "Sex             889 non-null object\n",
      "Age             712 non-null float64\n",
      "Fare            889 non-null float64\n",
      "Embarked        889 non-null object\n",
      "NumFamily       889 non-null int64\n",
      "Honorifics      889 non-null object\n",
      "LetterTicket    889 non-null int64\n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 69.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.drop(train_data.index[[61, 829]])\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset is complete, we standarize the numerical columns and change the non-numerical columns into categorical variables using `OrdinalEncoder` and `OneHotEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"standarize\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = [\"Age\", \"Fare\", \"NumFamily\"]\n",
    "ord_enc = [\"Pclass\", \"Sex\", \"LetterTicket\"]\n",
    "one_hot_enc = [\"Embarked\", \"Honorifics\"]\n",
    "target = [\"Survived\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num_column\", num_pipeline, num),\n",
    "    (\"ord_enc\", OrdinalEncoder(), ord_enc),\n",
    "    (\"one_hot_enc\", OneHotEncoder(), one_hot_enc),\n",
    "    (\"target\", \"passthrough\", target)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_prepared = full_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.563674</td>\n",
       "      <td>-0.500240</td>\n",
       "      <td>0.057853</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.669217</td>\n",
       "      <td>0.788947</td>\n",
       "      <td>0.057853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.255451</td>\n",
       "      <td>-0.486650</td>\n",
       "      <td>-0.561804</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.438050</td>\n",
       "      <td>0.422861</td>\n",
       "      <td>0.057853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.438050</td>\n",
       "      <td>-0.484133</td>\n",
       "      <td>-0.561804</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2    3    4    5    6    7    8    9   10   11  \\\n",
       "0 -0.563674 -0.500240  0.057853  2.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "1  0.669217  0.788947  0.057853  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2 -0.255451 -0.486650 -0.561804  2.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "3  0.438050  0.422861  0.057853  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "4  0.438050 -0.484133 -0.561804  2.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "\n",
       "    12   13   14  \n",
       "0  0.0  0.0  0.0  \n",
       "1  1.0  0.0  1.0  \n",
       "2  0.0  0.0  1.0  \n",
       "3  1.0  0.0  1.0  \n",
       "4  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train = pd.DataFrame(titanic_prepared)\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting and Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use cross-validation to check which machine learning algorithm produces the highest accuracy using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = titanic_train.loc[:, titanic_train.columns != 14]\n",
    "test = titanic_train.loc[:, titanic_train.columns == 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train, test, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    \"\"\"\n",
    "    display list of scores, mean, and standard deviation\n",
    "    \"\"\"\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Std:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.74157303 0.85393258 0.74157303 0.80898876 0.85393258 0.86516854\n",
      " 0.78651685 0.73033708 0.82022472 0.82954545]\n",
      "Mean: 0.803179264555669\n",
      "Std: 0.04815414647115755\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "scores = cross_val_score(RandomForestClassifier(), train, test.values.ravel(), scoring=\"accuracy\", cv=10)\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.78651685 0.84269663 0.78651685 0.85393258 0.79775281 0.7752809\n",
      " 0.80898876 0.83146067 0.83146067 0.82954545]\n",
      "Mean: 0.8144152196118487\n",
      "Std: 0.02562556206483465\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier\n",
    "scores = cross_val_score(AdaBoostClassifier(), train, test.values.ravel(), scoring=\"accuracy\", cv=10)\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.42696629 0.24719101 0.21348315 0.35955056 0.25842697 0.65168539\n",
      " 0.64044944 0.62921348 0.6741573  0.23863636]\n",
      "Mean: 0.4339759959141981\n",
      "Std: 0.18544606849416487\n"
     ]
    }
   ],
   "source": [
    "# KMeans\n",
    "scores = cross_val_score(KMeans(n_clusters=3), train, test.values.ravel(), scoring=\"accuracy\", cv=10)\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.7752809  0.84269663 0.76404494 0.85393258 0.85393258 0.86516854\n",
      " 0.82022472 0.78651685 0.85393258 0.85227273]\n",
      "Mean: 0.8268003064351379\n",
      "Std: 0.03583381068805046\n"
     ]
    }
   ],
   "source": [
    "# KNeighborsClassifier\n",
    "scores = cross_val_score(KNeighborsClassifier(), train, test.values.ravel(), scoring=\"accuracy\", cv=10)\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.82022472 0.85393258 0.7752809  0.85393258 0.80898876 0.78651685\n",
      " 0.82022472 0.82022472 0.84269663 0.86363636]\n",
      "Mean: 0.8245658835546475\n",
      "Std: 0.027849514757539735\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "scores = cross_val_score(LogisticRegression(), train, test.values.ravel(), scoring=\"accuracy\", cv=10)\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.57303371 0.7752809  0.61797753 0.49438202 0.58426966 0.64044944\n",
      " 0.56179775 0.62921348 0.66292135 0.63636364]\n",
      "Mean: 0.6175689479060266\n",
      "Std: 0.07022826623040783\n"
     ]
    }
   ],
   "source": [
    "# GaussianMixture\n",
    "scores = cross_val_score(GaussianMixture(), train, test.values.ravel(), scoring=\"accuracy\", cv=10)\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.83146067 0.84269663 0.7752809  0.85393258 0.83146067 0.79775281\n",
      " 0.80898876 0.79775281 0.86516854 0.86363636]\n",
      "Mean: 0.8268130745658835\n",
      "Std: 0.02918958893394229\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC\n",
    "scores = cross_val_score(LinearSVC(max_iter=5000), train, test.values.ravel(), scoring=\"accuracy\", cv=10)\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.82022472 0.86516854 0.7752809  0.87640449 0.83146067 0.79775281\n",
      " 0.82022472 0.79775281 0.86516854 0.86363636]\n",
      "Mean: 0.8313074565883556\n",
      "Std: 0.033179102509190074\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "scores = cross_val_score(SVC(), train, test.values.ravel(), scoring=\"accuracy\", cv=10)\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.75280899 0.79775281 0.66292135 0.82022472 0.80898876 0.76404494\n",
      " 0.83146067 0.75280899 0.78651685 0.79545455]\n",
      "Mean: 0.7772982635342185\n",
      "Std: 0.045902870196372736\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "scores = cross_val_score(DecisionTreeClassifier(), train, test.values.ravel(), scoring=\"accuracy\", cv=10)\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the mean and standard deviation value the promising models are: RandomForestClassifier, AdaBoostClassifier, KNeighborsClassifier, Logistic Regression, LinearSVC, and SVC. The model have means that are higher than 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"binary_crossentropy_adam.h5\")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5905 - accuracy: 0.7229 - val_loss: 0.5528 - val_accuracy: 0.7022\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7848 - val_loss: 0.4990 - val_accuracy: 0.7978\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8129 - val_loss: 0.4788 - val_accuracy: 0.8034\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8214 - val_loss: 0.4722 - val_accuracy: 0.8146\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8214 - val_loss: 0.4679 - val_accuracy: 0.8146\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8242 - val_loss: 0.4660 - val_accuracy: 0.8090\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8270 - val_loss: 0.4705 - val_accuracy: 0.8090\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8340 - val_loss: 0.4656 - val_accuracy: 0.8146\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3853 - accuracy: 0.8298 - val_loss: 0.4693 - val_accuracy: 0.8090\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8298 - val_loss: 0.4742 - val_accuracy: 0.8090\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8383 - val_loss: 0.4659 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8383 - val_loss: 0.4742 - val_accuracy: 0.8090\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8397 - val_loss: 0.4740 - val_accuracy: 0.8202\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.8453 - val_loss: 0.4712 - val_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8495 - val_loss: 0.4717 - val_accuracy: 0.8146\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8453 - val_loss: 0.4798 - val_accuracy: 0.7978\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8453 - val_loss: 0.4800 - val_accuracy: 0.8034\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8453 - val_loss: 0.4754 - val_accuracy: 0.8090\n"
     ]
    }
   ],
   "source": [
    "history = nn_model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.save(\"binary_crossentropy_adam.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5459 - accuracy: 0.7637 - val_loss: 0.6240 - val_accuracy: 0.6685\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8298 - val_loss: 0.6296 - val_accuracy: 0.6348\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8523 - val_loss: 0.6022 - val_accuracy: 0.6742\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.8523 - val_loss: 0.6058 - val_accuracy: 0.7079\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.8453 - val_loss: 0.5852 - val_accuracy: 0.6854\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8537 - val_loss: 0.5690 - val_accuracy: 0.7191\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8537 - val_loss: 0.5631 - val_accuracy: 0.7247\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8551 - val_loss: 0.5472 - val_accuracy: 0.7247\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8579 - val_loss: 0.5123 - val_accuracy: 0.7921\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8622 - val_loss: 0.5215 - val_accuracy: 0.7697\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8678 - val_loss: 0.5026 - val_accuracy: 0.7697\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8565 - val_loss: 0.4941 - val_accuracy: 0.7865\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3328 - accuracy: 0.8678 - val_loss: 0.4886 - val_accuracy: 0.7584\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.8664 - val_loss: 0.4722 - val_accuracy: 0.8090\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8720 - val_loss: 0.4818 - val_accuracy: 0.7978\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8636 - val_loss: 0.4665 - val_accuracy: 0.8034\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8608 - val_loss: 0.4743 - val_accuracy: 0.8090\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 0.8762 - val_loss: 0.4857 - val_accuracy: 0.7978\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.8664 - val_loss: 0.5094 - val_accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2967 - accuracy: 0.8833 - val_loss: 0.4636 - val_accuracy: 0.8258\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.8734 - val_loss: 0.4656 - val_accuracy: 0.8146\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.8706 - val_loss: 0.4829 - val_accuracy: 0.8258\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8664 - val_loss: 0.4985 - val_accuracy: 0.8202\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8762 - val_loss: 0.5039 - val_accuracy: 0.8034\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3040 - accuracy: 0.8748 - val_loss: 0.5019 - val_accuracy: 0.8315\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8678 - val_loss: 0.5335 - val_accuracy: 0.8034\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2990 - accuracy: 0.8734 - val_loss: 0.5491 - val_accuracy: 0.8034\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.8692 - val_loss: 0.5180 - val_accuracy: 0.8146\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8776 - val_loss: 0.5692 - val_accuracy: 0.7865\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8650 - val_loss: 0.5680 - val_accuracy: 0.8034\n"
     ]
    }
   ],
   "source": [
    "nn_model_1 = keras.models.Sequential([\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "nn_model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"binary_crossentropy_adam2.h5\")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = nn_model_1.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "nn_model_1.save(\"binary_crossentropy_adam1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network model shows an accuracy score higher than 0.8 for the validation set. Since the model shows promise, we check further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous section, the list of promising models are:\n",
    "\n",
    "- RandomForestClassifier\n",
    "- AdaBoostClassifier\n",
    "- KNeighborsClassifier\n",
    "- Logistic Regression\n",
    "- LinearSVC\n",
    "- SVC\n",
    "- Neural Networks\n",
    "\n",
    "We use GridSearchCV to find the parameters that produce the highest accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'max_depth': [4, 8, 16, 32],\n",
       "                          'n_estimators': [50, 100, 200, 500]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators': [50, 100, 200, 500], 'max_depth': [4, 8, 16, 32]}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=3, scoring='accuracy',\n",
    "                          return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8033707865168539\n"
     ]
    }
   ],
   "source": [
    "predict = grid_search.best_estimator_.predict(X_valid)\n",
    "print(accuracy_score(y_valid, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797752808988764\n",
      "{'learning_rate': 0.1, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators': [10, 50, 100, 300], 'learning_rate':[0.01, 0.1, 1, 10]}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(AdaBoostClassifier(), param_grid, cv=3, scoring='accuracy',\n",
    "                          return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "predict = grid_search.best_estimator_.predict(X_valid)\n",
    "print(accuracy_score(y_valid, predict))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8033707865168539\n",
      "{'algorithm': 'auto', 'n_neighbors': 4, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'n_neighbors': [2, 3, 4, 5, 6, 7], 'weights':['uniform', 'distance'],\n",
    "     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=3, scoring='accuracy',\n",
    "                          return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "predict = grid_search.best_estimator_.predict(X_valid)\n",
    "print(accuracy_score(y_valid, predict))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8146067415730337\n",
      "{'penalty': 'l2', 'tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'penalty': ['l2', 'none'], 'tol': [1e-2, 1e-3, 1e-4, 1e-5, 1e-10]}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=3, scoring='accuracy',\n",
    "                          return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "predict = grid_search.best_estimator_.predict(X_valid)\n",
    "print(accuracy_score(y_valid, predict))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8258426966292135\n",
      "{'C': 5, 'loss': 'hinge', 'tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'tol': [1e-2, 1e-3, 1e-4], 'C':[1, 5], 'loss':['hinge','squared_hinge']}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(LinearSVC(max_iter=1000000), param_grid, cv=3, scoring='accuracy',\n",
    "                          return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "predict = grid_search.best_estimator_.predict(X_valid)\n",
    "print(accuracy_score(y_valid, predict))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8258426966292135\n",
      "{'C': 5, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'kernel':['linear', 'poly', 'rbf', 'sigmoid'], 'C': [1, 5, 10]}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=3, scoring='accuracy',\n",
    "                          return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "predict = grid_search.best_estimator_.predict(X_valid)\n",
    "print(accuracy_score(y_valid, predict))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the grid searches we see that LinearSVC has the highest accuracy score on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=1e-3):\n",
    "    \"\"\"\n",
    "    create sequential model for GridSearch\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential()\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    optimizer = keras.optimizers.SGD(lr = learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_classifier = keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_869 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7143 - accuracy: 0.6730 - val_loss: 0.7107 - val_accuracy: 0.6517\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7041 - accuracy: 0.6751 - val_loss: 0.7024 - val_accuracy: 0.6685\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.6772 - val_loss: 0.6946 - val_accuracy: 0.6629\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.6793 - val_loss: 0.6871 - val_accuracy: 0.6629\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.6835 - val_loss: 0.6796 - val_accuracy: 0.6685\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.6835 - val_loss: 0.6727 - val_accuracy: 0.6685\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6835 - val_loss: 0.6660 - val_accuracy: 0.6629\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6835 - val_loss: 0.6595 - val_accuracy: 0.6685\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6899 - val_loss: 0.6532 - val_accuracy: 0.6742\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.6899 - val_loss: 0.6471 - val_accuracy: 0.6742\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.7004 - val_loss: 0.6413 - val_accuracy: 0.6798\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.7004 - val_loss: 0.6356 - val_accuracy: 0.6854\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.7046 - val_loss: 0.6299 - val_accuracy: 0.6910\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6061 - accuracy: 0.7068 - val_loss: 0.6248 - val_accuracy: 0.6910\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.7068 - val_loss: 0.6199 - val_accuracy: 0.6910\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.7152 - val_loss: 0.6150 - val_accuracy: 0.6910\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7236 - val_loss: 0.6102 - val_accuracy: 0.7191\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7257 - val_loss: 0.6055 - val_accuracy: 0.7191\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.7363 - val_loss: 0.6009 - val_accuracy: 0.7191\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7426 - val_loss: 0.5968 - val_accuracy: 0.7191\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7426 - val_loss: 0.5925 - val_accuracy: 0.7247\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7426 - val_loss: 0.5885 - val_accuracy: 0.7247\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7468 - val_loss: 0.5844 - val_accuracy: 0.7360\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7447 - val_loss: 0.5807 - val_accuracy: 0.7360\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7511 - val_loss: 0.5772 - val_accuracy: 0.7360\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7595 - val_loss: 0.5737 - val_accuracy: 0.7472\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7658 - val_loss: 0.5700 - val_accuracy: 0.7528\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7679 - val_loss: 0.5671 - val_accuracy: 0.7528\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7700 - val_loss: 0.5641 - val_accuracy: 0.7472\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7743 - val_loss: 0.5608 - val_accuracy: 0.7472\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7764 - val_loss: 0.5579 - val_accuracy: 0.7528\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7785 - val_loss: 0.5550 - val_accuracy: 0.7528\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7806 - val_loss: 0.5522 - val_accuracy: 0.7584\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7806 - val_loss: 0.5496 - val_accuracy: 0.7584\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7827 - val_loss: 0.5470 - val_accuracy: 0.7584\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7848 - val_loss: 0.5444 - val_accuracy: 0.7528\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7869 - val_loss: 0.5420 - val_accuracy: 0.7528\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7890 - val_loss: 0.5400 - val_accuracy: 0.7528\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7911 - val_loss: 0.5378 - val_accuracy: 0.7528\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7911 - val_loss: 0.5357 - val_accuracy: 0.7528\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7932 - val_loss: 0.5338 - val_accuracy: 0.7528\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7975 - val_loss: 0.5316 - val_accuracy: 0.7640\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7996 - val_loss: 0.5298 - val_accuracy: 0.7640\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.8038 - val_loss: 0.5280 - val_accuracy: 0.7640\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8059 - val_loss: 0.5262 - val_accuracy: 0.7640\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.8101 - val_loss: 0.5244 - val_accuracy: 0.7640\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.8101 - val_loss: 0.5227 - val_accuracy: 0.7753\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.8143 - val_loss: 0.5213 - val_accuracy: 0.7753\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.4701 - accuracy: 0.8186 - val_loss: 0.5197 - val_accuracy: 0.7753\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.8186 - val_loss: 0.5179 - val_accuracy: 0.7753\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.8186 - val_loss: 0.5166 - val_accuracy: 0.7753\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.8186 - val_loss: 0.5155 - val_accuracy: 0.7809\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.8186 - val_loss: 0.5142 - val_accuracy: 0.7865\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.8143 - val_loss: 0.5128 - val_accuracy: 0.7865\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.8165 - val_loss: 0.5116 - val_accuracy: 0.7865\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8165 - val_loss: 0.5104 - val_accuracy: 0.7865\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.8186 - val_loss: 0.5091 - val_accuracy: 0.7865\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.8207 - val_loss: 0.5080 - val_accuracy: 0.7865\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.8207 - val_loss: 0.5071 - val_accuracy: 0.7865\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.8207 - val_loss: 0.5059 - val_accuracy: 0.7865\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.8228 - val_loss: 0.5049 - val_accuracy: 0.7921\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.8228 - val_loss: 0.5039 - val_accuracy: 0.7921\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.8228 - val_loss: 0.5029 - val_accuracy: 0.7921\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.8228 - val_loss: 0.5020 - val_accuracy: 0.7921\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.8228 - val_loss: 0.5013 - val_accuracy: 0.7921\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.8228 - val_loss: 0.5003 - val_accuracy: 0.7921\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8228 - val_loss: 0.4997 - val_accuracy: 0.7921\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8228 - val_loss: 0.4989 - val_accuracy: 0.7921\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.4983 - val_accuracy: 0.7978\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.8228 - val_loss: 0.4973 - val_accuracy: 0.7978\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.8228 - val_loss: 0.4966 - val_accuracy: 0.7978\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8249 - val_loss: 0.4958 - val_accuracy: 0.7978\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8249 - val_loss: 0.4953 - val_accuracy: 0.7978\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8249 - val_loss: 0.4948 - val_accuracy: 0.7978\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.8249 - val_loss: 0.4940 - val_accuracy: 0.7978\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.8249 - val_loss: 0.4933 - val_accuracy: 0.7978\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.8228 - val_loss: 0.4928 - val_accuracy: 0.7978\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.8228 - val_loss: 0.4923 - val_accuracy: 0.7978\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8228 - val_loss: 0.4920 - val_accuracy: 0.7978\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8228 - val_loss: 0.4912 - val_accuracy: 0.8034\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8228 - val_loss: 0.4905 - val_accuracy: 0.8034\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4902 - val_accuracy: 0.8090\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8228 - val_loss: 0.4896 - val_accuracy: 0.8090\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8228 - val_loss: 0.4891 - val_accuracy: 0.8090\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8228 - val_loss: 0.4889 - val_accuracy: 0.8090\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8228 - val_loss: 0.4882 - val_accuracy: 0.8090\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8228 - val_loss: 0.4878 - val_accuracy: 0.8090\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8249 - val_loss: 0.4873 - val_accuracy: 0.8090\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.8249 - val_loss: 0.4869 - val_accuracy: 0.8090\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8249 - val_loss: 0.4865 - val_accuracy: 0.8090\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8270 - val_loss: 0.4862 - val_accuracy: 0.8090\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8270 - val_loss: 0.4858 - val_accuracy: 0.8090\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8270 - val_loss: 0.4852 - val_accuracy: 0.8090\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8270 - val_loss: 0.4850 - val_accuracy: 0.8090\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8270 - val_loss: 0.4847 - val_accuracy: 0.8034\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8270 - val_loss: 0.4844 - val_accuracy: 0.8034\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8270 - val_loss: 0.4842 - val_accuracy: 0.8034\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8270 - val_loss: 0.4838 - val_accuracy: 0.8034\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8270 - val_loss: 0.4834 - val_accuracy: 0.8090\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8291 - val_loss: 0.4831 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 715us/step - loss: 0.5009 - accuracy: 0.7848\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_870 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6508 - accuracy: 0.6414 - val_loss: 0.6997 - val_accuracy: 0.5843\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6646 - val_loss: 0.6865 - val_accuracy: 0.6461\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.6941 - val_loss: 0.6745 - val_accuracy: 0.6685\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.7152 - val_loss: 0.6644 - val_accuracy: 0.6742\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.7342 - val_loss: 0.6548 - val_accuracy: 0.6798\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.7300 - val_loss: 0.6463 - val_accuracy: 0.6910\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.7215 - val_loss: 0.6386 - val_accuracy: 0.6798\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7236 - val_loss: 0.6314 - val_accuracy: 0.6966\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7257 - val_loss: 0.6253 - val_accuracy: 0.7022\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7342 - val_loss: 0.6195 - val_accuracy: 0.7079\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7363 - val_loss: 0.6143 - val_accuracy: 0.7079\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7384 - val_loss: 0.6093 - val_accuracy: 0.7079\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.7384 - val_loss: 0.6046 - val_accuracy: 0.7135\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7384 - val_loss: 0.5998 - val_accuracy: 0.7191\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7426 - val_loss: 0.5959 - val_accuracy: 0.7191\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7405 - val_loss: 0.5919 - val_accuracy: 0.7191\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7426 - val_loss: 0.5882 - val_accuracy: 0.7191\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7468 - val_loss: 0.5849 - val_accuracy: 0.7191\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7468 - val_loss: 0.5815 - val_accuracy: 0.7247\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7468 - val_loss: 0.5782 - val_accuracy: 0.7247\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7489 - val_loss: 0.5753 - val_accuracy: 0.7303\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7489 - val_loss: 0.5723 - val_accuracy: 0.7360\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7511 - val_loss: 0.5694 - val_accuracy: 0.7360\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7511 - val_loss: 0.5667 - val_accuracy: 0.7303\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7511 - val_loss: 0.5641 - val_accuracy: 0.7303\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7595 - val_loss: 0.5615 - val_accuracy: 0.7416\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7616 - val_loss: 0.5591 - val_accuracy: 0.7416\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7743 - val_loss: 0.5567 - val_accuracy: 0.7472\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7932 - val_loss: 0.5546 - val_accuracy: 0.7472\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7911 - val_loss: 0.5524 - val_accuracy: 0.7472\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7890 - val_loss: 0.5501 - val_accuracy: 0.7528\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7890 - val_loss: 0.5483 - val_accuracy: 0.7528\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7890 - val_loss: 0.5463 - val_accuracy: 0.7584\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7890 - val_loss: 0.5447 - val_accuracy: 0.7584\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7975 - val_loss: 0.5430 - val_accuracy: 0.7640\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7975 - val_loss: 0.5411 - val_accuracy: 0.7753\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7954 - val_loss: 0.5395 - val_accuracy: 0.7753\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7954 - val_loss: 0.5380 - val_accuracy: 0.7753\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7954 - val_loss: 0.5365 - val_accuracy: 0.7753\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7996 - val_loss: 0.5349 - val_accuracy: 0.7753\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.8017 - val_loss: 0.5335 - val_accuracy: 0.7753\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7996 - val_loss: 0.5321 - val_accuracy: 0.7809\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7996 - val_loss: 0.5308 - val_accuracy: 0.7809\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7996 - val_loss: 0.5296 - val_accuracy: 0.7865\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7996 - val_loss: 0.5283 - val_accuracy: 0.7865\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7996 - val_loss: 0.5271 - val_accuracy: 0.7865\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.8017 - val_loss: 0.5259 - val_accuracy: 0.7865\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7996 - val_loss: 0.5248 - val_accuracy: 0.7865\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.8017 - val_loss: 0.5237 - val_accuracy: 0.7865\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.8038 - val_loss: 0.5227 - val_accuracy: 0.7865\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7975 - val_loss: 0.5216 - val_accuracy: 0.7865\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7996 - val_loss: 0.5206 - val_accuracy: 0.7865\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7996 - val_loss: 0.5196 - val_accuracy: 0.7865\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7996 - val_loss: 0.5187 - val_accuracy: 0.7865\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7996 - val_loss: 0.5178 - val_accuracy: 0.7865\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7996 - val_loss: 0.5169 - val_accuracy: 0.7865\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7865\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.8038 - val_loss: 0.5151 - val_accuracy: 0.7809\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.8059 - val_loss: 0.5145 - val_accuracy: 0.7809\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.8059 - val_loss: 0.5135 - val_accuracy: 0.7865\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.8059 - val_loss: 0.5127 - val_accuracy: 0.7865\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.8059 - val_loss: 0.5118 - val_accuracy: 0.7865\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8038 - val_loss: 0.5110 - val_accuracy: 0.7865\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8038 - val_loss: 0.5104 - val_accuracy: 0.7865\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.8038 - val_loss: 0.5096 - val_accuracy: 0.7865\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.8038 - val_loss: 0.5089 - val_accuracy: 0.7921\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.8038 - val_loss: 0.5084 - val_accuracy: 0.7921\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.8038 - val_loss: 0.5077 - val_accuracy: 0.7921\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.8038 - val_loss: 0.5071 - val_accuracy: 0.7921\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.8038 - val_loss: 0.5064 - val_accuracy: 0.7921\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.8038 - val_loss: 0.5058 - val_accuracy: 0.7921\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7921\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8038 - val_loss: 0.5046 - val_accuracy: 0.7921\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8038 - val_loss: 0.5041 - val_accuracy: 0.7921\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.8038 - val_loss: 0.5035 - val_accuracy: 0.7921\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7921\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.8038 - val_loss: 0.5025 - val_accuracy: 0.7921\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.8038 - val_loss: 0.5019 - val_accuracy: 0.7921\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8038 - val_loss: 0.5015 - val_accuracy: 0.7921\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.8038 - val_loss: 0.5009 - val_accuracy: 0.7921\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.8038 - val_loss: 0.5004 - val_accuracy: 0.7921\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8038 - val_loss: 0.4999 - val_accuracy: 0.7921\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.8038 - val_loss: 0.4995 - val_accuracy: 0.7921\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.8038 - val_loss: 0.4990 - val_accuracy: 0.7921\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.8038 - val_loss: 0.4986 - val_accuracy: 0.7921\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.8038 - val_loss: 0.4981 - val_accuracy: 0.7921\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.8038 - val_loss: 0.4977 - val_accuracy: 0.7921\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.8038 - val_loss: 0.4973 - val_accuracy: 0.7921\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8017 - val_loss: 0.4969 - val_accuracy: 0.7921\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.8017 - val_loss: 0.4965 - val_accuracy: 0.7921\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8017 - val_loss: 0.4960 - val_accuracy: 0.7921\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8038 - val_loss: 0.4958 - val_accuracy: 0.7921\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.8017 - val_loss: 0.4952 - val_accuracy: 0.7921\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8017 - val_loss: 0.4949 - val_accuracy: 0.7921\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.8017 - val_loss: 0.4945 - val_accuracy: 0.7921\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8017 - val_loss: 0.4942 - val_accuracy: 0.7921\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.8017 - val_loss: 0.4937 - val_accuracy: 0.7921\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.8017 - val_loss: 0.4934 - val_accuracy: 0.7921\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.8038 - val_loss: 0.4931 - val_accuracy: 0.7921\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8038 - val_loss: 0.4927 - val_accuracy: 0.7921\n",
      "8/8 [==============================] - 0s 819us/step - loss: 0.4316 - accuracy: 0.7975\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_871 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.9932 - accuracy: 0.3671 - val_loss: 0.9257 - val_accuracy: 0.3708\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9639 - accuracy: 0.3755 - val_loss: 0.9003 - val_accuracy: 0.3820\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9363 - accuracy: 0.3776 - val_loss: 0.8764 - val_accuracy: 0.3876\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9107 - accuracy: 0.3840 - val_loss: 0.8537 - val_accuracy: 0.3933\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8859 - accuracy: 0.4051 - val_loss: 0.8329 - val_accuracy: 0.3933\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8634 - accuracy: 0.4114 - val_loss: 0.8130 - val_accuracy: 0.3989\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8425 - accuracy: 0.4135 - val_loss: 0.7941 - val_accuracy: 0.4045\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8216 - accuracy: 0.4325 - val_loss: 0.7773 - val_accuracy: 0.4494\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8035 - accuracy: 0.4557 - val_loss: 0.7613 - val_accuracy: 0.4831\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7857 - accuracy: 0.4684 - val_loss: 0.7468 - val_accuracy: 0.4888\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7699 - accuracy: 0.4684 - val_loss: 0.7330 - val_accuracy: 0.5056\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7543 - accuracy: 0.4705 - val_loss: 0.7208 - val_accuracy: 0.5112\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7405 - accuracy: 0.4852 - val_loss: 0.7089 - val_accuracy: 0.5281\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7269 - accuracy: 0.5127 - val_loss: 0.6985 - val_accuracy: 0.5225\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7151 - accuracy: 0.5211 - val_loss: 0.6883 - val_accuracy: 0.5393\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.5380 - val_loss: 0.6792 - val_accuracy: 0.5787\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6013 - val_loss: 0.6705 - val_accuracy: 0.6629\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.6435 - val_loss: 0.6626 - val_accuracy: 0.6685\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6739 - accuracy: 0.6456 - val_loss: 0.6554 - val_accuracy: 0.6742\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.6540 - val_loss: 0.6484 - val_accuracy: 0.6798\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6582 - val_loss: 0.6422 - val_accuracy: 0.6742\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.6561 - val_loss: 0.6361 - val_accuracy: 0.6742\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.6603 - val_loss: 0.6307 - val_accuracy: 0.6742\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6624 - val_loss: 0.6257 - val_accuracy: 0.6685\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6624 - val_loss: 0.6208 - val_accuracy: 0.6685\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6667 - val_loss: 0.6163 - val_accuracy: 0.6629\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.6667 - val_loss: 0.6120 - val_accuracy: 0.6629\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6730 - val_loss: 0.6081 - val_accuracy: 0.6685\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6751 - val_loss: 0.6045 - val_accuracy: 0.6798\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.6793 - val_loss: 0.6008 - val_accuracy: 0.6854\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6899 - val_loss: 0.5976 - val_accuracy: 0.6854\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6941 - val_loss: 0.5943 - val_accuracy: 0.6854\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.7025 - val_loss: 0.5912 - val_accuracy: 0.6854\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7046 - val_loss: 0.5883 - val_accuracy: 0.6854\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7046 - val_loss: 0.5855 - val_accuracy: 0.6854\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7068 - val_loss: 0.5829 - val_accuracy: 0.6854\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7152 - val_loss: 0.5803 - val_accuracy: 0.6910\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7152 - val_loss: 0.5781 - val_accuracy: 0.6966\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7173 - val_loss: 0.5756 - val_accuracy: 0.6966\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7215 - val_loss: 0.5734 - val_accuracy: 0.6966\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7236 - val_loss: 0.5712 - val_accuracy: 0.6966\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7236 - val_loss: 0.5690 - val_accuracy: 0.6910\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.7257 - val_loss: 0.5671 - val_accuracy: 0.7022\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7236 - val_loss: 0.5651 - val_accuracy: 0.7022\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7257 - val_loss: 0.5632 - val_accuracy: 0.7022\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7278 - val_loss: 0.5613 - val_accuracy: 0.7022\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7278 - val_loss: 0.5596 - val_accuracy: 0.7022\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7278 - val_loss: 0.5578 - val_accuracy: 0.6966\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7300 - val_loss: 0.5563 - val_accuracy: 0.6966\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7321 - val_loss: 0.5546 - val_accuracy: 0.6966\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7321 - val_loss: 0.5530 - val_accuracy: 0.6966\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7342 - val_loss: 0.5515 - val_accuracy: 0.6966\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7342 - val_loss: 0.5500 - val_accuracy: 0.6966\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7384 - val_loss: 0.5486 - val_accuracy: 0.7022\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7384 - val_loss: 0.5472 - val_accuracy: 0.7022\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7426 - val_loss: 0.5456 - val_accuracy: 0.7079\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7447 - val_loss: 0.5444 - val_accuracy: 0.7135\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7468 - val_loss: 0.5432 - val_accuracy: 0.7135\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7489 - val_loss: 0.5419 - val_accuracy: 0.7135\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7489 - val_loss: 0.5406 - val_accuracy: 0.7191\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7511 - val_loss: 0.5395 - val_accuracy: 0.7191\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7511 - val_loss: 0.5384 - val_accuracy: 0.7247\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7511 - val_loss: 0.5373 - val_accuracy: 0.7191\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7532 - val_loss: 0.5361 - val_accuracy: 0.7247\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7532 - val_loss: 0.5350 - val_accuracy: 0.7303\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7532 - val_loss: 0.5340 - val_accuracy: 0.7303\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7553 - val_loss: 0.5329 - val_accuracy: 0.7303\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7553 - val_loss: 0.5320 - val_accuracy: 0.7303\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7553 - val_loss: 0.5308 - val_accuracy: 0.7303\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7553 - val_loss: 0.5299 - val_accuracy: 0.7303\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7553 - val_loss: 0.5289 - val_accuracy: 0.7303\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7553 - val_loss: 0.5282 - val_accuracy: 0.7303\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7595 - val_loss: 0.5273 - val_accuracy: 0.7303\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.7616 - val_loss: 0.5262 - val_accuracy: 0.7247\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7616 - val_loss: 0.5256 - val_accuracy: 0.7247\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7658 - val_loss: 0.5248 - val_accuracy: 0.7416\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7658 - val_loss: 0.5239 - val_accuracy: 0.7416\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7658 - val_loss: 0.5231 - val_accuracy: 0.7472\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7658 - val_loss: 0.5222 - val_accuracy: 0.7472\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7658 - val_loss: 0.5214 - val_accuracy: 0.7472\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7658 - val_loss: 0.5206 - val_accuracy: 0.7472\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7658 - val_loss: 0.5200 - val_accuracy: 0.7472\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7658 - val_loss: 0.5193 - val_accuracy: 0.7528\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7637 - val_loss: 0.5186 - val_accuracy: 0.7584\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7637 - val_loss: 0.5179 - val_accuracy: 0.7584\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7637 - val_loss: 0.5172 - val_accuracy: 0.7584\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7637 - val_loss: 0.5166 - val_accuracy: 0.7584\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7658 - val_loss: 0.5160 - val_accuracy: 0.7640\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7679 - val_loss: 0.5153 - val_accuracy: 0.7640\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7700 - val_loss: 0.5147 - val_accuracy: 0.7640\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7700 - val_loss: 0.5142 - val_accuracy: 0.7640\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7700 - val_loss: 0.5137 - val_accuracy: 0.7640\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7700 - val_loss: 0.5131 - val_accuracy: 0.7697\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7700 - val_loss: 0.5123 - val_accuracy: 0.7697\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7743 - val_loss: 0.5118 - val_accuracy: 0.7697\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7743 - val_loss: 0.5114 - val_accuracy: 0.7697\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7743 - val_loss: 0.5110 - val_accuracy: 0.7697\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7764 - val_loss: 0.5104 - val_accuracy: 0.7697\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7764 - val_loss: 0.5100 - val_accuracy: 0.7697\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7722 - val_loss: 0.5093 - val_accuracy: 0.7753\n",
      "8/8 [==============================] - 0s 738us/step - loss: 0.4437 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_872 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.0050 - accuracy: 0.3966 - val_loss: 0.9466 - val_accuracy: 0.3820\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9747 - accuracy: 0.4030 - val_loss: 0.9222 - val_accuracy: 0.3820\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9470 - accuracy: 0.4051 - val_loss: 0.8977 - val_accuracy: 0.3820\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9193 - accuracy: 0.4051 - val_loss: 0.8750 - val_accuracy: 0.3820\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8941 - accuracy: 0.4072 - val_loss: 0.8533 - val_accuracy: 0.3820\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8695 - accuracy: 0.4114 - val_loss: 0.8332 - val_accuracy: 0.4045\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8463 - accuracy: 0.4241 - val_loss: 0.8145 - val_accuracy: 0.4270\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8247 - accuracy: 0.4515 - val_loss: 0.7971 - val_accuracy: 0.4944\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8041 - accuracy: 0.5000 - val_loss: 0.7809 - val_accuracy: 0.5112\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7852 - accuracy: 0.5169 - val_loss: 0.7657 - val_accuracy: 0.5112\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7674 - accuracy: 0.5148 - val_loss: 0.7514 - val_accuracy: 0.5056\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7501 - accuracy: 0.5232 - val_loss: 0.7386 - val_accuracy: 0.5393\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7342 - accuracy: 0.5549 - val_loss: 0.7269 - val_accuracy: 0.5618\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7198 - accuracy: 0.5928 - val_loss: 0.7159 - val_accuracy: 0.6629\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.6730 - val_loss: 0.7054 - val_accuracy: 0.6742\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.6857 - val_loss: 0.6961 - val_accuracy: 0.6742\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.6793 - val_loss: 0.6873 - val_accuracy: 0.6573\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6857 - val_loss: 0.6794 - val_accuracy: 0.6685\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6899 - val_loss: 0.6720 - val_accuracy: 0.6685\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6941 - val_loss: 0.6655 - val_accuracy: 0.6742\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.6962 - val_loss: 0.6592 - val_accuracy: 0.6742\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.7089 - val_loss: 0.6534 - val_accuracy: 0.6685\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.7236 - val_loss: 0.6480 - val_accuracy: 0.6685\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.7278 - val_loss: 0.6431 - val_accuracy: 0.6742\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.7278 - val_loss: 0.6384 - val_accuracy: 0.6742\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.7257 - val_loss: 0.6341 - val_accuracy: 0.6742\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.7300 - val_loss: 0.6301 - val_accuracy: 0.6742\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.7405 - val_loss: 0.6265 - val_accuracy: 0.6742\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.7384 - val_loss: 0.6231 - val_accuracy: 0.6685\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.7426 - val_loss: 0.6198 - val_accuracy: 0.6629\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7426 - val_loss: 0.6167 - val_accuracy: 0.6685\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7426 - val_loss: 0.6138 - val_accuracy: 0.6685\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.7426 - val_loss: 0.6112 - val_accuracy: 0.6685\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7426 - val_loss: 0.6086 - val_accuracy: 0.6685\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7405 - val_loss: 0.6061 - val_accuracy: 0.6685\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7426 - val_loss: 0.6039 - val_accuracy: 0.6685\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.7511 - val_loss: 0.6016 - val_accuracy: 0.6685\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7511 - val_loss: 0.5995 - val_accuracy: 0.6685\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7553 - val_loss: 0.5975 - val_accuracy: 0.6685\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7532 - val_loss: 0.5956 - val_accuracy: 0.6742\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7511 - val_loss: 0.5938 - val_accuracy: 0.6629\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7511 - val_loss: 0.5920 - val_accuracy: 0.6629\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7511 - val_loss: 0.5901 - val_accuracy: 0.6629\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7511 - val_loss: 0.5885 - val_accuracy: 0.6742\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7511 - val_loss: 0.5867 - val_accuracy: 0.6742\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7574 - val_loss: 0.5852 - val_accuracy: 0.6742\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7574 - val_loss: 0.5836 - val_accuracy: 0.6742\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7574 - val_loss: 0.5821 - val_accuracy: 0.6742\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7616 - val_loss: 0.5805 - val_accuracy: 0.6742\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7616 - val_loss: 0.5791 - val_accuracy: 0.6854\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7616 - val_loss: 0.5778 - val_accuracy: 0.6966\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7616 - val_loss: 0.5764 - val_accuracy: 0.6966\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7616 - val_loss: 0.5750 - val_accuracy: 0.6966\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7574 - val_loss: 0.5737 - val_accuracy: 0.6966\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7595 - val_loss: 0.5724 - val_accuracy: 0.6966\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7616 - val_loss: 0.5713 - val_accuracy: 0.6966\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7595 - val_loss: 0.5699 - val_accuracy: 0.7022\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7637 - val_loss: 0.5687 - val_accuracy: 0.6966\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7637 - val_loss: 0.5674 - val_accuracy: 0.7022\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7700 - val_loss: 0.5663 - val_accuracy: 0.7022\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7700 - val_loss: 0.5650 - val_accuracy: 0.7022\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7700 - val_loss: 0.5637 - val_accuracy: 0.7079\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7722 - val_loss: 0.5627 - val_accuracy: 0.7135\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7743 - val_loss: 0.5616 - val_accuracy: 0.7135\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7743 - val_loss: 0.5604 - val_accuracy: 0.7135\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7743 - val_loss: 0.5593 - val_accuracy: 0.7135\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7764 - val_loss: 0.5582 - val_accuracy: 0.7135\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7764 - val_loss: 0.5574 - val_accuracy: 0.7135\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7764 - val_loss: 0.5562 - val_accuracy: 0.7135\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7764 - val_loss: 0.5552 - val_accuracy: 0.7135\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7764 - val_loss: 0.5541 - val_accuracy: 0.7191\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7764 - val_loss: 0.5531 - val_accuracy: 0.7191\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7764 - val_loss: 0.5523 - val_accuracy: 0.7191\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7764 - val_loss: 0.5511 - val_accuracy: 0.7191\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7764 - val_loss: 0.5503 - val_accuracy: 0.7191\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7764 - val_loss: 0.5492 - val_accuracy: 0.7191\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7806 - val_loss: 0.5484 - val_accuracy: 0.7303\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7954 - val_loss: 0.5475 - val_accuracy: 0.7303\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7954 - val_loss: 0.5467 - val_accuracy: 0.7360\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7932 - val_loss: 0.5458 - val_accuracy: 0.7360\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7932 - val_loss: 0.5447 - val_accuracy: 0.7360\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7932 - val_loss: 0.5439 - val_accuracy: 0.7360\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7932 - val_loss: 0.5430 - val_accuracy: 0.7360\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7932 - val_loss: 0.5422 - val_accuracy: 0.7416\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7932 - val_loss: 0.5414 - val_accuracy: 0.7416\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7954 - val_loss: 0.5407 - val_accuracy: 0.7416\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7975 - val_loss: 0.5399 - val_accuracy: 0.7416\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7975 - val_loss: 0.5390 - val_accuracy: 0.7416\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7975 - val_loss: 0.5381 - val_accuracy: 0.7416\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7975 - val_loss: 0.5373 - val_accuracy: 0.7416\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7975 - val_loss: 0.5367 - val_accuracy: 0.7416\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7975 - val_loss: 0.5359 - val_accuracy: 0.7416\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7975 - val_loss: 0.5352 - val_accuracy: 0.7416\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7975 - val_loss: 0.5345 - val_accuracy: 0.7416\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7975 - val_loss: 0.5338 - val_accuracy: 0.7416\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7975 - val_loss: 0.5329 - val_accuracy: 0.7416\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7975 - val_loss: 0.5323 - val_accuracy: 0.7416\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7975 - val_loss: 0.5317 - val_accuracy: 0.7416\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7975 - val_loss: 0.5310 - val_accuracy: 0.7416\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7975 - val_loss: 0.5303 - val_accuracy: 0.7416\n",
      "8/8 [==============================] - 0s 697us/step - loss: 0.5333 - accuracy: 0.7637\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_873 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3171 - accuracy: 0.3143 - val_loss: 1.2178 - val_accuracy: 0.3652\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2825 - accuracy: 0.3059 - val_loss: 1.1855 - val_accuracy: 0.3652\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2484 - accuracy: 0.3080 - val_loss: 1.1546 - val_accuracy: 0.3596\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2157 - accuracy: 0.3101 - val_loss: 1.1250 - val_accuracy: 0.3596\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1844 - accuracy: 0.3101 - val_loss: 1.0965 - val_accuracy: 0.3596\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1543 - accuracy: 0.3143 - val_loss: 1.0690 - val_accuracy: 0.3652\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1248 - accuracy: 0.3122 - val_loss: 1.0432 - val_accuracy: 0.3652\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0972 - accuracy: 0.3101 - val_loss: 1.0180 - val_accuracy: 0.3764\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0703 - accuracy: 0.3207 - val_loss: 0.9943 - val_accuracy: 0.3708\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0444 - accuracy: 0.3228 - val_loss: 0.9717 - val_accuracy: 0.3652\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0201 - accuracy: 0.3228 - val_loss: 0.9498 - val_accuracy: 0.3539\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9963 - accuracy: 0.3291 - val_loss: 0.9293 - val_accuracy: 0.3539\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9740 - accuracy: 0.3291 - val_loss: 0.9096 - val_accuracy: 0.3652\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9525 - accuracy: 0.3523 - val_loss: 0.8912 - val_accuracy: 0.3820\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9322 - accuracy: 0.3523 - val_loss: 0.8735 - val_accuracy: 0.3933\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9127 - accuracy: 0.3608 - val_loss: 0.8568 - val_accuracy: 0.4045\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8943 - accuracy: 0.3586 - val_loss: 0.8410 - val_accuracy: 0.4101\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8764 - accuracy: 0.3797 - val_loss: 0.8264 - val_accuracy: 0.4382\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8601 - accuracy: 0.4030 - val_loss: 0.8121 - val_accuracy: 0.4607\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8441 - accuracy: 0.4030 - val_loss: 0.7990 - val_accuracy: 0.4551\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8291 - accuracy: 0.4072 - val_loss: 0.7865 - val_accuracy: 0.4775\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8149 - accuracy: 0.4177 - val_loss: 0.7747 - val_accuracy: 0.4944\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8012 - accuracy: 0.4346 - val_loss: 0.7638 - val_accuracy: 0.5169\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7888 - accuracy: 0.4473 - val_loss: 0.7529 - val_accuracy: 0.5225\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7766 - accuracy: 0.4852 - val_loss: 0.7428 - val_accuracy: 0.5337\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7647 - accuracy: 0.5042 - val_loss: 0.7336 - val_accuracy: 0.5618\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7539 - accuracy: 0.5316 - val_loss: 0.7246 - val_accuracy: 0.5674\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7435 - accuracy: 0.5485 - val_loss: 0.7161 - val_accuracy: 0.5955\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7335 - accuracy: 0.5591 - val_loss: 0.7081 - val_accuracy: 0.5955\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7242 - accuracy: 0.5675 - val_loss: 0.7003 - val_accuracy: 0.6348\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7155 - accuracy: 0.5907 - val_loss: 0.6928 - val_accuracy: 0.6348\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.5992 - val_loss: 0.6863 - val_accuracy: 0.6348\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.6055 - val_loss: 0.6796 - val_accuracy: 0.6292\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.6097 - val_loss: 0.6735 - val_accuracy: 0.6236\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.6118 - val_loss: 0.6673 - val_accuracy: 0.6236\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.6118 - val_loss: 0.6619 - val_accuracy: 0.6180\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.6139 - val_loss: 0.6563 - val_accuracy: 0.6236\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.6160 - val_loss: 0.6512 - val_accuracy: 0.6236\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.6224 - val_loss: 0.6461 - val_accuracy: 0.6236\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.6224 - val_loss: 0.6414 - val_accuracy: 0.6236\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.6203 - val_loss: 0.6365 - val_accuracy: 0.6292\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6181 - val_loss: 0.6321 - val_accuracy: 0.6292\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.6181 - val_loss: 0.6279 - val_accuracy: 0.6292\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.6203 - val_loss: 0.6240 - val_accuracy: 0.6292\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.6245 - val_loss: 0.6198 - val_accuracy: 0.6348\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.6350 - val_loss: 0.6161 - val_accuracy: 0.6348\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.6329 - val_loss: 0.6123 - val_accuracy: 0.6348\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6435 - val_loss: 0.6089 - val_accuracy: 0.6292\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.6498 - val_loss: 0.6055 - val_accuracy: 0.6292\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6561 - val_loss: 0.6021 - val_accuracy: 0.6292\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6646 - val_loss: 0.5989 - val_accuracy: 0.6292\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.6730 - val_loss: 0.5957 - val_accuracy: 0.6404\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.6835 - val_loss: 0.5929 - val_accuracy: 0.6629\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.6878 - val_loss: 0.5899 - val_accuracy: 0.6573\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6962 - val_loss: 0.5871 - val_accuracy: 0.6685\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.6962 - val_loss: 0.5844 - val_accuracy: 0.6685\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.6962 - val_loss: 0.5818 - val_accuracy: 0.6742\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.6983 - val_loss: 0.5792 - val_accuracy: 0.6798\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7046 - val_loss: 0.5767 - val_accuracy: 0.6798\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.6742\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7110 - val_loss: 0.5721 - val_accuracy: 0.6742\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7215 - val_loss: 0.5698 - val_accuracy: 0.6910\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7278 - val_loss: 0.5676 - val_accuracy: 0.6966\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7278 - val_loss: 0.5653 - val_accuracy: 0.7079\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7257 - val_loss: 0.5633 - val_accuracy: 0.7191\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7321 - val_loss: 0.5613 - val_accuracy: 0.7191\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7384 - val_loss: 0.5594 - val_accuracy: 0.7247\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7405 - val_loss: 0.5574 - val_accuracy: 0.7360\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7447 - val_loss: 0.5556 - val_accuracy: 0.7472\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7532 - val_loss: 0.5537 - val_accuracy: 0.7528\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7553 - val_loss: 0.5521 - val_accuracy: 0.7697\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7595 - val_loss: 0.5504 - val_accuracy: 0.7697\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7595 - val_loss: 0.5486 - val_accuracy: 0.7697\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7595 - val_loss: 0.5470 - val_accuracy: 0.7584\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7616 - val_loss: 0.5454 - val_accuracy: 0.7584\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7658 - val_loss: 0.5439 - val_accuracy: 0.7584\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7637 - val_loss: 0.5423 - val_accuracy: 0.7584\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7637 - val_loss: 0.5409 - val_accuracy: 0.7640\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7679 - val_loss: 0.5396 - val_accuracy: 0.7584\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7722 - val_loss: 0.5382 - val_accuracy: 0.7697\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7890 - val_loss: 0.5367 - val_accuracy: 0.7753\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7869 - val_loss: 0.5355 - val_accuracy: 0.7753\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7911 - val_loss: 0.5342 - val_accuracy: 0.7697\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7932 - val_loss: 0.5330 - val_accuracy: 0.7640\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7911 - val_loss: 0.5317 - val_accuracy: 0.7640\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7911 - val_loss: 0.5306 - val_accuracy: 0.7640\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7954 - val_loss: 0.5294 - val_accuracy: 0.7640\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7996 - val_loss: 0.5283 - val_accuracy: 0.7640\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.8017 - val_loss: 0.5272 - val_accuracy: 0.7640\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.8059 - val_loss: 0.5261 - val_accuracy: 0.7640\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.8059 - val_loss: 0.5250 - val_accuracy: 0.7640\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.8059 - val_loss: 0.5239 - val_accuracy: 0.7640\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.8080 - val_loss: 0.5230 - val_accuracy: 0.7640\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.8080 - val_loss: 0.5220 - val_accuracy: 0.7640\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.8101 - val_loss: 0.5210 - val_accuracy: 0.7640\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.8101 - val_loss: 0.5201 - val_accuracy: 0.7640\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8101 - val_loss: 0.5192 - val_accuracy: 0.7697\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8080 - val_loss: 0.5183 - val_accuracy: 0.7640\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8101 - val_loss: 0.5174 - val_accuracy: 0.7640\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.8080 - val_loss: 0.5165 - val_accuracy: 0.7640\n",
      "8/8 [==============================] - 0s 829us/step - loss: 0.4792 - accuracy: 0.7806\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_874 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.8962 - accuracy: 0.3207 - val_loss: 0.8306 - val_accuracy: 0.3371\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8734 - accuracy: 0.3819 - val_loss: 0.8113 - val_accuracy: 0.3708\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8536 - accuracy: 0.4177 - val_loss: 0.7930 - val_accuracy: 0.4494\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8343 - accuracy: 0.4557 - val_loss: 0.7770 - val_accuracy: 0.4719\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8172 - accuracy: 0.4937 - val_loss: 0.7617 - val_accuracy: 0.4944\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8007 - accuracy: 0.5063 - val_loss: 0.7481 - val_accuracy: 0.5225\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7856 - accuracy: 0.5274 - val_loss: 0.7359 - val_accuracy: 0.5449\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7722 - accuracy: 0.5464 - val_loss: 0.7242 - val_accuracy: 0.5730\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7592 - accuracy: 0.5549 - val_loss: 0.7137 - val_accuracy: 0.6011\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7474 - accuracy: 0.5654 - val_loss: 0.7040 - val_accuracy: 0.6011\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7363 - accuracy: 0.5717 - val_loss: 0.6951 - val_accuracy: 0.6067\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7263 - accuracy: 0.5759 - val_loss: 0.6866 - val_accuracy: 0.6067\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7165 - accuracy: 0.5844 - val_loss: 0.6791 - val_accuracy: 0.6124\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7077 - accuracy: 0.5865 - val_loss: 0.6720 - val_accuracy: 0.6180\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6993 - accuracy: 0.5970 - val_loss: 0.6654 - val_accuracy: 0.6236\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.6097 - val_loss: 0.6591 - val_accuracy: 0.6461\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.6245 - val_loss: 0.6533 - val_accuracy: 0.6461\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.6329 - val_loss: 0.6480 - val_accuracy: 0.6629\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.6350 - val_loss: 0.6427 - val_accuracy: 0.6629\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.6371 - val_loss: 0.6380 - val_accuracy: 0.6742\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6414 - val_loss: 0.6334 - val_accuracy: 0.6742\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6435 - val_loss: 0.6289 - val_accuracy: 0.6798\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6435 - val_loss: 0.6246 - val_accuracy: 0.6854\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6456 - val_loss: 0.6206 - val_accuracy: 0.6854\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6477 - val_loss: 0.6166 - val_accuracy: 0.6854\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6561 - val_loss: 0.6131 - val_accuracy: 0.6854\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.6646 - val_loss: 0.6095 - val_accuracy: 0.6854\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.6688 - val_loss: 0.6059 - val_accuracy: 0.6854\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6730 - val_loss: 0.6027 - val_accuracy: 0.6854\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.6751 - val_loss: 0.5994 - val_accuracy: 0.6854\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.6793 - val_loss: 0.5962 - val_accuracy: 0.6854\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.6899 - val_loss: 0.5930 - val_accuracy: 0.6854\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6899 - val_loss: 0.5900 - val_accuracy: 0.6854\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.6920 - val_loss: 0.5871 - val_accuracy: 0.6854\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6941 - val_loss: 0.5843 - val_accuracy: 0.6798\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.6962 - val_loss: 0.5816 - val_accuracy: 0.6798\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.6962 - val_loss: 0.5789 - val_accuracy: 0.6798\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7004 - val_loss: 0.5762 - val_accuracy: 0.6798\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7025 - val_loss: 0.5737 - val_accuracy: 0.6854\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7025 - val_loss: 0.5712 - val_accuracy: 0.6910\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7025 - val_loss: 0.5687 - val_accuracy: 0.6910\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7068 - val_loss: 0.5663 - val_accuracy: 0.6910\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7110 - val_loss: 0.5641 - val_accuracy: 0.6910\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7110 - val_loss: 0.5618 - val_accuracy: 0.6854\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7131 - val_loss: 0.5597 - val_accuracy: 0.6854\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7131 - val_loss: 0.5576 - val_accuracy: 0.6854\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7131 - val_loss: 0.5555 - val_accuracy: 0.6854\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7173 - val_loss: 0.5534 - val_accuracy: 0.6854\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7173 - val_loss: 0.5515 - val_accuracy: 0.6910\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7194 - val_loss: 0.5496 - val_accuracy: 0.6966\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7194 - val_loss: 0.5477 - val_accuracy: 0.6966\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7215 - val_loss: 0.5458 - val_accuracy: 0.7079\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7257 - val_loss: 0.5441 - val_accuracy: 0.7079\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7278 - val_loss: 0.5425 - val_accuracy: 0.7079\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7278 - val_loss: 0.5407 - val_accuracy: 0.7135\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7278 - val_loss: 0.5390 - val_accuracy: 0.7135\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7342 - val_loss: 0.5375 - val_accuracy: 0.7247\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7384 - val_loss: 0.5360 - val_accuracy: 0.7247\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7405 - val_loss: 0.5345 - val_accuracy: 0.7247\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7426 - val_loss: 0.5331 - val_accuracy: 0.7247\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7426 - val_loss: 0.5316 - val_accuracy: 0.7303\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7447 - val_loss: 0.5302 - val_accuracy: 0.7303\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7468 - val_loss: 0.5289 - val_accuracy: 0.7303\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7511 - val_loss: 0.5276 - val_accuracy: 0.7303\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7553 - val_loss: 0.5263 - val_accuracy: 0.7303\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7532 - val_loss: 0.5252 - val_accuracy: 0.7360\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7553 - val_loss: 0.5239 - val_accuracy: 0.7416\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7616 - val_loss: 0.5227 - val_accuracy: 0.7472\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7637 - val_loss: 0.5216 - val_accuracy: 0.7472\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7679 - val_loss: 0.5205 - val_accuracy: 0.7472\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7743 - val_loss: 0.5194 - val_accuracy: 0.7472\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7806 - val_loss: 0.5185 - val_accuracy: 0.7528\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7806 - val_loss: 0.5174 - val_accuracy: 0.7528\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7806 - val_loss: 0.5165 - val_accuracy: 0.7528\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7806 - val_loss: 0.5155 - val_accuracy: 0.7584\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7827 - val_loss: 0.5146 - val_accuracy: 0.7584\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7848 - val_loss: 0.5136 - val_accuracy: 0.7640\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7848 - val_loss: 0.5127 - val_accuracy: 0.7697\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7869 - val_loss: 0.5119 - val_accuracy: 0.7697\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7869 - val_loss: 0.5110 - val_accuracy: 0.7753\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7869 - val_loss: 0.5102 - val_accuracy: 0.7753\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7869 - val_loss: 0.5094 - val_accuracy: 0.7753\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7827 - val_loss: 0.5087 - val_accuracy: 0.7753\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7848 - val_loss: 0.5079 - val_accuracy: 0.7753\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7848 - val_loss: 0.5072 - val_accuracy: 0.7753\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7869 - val_loss: 0.5065 - val_accuracy: 0.7753\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7869 - val_loss: 0.5059 - val_accuracy: 0.7753\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7869 - val_loss: 0.5051 - val_accuracy: 0.7753\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7869 - val_loss: 0.5045 - val_accuracy: 0.7753\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7869 - val_loss: 0.5038 - val_accuracy: 0.7753\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7869 - val_loss: 0.5032 - val_accuracy: 0.7753\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7848 - val_loss: 0.5027 - val_accuracy: 0.7753\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7869 - val_loss: 0.5021 - val_accuracy: 0.7753\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7848 - val_loss: 0.5015 - val_accuracy: 0.7809\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7827 - val_loss: 0.5010 - val_accuracy: 0.7809\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7848 - val_loss: 0.5005 - val_accuracy: 0.7809\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7848 - val_loss: 0.5000 - val_accuracy: 0.7809\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7848 - val_loss: 0.4994 - val_accuracy: 0.7753\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7848 - val_loss: 0.4988 - val_accuracy: 0.7753\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7869 - val_loss: 0.4983 - val_accuracy: 0.7753\n",
      "8/8 [==============================] - 0s 713us/step - loss: 0.4285 - accuracy: 0.8059\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_875 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.1461 - accuracy: 0.3523 - val_loss: 1.0541 - val_accuracy: 0.3708\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1105 - accuracy: 0.3544 - val_loss: 1.0239 - val_accuracy: 0.3820\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0768 - accuracy: 0.3544 - val_loss: 0.9941 - val_accuracy: 0.3820\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0448 - accuracy: 0.3565 - val_loss: 0.9649 - val_accuracy: 0.4045\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0132 - accuracy: 0.3544 - val_loss: 0.9376 - val_accuracy: 0.4045\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9835 - accuracy: 0.3502 - val_loss: 0.9117 - val_accuracy: 0.4045\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9543 - accuracy: 0.3629 - val_loss: 0.8880 - val_accuracy: 0.4045\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9273 - accuracy: 0.3692 - val_loss: 0.8648 - val_accuracy: 0.4101\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9013 - accuracy: 0.3734 - val_loss: 0.8429 - val_accuracy: 0.4213\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8766 - accuracy: 0.3797 - val_loss: 0.8221 - val_accuracy: 0.4157\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8533 - accuracy: 0.3882 - val_loss: 0.8024 - val_accuracy: 0.4101\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8313 - accuracy: 0.3903 - val_loss: 0.7836 - val_accuracy: 0.4101\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8100 - accuracy: 0.3987 - val_loss: 0.7668 - val_accuracy: 0.4326\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7904 - accuracy: 0.4093 - val_loss: 0.7511 - val_accuracy: 0.4270\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7717 - accuracy: 0.4177 - val_loss: 0.7367 - val_accuracy: 0.4382\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7546 - accuracy: 0.4346 - val_loss: 0.7228 - val_accuracy: 0.4326\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7390 - accuracy: 0.4494 - val_loss: 0.7093 - val_accuracy: 0.4494\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7227 - accuracy: 0.4620 - val_loss: 0.6978 - val_accuracy: 0.4775\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7087 - accuracy: 0.4958 - val_loss: 0.6869 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5148 - val_loss: 0.6765 - val_accuracy: 0.5337\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5422 - val_loss: 0.6669 - val_accuracy: 0.5787\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.5633 - val_loss: 0.6583 - val_accuracy: 0.6067\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.5717 - val_loss: 0.6502 - val_accuracy: 0.6124\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6504 - accuracy: 0.6034 - val_loss: 0.6427 - val_accuracy: 0.6517\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6266 - val_loss: 0.6357 - val_accuracy: 0.6461\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.6456 - val_loss: 0.6292 - val_accuracy: 0.6742\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6667 - val_loss: 0.6235 - val_accuracy: 0.6854\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.6899 - val_loss: 0.6179 - val_accuracy: 0.6854\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.7068 - val_loss: 0.6126 - val_accuracy: 0.6910\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.7131 - val_loss: 0.6080 - val_accuracy: 0.6910\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.7046 - val_loss: 0.6035 - val_accuracy: 0.6854\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.7046 - val_loss: 0.5994 - val_accuracy: 0.6966\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7110 - val_loss: 0.5955 - val_accuracy: 0.7022\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7173 - val_loss: 0.5919 - val_accuracy: 0.7022\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7215 - val_loss: 0.5883 - val_accuracy: 0.7247\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7363 - val_loss: 0.5852 - val_accuracy: 0.7360\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7405 - val_loss: 0.5822 - val_accuracy: 0.7360\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7468 - val_loss: 0.5793 - val_accuracy: 0.7360\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7426 - val_loss: 0.5766 - val_accuracy: 0.7360\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7468 - val_loss: 0.5741 - val_accuracy: 0.7303\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7468 - val_loss: 0.5716 - val_accuracy: 0.7247\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7405 - val_loss: 0.5692 - val_accuracy: 0.7247\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7447 - val_loss: 0.5670 - val_accuracy: 0.7247\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7511 - val_loss: 0.5648 - val_accuracy: 0.7247\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7511 - val_loss: 0.5628 - val_accuracy: 0.7247\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7511 - val_loss: 0.5609 - val_accuracy: 0.7247\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7532 - val_loss: 0.5591 - val_accuracy: 0.7247\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7511 - val_loss: 0.5572 - val_accuracy: 0.7360\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7532 - val_loss: 0.5553 - val_accuracy: 0.7360\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7532 - val_loss: 0.5536 - val_accuracy: 0.7360\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7532 - val_loss: 0.5522 - val_accuracy: 0.7360\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7532 - val_loss: 0.5504 - val_accuracy: 0.7360\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7532 - val_loss: 0.5488 - val_accuracy: 0.7360\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7532 - val_loss: 0.5474 - val_accuracy: 0.7360\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7553 - val_loss: 0.5459 - val_accuracy: 0.7360\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7553 - val_loss: 0.5445 - val_accuracy: 0.7360\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7595 - val_loss: 0.5432 - val_accuracy: 0.7416\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7595 - val_loss: 0.5418 - val_accuracy: 0.7416\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7595 - val_loss: 0.5405 - val_accuracy: 0.7416\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7616 - val_loss: 0.5394 - val_accuracy: 0.7416\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7637 - val_loss: 0.5381 - val_accuracy: 0.7360\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7637 - val_loss: 0.5368 - val_accuracy: 0.7303\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7658 - val_loss: 0.5357 - val_accuracy: 0.7303\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7637 - val_loss: 0.5345 - val_accuracy: 0.7303\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7679 - val_loss: 0.5334 - val_accuracy: 0.7247\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7679 - val_loss: 0.5323 - val_accuracy: 0.7247\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7700 - val_loss: 0.5312 - val_accuracy: 0.7247\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7743 - val_loss: 0.5302 - val_accuracy: 0.7303\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7764 - val_loss: 0.5293 - val_accuracy: 0.7303\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7764 - val_loss: 0.5283 - val_accuracy: 0.7303\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7785 - val_loss: 0.5275 - val_accuracy: 0.7360\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7764 - val_loss: 0.5265 - val_accuracy: 0.7360\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7806 - val_loss: 0.5254 - val_accuracy: 0.7360\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7848 - val_loss: 0.5242 - val_accuracy: 0.7416\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7806 - val_loss: 0.5232 - val_accuracy: 0.7360\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7806 - val_loss: 0.5224 - val_accuracy: 0.7360\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7827 - val_loss: 0.5217 - val_accuracy: 0.7416\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7827 - val_loss: 0.5208 - val_accuracy: 0.7416\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7827 - val_loss: 0.5200 - val_accuracy: 0.7472\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7848 - val_loss: 0.5192 - val_accuracy: 0.7528\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7890 - val_loss: 0.5184 - val_accuracy: 0.7584\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7911 - val_loss: 0.5177 - val_accuracy: 0.7697\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7890 - val_loss: 0.5167 - val_accuracy: 0.7697\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7911 - val_loss: 0.5161 - val_accuracy: 0.7697\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7932 - val_loss: 0.5153 - val_accuracy: 0.7584\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7932 - val_loss: 0.5146 - val_accuracy: 0.7697\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7954 - val_loss: 0.5139 - val_accuracy: 0.7753\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7975 - val_loss: 0.5132 - val_accuracy: 0.7753\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7975 - val_loss: 0.5125 - val_accuracy: 0.7753\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7954 - val_loss: 0.5119 - val_accuracy: 0.7697\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7954 - val_loss: 0.5111 - val_accuracy: 0.7697\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7954 - val_loss: 0.5106 - val_accuracy: 0.7697\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7975 - val_loss: 0.5100 - val_accuracy: 0.7697\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7996 - val_loss: 0.5094 - val_accuracy: 0.7697\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7996 - val_loss: 0.5089 - val_accuracy: 0.7697\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.8059 - val_loss: 0.5082 - val_accuracy: 0.7697\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8122 - val_loss: 0.5076 - val_accuracy: 0.7753\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8122 - val_loss: 0.5070 - val_accuracy: 0.7753\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8122 - val_loss: 0.5065 - val_accuracy: 0.7809\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8080 - val_loss: 0.5059 - val_accuracy: 0.7809\n",
      "8/8 [==============================] - 0s 793us/step - loss: 0.5098 - accuracy: 0.7679\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_876 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.6780 - accuracy: 0.6287 - val_loss: 0.6657 - val_accuracy: 0.6404\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.6519 - val_loss: 0.6518 - val_accuracy: 0.6517\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6646 - val_loss: 0.6390 - val_accuracy: 0.6798\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6835 - val_loss: 0.6282 - val_accuracy: 0.6854\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6920 - val_loss: 0.6181 - val_accuracy: 0.6910\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.7131 - val_loss: 0.6089 - val_accuracy: 0.6854\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.7152 - val_loss: 0.6008 - val_accuracy: 0.6854\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.7300 - val_loss: 0.5936 - val_accuracy: 0.7022\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7384 - val_loss: 0.5872 - val_accuracy: 0.7191\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7489 - val_loss: 0.5810 - val_accuracy: 0.7247\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7511 - val_loss: 0.5758 - val_accuracy: 0.7360\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7489 - val_loss: 0.5710 - val_accuracy: 0.7303\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7553 - val_loss: 0.5667 - val_accuracy: 0.7416\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7595 - val_loss: 0.5626 - val_accuracy: 0.7416\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7637 - val_loss: 0.5589 - val_accuracy: 0.7416\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7637 - val_loss: 0.5554 - val_accuracy: 0.7360\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7679 - val_loss: 0.5520 - val_accuracy: 0.7360\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7722 - val_loss: 0.5489 - val_accuracy: 0.7360\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7722 - val_loss: 0.5461 - val_accuracy: 0.7360\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5435 - val_accuracy: 0.7416\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7764 - val_loss: 0.5411 - val_accuracy: 0.7528\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7764 - val_loss: 0.5386 - val_accuracy: 0.7528\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7764 - val_loss: 0.5362 - val_accuracy: 0.7640\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7827 - val_loss: 0.5342 - val_accuracy: 0.7753\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7890 - val_loss: 0.5323 - val_accuracy: 0.7753\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7911 - val_loss: 0.5302 - val_accuracy: 0.7753\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7932 - val_loss: 0.5284 - val_accuracy: 0.7753\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7954 - val_loss: 0.5265 - val_accuracy: 0.7809\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7975 - val_loss: 0.5247 - val_accuracy: 0.7865\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7975 - val_loss: 0.5232 - val_accuracy: 0.7865\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.8059 - val_loss: 0.5217 - val_accuracy: 0.7865\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8038 - val_loss: 0.5202 - val_accuracy: 0.7865\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.8038 - val_loss: 0.5187 - val_accuracy: 0.7809\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8017 - val_loss: 0.5172 - val_accuracy: 0.7809\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7809\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8038 - val_loss: 0.5146 - val_accuracy: 0.7753\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.8038 - val_loss: 0.5133 - val_accuracy: 0.7753\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7753\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.8038 - val_loss: 0.5109 - val_accuracy: 0.7640\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.8038 - val_loss: 0.5096 - val_accuracy: 0.7640\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7697\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8038 - val_loss: 0.5075 - val_accuracy: 0.7697\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8101 - val_loss: 0.5065 - val_accuracy: 0.7697\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8101 - val_loss: 0.5055 - val_accuracy: 0.7697\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8080 - val_loss: 0.5045 - val_accuracy: 0.7697\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.8101 - val_loss: 0.5036 - val_accuracy: 0.7697\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8101 - val_loss: 0.5026 - val_accuracy: 0.7697\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8101 - val_loss: 0.5018 - val_accuracy: 0.7809\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.8101 - val_loss: 0.5010 - val_accuracy: 0.7809\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8101 - val_loss: 0.5001 - val_accuracy: 0.7809\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.8122 - val_loss: 0.4993 - val_accuracy: 0.7809\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8101 - val_loss: 0.4985 - val_accuracy: 0.7809\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.8143 - val_loss: 0.4977 - val_accuracy: 0.7809\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8122 - val_loss: 0.4969 - val_accuracy: 0.7753\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8122 - val_loss: 0.4963 - val_accuracy: 0.7753\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8122 - val_loss: 0.4956 - val_accuracy: 0.7809\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8122 - val_loss: 0.4948 - val_accuracy: 0.7809\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8122 - val_loss: 0.4943 - val_accuracy: 0.7809\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.8122 - val_loss: 0.4936 - val_accuracy: 0.7809\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.8122 - val_loss: 0.4930 - val_accuracy: 0.7865\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8122 - val_loss: 0.4925 - val_accuracy: 0.7865\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8122 - val_loss: 0.4919 - val_accuracy: 0.7865\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8122 - val_loss: 0.4913 - val_accuracy: 0.7865\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8143 - val_loss: 0.4908 - val_accuracy: 0.7865\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8143 - val_loss: 0.4902 - val_accuracy: 0.7865\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8143 - val_loss: 0.4896 - val_accuracy: 0.7865\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8143 - val_loss: 0.4892 - val_accuracy: 0.7865\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.8143 - val_loss: 0.4888 - val_accuracy: 0.7865\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8143 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8165 - val_loss: 0.4878 - val_accuracy: 0.7865\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8165 - val_loss: 0.4873 - val_accuracy: 0.7865\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8165 - val_loss: 0.4870 - val_accuracy: 0.7865\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8165 - val_loss: 0.4866 - val_accuracy: 0.7865\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8186 - val_loss: 0.4862 - val_accuracy: 0.7865\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8186 - val_loss: 0.4858 - val_accuracy: 0.7865\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8186 - val_loss: 0.4853 - val_accuracy: 0.7865\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8186 - val_loss: 0.4850 - val_accuracy: 0.7865\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8186 - val_loss: 0.4846 - val_accuracy: 0.7865\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8207 - val_loss: 0.4843 - val_accuracy: 0.7865\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8207 - val_loss: 0.4839 - val_accuracy: 0.7865\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8207 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8207 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8207 - val_loss: 0.4829 - val_accuracy: 0.7865\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8207 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8207 - val_loss: 0.4823 - val_accuracy: 0.7921\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8207 - val_loss: 0.4820 - val_accuracy: 0.7978\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8207 - val_loss: 0.4818 - val_accuracy: 0.7978\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8207 - val_loss: 0.4815 - val_accuracy: 0.7978\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.8207 - val_loss: 0.4812 - val_accuracy: 0.7978\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8207 - val_loss: 0.4810 - val_accuracy: 0.8034\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8207 - val_loss: 0.4807 - val_accuracy: 0.8034\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8207 - val_loss: 0.4804 - val_accuracy: 0.8034\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8207 - val_loss: 0.4802 - val_accuracy: 0.8034\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8207 - val_loss: 0.4799 - val_accuracy: 0.7978\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8207 - val_loss: 0.4797 - val_accuracy: 0.8034\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8207 - val_loss: 0.4795 - val_accuracy: 0.8034\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8207 - val_loss: 0.4792 - val_accuracy: 0.8034\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8207 - val_loss: 0.4791 - val_accuracy: 0.8034\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8207 - val_loss: 0.4788 - val_accuracy: 0.8034\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8207 - val_loss: 0.4786 - val_accuracy: 0.8034\n",
      "8/8 [==============================] - 0s 823us/step - loss: 0.4290 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_877 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9694 - accuracy: 0.3776 - val_loss: 1.0285 - val_accuracy: 0.3427\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9380 - accuracy: 0.3692 - val_loss: 0.9991 - val_accuracy: 0.3371\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9098 - accuracy: 0.3819 - val_loss: 0.9703 - val_accuracy: 0.3427\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8810 - accuracy: 0.3882 - val_loss: 0.9444 - val_accuracy: 0.3483\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8554 - accuracy: 0.3945 - val_loss: 0.9194 - val_accuracy: 0.3539\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8312 - accuracy: 0.4008 - val_loss: 0.8959 - val_accuracy: 0.3483\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8072 - accuracy: 0.4093 - val_loss: 0.8750 - val_accuracy: 0.3539\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7866 - accuracy: 0.4346 - val_loss: 0.8539 - val_accuracy: 0.3596\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7660 - accuracy: 0.4578 - val_loss: 0.8350 - val_accuracy: 0.3596\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7473 - accuracy: 0.4789 - val_loss: 0.8172 - val_accuracy: 0.4157\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7301 - accuracy: 0.5274 - val_loss: 0.8004 - val_accuracy: 0.4494\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7136 - accuracy: 0.5464 - val_loss: 0.7853 - val_accuracy: 0.4663\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.5738 - val_loss: 0.7713 - val_accuracy: 0.5056\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.6055 - val_loss: 0.7580 - val_accuracy: 0.5169\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6181 - val_loss: 0.7459 - val_accuracy: 0.5281\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.6414 - val_loss: 0.7351 - val_accuracy: 0.5674\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6603 - val_loss: 0.7243 - val_accuracy: 0.6067\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6709 - val_loss: 0.7151 - val_accuracy: 0.6180\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.6688 - val_loss: 0.7063 - val_accuracy: 0.6180\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.6814 - val_loss: 0.6981 - val_accuracy: 0.6236\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.6941 - val_loss: 0.6907 - val_accuracy: 0.6292\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.7110 - val_loss: 0.6836 - val_accuracy: 0.6404\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.7321 - val_loss: 0.6772 - val_accuracy: 0.6517\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.7321 - val_loss: 0.6713 - val_accuracy: 0.6517\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.7405 - val_loss: 0.6658 - val_accuracy: 0.6573\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7511 - val_loss: 0.6605 - val_accuracy: 0.6629\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7595 - val_loss: 0.6556 - val_accuracy: 0.6685\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7658 - val_loss: 0.6511 - val_accuracy: 0.6629\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7722 - val_loss: 0.6470 - val_accuracy: 0.6573\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7700 - val_loss: 0.6428 - val_accuracy: 0.6573\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7700 - val_loss: 0.6389 - val_accuracy: 0.6685\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7743 - val_loss: 0.6356 - val_accuracy: 0.6742\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7743 - val_loss: 0.6321 - val_accuracy: 0.6742\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7743 - val_loss: 0.6289 - val_accuracy: 0.6742\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7764 - val_loss: 0.6257 - val_accuracy: 0.6742\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7785 - val_loss: 0.6227 - val_accuracy: 0.6742\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7806 - val_loss: 0.6200 - val_accuracy: 0.6798\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7827 - val_loss: 0.6172 - val_accuracy: 0.6742\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7848 - val_loss: 0.6146 - val_accuracy: 0.6742\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7890 - val_loss: 0.6121 - val_accuracy: 0.6742\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7890 - val_loss: 0.6100 - val_accuracy: 0.6798\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7869 - val_loss: 0.6076 - val_accuracy: 0.6798\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7890 - val_loss: 0.6055 - val_accuracy: 0.6798\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7911 - val_loss: 0.6032 - val_accuracy: 0.6854\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7932 - val_loss: 0.6012 - val_accuracy: 0.6854\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7911 - val_loss: 0.5993 - val_accuracy: 0.6854\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7911 - val_loss: 0.5972 - val_accuracy: 0.6854\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7932 - val_loss: 0.5952 - val_accuracy: 0.6910\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7911 - val_loss: 0.5934 - val_accuracy: 0.6966\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7890 - val_loss: 0.5916 - val_accuracy: 0.7022\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7869 - val_loss: 0.5898 - val_accuracy: 0.7022\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7869 - val_loss: 0.5881 - val_accuracy: 0.7022\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7869 - val_loss: 0.5866 - val_accuracy: 0.7022\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7869 - val_loss: 0.5849 - val_accuracy: 0.7022\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7890 - val_loss: 0.5832 - val_accuracy: 0.7022\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7890 - val_loss: 0.5817 - val_accuracy: 0.7022\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7890 - val_loss: 0.5802 - val_accuracy: 0.7022\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7890 - val_loss: 0.5789 - val_accuracy: 0.7079\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7890 - val_loss: 0.5774 - val_accuracy: 0.7079\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7911 - val_loss: 0.5759 - val_accuracy: 0.7191\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7911 - val_loss: 0.5747 - val_accuracy: 0.7191\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7911 - val_loss: 0.5733 - val_accuracy: 0.7247\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7911 - val_loss: 0.5719 - val_accuracy: 0.7303\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7911 - val_loss: 0.5706 - val_accuracy: 0.7303\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7911 - val_loss: 0.5693 - val_accuracy: 0.7360\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7932 - val_loss: 0.5681 - val_accuracy: 0.7360\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7954 - val_loss: 0.5671 - val_accuracy: 0.7472\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7996 - val_loss: 0.5658 - val_accuracy: 0.7584\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.8017 - val_loss: 0.5648 - val_accuracy: 0.7584\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8017 - val_loss: 0.5635 - val_accuracy: 0.7640\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8017 - val_loss: 0.5624 - val_accuracy: 0.7640\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.8017 - val_loss: 0.5614 - val_accuracy: 0.7640\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.8038 - val_loss: 0.5604 - val_accuracy: 0.7640\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.8038 - val_loss: 0.5593 - val_accuracy: 0.7640\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8017 - val_loss: 0.5583 - val_accuracy: 0.7640\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7954 - val_loss: 0.5573 - val_accuracy: 0.7640\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7996 - val_loss: 0.5564 - val_accuracy: 0.7640\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8017 - val_loss: 0.5554 - val_accuracy: 0.7697\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.8059 - val_loss: 0.5543 - val_accuracy: 0.7697\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8017 - val_loss: 0.5534 - val_accuracy: 0.7697\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.8038 - val_loss: 0.5526 - val_accuracy: 0.7697\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.8059 - val_loss: 0.5518 - val_accuracy: 0.7697\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8017 - val_loss: 0.5507 - val_accuracy: 0.7697\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.8038 - val_loss: 0.5499 - val_accuracy: 0.7697\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8038 - val_loss: 0.5490 - val_accuracy: 0.7640\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7996 - val_loss: 0.5483 - val_accuracy: 0.7584\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7996 - val_loss: 0.5475 - val_accuracy: 0.7584\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8017 - val_loss: 0.5467 - val_accuracy: 0.7640\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8017 - val_loss: 0.5460 - val_accuracy: 0.7697\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8038 - val_loss: 0.5452 - val_accuracy: 0.7697\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.8038 - val_loss: 0.5443 - val_accuracy: 0.7697\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8038 - val_loss: 0.5436 - val_accuracy: 0.7753\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8017 - val_loss: 0.5430 - val_accuracy: 0.7753\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8017 - val_loss: 0.5421 - val_accuracy: 0.7809\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8017 - val_loss: 0.5416 - val_accuracy: 0.7809\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7996 - val_loss: 0.5408 - val_accuracy: 0.7809\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7996 - val_loss: 0.5401 - val_accuracy: 0.7809\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7996 - val_loss: 0.5396 - val_accuracy: 0.7809\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7996 - val_loss: 0.5388 - val_accuracy: 0.7809\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7996 - val_loss: 0.5382 - val_accuracy: 0.7809\n",
      "8/8 [==============================] - 0s 950us/step - loss: 0.4613 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_878 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.2189 - accuracy: 0.3354 - val_loss: 1.1747 - val_accuracy: 0.3483\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1852 - accuracy: 0.3312 - val_loss: 1.1432 - val_accuracy: 0.3483\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1513 - accuracy: 0.3333 - val_loss: 1.1139 - val_accuracy: 0.3483\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1200 - accuracy: 0.3312 - val_loss: 1.0853 - val_accuracy: 0.3483\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0885 - accuracy: 0.3376 - val_loss: 1.0587 - val_accuracy: 0.3483\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0590 - accuracy: 0.3354 - val_loss: 1.0329 - val_accuracy: 0.3427\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0318 - accuracy: 0.3397 - val_loss: 1.0075 - val_accuracy: 0.3371\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0041 - accuracy: 0.3439 - val_loss: 0.9841 - val_accuracy: 0.3315\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9787 - accuracy: 0.3523 - val_loss: 0.9619 - val_accuracy: 0.3258\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9542 - accuracy: 0.3629 - val_loss: 0.9406 - val_accuracy: 0.3371\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9310 - accuracy: 0.3692 - val_loss: 0.9205 - val_accuracy: 0.3427\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9085 - accuracy: 0.3734 - val_loss: 0.9023 - val_accuracy: 0.3371\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8877 - accuracy: 0.3903 - val_loss: 0.8843 - val_accuracy: 0.3427\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.4030 - val_loss: 0.8672 - val_accuracy: 0.4045\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8488 - accuracy: 0.4156 - val_loss: 0.8516 - val_accuracy: 0.3820\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8310 - accuracy: 0.4219 - val_loss: 0.8370 - val_accuracy: 0.4045\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8143 - accuracy: 0.4536 - val_loss: 0.8231 - val_accuracy: 0.4438\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7980 - accuracy: 0.4662 - val_loss: 0.8103 - val_accuracy: 0.4494\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7830 - accuracy: 0.4810 - val_loss: 0.7983 - val_accuracy: 0.4551\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7688 - accuracy: 0.4979 - val_loss: 0.7869 - val_accuracy: 0.4663\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7552 - accuracy: 0.5359 - val_loss: 0.7759 - val_accuracy: 0.4888\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7427 - accuracy: 0.5654 - val_loss: 0.7658 - val_accuracy: 0.5225\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7302 - accuracy: 0.6055 - val_loss: 0.7565 - val_accuracy: 0.5506\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7192 - accuracy: 0.6308 - val_loss: 0.7473 - val_accuracy: 0.5674\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7080 - accuracy: 0.6392 - val_loss: 0.7394 - val_accuracy: 0.5674\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.6477 - val_loss: 0.7316 - val_accuracy: 0.6067\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.6519 - val_loss: 0.7243 - val_accuracy: 0.6124\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.6603 - val_loss: 0.7173 - val_accuracy: 0.6124\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.6624 - val_loss: 0.7110 - val_accuracy: 0.6292\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.6646 - val_loss: 0.7048 - val_accuracy: 0.6292\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6772 - val_loss: 0.6993 - val_accuracy: 0.6236\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6835 - val_loss: 0.6936 - val_accuracy: 0.6348\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6899 - val_loss: 0.6883 - val_accuracy: 0.6404\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.7025 - val_loss: 0.6833 - val_accuracy: 0.6517\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.7025 - val_loss: 0.6787 - val_accuracy: 0.6517\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.7089 - val_loss: 0.6745 - val_accuracy: 0.6461\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.7089 - val_loss: 0.6705 - val_accuracy: 0.6461\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.7110 - val_loss: 0.6663 - val_accuracy: 0.6404\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.7068 - val_loss: 0.6625 - val_accuracy: 0.6348\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.7089 - val_loss: 0.6587 - val_accuracy: 0.6348\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.7089 - val_loss: 0.6552 - val_accuracy: 0.6461\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7089 - val_loss: 0.6519 - val_accuracy: 0.6461\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7089 - val_loss: 0.6488 - val_accuracy: 0.6517\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7110 - val_loss: 0.6456 - val_accuracy: 0.6573\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7110 - val_loss: 0.6426 - val_accuracy: 0.6573\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7131 - val_loss: 0.6396 - val_accuracy: 0.6573\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7089 - val_loss: 0.6369 - val_accuracy: 0.6573\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7110 - val_loss: 0.6341 - val_accuracy: 0.6573\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7194 - val_loss: 0.6316 - val_accuracy: 0.6573\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7236 - val_loss: 0.6289 - val_accuracy: 0.6573\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7257 - val_loss: 0.6264 - val_accuracy: 0.6573\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7278 - val_loss: 0.6240 - val_accuracy: 0.6629\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7278 - val_loss: 0.6217 - val_accuracy: 0.6685\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7300 - val_loss: 0.6194 - val_accuracy: 0.6685\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7300 - val_loss: 0.6171 - val_accuracy: 0.6854\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7278 - val_loss: 0.6147 - val_accuracy: 0.6854\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7384 - val_loss: 0.6127 - val_accuracy: 0.6854\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7405 - val_loss: 0.6104 - val_accuracy: 0.6854\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7405 - val_loss: 0.6083 - val_accuracy: 0.6798\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7426 - val_loss: 0.6065 - val_accuracy: 0.6854\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7447 - val_loss: 0.6042 - val_accuracy: 0.6854\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7447 - val_loss: 0.6024 - val_accuracy: 0.6854\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7405 - val_loss: 0.6005 - val_accuracy: 0.6854\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7468 - val_loss: 0.5986 - val_accuracy: 0.6910\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7468 - val_loss: 0.5967 - val_accuracy: 0.6910\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7489 - val_loss: 0.5950 - val_accuracy: 0.6910\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7532 - val_loss: 0.5932 - val_accuracy: 0.6854\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7511 - val_loss: 0.5913 - val_accuracy: 0.6854\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7511 - val_loss: 0.5897 - val_accuracy: 0.6854\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7532 - val_loss: 0.5881 - val_accuracy: 0.6910\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7553 - val_loss: 0.5863 - val_accuracy: 0.6966\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7574 - val_loss: 0.5847 - val_accuracy: 0.6966\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7595 - val_loss: 0.5831 - val_accuracy: 0.6966\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7574 - val_loss: 0.5815 - val_accuracy: 0.6966\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7595 - val_loss: 0.5798 - val_accuracy: 0.7022\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7658 - val_loss: 0.5785 - val_accuracy: 0.7022\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7679 - val_loss: 0.5771 - val_accuracy: 0.7135\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7679 - val_loss: 0.5754 - val_accuracy: 0.7135\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7679 - val_loss: 0.5742 - val_accuracy: 0.7135\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7700 - val_loss: 0.5725 - val_accuracy: 0.7079\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7700 - val_loss: 0.5713 - val_accuracy: 0.7135\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7848 - val_loss: 0.5698 - val_accuracy: 0.7191\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7890 - val_loss: 0.5683 - val_accuracy: 0.7135\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7848 - val_loss: 0.5671 - val_accuracy: 0.7135\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7848 - val_loss: 0.5658 - val_accuracy: 0.7191\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7869 - val_loss: 0.5644 - val_accuracy: 0.7191\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7848 - val_loss: 0.5634 - val_accuracy: 0.7191\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7869 - val_loss: 0.5621 - val_accuracy: 0.7247\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7869 - val_loss: 0.5605 - val_accuracy: 0.7247\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7890 - val_loss: 0.5593 - val_accuracy: 0.7247\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7890 - val_loss: 0.5580 - val_accuracy: 0.7247\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7911 - val_loss: 0.5569 - val_accuracy: 0.7247\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7932 - val_loss: 0.5558 - val_accuracy: 0.7247\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7954 - val_loss: 0.5546 - val_accuracy: 0.7303\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7996 - val_loss: 0.5534 - val_accuracy: 0.7303\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7996 - val_loss: 0.5524 - val_accuracy: 0.7303\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7996 - val_loss: 0.5514 - val_accuracy: 0.7303\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7996 - val_loss: 0.5502 - val_accuracy: 0.7303\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7996 - val_loss: 0.5493 - val_accuracy: 0.7303\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7996 - val_loss: 0.5485 - val_accuracy: 0.7303\n",
      "8/8 [==============================] - 0s 780us/step - loss: 0.5372 - accuracy: 0.7426\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_879 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0583 - accuracy: 0.3523 - val_loss: 1.0086 - val_accuracy: 0.3933\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0272 - accuracy: 0.3460 - val_loss: 0.9815 - val_accuracy: 0.3933\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9993 - accuracy: 0.3502 - val_loss: 0.9543 - val_accuracy: 0.3820\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9710 - accuracy: 0.3523 - val_loss: 0.9290 - val_accuracy: 0.3764\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9445 - accuracy: 0.3565 - val_loss: 0.9048 - val_accuracy: 0.3708\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9201 - accuracy: 0.3608 - val_loss: 0.8814 - val_accuracy: 0.3708\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8949 - accuracy: 0.3671 - val_loss: 0.8613 - val_accuracy: 0.3764\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8738 - accuracy: 0.3650 - val_loss: 0.8403 - val_accuracy: 0.3708\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8520 - accuracy: 0.3734 - val_loss: 0.8214 - val_accuracy: 0.3820\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8320 - accuracy: 0.3819 - val_loss: 0.8036 - val_accuracy: 0.3933\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8130 - accuracy: 0.3882 - val_loss: 0.7872 - val_accuracy: 0.4213\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7956 - accuracy: 0.4177 - val_loss: 0.7715 - val_accuracy: 0.4663\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7788 - accuracy: 0.4430 - val_loss: 0.7567 - val_accuracy: 0.4944\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7631 - accuracy: 0.4599 - val_loss: 0.7430 - val_accuracy: 0.4944\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7484 - accuracy: 0.4895 - val_loss: 0.7301 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7350 - accuracy: 0.5021 - val_loss: 0.7177 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7217 - accuracy: 0.5169 - val_loss: 0.7066 - val_accuracy: 0.5225\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.5232 - val_loss: 0.6960 - val_accuracy: 0.5225\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.5464 - val_loss: 0.6860 - val_accuracy: 0.5562\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.5654 - val_loss: 0.6770 - val_accuracy: 0.5843\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.6181 - val_loss: 0.6686 - val_accuracy: 0.6348\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6679 - accuracy: 0.6477 - val_loss: 0.6604 - val_accuracy: 0.6742\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6624 - val_loss: 0.6525 - val_accuracy: 0.6798\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6962 - val_loss: 0.6457 - val_accuracy: 0.7022\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.7046 - val_loss: 0.6385 - val_accuracy: 0.7022\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.7131 - val_loss: 0.6321 - val_accuracy: 0.7022\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.7152 - val_loss: 0.6263 - val_accuracy: 0.7022\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.7194 - val_loss: 0.6204 - val_accuracy: 0.6966\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.7194 - val_loss: 0.6150 - val_accuracy: 0.7022\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7236 - val_loss: 0.6098 - val_accuracy: 0.7022\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.7236 - val_loss: 0.6052 - val_accuracy: 0.7022\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.7236 - val_loss: 0.6005 - val_accuracy: 0.7022\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.7300 - val_loss: 0.5962 - val_accuracy: 0.7135\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.7321 - val_loss: 0.5921 - val_accuracy: 0.7135\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7363 - val_loss: 0.5880 - val_accuracy: 0.7191\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7384 - val_loss: 0.5841 - val_accuracy: 0.7247\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7468 - val_loss: 0.5805 - val_accuracy: 0.7303\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7511 - val_loss: 0.5770 - val_accuracy: 0.7247\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7553 - val_loss: 0.5739 - val_accuracy: 0.7247\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7658 - val_loss: 0.5706 - val_accuracy: 0.7303\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7679 - val_loss: 0.5677 - val_accuracy: 0.7191\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7764 - val_loss: 0.5647 - val_accuracy: 0.7303\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7785 - val_loss: 0.5619 - val_accuracy: 0.7360\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7785 - val_loss: 0.5590 - val_accuracy: 0.7360\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7806 - val_loss: 0.5565 - val_accuracy: 0.7416\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7827 - val_loss: 0.5541 - val_accuracy: 0.7416\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7764 - val_loss: 0.5517 - val_accuracy: 0.7416\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7869 - val_loss: 0.5494 - val_accuracy: 0.7416\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7911 - val_loss: 0.5471 - val_accuracy: 0.7472\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7932 - val_loss: 0.5450 - val_accuracy: 0.7472\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7932 - val_loss: 0.5430 - val_accuracy: 0.7472\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7954 - val_loss: 0.5410 - val_accuracy: 0.7528\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7954 - val_loss: 0.5391 - val_accuracy: 0.7528\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7932 - val_loss: 0.5372 - val_accuracy: 0.7528\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7932 - val_loss: 0.5355 - val_accuracy: 0.7528\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7954 - val_loss: 0.5337 - val_accuracy: 0.7528\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7954 - val_loss: 0.5321 - val_accuracy: 0.7528\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7954 - val_loss: 0.5306 - val_accuracy: 0.7528\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7954 - val_loss: 0.5290 - val_accuracy: 0.7528\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7954 - val_loss: 0.5275 - val_accuracy: 0.7528\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7975 - val_loss: 0.5261 - val_accuracy: 0.7528\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7975 - val_loss: 0.5247 - val_accuracy: 0.7528\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7975 - val_loss: 0.5233 - val_accuracy: 0.7528\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7975 - val_loss: 0.5221 - val_accuracy: 0.7528\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7975 - val_loss: 0.5208 - val_accuracy: 0.7584\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7975 - val_loss: 0.5196 - val_accuracy: 0.7640\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.8017 - val_loss: 0.5184 - val_accuracy: 0.7640\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8017 - val_loss: 0.5173 - val_accuracy: 0.7640\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.8017 - val_loss: 0.5162 - val_accuracy: 0.7640\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.8017 - val_loss: 0.5152 - val_accuracy: 0.7640\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.8038 - val_loss: 0.5141 - val_accuracy: 0.7640\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8038 - val_loss: 0.5131 - val_accuracy: 0.7640\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7640\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8038 - val_loss: 0.5113 - val_accuracy: 0.7640\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8038 - val_loss: 0.5103 - val_accuracy: 0.7640\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.8038 - val_loss: 0.5095 - val_accuracy: 0.7640\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8059 - val_loss: 0.5086 - val_accuracy: 0.7640\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8059 - val_loss: 0.5078 - val_accuracy: 0.7640\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.8059 - val_loss: 0.5070 - val_accuracy: 0.7640\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8059 - val_loss: 0.5062 - val_accuracy: 0.7640\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.8059 - val_loss: 0.5054 - val_accuracy: 0.7640\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8080 - val_loss: 0.5047 - val_accuracy: 0.7640\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.8101 - val_loss: 0.5040 - val_accuracy: 0.7640\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.8101 - val_loss: 0.5032 - val_accuracy: 0.7640\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8101 - val_loss: 0.5026 - val_accuracy: 0.7640\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8101 - val_loss: 0.5019 - val_accuracy: 0.7640\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8101 - val_loss: 0.5014 - val_accuracy: 0.7640\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.8101 - val_loss: 0.5007 - val_accuracy: 0.7640\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.8101 - val_loss: 0.5001 - val_accuracy: 0.7640\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8101 - val_loss: 0.4996 - val_accuracy: 0.7640\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8101 - val_loss: 0.4990 - val_accuracy: 0.7640\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8101 - val_loss: 0.4985 - val_accuracy: 0.7640\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8122 - val_loss: 0.4979 - val_accuracy: 0.7640\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8143 - val_loss: 0.4974 - val_accuracy: 0.7640\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.8143 - val_loss: 0.4968 - val_accuracy: 0.7584\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8143 - val_loss: 0.4963 - val_accuracy: 0.7584\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8143 - val_loss: 0.4958 - val_accuracy: 0.7584\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.8143 - val_loss: 0.4954 - val_accuracy: 0.7584\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8122 - val_loss: 0.4949 - val_accuracy: 0.7584\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8122 - val_loss: 0.4945 - val_accuracy: 0.7584\n",
      "8/8 [==============================] - 0s 742us/step - loss: 0.4610 - accuracy: 0.8059\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_880 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5836 - accuracy: 0.7679 - val_loss: 0.6242 - val_accuracy: 0.7472\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7764 - val_loss: 0.6147 - val_accuracy: 0.7528\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7785 - val_loss: 0.6062 - val_accuracy: 0.7528\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7743 - val_loss: 0.5990 - val_accuracy: 0.7416\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7722 - val_loss: 0.5928 - val_accuracy: 0.7416\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7722 - val_loss: 0.5875 - val_accuracy: 0.7472\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7722 - val_loss: 0.5827 - val_accuracy: 0.7472\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7722 - val_loss: 0.5786 - val_accuracy: 0.7472\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7743 - val_loss: 0.5754 - val_accuracy: 0.7472\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7743 - val_loss: 0.5726 - val_accuracy: 0.7472\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7743 - val_loss: 0.5696 - val_accuracy: 0.7416\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7785 - val_loss: 0.5673 - val_accuracy: 0.7416\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7743 - val_loss: 0.5652 - val_accuracy: 0.7360\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7764 - val_loss: 0.5633 - val_accuracy: 0.7247\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7743 - val_loss: 0.5618 - val_accuracy: 0.7247\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7743 - val_loss: 0.5602 - val_accuracy: 0.7247\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7743 - val_loss: 0.5588 - val_accuracy: 0.7247\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7743 - val_loss: 0.5573 - val_accuracy: 0.7303\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7764 - val_loss: 0.5560 - val_accuracy: 0.7303\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7764 - val_loss: 0.5548 - val_accuracy: 0.7303\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7764 - val_loss: 0.5537 - val_accuracy: 0.7303\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7764 - val_loss: 0.5526 - val_accuracy: 0.7247\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7785 - val_loss: 0.5515 - val_accuracy: 0.7247\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7785 - val_loss: 0.5504 - val_accuracy: 0.7247\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7764 - val_loss: 0.5494 - val_accuracy: 0.7303\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7785 - val_loss: 0.5485 - val_accuracy: 0.7360\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7806 - val_loss: 0.5475 - val_accuracy: 0.7360\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7848 - val_loss: 0.5468 - val_accuracy: 0.7360\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7827 - val_loss: 0.5457 - val_accuracy: 0.7360\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7890 - val_loss: 0.5449 - val_accuracy: 0.7472\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7911 - val_loss: 0.5440 - val_accuracy: 0.7472\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7911 - val_loss: 0.5430 - val_accuracy: 0.7472\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7911 - val_loss: 0.5421 - val_accuracy: 0.7528\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7911 - val_loss: 0.5414 - val_accuracy: 0.7528\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7932 - val_loss: 0.5407 - val_accuracy: 0.7528\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7932 - val_loss: 0.5399 - val_accuracy: 0.7528\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7932 - val_loss: 0.5393 - val_accuracy: 0.7584\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7890 - val_loss: 0.5383 - val_accuracy: 0.7640\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7890 - val_loss: 0.5376 - val_accuracy: 0.7753\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7890 - val_loss: 0.5369 - val_accuracy: 0.7753\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7890 - val_loss: 0.5363 - val_accuracy: 0.7809\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7911 - val_loss: 0.5356 - val_accuracy: 0.7809\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7911 - val_loss: 0.5349 - val_accuracy: 0.7809\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7911 - val_loss: 0.5341 - val_accuracy: 0.7809\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7911 - val_loss: 0.5336 - val_accuracy: 0.7809\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7911 - val_loss: 0.5329 - val_accuracy: 0.7809\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7911 - val_loss: 0.5323 - val_accuracy: 0.7809\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7890 - val_loss: 0.5318 - val_accuracy: 0.7809\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7911 - val_loss: 0.5313 - val_accuracy: 0.7809\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7911 - val_loss: 0.5305 - val_accuracy: 0.7809\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7911 - val_loss: 0.5298 - val_accuracy: 0.7809\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7911 - val_loss: 0.5293 - val_accuracy: 0.7809\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7911 - val_loss: 0.5286 - val_accuracy: 0.7809\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7911 - val_loss: 0.5283 - val_accuracy: 0.7865\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7911 - val_loss: 0.5276 - val_accuracy: 0.7865\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7911 - val_loss: 0.5270 - val_accuracy: 0.7865\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7911 - val_loss: 0.5267 - val_accuracy: 0.7865\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7911 - val_loss: 0.5259 - val_accuracy: 0.7865\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7911 - val_loss: 0.5255 - val_accuracy: 0.7865\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7911 - val_loss: 0.5252 - val_accuracy: 0.7865\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7911 - val_loss: 0.5246 - val_accuracy: 0.7865\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7911 - val_loss: 0.5238 - val_accuracy: 0.7865\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7911 - val_loss: 0.5236 - val_accuracy: 0.7921\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7911 - val_loss: 0.5233 - val_accuracy: 0.7921\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7911 - val_loss: 0.5227 - val_accuracy: 0.7921\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7911 - val_loss: 0.5221 - val_accuracy: 0.7921\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7911 - val_loss: 0.5216 - val_accuracy: 0.7921\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7890 - val_loss: 0.5212 - val_accuracy: 0.7921\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7890 - val_loss: 0.5208 - val_accuracy: 0.7921\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7890 - val_loss: 0.5203 - val_accuracy: 0.7921\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7911 - val_loss: 0.5198 - val_accuracy: 0.7921\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7911 - val_loss: 0.5196 - val_accuracy: 0.7921\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7890 - val_loss: 0.5192 - val_accuracy: 0.7921\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7911 - val_loss: 0.5186 - val_accuracy: 0.7921\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7911 - val_loss: 0.5180 - val_accuracy: 0.7921\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7911 - val_loss: 0.5178 - val_accuracy: 0.7921\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7932 - val_loss: 0.5174 - val_accuracy: 0.7921\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7911 - val_loss: 0.5170 - val_accuracy: 0.7921\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7911 - val_loss: 0.5166 - val_accuracy: 0.7921\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7911 - val_loss: 0.5164 - val_accuracy: 0.7921\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7911 - val_loss: 0.5160 - val_accuracy: 0.7921\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7911 - val_loss: 0.5156 - val_accuracy: 0.7921\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7911 - val_loss: 0.5152 - val_accuracy: 0.7921\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7911 - val_loss: 0.5149 - val_accuracy: 0.7921\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7911 - val_loss: 0.5144 - val_accuracy: 0.7921\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7911 - val_loss: 0.5141 - val_accuracy: 0.7921\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7911 - val_loss: 0.5137 - val_accuracy: 0.7921\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7911 - val_loss: 0.5134 - val_accuracy: 0.7921\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7911 - val_loss: 0.5132 - val_accuracy: 0.7921\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7911 - val_loss: 0.5130 - val_accuracy: 0.7921\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7911 - val_loss: 0.5126 - val_accuracy: 0.7921\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7911 - val_loss: 0.5124 - val_accuracy: 0.7921\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7911 - val_loss: 0.5121 - val_accuracy: 0.7921\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7911 - val_loss: 0.5117 - val_accuracy: 0.7921\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7954 - val_loss: 0.5115 - val_accuracy: 0.7921\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7975 - val_loss: 0.5110 - val_accuracy: 0.7921\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7975 - val_loss: 0.5108 - val_accuracy: 0.7921\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7975 - val_loss: 0.5105 - val_accuracy: 0.7921\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7975 - val_loss: 0.5102 - val_accuracy: 0.7921\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7975 - val_loss: 0.5100 - val_accuracy: 0.7921\n",
      "8/8 [==============================] - 0s 781us/step - loss: 0.4329 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_881 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7176 - accuracy: 0.5717 - val_loss: 0.7061 - val_accuracy: 0.5674\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.6097 - val_loss: 0.6874 - val_accuracy: 0.5899\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.6308 - val_loss: 0.6703 - val_accuracy: 0.5955\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6350 - val_loss: 0.6552 - val_accuracy: 0.6124\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.6414 - val_loss: 0.6409 - val_accuracy: 0.6461\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.6456 - val_loss: 0.6267 - val_accuracy: 0.6517\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6582 - val_loss: 0.6148 - val_accuracy: 0.6517\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.6709 - val_loss: 0.6047 - val_accuracy: 0.6517\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.6751 - val_loss: 0.5953 - val_accuracy: 0.6629\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.6878 - val_loss: 0.5872 - val_accuracy: 0.6742\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7004 - val_loss: 0.5793 - val_accuracy: 0.6798\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7110 - val_loss: 0.5725 - val_accuracy: 0.7022\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7300 - val_loss: 0.5658 - val_accuracy: 0.7079\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7447 - val_loss: 0.5593 - val_accuracy: 0.7135\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7489 - val_loss: 0.5535 - val_accuracy: 0.7191\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7637 - val_loss: 0.5470 - val_accuracy: 0.7247\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7679 - val_loss: 0.5424 - val_accuracy: 0.7247\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7679 - val_loss: 0.5369 - val_accuracy: 0.7416\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7785 - val_loss: 0.5315 - val_accuracy: 0.7360\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7785 - val_loss: 0.5278 - val_accuracy: 0.7472\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7848 - val_loss: 0.5231 - val_accuracy: 0.7584\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7911 - val_loss: 0.5181 - val_accuracy: 0.7921\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8038 - val_loss: 0.5149 - val_accuracy: 0.7978\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8249 - val_loss: 0.5125 - val_accuracy: 0.7921\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8249 - val_loss: 0.5082 - val_accuracy: 0.8034\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8249 - val_loss: 0.5055 - val_accuracy: 0.8034\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8270 - val_loss: 0.5031 - val_accuracy: 0.8034\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8249 - val_loss: 0.4999 - val_accuracy: 0.7921\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8270 - val_loss: 0.4983 - val_accuracy: 0.7921\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.4243 - accuracy: 0.8291 - val_loss: 0.4964 - val_accuracy: 0.7921\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8312 - val_loss: 0.4928 - val_accuracy: 0.7921\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8312 - val_loss: 0.4913 - val_accuracy: 0.7921\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8376 - val_loss: 0.4894 - val_accuracy: 0.8034\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8312 - val_loss: 0.4870 - val_accuracy: 0.8034\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8312 - val_loss: 0.4864 - val_accuracy: 0.8034\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8312 - val_loss: 0.4843 - val_accuracy: 0.8034\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8354 - val_loss: 0.4837 - val_accuracy: 0.8034\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8376 - val_loss: 0.4828 - val_accuracy: 0.8034\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8354 - val_loss: 0.4801 - val_accuracy: 0.8034\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8397 - val_loss: 0.4803 - val_accuracy: 0.8034\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8397 - val_loss: 0.4794 - val_accuracy: 0.8034\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8418 - val_loss: 0.4775 - val_accuracy: 0.8034\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8418 - val_loss: 0.4763 - val_accuracy: 0.8034\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8418 - val_loss: 0.4758 - val_accuracy: 0.8090\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8397 - val_loss: 0.4751 - val_accuracy: 0.8090\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8418 - val_loss: 0.4733 - val_accuracy: 0.8146\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8418 - val_loss: 0.4720 - val_accuracy: 0.8146\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8439 - val_loss: 0.4720 - val_accuracy: 0.8146\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8439 - val_loss: 0.4706 - val_accuracy: 0.8146\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8439 - val_loss: 0.4706 - val_accuracy: 0.8146\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8439 - val_loss: 0.4701 - val_accuracy: 0.8146\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8439 - val_loss: 0.4682 - val_accuracy: 0.8146\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8439 - val_loss: 0.4676 - val_accuracy: 0.8146\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8439 - val_loss: 0.4687 - val_accuracy: 0.8146\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8460 - val_loss: 0.4677 - val_accuracy: 0.8146\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8481 - val_loss: 0.4687 - val_accuracy: 0.8146\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8481 - val_loss: 0.4683 - val_accuracy: 0.8146\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8481 - val_loss: 0.4673 - val_accuracy: 0.8146\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8481 - val_loss: 0.4666 - val_accuracy: 0.8146\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8481 - val_loss: 0.4668 - val_accuracy: 0.8146\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8502 - val_loss: 0.4674 - val_accuracy: 0.8146\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8502 - val_loss: 0.4675 - val_accuracy: 0.8146\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8502 - val_loss: 0.4667 - val_accuracy: 0.8146\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8502 - val_loss: 0.4672 - val_accuracy: 0.8146\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8502 - val_loss: 0.4659 - val_accuracy: 0.8146\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8502 - val_loss: 0.4662 - val_accuracy: 0.8146\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8502 - val_loss: 0.4669 - val_accuracy: 0.8090\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8502 - val_loss: 0.4664 - val_accuracy: 0.8146\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8502 - val_loss: 0.4680 - val_accuracy: 0.8090\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8481 - val_loss: 0.4672 - val_accuracy: 0.8090\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8502 - val_loss: 0.4667 - val_accuracy: 0.8090\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8481 - val_loss: 0.4674 - val_accuracy: 0.8090\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8502 - val_loss: 0.4674 - val_accuracy: 0.8090\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8481 - val_loss: 0.4666 - val_accuracy: 0.8090\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8481 - val_loss: 0.4676 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 806us/step - loss: 0.4569 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_883 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7378 - accuracy: 0.4008 - val_loss: 0.7248 - val_accuracy: 0.4213\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7122 - accuracy: 0.4662 - val_loss: 0.7025 - val_accuracy: 0.5169\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5696 - val_loss: 0.6841 - val_accuracy: 0.6292\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.6329 - val_loss: 0.6664 - val_accuracy: 0.6236\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.6435 - val_loss: 0.6514 - val_accuracy: 0.6348\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.6435 - val_loss: 0.6377 - val_accuracy: 0.6292\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.6477 - val_loss: 0.6252 - val_accuracy: 0.6461\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.6582 - val_loss: 0.6142 - val_accuracy: 0.6461\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.6667 - val_loss: 0.6041 - val_accuracy: 0.6461\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6835 - val_loss: 0.5950 - val_accuracy: 0.6742\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.6941 - val_loss: 0.5863 - val_accuracy: 0.6910\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7046 - val_loss: 0.5780 - val_accuracy: 0.6910\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7194 - val_loss: 0.5707 - val_accuracy: 0.7191\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7194 - val_loss: 0.5637 - val_accuracy: 0.7135\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7278 - val_loss: 0.5576 - val_accuracy: 0.7191\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7363 - val_loss: 0.5513 - val_accuracy: 0.7135\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7489 - val_loss: 0.5455 - val_accuracy: 0.7191\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7553 - val_loss: 0.5403 - val_accuracy: 0.7360\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7679 - val_loss: 0.5354 - val_accuracy: 0.7472\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7743 - val_loss: 0.5306 - val_accuracy: 0.7640\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7806 - val_loss: 0.5266 - val_accuracy: 0.7753\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7890 - val_loss: 0.5223 - val_accuracy: 0.7809\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7890 - val_loss: 0.5187 - val_accuracy: 0.7640\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7954 - val_loss: 0.5155 - val_accuracy: 0.7528\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7932 - val_loss: 0.5122 - val_accuracy: 0.7584\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7869 - val_loss: 0.5092 - val_accuracy: 0.7528\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7890 - val_loss: 0.5068 - val_accuracy: 0.7528\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7975 - val_loss: 0.5044 - val_accuracy: 0.7640\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.8080 - val_loss: 0.5028 - val_accuracy: 0.7640\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.8122 - val_loss: 0.5004 - val_accuracy: 0.7697\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8122 - val_loss: 0.4986 - val_accuracy: 0.7697\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.8122 - val_loss: 0.4968 - val_accuracy: 0.7753\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8122 - val_loss: 0.4954 - val_accuracy: 0.7753\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8122 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8122 - val_loss: 0.4930 - val_accuracy: 0.7809\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8122 - val_loss: 0.4922 - val_accuracy: 0.7809\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8122 - val_loss: 0.4910 - val_accuracy: 0.7865\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8122 - val_loss: 0.4899 - val_accuracy: 0.7921\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8143 - val_loss: 0.4898 - val_accuracy: 0.7921\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8207 - val_loss: 0.4880 - val_accuracy: 0.7921\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8270 - val_loss: 0.4872 - val_accuracy: 0.7978\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8270 - val_loss: 0.4871 - val_accuracy: 0.7921\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8249 - val_loss: 0.4856 - val_accuracy: 0.7978\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8249 - val_loss: 0.4841 - val_accuracy: 0.8034\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8249 - val_loss: 0.4835 - val_accuracy: 0.8034\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8270 - val_loss: 0.4827 - val_accuracy: 0.8034\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8249 - val_loss: 0.4828 - val_accuracy: 0.8034\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8270 - val_loss: 0.4820 - val_accuracy: 0.8034\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8249 - val_loss: 0.4808 - val_accuracy: 0.8090\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8270 - val_loss: 0.4800 - val_accuracy: 0.8090\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8291 - val_loss: 0.4792 - val_accuracy: 0.8090\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8312 - val_loss: 0.4780 - val_accuracy: 0.8090\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8312 - val_loss: 0.4775 - val_accuracy: 0.8090\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8312 - val_loss: 0.4775 - val_accuracy: 0.8090\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8333 - val_loss: 0.4767 - val_accuracy: 0.8090\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8333 - val_loss: 0.4751 - val_accuracy: 0.8090\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8333 - val_loss: 0.4746 - val_accuracy: 0.8146\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8333 - val_loss: 0.4744 - val_accuracy: 0.8146\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8354 - val_loss: 0.4734 - val_accuracy: 0.8146\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8354 - val_loss: 0.4732 - val_accuracy: 0.8146\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8354 - val_loss: 0.4723 - val_accuracy: 0.8202\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8354 - val_loss: 0.4720 - val_accuracy: 0.8090\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8376 - val_loss: 0.4716 - val_accuracy: 0.8146\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8376 - val_loss: 0.4715 - val_accuracy: 0.8146\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8376 - val_loss: 0.4706 - val_accuracy: 0.8146\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8376 - val_loss: 0.4709 - val_accuracy: 0.8090\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8376 - val_loss: 0.4698 - val_accuracy: 0.8090\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8376 - val_loss: 0.4697 - val_accuracy: 0.8090\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8376 - val_loss: 0.4698 - val_accuracy: 0.8090\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8376 - val_loss: 0.4701 - val_accuracy: 0.8090\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8376 - val_loss: 0.4689 - val_accuracy: 0.8090\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8376 - val_loss: 0.4693 - val_accuracy: 0.8090\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8397 - val_loss: 0.4692 - val_accuracy: 0.8146\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8397 - val_loss: 0.4684 - val_accuracy: 0.8202\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8397 - val_loss: 0.4682 - val_accuracy: 0.8146\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8397 - val_loss: 0.4678 - val_accuracy: 0.8090\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8397 - val_loss: 0.4671 - val_accuracy: 0.8202\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8397 - val_loss: 0.4676 - val_accuracy: 0.8202\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8397 - val_loss: 0.4679 - val_accuracy: 0.8202\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8397 - val_loss: 0.4669 - val_accuracy: 0.8202\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8439 - val_loss: 0.4665 - val_accuracy: 0.8202\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8439 - val_loss: 0.4672 - val_accuracy: 0.8202\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8439 - val_loss: 0.4667 - val_accuracy: 0.8202\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8418 - val_loss: 0.4674 - val_accuracy: 0.8202\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8418 - val_loss: 0.4675 - val_accuracy: 0.8202\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8397 - val_loss: 0.4676 - val_accuracy: 0.8202\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8460 - val_loss: 0.4665 - val_accuracy: 0.8202\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8460 - val_loss: 0.4664 - val_accuracy: 0.8202\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8460 - val_loss: 0.4666 - val_accuracy: 0.8202\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8460 - val_loss: 0.4670 - val_accuracy: 0.8146\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8439 - val_loss: 0.4663 - val_accuracy: 0.8146\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8439 - val_loss: 0.4665 - val_accuracy: 0.8146\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8460 - val_loss: 0.4672 - val_accuracy: 0.8202\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8439 - val_loss: 0.4668 - val_accuracy: 0.8146\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8481 - val_loss: 0.4670 - val_accuracy: 0.8146\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8460 - val_loss: 0.4665 - val_accuracy: 0.8146\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8481 - val_loss: 0.4672 - val_accuracy: 0.8146\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8481 - val_loss: 0.4667 - val_accuracy: 0.8090\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8481 - val_loss: 0.4670 - val_accuracy: 0.8146\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8502 - val_loss: 0.4669 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 775us/step - loss: 0.4092 - accuracy: 0.8101\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_885 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7338 - accuracy: 0.4409 - val_loss: 0.7150 - val_accuracy: 0.5506\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7098 - accuracy: 0.5127 - val_loss: 0.7004 - val_accuracy: 0.6067\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.6224 - val_loss: 0.6859 - val_accuracy: 0.6011\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.6392 - val_loss: 0.6728 - val_accuracy: 0.6236\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.6414 - val_loss: 0.6610 - val_accuracy: 0.6180\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6540 - val_loss: 0.6493 - val_accuracy: 0.5955\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6646 - val_loss: 0.6386 - val_accuracy: 0.5955\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.6688 - val_loss: 0.6279 - val_accuracy: 0.6180\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.6730 - val_loss: 0.6174 - val_accuracy: 0.6292\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.6793 - val_loss: 0.6082 - val_accuracy: 0.6404\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.6878 - val_loss: 0.6010 - val_accuracy: 0.6404\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.6899 - val_loss: 0.5924 - val_accuracy: 0.6517\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.6983 - val_loss: 0.5848 - val_accuracy: 0.6685\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7046 - val_loss: 0.5782 - val_accuracy: 0.6742\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7173 - val_loss: 0.5707 - val_accuracy: 0.6910\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7215 - val_loss: 0.5651 - val_accuracy: 0.6854\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7426 - val_loss: 0.5596 - val_accuracy: 0.7022\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7532 - val_loss: 0.5544 - val_accuracy: 0.6966\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7574 - val_loss: 0.5499 - val_accuracy: 0.7022\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7595 - val_loss: 0.5446 - val_accuracy: 0.7079\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7679 - val_loss: 0.5392 - val_accuracy: 0.7135\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7743 - val_loss: 0.5353 - val_accuracy: 0.7191\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7848 - val_loss: 0.5306 - val_accuracy: 0.7360\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7890 - val_loss: 0.5268 - val_accuracy: 0.7303\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7869 - val_loss: 0.5236 - val_accuracy: 0.7416\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7932 - val_loss: 0.5202 - val_accuracy: 0.7472\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7932 - val_loss: 0.5177 - val_accuracy: 0.7528\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7996 - val_loss: 0.5133 - val_accuracy: 0.7584\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.8017 - val_loss: 0.5107 - val_accuracy: 0.7472\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.8038 - val_loss: 0.5087 - val_accuracy: 0.7472\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.8059 - val_loss: 0.5053 - val_accuracy: 0.7472\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.8059 - val_loss: 0.5029 - val_accuracy: 0.7584\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.8101 - val_loss: 0.5005 - val_accuracy: 0.7640\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8122 - val_loss: 0.4992 - val_accuracy: 0.7809\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8228 - val_loss: 0.4978 - val_accuracy: 0.7865\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.8249 - val_loss: 0.4960 - val_accuracy: 0.7865\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8186 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8228 - val_loss: 0.4937 - val_accuracy: 0.7865\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8228 - val_loss: 0.4921 - val_accuracy: 0.7921\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.8270 - val_loss: 0.4915 - val_accuracy: 0.7865\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.8228 - val_loss: 0.4890 - val_accuracy: 0.7978\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8249 - val_loss: 0.4887 - val_accuracy: 0.7978\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8249 - val_loss: 0.4876 - val_accuracy: 0.7978\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8249 - val_loss: 0.4865 - val_accuracy: 0.7921\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8312 - val_loss: 0.4858 - val_accuracy: 0.7921\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8291 - val_loss: 0.4857 - val_accuracy: 0.7921\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8291 - val_loss: 0.4845 - val_accuracy: 0.7921\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8291 - val_loss: 0.4826 - val_accuracy: 0.7978\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8270 - val_loss: 0.4824 - val_accuracy: 0.8034\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8312 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8312 - val_loss: 0.4813 - val_accuracy: 0.7978\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8312 - val_loss: 0.4809 - val_accuracy: 0.8034\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8333 - val_loss: 0.4805 - val_accuracy: 0.8034\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8291 - val_loss: 0.4799 - val_accuracy: 0.7978\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8291 - val_loss: 0.4805 - val_accuracy: 0.8034\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8291 - val_loss: 0.4803 - val_accuracy: 0.7978\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8291 - val_loss: 0.4789 - val_accuracy: 0.8034\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8312 - val_loss: 0.4779 - val_accuracy: 0.8090\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8291 - val_loss: 0.4781 - val_accuracy: 0.8034\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8270 - val_loss: 0.4783 - val_accuracy: 0.8034\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8270 - val_loss: 0.4778 - val_accuracy: 0.8034\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8291 - val_loss: 0.4775 - val_accuracy: 0.8034\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8291 - val_loss: 0.4771 - val_accuracy: 0.8034\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8291 - val_loss: 0.4781 - val_accuracy: 0.8034\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8312 - val_loss: 0.4766 - val_accuracy: 0.8034\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8312 - val_loss: 0.4769 - val_accuracy: 0.8034\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8312 - val_loss: 0.4767 - val_accuracy: 0.8090\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8291 - val_loss: 0.4762 - val_accuracy: 0.8090\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8312 - val_loss: 0.4766 - val_accuracy: 0.8090\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8312 - val_loss: 0.4759 - val_accuracy: 0.8090\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8333 - val_loss: 0.4761 - val_accuracy: 0.8090\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8333 - val_loss: 0.4769 - val_accuracy: 0.8034\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8312 - val_loss: 0.4763 - val_accuracy: 0.8034\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8333 - val_loss: 0.4771 - val_accuracy: 0.8034\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8354 - val_loss: 0.4781 - val_accuracy: 0.8034\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8333 - val_loss: 0.4777 - val_accuracy: 0.8034\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8333 - val_loss: 0.4769 - val_accuracy: 0.8034\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8312 - val_loss: 0.4770 - val_accuracy: 0.8034\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8354 - val_loss: 0.4767 - val_accuracy: 0.8034\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8354 - val_loss: 0.4772 - val_accuracy: 0.8034\n",
      "8/8 [==============================] - 0s 771us/step - loss: 0.4086 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_887 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6206 - accuracy: 0.7489 - val_loss: 0.6127 - val_accuracy: 0.6966\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.7722 - val_loss: 0.5861 - val_accuracy: 0.7079\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5688 - val_accuracy: 0.7135\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7806 - val_loss: 0.5550 - val_accuracy: 0.7135\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7954 - val_loss: 0.5431 - val_accuracy: 0.7247\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7996 - val_loss: 0.5327 - val_accuracy: 0.7360\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8059 - val_loss: 0.5229 - val_accuracy: 0.7472\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8228 - val_loss: 0.5167 - val_accuracy: 0.7472\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8228 - val_loss: 0.5112 - val_accuracy: 0.7472\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8249 - val_loss: 0.5072 - val_accuracy: 0.7472\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8270 - val_loss: 0.5027 - val_accuracy: 0.7584\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8312 - val_loss: 0.4998 - val_accuracy: 0.7528\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8333 - val_loss: 0.4954 - val_accuracy: 0.7697\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8270 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8291 - val_loss: 0.4910 - val_accuracy: 0.7753\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8270 - val_loss: 0.4883 - val_accuracy: 0.7753\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8333 - val_loss: 0.4874 - val_accuracy: 0.7753\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8354 - val_loss: 0.4850 - val_accuracy: 0.7809\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8354 - val_loss: 0.4852 - val_accuracy: 0.7809\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8376 - val_loss: 0.4805 - val_accuracy: 0.7865\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8376 - val_loss: 0.4809 - val_accuracy: 0.7921\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8376 - val_loss: 0.4793 - val_accuracy: 0.7921\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8397 - val_loss: 0.4776 - val_accuracy: 0.7978\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8418 - val_loss: 0.4784 - val_accuracy: 0.7978\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8397 - val_loss: 0.4751 - val_accuracy: 0.8034\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8439 - val_loss: 0.4748 - val_accuracy: 0.8034\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8439 - val_loss: 0.4756 - val_accuracy: 0.7978\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8418 - val_loss: 0.4769 - val_accuracy: 0.7978\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8439 - val_loss: 0.4732 - val_accuracy: 0.8090\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8460 - val_loss: 0.4721 - val_accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8460 - val_loss: 0.4734 - val_accuracy: 0.8090\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8481 - val_loss: 0.4718 - val_accuracy: 0.8090\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8481 - val_loss: 0.4726 - val_accuracy: 0.8090\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8481 - val_loss: 0.4722 - val_accuracy: 0.8090\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8481 - val_loss: 0.4705 - val_accuracy: 0.8090\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8502 - val_loss: 0.4723 - val_accuracy: 0.8090\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8523 - val_loss: 0.4729 - val_accuracy: 0.8146\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8523 - val_loss: 0.4697 - val_accuracy: 0.8146\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8565 - val_loss: 0.4702 - val_accuracy: 0.8146\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8586 - val_loss: 0.4720 - val_accuracy: 0.8146\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8565 - val_loss: 0.4691 - val_accuracy: 0.8146\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8523 - val_loss: 0.4714 - val_accuracy: 0.8146\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8565 - val_loss: 0.4701 - val_accuracy: 0.8202\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8565 - val_loss: 0.4714 - val_accuracy: 0.8202\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8565 - val_loss: 0.4715 - val_accuracy: 0.8202\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8565 - val_loss: 0.4702 - val_accuracy: 0.8258\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8565 - val_loss: 0.4705 - val_accuracy: 0.8202\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8544 - val_loss: 0.4719 - val_accuracy: 0.8315\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8629 - val_loss: 0.4718 - val_accuracy: 0.8371\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8565 - val_loss: 0.4689 - val_accuracy: 0.8202\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8544 - val_loss: 0.4696 - val_accuracy: 0.8371\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8565 - val_loss: 0.4700 - val_accuracy: 0.8371\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8586 - val_loss: 0.4703 - val_accuracy: 0.8315\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8586 - val_loss: 0.4709 - val_accuracy: 0.8315\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8608 - val_loss: 0.4702 - val_accuracy: 0.8371\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8586 - val_loss: 0.4718 - val_accuracy: 0.8315\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8650 - val_loss: 0.4720 - val_accuracy: 0.8315\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8629 - val_loss: 0.4693 - val_accuracy: 0.8371\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8650 - val_loss: 0.4708 - val_accuracy: 0.8371\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8629 - val_loss: 0.4699 - val_accuracy: 0.8371\n",
      "8/8 [==============================] - 0s 763us/step - loss: 0.4247 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_889 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.7219 - accuracy: 0.4135 - val_loss: 0.6703 - val_accuracy: 0.6404\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.6582 - val_loss: 0.6257 - val_accuracy: 0.7247\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.6920 - val_loss: 0.5931 - val_accuracy: 0.6910\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7004 - val_loss: 0.5721 - val_accuracy: 0.7135\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7236 - val_loss: 0.5551 - val_accuracy: 0.7191\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7405 - val_loss: 0.5410 - val_accuracy: 0.7247\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7489 - val_loss: 0.5287 - val_accuracy: 0.7303\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7637 - val_loss: 0.5181 - val_accuracy: 0.7640\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7911 - val_loss: 0.5093 - val_accuracy: 0.7697\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.8017 - val_loss: 0.5022 - val_accuracy: 0.7865\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.8038 - val_loss: 0.4969 - val_accuracy: 0.7753\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8017 - val_loss: 0.4925 - val_accuracy: 0.7640\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8017 - val_loss: 0.4895 - val_accuracy: 0.7809\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.8059 - val_loss: 0.4866 - val_accuracy: 0.7809\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.8101 - val_loss: 0.4838 - val_accuracy: 0.7809\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8186 - val_loss: 0.4821 - val_accuracy: 0.7865\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8186 - val_loss: 0.4799 - val_accuracy: 0.7865\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8186 - val_loss: 0.4787 - val_accuracy: 0.7921\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8249 - val_loss: 0.4770 - val_accuracy: 0.7921\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8249 - val_loss: 0.4759 - val_accuracy: 0.7921\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8249 - val_loss: 0.4753 - val_accuracy: 0.7921\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8312 - val_loss: 0.4745 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8270 - val_loss: 0.4736 - val_accuracy: 0.7978\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8270 - val_loss: 0.4733 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8270 - val_loss: 0.4726 - val_accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8270 - val_loss: 0.4721 - val_accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8270 - val_loss: 0.4710 - val_accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8270 - val_loss: 0.4709 - val_accuracy: 0.8090\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8270 - val_loss: 0.4708 - val_accuracy: 0.8090\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8270 - val_loss: 0.4699 - val_accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8291 - val_loss: 0.4708 - val_accuracy: 0.8090\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8291 - val_loss: 0.4700 - val_accuracy: 0.8146\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8312 - val_loss: 0.4698 - val_accuracy: 0.8202\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8312 - val_loss: 0.4685 - val_accuracy: 0.8202\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8312 - val_loss: 0.4678 - val_accuracy: 0.8202\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8333 - val_loss: 0.4681 - val_accuracy: 0.8202\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8333 - val_loss: 0.4685 - val_accuracy: 0.8146\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.8333 - val_loss: 0.4680 - val_accuracy: 0.8202\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3889 - accuracy: 0.8418 - val_loss: 0.4673 - val_accuracy: 0.8202\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8397 - val_loss: 0.4674 - val_accuracy: 0.8202\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8418 - val_loss: 0.4675 - val_accuracy: 0.8202\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8418 - val_loss: 0.4687 - val_accuracy: 0.8202\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8418 - val_loss: 0.4676 - val_accuracy: 0.8258\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8418 - val_loss: 0.4676 - val_accuracy: 0.8258\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8418 - val_loss: 0.4687 - val_accuracy: 0.8202\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8418 - val_loss: 0.4680 - val_accuracy: 0.8146\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8418 - val_loss: 0.4677 - val_accuracy: 0.8146\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8418 - val_loss: 0.4685 - val_accuracy: 0.8258\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8418 - val_loss: 0.4679 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 807us/step - loss: 0.4083 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_891 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.6640 - accuracy: 0.6329 - val_loss: 0.6307 - val_accuracy: 0.7022\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.6857 - val_loss: 0.6079 - val_accuracy: 0.7022\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.7152 - val_loss: 0.5883 - val_accuracy: 0.6910\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7342 - val_loss: 0.5717 - val_accuracy: 0.7191\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7405 - val_loss: 0.5570 - val_accuracy: 0.7247\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7616 - val_loss: 0.5440 - val_accuracy: 0.7416\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7616 - val_loss: 0.5316 - val_accuracy: 0.7472\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7764 - val_loss: 0.5203 - val_accuracy: 0.7416\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7890 - val_loss: 0.5096 - val_accuracy: 0.7697\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8143 - val_loss: 0.5020 - val_accuracy: 0.7753\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.8186 - val_loss: 0.4937 - val_accuracy: 0.7921\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8249 - val_loss: 0.4887 - val_accuracy: 0.7921\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.8207 - val_loss: 0.4842 - val_accuracy: 0.8090\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8228 - val_loss: 0.4798 - val_accuracy: 0.8034\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8249 - val_loss: 0.4777 - val_accuracy: 0.8034\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.8207 - val_loss: 0.4746 - val_accuracy: 0.8090\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8207 - val_loss: 0.4746 - val_accuracy: 0.8034\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8228 - val_loss: 0.4749 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8249 - val_loss: 0.4731 - val_accuracy: 0.8034\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8249 - val_loss: 0.4731 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8312 - val_loss: 0.4717 - val_accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8333 - val_loss: 0.4728 - val_accuracy: 0.8034\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8333 - val_loss: 0.4721 - val_accuracy: 0.8090\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8354 - val_loss: 0.4720 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8376 - val_loss: 0.4723 - val_accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8354 - val_loss: 0.4726 - val_accuracy: 0.8034\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8397 - val_loss: 0.4729 - val_accuracy: 0.8034\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8354 - val_loss: 0.4737 - val_accuracy: 0.7978\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8376 - val_loss: 0.4733 - val_accuracy: 0.7978\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8354 - val_loss: 0.4749 - val_accuracy: 0.7978\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.8354 - val_loss: 0.4752 - val_accuracy: 0.7921\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3986 - accuracy: 0.8397\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_893 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6895 - accuracy: 0.5527 - val_loss: 0.6566 - val_accuracy: 0.6461\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.6667 - val_loss: 0.6125 - val_accuracy: 0.6517\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.6962 - val_loss: 0.5857 - val_accuracy: 0.6629\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7342 - val_loss: 0.5639 - val_accuracy: 0.6966\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7532 - val_loss: 0.5431 - val_accuracy: 0.7191\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7996 - val_loss: 0.5303 - val_accuracy: 0.7584\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.8165 - val_loss: 0.5192 - val_accuracy: 0.7697\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8186 - val_loss: 0.5111 - val_accuracy: 0.7753\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8207 - val_loss: 0.5041 - val_accuracy: 0.7865\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8249 - val_loss: 0.4991 - val_accuracy: 0.7921\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8228 - val_loss: 0.4936 - val_accuracy: 0.7697\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.8249 - val_loss: 0.4911 - val_accuracy: 0.7865\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8186 - val_loss: 0.4877 - val_accuracy: 0.7865\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8207 - val_loss: 0.4863 - val_accuracy: 0.7921\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8333 - val_loss: 0.4850 - val_accuracy: 0.7978\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8354 - val_loss: 0.4825 - val_accuracy: 0.7978\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8312 - val_loss: 0.4819 - val_accuracy: 0.8034\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.8376 - val_loss: 0.4826 - val_accuracy: 0.8146\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8397 - val_loss: 0.4764 - val_accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8397 - val_loss: 0.4783 - val_accuracy: 0.8146\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8397 - val_loss: 0.4753 - val_accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8376 - val_loss: 0.4755 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8439 - val_loss: 0.4771 - val_accuracy: 0.8146\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8418 - val_loss: 0.4748 - val_accuracy: 0.8146\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8418 - val_loss: 0.4742 - val_accuracy: 0.8146\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8418 - val_loss: 0.4738 - val_accuracy: 0.8146\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8418 - val_loss: 0.4748 - val_accuracy: 0.8146\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8397 - val_loss: 0.4745 - val_accuracy: 0.8146\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8439 - val_loss: 0.4723 - val_accuracy: 0.8090\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8418 - val_loss: 0.4732 - val_accuracy: 0.8146\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8418 - val_loss: 0.4747 - val_accuracy: 0.8146\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8460 - val_loss: 0.4750 - val_accuracy: 0.8146\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8439 - val_loss: 0.4735 - val_accuracy: 0.8315\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8439 - val_loss: 0.4749 - val_accuracy: 0.8146\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8502 - val_loss: 0.4721 - val_accuracy: 0.8315\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8481 - val_loss: 0.4728 - val_accuracy: 0.8258\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8481 - val_loss: 0.4736 - val_accuracy: 0.8258\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8523 - val_loss: 0.4756 - val_accuracy: 0.8258\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8544 - val_loss: 0.4782 - val_accuracy: 0.8315\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8544 - val_loss: 0.4747 - val_accuracy: 0.8315\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8523 - val_loss: 0.4737 - val_accuracy: 0.8258\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8523 - val_loss: 0.4743 - val_accuracy: 0.8258\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8544 - val_loss: 0.4741 - val_accuracy: 0.8315\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8586 - val_loss: 0.4763 - val_accuracy: 0.8371\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8586 - val_loss: 0.4771 - val_accuracy: 0.8371\n",
      "8/8 [==============================] - 0s 854us/step - loss: 0.4377 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_895 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6024 - accuracy: 0.6730 - val_loss: 0.5786 - val_accuracy: 0.6966\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.7152 - val_loss: 0.5521 - val_accuracy: 0.7247\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7553 - val_loss: 0.5354 - val_accuracy: 0.7753\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7932 - val_loss: 0.5221 - val_accuracy: 0.7640\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.8143 - val_loss: 0.5109 - val_accuracy: 0.7921\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.8143 - val_loss: 0.5023 - val_accuracy: 0.7921\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.8228 - val_loss: 0.4951 - val_accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8207 - val_loss: 0.4898 - val_accuracy: 0.7978\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.8249 - val_loss: 0.4859 - val_accuracy: 0.7978\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8249 - val_loss: 0.4822 - val_accuracy: 0.8146\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8270 - val_loss: 0.4799 - val_accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8249 - val_loss: 0.4781 - val_accuracy: 0.8202\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8249 - val_loss: 0.4757 - val_accuracy: 0.8146\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8291 - val_loss: 0.4736 - val_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8312 - val_loss: 0.4720 - val_accuracy: 0.8202\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8312 - val_loss: 0.4709 - val_accuracy: 0.8202\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8354 - val_loss: 0.4711 - val_accuracy: 0.8146\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8376 - val_loss: 0.4693 - val_accuracy: 0.8202\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8397 - val_loss: 0.4684 - val_accuracy: 0.8146\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.8397 - val_loss: 0.4677 - val_accuracy: 0.8202\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8397 - val_loss: 0.4673 - val_accuracy: 0.8202\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8418 - val_loss: 0.4674 - val_accuracy: 0.8202\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8439 - val_loss: 0.4660 - val_accuracy: 0.8202\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8439 - val_loss: 0.4651 - val_accuracy: 0.8202\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8439 - val_loss: 0.4643 - val_accuracy: 0.8258\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8439 - val_loss: 0.4645 - val_accuracy: 0.8202\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8439 - val_loss: 0.4635 - val_accuracy: 0.8202\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.8439 - val_loss: 0.4641 - val_accuracy: 0.8146\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8439 - val_loss: 0.4649 - val_accuracy: 0.8146\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8439 - val_loss: 0.4640 - val_accuracy: 0.8202\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8439 - val_loss: 0.4641 - val_accuracy: 0.8258\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8439 - val_loss: 0.4637 - val_accuracy: 0.8146\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8439 - val_loss: 0.4629 - val_accuracy: 0.8146\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8439 - val_loss: 0.4625 - val_accuracy: 0.8146\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8439 - val_loss: 0.4644 - val_accuracy: 0.8146\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8481 - val_loss: 0.4637 - val_accuracy: 0.8146\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8481 - val_loss: 0.4631 - val_accuracy: 0.8146\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8481 - val_loss: 0.4631 - val_accuracy: 0.8146\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8481 - val_loss: 0.4629 - val_accuracy: 0.8146\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8481 - val_loss: 0.4629 - val_accuracy: 0.8202\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8481 - val_loss: 0.4631 - val_accuracy: 0.8202\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8502 - val_loss: 0.4635 - val_accuracy: 0.8146\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8481 - val_loss: 0.4629 - val_accuracy: 0.8202\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8523 - val_loss: 0.4629 - val_accuracy: 0.8202\n",
      "8/8 [==============================] - 0s 864us/step - loss: 0.4040 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_897 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6696 - accuracy: 0.5759 - val_loss: 0.6130 - val_accuracy: 0.7528\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.7300 - val_loss: 0.5724 - val_accuracy: 0.7528\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7321 - val_loss: 0.5512 - val_accuracy: 0.7360\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7553 - val_loss: 0.5345 - val_accuracy: 0.7472\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7700 - val_loss: 0.5211 - val_accuracy: 0.7640\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7911 - val_loss: 0.5116 - val_accuracy: 0.7640\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.8080 - val_loss: 0.5024 - val_accuracy: 0.7921\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.8080 - val_loss: 0.4961 - val_accuracy: 0.7865\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.8122 - val_loss: 0.4925 - val_accuracy: 0.7921\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.8143 - val_loss: 0.4897 - val_accuracy: 0.7978\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.8207 - val_loss: 0.4866 - val_accuracy: 0.7921\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8186 - val_loss: 0.4829 - val_accuracy: 0.8034\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8207 - val_loss: 0.4814 - val_accuracy: 0.8034\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8228 - val_loss: 0.4800 - val_accuracy: 0.8090\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8270 - val_loss: 0.4810 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8270 - val_loss: 0.4800 - val_accuracy: 0.8090\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8291 - val_loss: 0.4774 - val_accuracy: 0.8090\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8291 - val_loss: 0.4783 - val_accuracy: 0.8090\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8270 - val_loss: 0.4774 - val_accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8270 - val_loss: 0.4776 - val_accuracy: 0.8090\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8333 - val_loss: 0.4785 - val_accuracy: 0.8034\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8312 - val_loss: 0.4768 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8333 - val_loss: 0.4791 - val_accuracy: 0.8034\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8291 - val_loss: 0.4759 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8312 - val_loss: 0.4778 - val_accuracy: 0.8034\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8291 - val_loss: 0.4773 - val_accuracy: 0.8034\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8354 - val_loss: 0.4772 - val_accuracy: 0.7978\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8354 - val_loss: 0.4797 - val_accuracy: 0.7978\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8354 - val_loss: 0.4786 - val_accuracy: 0.7978\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8354 - val_loss: 0.4801 - val_accuracy: 0.7978\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8333 - val_loss: 0.4793 - val_accuracy: 0.7978\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8397 - val_loss: 0.4785 - val_accuracy: 0.7978\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8354 - val_loss: 0.4808 - val_accuracy: 0.7978\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8397 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
      "8/8 [==============================] - 0s 769us/step - loss: 0.4040 - accuracy: 0.8397\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_899 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6842 - accuracy: 0.5422 - val_loss: 0.6539 - val_accuracy: 0.6348\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.7046 - val_loss: 0.6100 - val_accuracy: 0.6517\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7300 - val_loss: 0.5841 - val_accuracy: 0.6573\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7384 - val_loss: 0.5611 - val_accuracy: 0.6629\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7574 - val_loss: 0.5414 - val_accuracy: 0.6910\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7954 - val_loss: 0.5251 - val_accuracy: 0.7584\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8101 - val_loss: 0.5127 - val_accuracy: 0.7753\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8228 - val_loss: 0.5034 - val_accuracy: 0.7978\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8249 - val_loss: 0.5018 - val_accuracy: 0.7921\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8249 - val_loss: 0.4918 - val_accuracy: 0.7809\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8312 - val_loss: 0.4893 - val_accuracy: 0.7921\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8291 - val_loss: 0.4930 - val_accuracy: 0.7978\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8397 - val_loss: 0.4856 - val_accuracy: 0.7921\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3889 - accuracy: 0.8418 - val_loss: 0.4839 - val_accuracy: 0.7921\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8376 - val_loss: 0.4805 - val_accuracy: 0.7978\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8418 - val_loss: 0.4824 - val_accuracy: 0.7978\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3805 - accuracy: 0.8418 - val_loss: 0.4783 - val_accuracy: 0.7978\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8460 - val_loss: 0.4815 - val_accuracy: 0.8090\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8460 - val_loss: 0.4782 - val_accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8481 - val_loss: 0.4774 - val_accuracy: 0.8090\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8502 - val_loss: 0.4773 - val_accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8544 - val_loss: 0.4765 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8481 - val_loss: 0.4775 - val_accuracy: 0.8090\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8502 - val_loss: 0.4760 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8565 - val_loss: 0.4753 - val_accuracy: 0.8146\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8565 - val_loss: 0.4779 - val_accuracy: 0.8258\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8565 - val_loss: 0.4731 - val_accuracy: 0.8146\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8565 - val_loss: 0.4763 - val_accuracy: 0.8202\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8586 - val_loss: 0.4766 - val_accuracy: 0.8202\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8671 - val_loss: 0.4777 - val_accuracy: 0.8258\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8523 - val_loss: 0.4751 - val_accuracy: 0.8202\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8544 - val_loss: 0.4789 - val_accuracy: 0.8258\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8565 - val_loss: 0.4759 - val_accuracy: 0.8258\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8629 - val_loss: 0.4763 - val_accuracy: 0.8315\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8671 - val_loss: 0.4802 - val_accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3500 - accuracy: 0.8692 - val_loss: 0.4770 - val_accuracy: 0.8315\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8692 - val_loss: 0.4776 - val_accuracy: 0.8315\n",
      "8/8 [==============================] - 0s 793us/step - loss: 0.4294 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_901 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6711 - accuracy: 0.5949 - val_loss: 0.6268 - val_accuracy: 0.6854\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7025 - val_loss: 0.5831 - val_accuracy: 0.6854\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7194 - val_loss: 0.5556 - val_accuracy: 0.7135\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7384 - val_loss: 0.5354 - val_accuracy: 0.7303\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7764 - val_loss: 0.5181 - val_accuracy: 0.7753\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.8122 - val_loss: 0.5062 - val_accuracy: 0.7809\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.8165 - val_loss: 0.4961 - val_accuracy: 0.7809\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8186 - val_loss: 0.4889 - val_accuracy: 0.7865\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8207 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.8207 - val_loss: 0.4791 - val_accuracy: 0.7921\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8270 - val_loss: 0.4763 - val_accuracy: 0.8034\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8291 - val_loss: 0.4741 - val_accuracy: 0.8090\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8354 - val_loss: 0.4716 - val_accuracy: 0.8090\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8376 - val_loss: 0.4698 - val_accuracy: 0.8146\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8354 - val_loss: 0.4691 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8397 - val_loss: 0.4659 - val_accuracy: 0.8146\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3948 - accuracy: 0.8418 - val_loss: 0.4656 - val_accuracy: 0.8202\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8397 - val_loss: 0.4645 - val_accuracy: 0.8202\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8397 - val_loss: 0.4654 - val_accuracy: 0.8146\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3874 - accuracy: 0.8439 - val_loss: 0.4656 - val_accuracy: 0.8146\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8439 - val_loss: 0.4642 - val_accuracy: 0.8146\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8439 - val_loss: 0.4631 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8460 - val_loss: 0.4652 - val_accuracy: 0.8146\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8460 - val_loss: 0.4645 - val_accuracy: 0.8146\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8460 - val_loss: 0.4633 - val_accuracy: 0.8146\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8439 - val_loss: 0.4622 - val_accuracy: 0.8202\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8481 - val_loss: 0.4628 - val_accuracy: 0.8202\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8481 - val_loss: 0.4639 - val_accuracy: 0.8202\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8502 - val_loss: 0.4634 - val_accuracy: 0.8202\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8502 - val_loss: 0.4633 - val_accuracy: 0.8258\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8460 - val_loss: 0.4648 - val_accuracy: 0.8146\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8502 - val_loss: 0.4663 - val_accuracy: 0.8090\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8481 - val_loss: 0.4659 - val_accuracy: 0.8202\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8502 - val_loss: 0.4635 - val_accuracy: 0.8258\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8439 - val_loss: 0.4661 - val_accuracy: 0.8146\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8481 - val_loss: 0.4660 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 856us/step - loss: 0.3991 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_903 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6951 - accuracy: 0.5570 - val_loss: 0.6464 - val_accuracy: 0.6854\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.7384 - val_loss: 0.5936 - val_accuracy: 0.6854\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7426 - val_loss: 0.5671 - val_accuracy: 0.7022\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7616 - val_loss: 0.5485 - val_accuracy: 0.7079\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8059 - val_loss: 0.5345 - val_accuracy: 0.7416\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.8059 - val_loss: 0.5249 - val_accuracy: 0.7360\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.8165 - val_loss: 0.5172 - val_accuracy: 0.7584\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8186 - val_loss: 0.5126 - val_accuracy: 0.7640\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8165 - val_loss: 0.5061 - val_accuracy: 0.7809\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8165 - val_loss: 0.5042 - val_accuracy: 0.7753\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8143 - val_loss: 0.4995 - val_accuracy: 0.7809\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8143 - val_loss: 0.5020 - val_accuracy: 0.7753\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8165 - val_loss: 0.4966 - val_accuracy: 0.7921\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8186 - val_loss: 0.4970 - val_accuracy: 0.7921\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8249 - val_loss: 0.4962 - val_accuracy: 0.7921\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8291 - val_loss: 0.4979 - val_accuracy: 0.7865\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8333 - val_loss: 0.4967 - val_accuracy: 0.7865\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8291 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8312 - val_loss: 0.4967 - val_accuracy: 0.7865\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3827 - accuracy: 0.8333 - val_loss: 0.4951 - val_accuracy: 0.7753\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8376 - val_loss: 0.4937 - val_accuracy: 0.7809\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8354 - val_loss: 0.4946 - val_accuracy: 0.7809\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8418 - val_loss: 0.4942 - val_accuracy: 0.7809\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8439 - val_loss: 0.4952 - val_accuracy: 0.7753\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8397 - val_loss: 0.4938 - val_accuracy: 0.7809\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8460 - val_loss: 0.4965 - val_accuracy: 0.7809\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8439 - val_loss: 0.4970 - val_accuracy: 0.7809\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3647 - accuracy: 0.8481 - val_loss: 0.4971 - val_accuracy: 0.7753\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8481 - val_loss: 0.4967 - val_accuracy: 0.7753\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8481 - val_loss: 0.5022 - val_accuracy: 0.7809\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8481 - val_loss: 0.4972 - val_accuracy: 0.7753\n",
      "8/8 [==============================] - 0s 797us/step - loss: 0.4087 - accuracy: 0.8397\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_905 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6527 - accuracy: 0.6920 - val_loss: 0.6447 - val_accuracy: 0.7135\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.7236 - val_loss: 0.6240 - val_accuracy: 0.7135\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7468 - val_loss: 0.6039 - val_accuracy: 0.7303\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7679 - val_loss: 0.5845 - val_accuracy: 0.7360\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7785 - val_loss: 0.5646 - val_accuracy: 0.7416\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7911 - val_loss: 0.5456 - val_accuracy: 0.7584\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.8101 - val_loss: 0.5308 - val_accuracy: 0.7640\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.8101 - val_loss: 0.5181 - val_accuracy: 0.7697\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.8143 - val_loss: 0.5099 - val_accuracy: 0.7753\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.8228 - val_loss: 0.5014 - val_accuracy: 0.7809\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8249 - val_loss: 0.4975 - val_accuracy: 0.7921\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8249 - val_loss: 0.4928 - val_accuracy: 0.7978\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8228 - val_loss: 0.4904 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8249 - val_loss: 0.4883 - val_accuracy: 0.7978\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8333 - val_loss: 0.4856 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8397 - val_loss: 0.4849 - val_accuracy: 0.8090\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8354 - val_loss: 0.4828 - val_accuracy: 0.8090\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8376 - val_loss: 0.4802 - val_accuracy: 0.8090\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8439 - val_loss: 0.4780 - val_accuracy: 0.8146\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8460 - val_loss: 0.4766 - val_accuracy: 0.8090\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8418 - val_loss: 0.4762 - val_accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8481 - val_loss: 0.4743 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8544 - val_loss: 0.4756 - val_accuracy: 0.8090\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3805 - accuracy: 0.8544 - val_loss: 0.4736 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8523 - val_loss: 0.4762 - val_accuracy: 0.8146\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8523 - val_loss: 0.4739 - val_accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8523 - val_loss: 0.4728 - val_accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8586 - val_loss: 0.4729 - val_accuracy: 0.8146\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8565 - val_loss: 0.4718 - val_accuracy: 0.8146\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8544 - val_loss: 0.4708 - val_accuracy: 0.8146\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8586 - val_loss: 0.4717 - val_accuracy: 0.8146\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8502 - val_loss: 0.4718 - val_accuracy: 0.8146\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8544 - val_loss: 0.4719 - val_accuracy: 0.8146\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.8544 - val_loss: 0.4705 - val_accuracy: 0.8146\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8523 - val_loss: 0.4694 - val_accuracy: 0.8146\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8544 - val_loss: 0.4714 - val_accuracy: 0.8146\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8523 - val_loss: 0.4708 - val_accuracy: 0.8146\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8565 - val_loss: 0.4701 - val_accuracy: 0.8146\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8544 - val_loss: 0.4713 - val_accuracy: 0.8146\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8608 - val_loss: 0.4735 - val_accuracy: 0.8146\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8629 - val_loss: 0.4724 - val_accuracy: 0.8146\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8565 - val_loss: 0.4717 - val_accuracy: 0.8090\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8544 - val_loss: 0.4733 - val_accuracy: 0.8090\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8565 - val_loss: 0.4726 - val_accuracy: 0.8090\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8565 - val_loss: 0.4741 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 756us/step - loss: 0.4405 - accuracy: 0.8017\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_908 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7353 - accuracy: 0.6034 - val_loss: 0.7186 - val_accuracy: 0.6124\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7195 - accuracy: 0.6034 - val_loss: 0.7087 - val_accuracy: 0.6124\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7083 - accuracy: 0.6034 - val_loss: 0.7002 - val_accuracy: 0.6124\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6982 - accuracy: 0.6034 - val_loss: 0.6936 - val_accuracy: 0.6124\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.6034 - val_loss: 0.6870 - val_accuracy: 0.6124\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.6034 - val_loss: 0.6782 - val_accuracy: 0.6124\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.6034 - val_loss: 0.6664 - val_accuracy: 0.6124\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.6034 - val_loss: 0.6504 - val_accuracy: 0.6124\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.6034 - val_loss: 0.6334 - val_accuracy: 0.6124\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6034 - val_loss: 0.6194 - val_accuracy: 0.6124\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.6034 - val_loss: 0.6067 - val_accuracy: 0.6124\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.6055 - val_loss: 0.5950 - val_accuracy: 0.6236\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.6224 - val_loss: 0.5843 - val_accuracy: 0.6348\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.6561 - val_loss: 0.5740 - val_accuracy: 0.6461\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.6899 - val_loss: 0.5624 - val_accuracy: 0.6910\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7300 - val_loss: 0.5501 - val_accuracy: 0.7303\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7384 - val_loss: 0.5375 - val_accuracy: 0.7697\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7848 - val_loss: 0.5262 - val_accuracy: 0.8090\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.8080 - val_loss: 0.5165 - val_accuracy: 0.7921\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.8080 - val_loss: 0.5099 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.8186 - val_loss: 0.5029 - val_accuracy: 0.7978\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.8291 - val_loss: 0.4983 - val_accuracy: 0.7978\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.8291 - val_loss: 0.4940 - val_accuracy: 0.7978\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8291 - val_loss: 0.4902 - val_accuracy: 0.7978\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8249 - val_loss: 0.4883 - val_accuracy: 0.7978\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8270 - val_loss: 0.4859 - val_accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8291 - val_loss: 0.4845 - val_accuracy: 0.8034\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8291 - val_loss: 0.4825 - val_accuracy: 0.8034\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8312 - val_loss: 0.4815 - val_accuracy: 0.8034\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8312 - val_loss: 0.4804 - val_accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8312 - val_loss: 0.4801 - val_accuracy: 0.8034\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8291 - val_loss: 0.4790 - val_accuracy: 0.7978\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8291 - val_loss: 0.4784 - val_accuracy: 0.8034\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8291 - val_loss: 0.4783 - val_accuracy: 0.8146\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8312 - val_loss: 0.4772 - val_accuracy: 0.8146\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8312 - val_loss: 0.4767 - val_accuracy: 0.8090\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8312 - val_loss: 0.4759 - val_accuracy: 0.8146\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8312 - val_loss: 0.4752 - val_accuracy: 0.8202\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8333 - val_loss: 0.4753 - val_accuracy: 0.8146\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8312 - val_loss: 0.4754 - val_accuracy: 0.8146\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8291 - val_loss: 0.4747 - val_accuracy: 0.8146\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8291 - val_loss: 0.4739 - val_accuracy: 0.8146\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8312 - val_loss: 0.4736 - val_accuracy: 0.8090\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8312 - val_loss: 0.4731 - val_accuracy: 0.8090\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8354 - val_loss: 0.4727 - val_accuracy: 0.8034\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8333 - val_loss: 0.4717 - val_accuracy: 0.8034\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8354 - val_loss: 0.4716 - val_accuracy: 0.8034\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8333 - val_loss: 0.4722 - val_accuracy: 0.8090\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8376 - val_loss: 0.4724 - val_accuracy: 0.8034\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8333 - val_loss: 0.4715 - val_accuracy: 0.8034\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8354 - val_loss: 0.4710 - val_accuracy: 0.8146\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8354 - val_loss: 0.4714 - val_accuracy: 0.8034\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8376 - val_loss: 0.4714 - val_accuracy: 0.8034\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8354 - val_loss: 0.4711 - val_accuracy: 0.8034\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8333 - val_loss: 0.4706 - val_accuracy: 0.8034\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8354 - val_loss: 0.4707 - val_accuracy: 0.8034\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8354 - val_loss: 0.4714 - val_accuracy: 0.8034\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8333 - val_loss: 0.4720 - val_accuracy: 0.8034\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8333 - val_loss: 0.4723 - val_accuracy: 0.8034\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8354 - val_loss: 0.4726 - val_accuracy: 0.8034\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8333 - val_loss: 0.4726 - val_accuracy: 0.8034\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8376 - val_loss: 0.4727 - val_accuracy: 0.8034\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8376 - val_loss: 0.4732 - val_accuracy: 0.8090\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8397 - val_loss: 0.4732 - val_accuracy: 0.8034\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8354 - val_loss: 0.4732 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 963us/step - loss: 0.3985 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_911 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.6245 - val_loss: 0.6617 - val_accuracy: 0.6348\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.6477 - val_loss: 0.6438 - val_accuracy: 0.6461\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.6477 - val_loss: 0.6285 - val_accuracy: 0.6348\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.6582 - val_loss: 0.6153 - val_accuracy: 0.6629\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.6624 - val_loss: 0.6009 - val_accuracy: 0.6910\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.6793 - val_loss: 0.5884 - val_accuracy: 0.6966\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.6962 - val_loss: 0.5773 - val_accuracy: 0.7135\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.7194 - val_loss: 0.5661 - val_accuracy: 0.7079\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7384 - val_loss: 0.5575 - val_accuracy: 0.7191\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7511 - val_loss: 0.5482 - val_accuracy: 0.7247\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7764 - val_loss: 0.5387 - val_accuracy: 0.7191\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7911 - val_loss: 0.5306 - val_accuracy: 0.7247\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8059 - val_loss: 0.5237 - val_accuracy: 0.7416\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.8228 - val_loss: 0.5159 - val_accuracy: 0.7584\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.8291 - val_loss: 0.5095 - val_accuracy: 0.7640\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.8270 - val_loss: 0.5043 - val_accuracy: 0.7753\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8291 - val_loss: 0.5011 - val_accuracy: 0.7809\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8291 - val_loss: 0.4982 - val_accuracy: 0.8090\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8270 - val_loss: 0.4962 - val_accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8291 - val_loss: 0.4925 - val_accuracy: 0.8202\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8291 - val_loss: 0.4922 - val_accuracy: 0.8258\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8312 - val_loss: 0.4919 - val_accuracy: 0.8202\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8270 - val_loss: 0.4911 - val_accuracy: 0.8315\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.8258\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8270 - val_loss: 0.4919 - val_accuracy: 0.8258\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8333 - val_loss: 0.4919 - val_accuracy: 0.8146\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8312 - val_loss: 0.4925 - val_accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8291 - val_loss: 0.4938 - val_accuracy: 0.8146\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8354 - val_loss: 0.4939 - val_accuracy: 0.8090\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8228 - val_loss: 0.4933 - val_accuracy: 0.8146\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8376 - val_loss: 0.4957 - val_accuracy: 0.8034\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8376 - val_loss: 0.4958 - val_accuracy: 0.7978\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8397 - val_loss: 0.4958 - val_accuracy: 0.7978\n",
      "8/8 [==============================] - 0s 873us/step - loss: 0.4248 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_914 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6278 - accuracy: 0.6477 - val_loss: 0.6234 - val_accuracy: 0.6180\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.6793 - val_loss: 0.6006 - val_accuracy: 0.6348\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7046 - val_loss: 0.5844 - val_accuracy: 0.6742\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7342 - val_loss: 0.5690 - val_accuracy: 0.6798\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7532 - val_loss: 0.5537 - val_accuracy: 0.6966\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7827 - val_loss: 0.5380 - val_accuracy: 0.7303\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.8165 - val_loss: 0.5289 - val_accuracy: 0.7472\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.8165 - val_loss: 0.5168 - val_accuracy: 0.7640\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8143 - val_loss: 0.5101 - val_accuracy: 0.7640\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8207 - val_loss: 0.5059 - val_accuracy: 0.7697\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8291 - val_loss: 0.4991 - val_accuracy: 0.7753\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8376 - val_loss: 0.4966 - val_accuracy: 0.7865\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8291 - val_loss: 0.4965 - val_accuracy: 0.7921\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8354 - val_loss: 0.4923 - val_accuracy: 0.8034\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8397 - val_loss: 0.4889 - val_accuracy: 0.8034\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3779 - accuracy: 0.8418 - val_loss: 0.4862 - val_accuracy: 0.8034\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8397 - val_loss: 0.4878 - val_accuracy: 0.8034\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8397 - val_loss: 0.4857 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8397 - val_loss: 0.4834 - val_accuracy: 0.8034\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8523 - val_loss: 0.4859 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8481 - val_loss: 0.4844 - val_accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3601 - accuracy: 0.8481 - val_loss: 0.4841 - val_accuracy: 0.8146\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8502 - val_loss: 0.4826 - val_accuracy: 0.8146\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 0.8544 - val_loss: 0.4842 - val_accuracy: 0.8202\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8523 - val_loss: 0.4845 - val_accuracy: 0.8202\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8608 - val_loss: 0.4851 - val_accuracy: 0.8146\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8565 - val_loss: 0.4837 - val_accuracy: 0.8202\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8608 - val_loss: 0.4838 - val_accuracy: 0.8258\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8629 - val_loss: 0.4857 - val_accuracy: 0.8146\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8608 - val_loss: 0.4870 - val_accuracy: 0.8146\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8671 - val_loss: 0.4846 - val_accuracy: 0.8146\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8629 - val_loss: 0.4855 - val_accuracy: 0.8146\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.8629 - val_loss: 0.4884 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 782us/step - loss: 0.4319 - accuracy: 0.8354\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_917 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6683 - accuracy: 0.5886 - val_loss: 0.6215 - val_accuracy: 0.6573\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6245 - val_loss: 0.5903 - val_accuracy: 0.6236\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.6519 - val_loss: 0.5677 - val_accuracy: 0.6573\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7257 - val_loss: 0.5479 - val_accuracy: 0.7247\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7595 - val_loss: 0.5319 - val_accuracy: 0.7472\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 1s 46ms/step - loss: 0.4905 - accuracy: 0.7869 - val_loss: 0.5170 - val_accuracy: 0.7753\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.8122 - val_loss: 0.5037 - val_accuracy: 0.8034\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.8249 - val_loss: 0.4953 - val_accuracy: 0.7921\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.8228 - val_loss: 0.4891 - val_accuracy: 0.8034\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8333 - val_loss: 0.4861 - val_accuracy: 0.8090\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8291 - val_loss: 0.4829 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8291 - val_loss: 0.4814 - val_accuracy: 0.8146\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8354 - val_loss: 0.4769 - val_accuracy: 0.8202\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8376 - val_loss: 0.4755 - val_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8418 - val_loss: 0.4757 - val_accuracy: 0.8202\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8397 - val_loss: 0.4787 - val_accuracy: 0.8090\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8418 - val_loss: 0.4736 - val_accuracy: 0.8146\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3868 - accuracy: 0.8439 - val_loss: 0.4776 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8439 - val_loss: 0.4727 - val_accuracy: 0.8146\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8460 - val_loss: 0.4760 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8460 - val_loss: 0.4736 - val_accuracy: 0.8202\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8418 - val_loss: 0.4803 - val_accuracy: 0.8034\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8418 - val_loss: 0.4741 - val_accuracy: 0.8146\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8481 - val_loss: 0.4721 - val_accuracy: 0.8146\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8418 - val_loss: 0.4808 - val_accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8460 - val_loss: 0.4756 - val_accuracy: 0.8146\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8481 - val_loss: 0.4766 - val_accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8502 - val_loss: 0.4731 - val_accuracy: 0.8146\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.8523 - val_loss: 0.4769 - val_accuracy: 0.8090\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8460 - val_loss: 0.4781 - val_accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8439 - val_loss: 0.4786 - val_accuracy: 0.8034\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8502 - val_loss: 0.4770 - val_accuracy: 0.8202\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.8565 - val_loss: 0.4793 - val_accuracy: 0.8090\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8523 - val_loss: 0.4844 - val_accuracy: 0.7978\n",
      "8/8 [==============================] - 0s 772us/step - loss: 0.4106 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_920 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.8420 - accuracy: 0.2489 - val_loss: 0.7433 - val_accuracy: 0.2640\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7141 - accuracy: 0.4620 - val_loss: 0.6731 - val_accuracy: 0.6011\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6245 - val_loss: 0.6326 - val_accuracy: 0.6348\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.6582 - val_loss: 0.6051 - val_accuracy: 0.6404\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.6941 - val_loss: 0.5792 - val_accuracy: 0.6629\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7278 - val_loss: 0.5550 - val_accuracy: 0.7191\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7764 - val_loss: 0.5376 - val_accuracy: 0.7416\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.8122 - val_loss: 0.5237 - val_accuracy: 0.7528\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.8080 - val_loss: 0.5138 - val_accuracy: 0.7472\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.8101 - val_loss: 0.5081 - val_accuracy: 0.7640\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.8186 - val_loss: 0.5045 - val_accuracy: 0.7809\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8228 - val_loss: 0.5029 - val_accuracy: 0.7865\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8291 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8228 - val_loss: 0.4984 - val_accuracy: 0.7865\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8249 - val_loss: 0.4981 - val_accuracy: 0.7921\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8333 - val_loss: 0.4973 - val_accuracy: 0.7865\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8270 - val_loss: 0.4953 - val_accuracy: 0.7921\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8333 - val_loss: 0.4966 - val_accuracy: 0.7809\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8354 - val_loss: 0.4929 - val_accuracy: 0.7865\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8376 - val_loss: 0.4929 - val_accuracy: 0.7865\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8439 - val_loss: 0.4950 - val_accuracy: 0.7809\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8376 - val_loss: 0.4969 - val_accuracy: 0.7809\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8397 - val_loss: 0.4955 - val_accuracy: 0.7809\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8376 - val_loss: 0.4989 - val_accuracy: 0.7697\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8565 - val_loss: 0.5002 - val_accuracy: 0.7753\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8460 - val_loss: 0.4979 - val_accuracy: 0.7865\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8502 - val_loss: 0.5011 - val_accuracy: 0.7753\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3643 - accuracy: 0.8544 - val_loss: 0.5033 - val_accuracy: 0.7697\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8565 - val_loss: 0.5038 - val_accuracy: 0.7697\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8544 - val_loss: 0.5051 - val_accuracy: 0.7753\n",
      "8/8 [==============================] - 0s 795us/step - loss: 0.4219 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_923 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6319 - accuracy: 0.6667 - val_loss: 0.6172 - val_accuracy: 0.6292\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7046 - val_loss: 0.5753 - val_accuracy: 0.6910\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7722 - val_loss: 0.5346 - val_accuracy: 0.7584\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.8101 - val_loss: 0.5116 - val_accuracy: 0.7753\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8249 - val_loss: 0.4946 - val_accuracy: 0.7921\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8228 - val_loss: 0.4883 - val_accuracy: 0.7978\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8312 - val_loss: 0.4824 - val_accuracy: 0.8034\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8354 - val_loss: 0.4770 - val_accuracy: 0.8090\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8354 - val_loss: 0.4737 - val_accuracy: 0.8202\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8418 - val_loss: 0.4727 - val_accuracy: 0.8146\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8397 - val_loss: 0.4685 - val_accuracy: 0.8146\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8460 - val_loss: 0.4705 - val_accuracy: 0.8315\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8481 - val_loss: 0.4671 - val_accuracy: 0.8202\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8439 - val_loss: 0.4692 - val_accuracy: 0.8315\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8544 - val_loss: 0.4687 - val_accuracy: 0.8146\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8544 - val_loss: 0.4690 - val_accuracy: 0.8315\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8460 - val_loss: 0.4720 - val_accuracy: 0.8315\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8481 - val_loss: 0.4688 - val_accuracy: 0.8371\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8565 - val_loss: 0.4740 - val_accuracy: 0.8258\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8565 - val_loss: 0.4688 - val_accuracy: 0.8371\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8565 - val_loss: 0.4740 - val_accuracy: 0.8258\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8608 - val_loss: 0.4729 - val_accuracy: 0.8258\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8586 - val_loss: 0.4745 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 848us/step - loss: 0.4196 - accuracy: 0.8481\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_926 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6352 - accuracy: 0.6181 - val_loss: 0.6133 - val_accuracy: 0.6517\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.6857 - val_loss: 0.5744 - val_accuracy: 0.6798\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7426 - val_loss: 0.5461 - val_accuracy: 0.7360\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7785 - val_loss: 0.5241 - val_accuracy: 0.7640\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7848 - val_loss: 0.5035 - val_accuracy: 0.7753\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.8122 - val_loss: 0.4935 - val_accuracy: 0.7809\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8165 - val_loss: 0.4875 - val_accuracy: 0.8034\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8207 - val_loss: 0.4812 - val_accuracy: 0.8090\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8249 - val_loss: 0.4790 - val_accuracy: 0.8146\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8291 - val_loss: 0.4753 - val_accuracy: 0.8146\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8354 - val_loss: 0.4739 - val_accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8418 - val_loss: 0.4702 - val_accuracy: 0.8202\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8397 - val_loss: 0.4701 - val_accuracy: 0.8258\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8481 - val_loss: 0.4686 - val_accuracy: 0.8315\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8460 - val_loss: 0.4683 - val_accuracy: 0.8315\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8460 - val_loss: 0.4677 - val_accuracy: 0.8371\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8439 - val_loss: 0.4680 - val_accuracy: 0.8371\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8460 - val_loss: 0.4701 - val_accuracy: 0.8371\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8439 - val_loss: 0.4702 - val_accuracy: 0.8258\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8544 - val_loss: 0.4666 - val_accuracy: 0.8258\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8439 - val_loss: 0.4689 - val_accuracy: 0.8315\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8565 - val_loss: 0.4705 - val_accuracy: 0.8258\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8523 - val_loss: 0.4706 - val_accuracy: 0.8202\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8481 - val_loss: 0.4733 - val_accuracy: 0.8202\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8544 - val_loss: 0.4727 - val_accuracy: 0.8202\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8523 - val_loss: 0.4688 - val_accuracy: 0.8258\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8565 - val_loss: 0.4711 - val_accuracy: 0.8202\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8565 - val_loss: 0.4769 - val_accuracy: 0.8146\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8565 - val_loss: 0.4760 - val_accuracy: 0.8258\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8481 - val_loss: 0.4734 - val_accuracy: 0.8202\n",
      "8/8 [==============================] - 0s 775us/step - loss: 0.3955 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_929 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6244 - accuracy: 0.6709 - val_loss: 0.6002 - val_accuracy: 0.6685\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7236 - val_loss: 0.5712 - val_accuracy: 0.6910\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7574 - val_loss: 0.5450 - val_accuracy: 0.7303\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.8038 - val_loss: 0.5296 - val_accuracy: 0.7528\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.8270 - val_loss: 0.5114 - val_accuracy: 0.7584\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.8207 - val_loss: 0.5055 - val_accuracy: 0.7416\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8228 - val_loss: 0.4968 - val_accuracy: 0.7640\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8228 - val_loss: 0.4926 - val_accuracy: 0.7640\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8228 - val_loss: 0.4909 - val_accuracy: 0.7753\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8354 - val_loss: 0.4869 - val_accuracy: 0.7921\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8249 - val_loss: 0.4864 - val_accuracy: 0.7921\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3827 - accuracy: 0.8333 - val_loss: 0.4854 - val_accuracy: 0.7809\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8418 - val_loss: 0.4876 - val_accuracy: 0.7865\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8481 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8439 - val_loss: 0.4887 - val_accuracy: 0.7809\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8565 - val_loss: 0.4962 - val_accuracy: 0.7809\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8523 - val_loss: 0.4980 - val_accuracy: 0.7809\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8460 - val_loss: 0.4984 - val_accuracy: 0.7809\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8502 - val_loss: 0.5036 - val_accuracy: 0.7809\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8523 - val_loss: 0.5075 - val_accuracy: 0.7865\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8565 - val_loss: 0.5073 - val_accuracy: 0.7809\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8586 - val_loss: 0.5180 - val_accuracy: 0.7809\n",
      "8/8 [==============================] - 0s 803us/step - loss: 0.4287 - accuracy: 0.8354\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_932 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5793 - accuracy: 0.7131 - val_loss: 0.5682 - val_accuracy: 0.6854\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7532 - val_loss: 0.5243 - val_accuracy: 0.7360\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8397 - val_loss: 0.4869 - val_accuracy: 0.7921\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8376 - val_loss: 0.4786 - val_accuracy: 0.8034\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8376 - val_loss: 0.4786 - val_accuracy: 0.8258\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8439 - val_loss: 0.4675 - val_accuracy: 0.8315\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8397 - val_loss: 0.4662 - val_accuracy: 0.8258\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8439 - val_loss: 0.4600 - val_accuracy: 0.8315\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8460 - val_loss: 0.4626 - val_accuracy: 0.8427\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8502 - val_loss: 0.4633 - val_accuracy: 0.8371\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8544 - val_loss: 0.4663 - val_accuracy: 0.8146\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8565 - val_loss: 0.4653 - val_accuracy: 0.8315\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8608 - val_loss: 0.4691 - val_accuracy: 0.8371\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8629 - val_loss: 0.4726 - val_accuracy: 0.8146\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8650 - val_loss: 0.4809 - val_accuracy: 0.8315\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8650 - val_loss: 0.4733 - val_accuracy: 0.8315\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8650 - val_loss: 0.4791 - val_accuracy: 0.8258\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8671 - val_loss: 0.4811 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 775us/step - loss: 0.4185 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_935 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6363 - accuracy: 0.6371 - val_loss: 0.5790 - val_accuracy: 0.6517\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7321 - val_loss: 0.5250 - val_accuracy: 0.7809\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.8143 - val_loss: 0.4988 - val_accuracy: 0.7753\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.8270 - val_loss: 0.4818 - val_accuracy: 0.8090\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8186 - val_loss: 0.4768 - val_accuracy: 0.8202\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8333 - val_loss: 0.4683 - val_accuracy: 0.8202\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8376 - val_loss: 0.4670 - val_accuracy: 0.8202\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3872 - accuracy: 0.8418 - val_loss: 0.4708 - val_accuracy: 0.8258\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8439 - val_loss: 0.4677 - val_accuracy: 0.8202\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8481 - val_loss: 0.4728 - val_accuracy: 0.8202\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8523 - val_loss: 0.4674 - val_accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8481 - val_loss: 0.4725 - val_accuracy: 0.8258\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8544 - val_loss: 0.4731 - val_accuracy: 0.8146\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8565 - val_loss: 0.4738 - val_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8502 - val_loss: 0.4792 - val_accuracy: 0.8258\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8586 - val_loss: 0.4798 - val_accuracy: 0.8258\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8608 - val_loss: 0.4793 - val_accuracy: 0.8315\n",
      "8/8 [==============================] - 0s 877us/step - loss: 0.4078 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_938 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6053 - accuracy: 0.6899 - val_loss: 0.5793 - val_accuracy: 0.6685\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7700 - val_loss: 0.5360 - val_accuracy: 0.7416\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7996 - val_loss: 0.5164 - val_accuracy: 0.7640\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.8207 - val_loss: 0.5073 - val_accuracy: 0.7753\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8228 - val_loss: 0.5072 - val_accuracy: 0.7753\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8354 - val_loss: 0.5023 - val_accuracy: 0.7809\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8418 - val_loss: 0.5037 - val_accuracy: 0.7809\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8397 - val_loss: 0.4989 - val_accuracy: 0.7865\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8460 - val_loss: 0.5150 - val_accuracy: 0.7809\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8523 - val_loss: 0.5172 - val_accuracy: 0.7809\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8565 - val_loss: 0.5166 - val_accuracy: 0.7809\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8565 - val_loss: 0.5382 - val_accuracy: 0.7528\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8565 - val_loss: 0.5414 - val_accuracy: 0.7809\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8629 - val_loss: 0.5505 - val_accuracy: 0.7809\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8629 - val_loss: 0.5535 - val_accuracy: 0.7865\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3239 - accuracy: 0.8671 - val_loss: 0.5694 - val_accuracy: 0.7697\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8713 - val_loss: 0.5707 - val_accuracy: 0.7809\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8713 - val_loss: 0.5738 - val_accuracy: 0.7865\n",
      "8/8 [==============================] - 0s 824us/step - loss: 0.4499 - accuracy: 0.8439\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_941 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6505 - accuracy: 0.6329 - val_loss: 0.6630 - val_accuracy: 0.6124\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6329 - val_loss: 0.6453 - val_accuracy: 0.6124\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.6350 - val_loss: 0.6311 - val_accuracy: 0.6124\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.6414 - val_loss: 0.6189 - val_accuracy: 0.6124\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.6477 - val_loss: 0.6074 - val_accuracy: 0.6180\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.6519 - val_loss: 0.5986 - val_accuracy: 0.6236\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.6709 - val_loss: 0.5868 - val_accuracy: 0.6236\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.6835 - val_loss: 0.5770 - val_accuracy: 0.6236\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7025 - val_loss: 0.5648 - val_accuracy: 0.6404\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7342 - val_loss: 0.5548 - val_accuracy: 0.6685\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7532 - val_loss: 0.5456 - val_accuracy: 0.7135\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7869 - val_loss: 0.5338 - val_accuracy: 0.7584\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.8122 - val_loss: 0.5261 - val_accuracy: 0.7753\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.8228 - val_loss: 0.5176 - val_accuracy: 0.7809\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.8270 - val_loss: 0.5132 - val_accuracy: 0.7865\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.8376 - val_loss: 0.5061 - val_accuracy: 0.8034\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8397 - val_loss: 0.5011 - val_accuracy: 0.8202\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8354 - val_loss: 0.4987 - val_accuracy: 0.8146\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8376 - val_loss: 0.4944 - val_accuracy: 0.8146\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8376 - val_loss: 0.4917 - val_accuracy: 0.8146\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8439 - val_loss: 0.4902 - val_accuracy: 0.8202\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8439 - val_loss: 0.4893 - val_accuracy: 0.8202\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8439 - val_loss: 0.4875 - val_accuracy: 0.8258\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8460 - val_loss: 0.4851 - val_accuracy: 0.8258\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8397 - val_loss: 0.4895 - val_accuracy: 0.8202\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8439 - val_loss: 0.4874 - val_accuracy: 0.8202\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.8439 - val_loss: 0.4852 - val_accuracy: 0.8202\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3876 - accuracy: 0.8460 - val_loss: 0.4858 - val_accuracy: 0.8202\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.8502 - val_loss: 0.4838 - val_accuracy: 0.8258\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8544 - val_loss: 0.4843 - val_accuracy: 0.8258\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8544 - val_loss: 0.4864 - val_accuracy: 0.8202\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8544 - val_loss: 0.4859 - val_accuracy: 0.8202\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8544 - val_loss: 0.4864 - val_accuracy: 0.8202\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8544 - val_loss: 0.4874 - val_accuracy: 0.8202\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8502 - val_loss: 0.4839 - val_accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8544 - val_loss: 0.4837 - val_accuracy: 0.8202\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8544 - val_loss: 0.4842 - val_accuracy: 0.8202\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8523 - val_loss: 0.4860 - val_accuracy: 0.8146\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8544 - val_loss: 0.4843 - val_accuracy: 0.8146\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8565 - val_loss: 0.4865 - val_accuracy: 0.8202\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8608 - val_loss: 0.4877 - val_accuracy: 0.8146\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8608 - val_loss: 0.4890 - val_accuracy: 0.8146\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8565 - val_loss: 0.4881 - val_accuracy: 0.8146\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3567 - accuracy: 0.8629 - val_loss: 0.4911 - val_accuracy: 0.8090\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8608 - val_loss: 0.4927 - val_accuracy: 0.8146\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8671 - val_loss: 0.4904 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 887us/step - loss: 0.4489 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_945 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6846 - accuracy: 0.6097 - val_loss: 0.6843 - val_accuracy: 0.6348\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.6350 - val_loss: 0.6776 - val_accuracy: 0.6517\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.6899 - val_loss: 0.6714 - val_accuracy: 0.6404\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.6941 - val_loss: 0.6649 - val_accuracy: 0.6517\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.6962 - val_loss: 0.6577 - val_accuracy: 0.6404\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.7068 - val_loss: 0.6493 - val_accuracy: 0.6292\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.7152 - val_loss: 0.6418 - val_accuracy: 0.6292\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7152 - val_loss: 0.6332 - val_accuracy: 0.6404\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7321 - val_loss: 0.6252 - val_accuracy: 0.6573\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7426 - val_loss: 0.6127 - val_accuracy: 0.6629\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7511 - val_loss: 0.6019 - val_accuracy: 0.6798\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7658 - val_loss: 0.5850 - val_accuracy: 0.6966\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7764 - val_loss: 0.5714 - val_accuracy: 0.6966\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7975 - val_loss: 0.5584 - val_accuracy: 0.7303\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7890 - val_loss: 0.5456 - val_accuracy: 0.7247\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8038 - val_loss: 0.5331 - val_accuracy: 0.7528\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.8165 - val_loss: 0.5246 - val_accuracy: 0.7753\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8143 - val_loss: 0.5177 - val_accuracy: 0.7753\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8143 - val_loss: 0.5140 - val_accuracy: 0.7809\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8165 - val_loss: 0.5089 - val_accuracy: 0.7753\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8186 - val_loss: 0.5061 - val_accuracy: 0.7809\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8186 - val_loss: 0.5059 - val_accuracy: 0.7809\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8291 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8291 - val_loss: 0.4972 - val_accuracy: 0.7809\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8333 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8312 - val_loss: 0.4967 - val_accuracy: 0.7921\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8291 - val_loss: 0.4944 - val_accuracy: 0.7865\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8333 - val_loss: 0.4924 - val_accuracy: 0.7865\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8333 - val_loss: 0.4912 - val_accuracy: 0.7865\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8333 - val_loss: 0.4900 - val_accuracy: 0.7978\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8354 - val_loss: 0.4879 - val_accuracy: 0.7921\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3868 - accuracy: 0.8333 - val_loss: 0.4884 - val_accuracy: 0.8034\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3851 - accuracy: 0.8354 - val_loss: 0.4862 - val_accuracy: 0.7978\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8418 - val_loss: 0.4858 - val_accuracy: 0.8034\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3827 - accuracy: 0.8312 - val_loss: 0.4854 - val_accuracy: 0.8034\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8312 - val_loss: 0.4835 - val_accuracy: 0.8034\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8376 - val_loss: 0.4831 - val_accuracy: 0.8034\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8397 - val_loss: 0.4820 - val_accuracy: 0.8090\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8333 - val_loss: 0.4809 - val_accuracy: 0.8034\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8376 - val_loss: 0.4815 - val_accuracy: 0.8090\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8439 - val_loss: 0.4794 - val_accuracy: 0.8034\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8418 - val_loss: 0.4797 - val_accuracy: 0.8090\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8376 - val_loss: 0.4792 - val_accuracy: 0.8090\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8397 - val_loss: 0.4765 - val_accuracy: 0.8034\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8418 - val_loss: 0.4783 - val_accuracy: 0.8090\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8376 - val_loss: 0.4776 - val_accuracy: 0.8090\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8397 - val_loss: 0.4749 - val_accuracy: 0.8090\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8376 - val_loss: 0.4775 - val_accuracy: 0.8146\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8418 - val_loss: 0.4748 - val_accuracy: 0.8090\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8439 - val_loss: 0.4751 - val_accuracy: 0.8090\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8397 - val_loss: 0.4750 - val_accuracy: 0.8146\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8418 - val_loss: 0.4738 - val_accuracy: 0.8146\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8439 - val_loss: 0.4753 - val_accuracy: 0.8146\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8439 - val_loss: 0.4757 - val_accuracy: 0.8146\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8502 - val_loss: 0.4746 - val_accuracy: 0.8090\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8439 - val_loss: 0.4760 - val_accuracy: 0.8146\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8439 - val_loss: 0.4752 - val_accuracy: 0.8146\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3609 - accuracy: 0.8502 - val_loss: 0.4746 - val_accuracy: 0.8146\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8502 - val_loss: 0.4746 - val_accuracy: 0.8146\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8523 - val_loss: 0.4777 - val_accuracy: 0.8146\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8481 - val_loss: 0.4785 - val_accuracy: 0.8146\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8481 - val_loss: 0.4771 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 770us/step - loss: 0.3846 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_949 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6654 - accuracy: 0.6245 - val_loss: 0.6501 - val_accuracy: 0.6292\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.6498 - val_loss: 0.6295 - val_accuracy: 0.6236\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.6498 - val_loss: 0.6130 - val_accuracy: 0.6180\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.6709 - val_loss: 0.5987 - val_accuracy: 0.6348\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.7025 - val_loss: 0.5856 - val_accuracy: 0.6517\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7468 - val_loss: 0.5728 - val_accuracy: 0.6966\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7700 - val_loss: 0.5605 - val_accuracy: 0.7079\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7806 - val_loss: 0.5490 - val_accuracy: 0.7247\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7975 - val_loss: 0.5391 - val_accuracy: 0.7416\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.8101 - val_loss: 0.5311 - val_accuracy: 0.7416\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.8165 - val_loss: 0.5243 - val_accuracy: 0.7360\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.8143 - val_loss: 0.5195 - val_accuracy: 0.7472\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.8165 - val_loss: 0.5147 - val_accuracy: 0.7584\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.8165 - val_loss: 0.5118 - val_accuracy: 0.7697\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.8312 - val_loss: 0.5095 - val_accuracy: 0.7753\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8354 - val_loss: 0.5077 - val_accuracy: 0.7753\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8291 - val_loss: 0.5069 - val_accuracy: 0.7753\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8354 - val_loss: 0.5050 - val_accuracy: 0.7809\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8333 - val_loss: 0.5043 - val_accuracy: 0.7809\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8312 - val_loss: 0.5051 - val_accuracy: 0.7809\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8376 - val_loss: 0.5056 - val_accuracy: 0.7809\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8354 - val_loss: 0.5068 - val_accuracy: 0.7809\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8333 - val_loss: 0.5078 - val_accuracy: 0.7809\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8333 - val_loss: 0.5075 - val_accuracy: 0.7753\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8354 - val_loss: 0.5106 - val_accuracy: 0.7753\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8333 - val_loss: 0.5107 - val_accuracy: 0.7697\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8333 - val_loss: 0.5119 - val_accuracy: 0.7697\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8376 - val_loss: 0.5148 - val_accuracy: 0.7753\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8418 - val_loss: 0.5150 - val_accuracy: 0.7697\n",
      "8/8 [==============================] - 0s 922us/step - loss: 0.4195 - accuracy: 0.8439\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_953 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6706 - accuracy: 0.6308 - val_loss: 0.6634 - val_accuracy: 0.6124\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6435 - val_loss: 0.6333 - val_accuracy: 0.6348\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.6814 - val_loss: 0.6070 - val_accuracy: 0.6348\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.6899 - val_loss: 0.5832 - val_accuracy: 0.6573\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7257 - val_loss: 0.5600 - val_accuracy: 0.6966\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7616 - val_loss: 0.5316 - val_accuracy: 0.7303\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.8017 - val_loss: 0.5041 - val_accuracy: 0.7584\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8228 - val_loss: 0.4910 - val_accuracy: 0.7865\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8249 - val_loss: 0.4805 - val_accuracy: 0.7978\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8333 - val_loss: 0.4814 - val_accuracy: 0.8034\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8354 - val_loss: 0.4728 - val_accuracy: 0.8146\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8418 - val_loss: 0.4707 - val_accuracy: 0.8146\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8397 - val_loss: 0.4687 - val_accuracy: 0.8146\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8354 - val_loss: 0.4705 - val_accuracy: 0.8146\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.8418 - val_loss: 0.4711 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8397 - val_loss: 0.4701 - val_accuracy: 0.8146\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8439 - val_loss: 0.4679 - val_accuracy: 0.8202\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8502 - val_loss: 0.4694 - val_accuracy: 0.8315\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8502 - val_loss: 0.4715 - val_accuracy: 0.8315\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8523 - val_loss: 0.4692 - val_accuracy: 0.8427\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8586 - val_loss: 0.4729 - val_accuracy: 0.8371\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8608 - val_loss: 0.4741 - val_accuracy: 0.8371\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8650 - val_loss: 0.4763 - val_accuracy: 0.8371\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8650 - val_loss: 0.4764 - val_accuracy: 0.8427\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3388 - accuracy: 0.8629 - val_loss: 0.4852 - val_accuracy: 0.8315\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8650 - val_loss: 0.4768 - val_accuracy: 0.8371\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8671 - val_loss: 0.4804 - val_accuracy: 0.8371\n",
      "8/8 [==============================] - 0s 805us/step - loss: 0.4297 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_957 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6398 - accuracy: 0.6456 - val_loss: 0.6071 - val_accuracy: 0.6404\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.7194 - val_loss: 0.5719 - val_accuracy: 0.7079\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7658 - val_loss: 0.5399 - val_accuracy: 0.7584\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7890 - val_loss: 0.5160 - val_accuracy: 0.7697\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.8059 - val_loss: 0.5006 - val_accuracy: 0.7416\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8122 - val_loss: 0.4884 - val_accuracy: 0.7809\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8249 - val_loss: 0.4811 - val_accuracy: 0.7809\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8270 - val_loss: 0.4748 - val_accuracy: 0.7978\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8312 - val_loss: 0.4727 - val_accuracy: 0.7978\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8291 - val_loss: 0.4722 - val_accuracy: 0.8146\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3874 - accuracy: 0.8333 - val_loss: 0.4703 - val_accuracy: 0.8146\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8376 - val_loss: 0.4688 - val_accuracy: 0.8202\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8460 - val_loss: 0.4657 - val_accuracy: 0.8258\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8439 - val_loss: 0.4661 - val_accuracy: 0.8258\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8439 - val_loss: 0.4678 - val_accuracy: 0.8258\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8418 - val_loss: 0.4689 - val_accuracy: 0.8258\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8439 - val_loss: 0.4660 - val_accuracy: 0.8258\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8481 - val_loss: 0.4723 - val_accuracy: 0.8315\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8460 - val_loss: 0.4688 - val_accuracy: 0.8315\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8481 - val_loss: 0.4738 - val_accuracy: 0.8202\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3609 - accuracy: 0.8502 - val_loss: 0.4805 - val_accuracy: 0.8371\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8439 - val_loss: 0.4719 - val_accuracy: 0.8315\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8481 - val_loss: 0.4799 - val_accuracy: 0.8315\n",
      "8/8 [==============================] - 0s 818us/step - loss: 0.4017 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_961 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6457 - accuracy: 0.6203 - val_loss: 0.6335 - val_accuracy: 0.6124\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.6350 - val_loss: 0.6034 - val_accuracy: 0.6236\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.6962 - val_loss: 0.5711 - val_accuracy: 0.6854\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7574 - val_loss: 0.5422 - val_accuracy: 0.7191\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.8017 - val_loss: 0.5183 - val_accuracy: 0.7865\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.8122 - val_loss: 0.4999 - val_accuracy: 0.7753\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.8207 - val_loss: 0.4957 - val_accuracy: 0.7809\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.8270 - val_loss: 0.4938 - val_accuracy: 0.7865\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8270 - val_loss: 0.4968 - val_accuracy: 0.7921\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8333 - val_loss: 0.4958 - val_accuracy: 0.7978\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8354 - val_loss: 0.4987 - val_accuracy: 0.7978\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8418 - val_loss: 0.4958 - val_accuracy: 0.7921\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8481 - val_loss: 0.5009 - val_accuracy: 0.7921\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8376 - val_loss: 0.5136 - val_accuracy: 0.7697\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8481 - val_loss: 0.5129 - val_accuracy: 0.7809\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8502 - val_loss: 0.5146 - val_accuracy: 0.7809\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8565 - val_loss: 0.5260 - val_accuracy: 0.7697\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8650 - val_loss: 0.5289 - val_accuracy: 0.7753\n",
      "8/8 [==============================] - 0s 812us/step - loss: 0.4396 - accuracy: 0.8397\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_965 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6715 - accuracy: 0.5865 - val_loss: 0.6433 - val_accuracy: 0.6517\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7025 - val_loss: 0.5915 - val_accuracy: 0.6685\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7511 - val_loss: 0.5271 - val_accuracy: 0.7416\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.8080 - val_loss: 0.5008 - val_accuracy: 0.7697\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8207 - val_loss: 0.4950 - val_accuracy: 0.7865\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8333 - val_loss: 0.4810 - val_accuracy: 0.8090\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8523 - val_loss: 0.4741 - val_accuracy: 0.8146\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8439 - val_loss: 0.4820 - val_accuracy: 0.8202\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8544 - val_loss: 0.4722 - val_accuracy: 0.8146\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8523 - val_loss: 0.4691 - val_accuracy: 0.8258\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8523 - val_loss: 0.4710 - val_accuracy: 0.8034\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8629 - val_loss: 0.4744 - val_accuracy: 0.8202\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8671 - val_loss: 0.4722 - val_accuracy: 0.8202\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8713 - val_loss: 0.4775 - val_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.8671 - val_loss: 0.4831 - val_accuracy: 0.8258\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8713 - val_loss: 0.4882 - val_accuracy: 0.8090\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8692 - val_loss: 0.4920 - val_accuracy: 0.7978\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8776 - val_loss: 0.4952 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8755 - val_loss: 0.5048 - val_accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8797 - val_loss: 0.4957 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 839us/step - loss: 0.4319 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_969 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6059 - accuracy: 0.6688 - val_loss: 0.5814 - val_accuracy: 0.6798\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7025 - val_loss: 0.5344 - val_accuracy: 0.7360\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7911 - val_loss: 0.5020 - val_accuracy: 0.7640\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8228 - val_loss: 0.4838 - val_accuracy: 0.8034\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8249 - val_loss: 0.4758 - val_accuracy: 0.8146\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8249 - val_loss: 0.4767 - val_accuracy: 0.8034\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8439 - val_loss: 0.4752 - val_accuracy: 0.8146\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8439 - val_loss: 0.4684 - val_accuracy: 0.8090\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8523 - val_loss: 0.4717 - val_accuracy: 0.8146\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8523 - val_loss: 0.4824 - val_accuracy: 0.8090\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8523 - val_loss: 0.4823 - val_accuracy: 0.8034\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8565 - val_loss: 0.4832 - val_accuracy: 0.8146\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8586 - val_loss: 0.4862 - val_accuracy: 0.8090\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8544 - val_loss: 0.4943 - val_accuracy: 0.8146\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8650 - val_loss: 0.4865 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8650 - val_loss: 0.4953 - val_accuracy: 0.8090\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.8629 - val_loss: 0.4966 - val_accuracy: 0.8146\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8586 - val_loss: 0.5183 - val_accuracy: 0.8034\n",
      "8/8 [==============================] - 0s 800us/step - loss: 0.4174 - accuracy: 0.7848\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_973 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6385 - accuracy: 0.6414 - val_loss: 0.5995 - val_accuracy: 0.6461\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.6878 - val_loss: 0.5573 - val_accuracy: 0.6910\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7679 - val_loss: 0.5214 - val_accuracy: 0.7584\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.8059 - val_loss: 0.5095 - val_accuracy: 0.7640\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.8228 - val_loss: 0.4929 - val_accuracy: 0.7809\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8291 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8312 - val_loss: 0.4893 - val_accuracy: 0.7809\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8312 - val_loss: 0.4979 - val_accuracy: 0.7809\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8376 - val_loss: 0.4975 - val_accuracy: 0.7809\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8460 - val_loss: 0.5019 - val_accuracy: 0.7809\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8481 - val_loss: 0.5159 - val_accuracy: 0.7753\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8460 - val_loss: 0.5104 - val_accuracy: 0.7809\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8312 - val_loss: 0.5131 - val_accuracy: 0.7753\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8586 - val_loss: 0.5235 - val_accuracy: 0.7753\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8523 - val_loss: 0.5317 - val_accuracy: 0.7697\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8544 - val_loss: 0.5305 - val_accuracy: 0.7697\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8586 - val_loss: 0.5502 - val_accuracy: 0.7697\n",
      "8/8 [==============================] - 0s 789us/step - loss: 0.4735 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_977 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6149 - accuracy: 0.6287 - val_loss: 0.5896 - val_accuracy: 0.6348\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7785 - val_loss: 0.5242 - val_accuracy: 0.7697\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8207 - val_loss: 0.4958 - val_accuracy: 0.7978\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8354 - val_loss: 0.4821 - val_accuracy: 0.8034\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8397 - val_loss: 0.4692 - val_accuracy: 0.8258\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8544 - val_loss: 0.4899 - val_accuracy: 0.8146\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8586 - val_loss: 0.4653 - val_accuracy: 0.8258\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8544 - val_loss: 0.4818 - val_accuracy: 0.8090\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8544 - val_loss: 0.4864 - val_accuracy: 0.8034\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8692 - val_loss: 0.4770 - val_accuracy: 0.8146\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3300 - accuracy: 0.8734 - val_loss: 0.5055 - val_accuracy: 0.8034\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8692 - val_loss: 0.5127 - val_accuracy: 0.7921\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8692 - val_loss: 0.5012 - val_accuracy: 0.8146\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8713 - val_loss: 0.5075 - val_accuracy: 0.7921\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8734 - val_loss: 0.5161 - val_accuracy: 0.7921\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8819 - val_loss: 0.5329 - val_accuracy: 0.7978\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3052 - accuracy: 0.8776 - val_loss: 0.5313 - val_accuracy: 0.7809\n",
      "8/8 [==============================] - 0s 821us/step - loss: 0.4390 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_981 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5837 - accuracy: 0.6814 - val_loss: 0.5373 - val_accuracy: 0.7247\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7975 - val_loss: 0.4928 - val_accuracy: 0.7978\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8249 - val_loss: 0.4777 - val_accuracy: 0.7978\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8249 - val_loss: 0.4718 - val_accuracy: 0.8202\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8291 - val_loss: 0.4678 - val_accuracy: 0.8202\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8354 - val_loss: 0.4901 - val_accuracy: 0.7865\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8439 - val_loss: 0.4681 - val_accuracy: 0.8146\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8502 - val_loss: 0.4680 - val_accuracy: 0.8202\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8523 - val_loss: 0.4774 - val_accuracy: 0.8258\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8608 - val_loss: 0.4765 - val_accuracy: 0.8202\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8608 - val_loss: 0.4810 - val_accuracy: 0.8258\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8544 - val_loss: 0.4882 - val_accuracy: 0.8034\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.8502 - val_loss: 0.4984 - val_accuracy: 0.8034\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8586 - val_loss: 0.5018 - val_accuracy: 0.8258\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8565 - val_loss: 0.5055 - val_accuracy: 0.7978\n",
      "8/8 [==============================] - 0s 926us/step - loss: 0.3861 - accuracy: 0.8397\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_985 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6281 - accuracy: 0.6435 - val_loss: 0.5788 - val_accuracy: 0.6629\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7616 - val_loss: 0.5119 - val_accuracy: 0.7697\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.8186 - val_loss: 0.4949 - val_accuracy: 0.8034\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8333 - val_loss: 0.4922 - val_accuracy: 0.7753\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8270 - val_loss: 0.5068 - val_accuracy: 0.7809\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8333 - val_loss: 0.5003 - val_accuracy: 0.7865\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8439 - val_loss: 0.5046 - val_accuracy: 0.7865\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8460 - val_loss: 0.5126 - val_accuracy: 0.7921\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8586 - val_loss: 0.5247 - val_accuracy: 0.7809\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.8629 - val_loss: 0.5545 - val_accuracy: 0.7865\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3281 - accuracy: 0.8713 - val_loss: 0.5629 - val_accuracy: 0.7640\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8713 - val_loss: 0.5696 - val_accuracy: 0.7697\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.8755 - val_loss: 0.6092 - val_accuracy: 0.7584\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3093 - accuracy: 0.8650 - val_loss: 0.6370 - val_accuracy: 0.7584\n",
      "8/8 [==============================] - 0s 910us/step - loss: 0.5211 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_989 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.6821 - accuracy: 0.6224 - val_loss: 0.7441 - val_accuracy: 0.5730\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.6519 - val_loss: 0.7300 - val_accuracy: 0.6067\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6667 - val_loss: 0.7174 - val_accuracy: 0.6180\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6688 - val_loss: 0.7062 - val_accuracy: 0.6236\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6624 - val_loss: 0.6957 - val_accuracy: 0.6236\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6688 - val_loss: 0.6866 - val_accuracy: 0.6236\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.6857 - val_loss: 0.6783 - val_accuracy: 0.6236\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.6878 - val_loss: 0.6705 - val_accuracy: 0.6348\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.6920 - val_loss: 0.6637 - val_accuracy: 0.6348\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.6983 - val_loss: 0.6574 - val_accuracy: 0.6404\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7004 - val_loss: 0.6518 - val_accuracy: 0.6461\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.6962 - val_loss: 0.6461 - val_accuracy: 0.6461\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.6962 - val_loss: 0.6410 - val_accuracy: 0.6461\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.6899 - val_loss: 0.6367 - val_accuracy: 0.6461\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.6962 - val_loss: 0.6323 - val_accuracy: 0.6517\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7046 - val_loss: 0.6284 - val_accuracy: 0.6573\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7068 - val_loss: 0.6248 - val_accuracy: 0.6573\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7110 - val_loss: 0.6211 - val_accuracy: 0.6629\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7131 - val_loss: 0.6178 - val_accuracy: 0.6629\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7152 - val_loss: 0.6147 - val_accuracy: 0.6629\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7173 - val_loss: 0.6116 - val_accuracy: 0.6685\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7215 - val_loss: 0.6087 - val_accuracy: 0.6685\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7215 - val_loss: 0.6059 - val_accuracy: 0.6685\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7236 - val_loss: 0.6033 - val_accuracy: 0.6742\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7321 - val_loss: 0.6007 - val_accuracy: 0.6685\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7321 - val_loss: 0.5984 - val_accuracy: 0.6742\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7342 - val_loss: 0.5959 - val_accuracy: 0.6798\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7342 - val_loss: 0.5934 - val_accuracy: 0.6854\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7384 - val_loss: 0.5911 - val_accuracy: 0.6854\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7384 - val_loss: 0.5890 - val_accuracy: 0.6854\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7405 - val_loss: 0.5868 - val_accuracy: 0.6854\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7405 - val_loss: 0.5847 - val_accuracy: 0.6854\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7426 - val_loss: 0.5827 - val_accuracy: 0.6910\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7447 - val_loss: 0.5806 - val_accuracy: 0.6854\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7489 - val_loss: 0.5785 - val_accuracy: 0.6854\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7532 - val_loss: 0.5765 - val_accuracy: 0.6910\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7532 - val_loss: 0.5745 - val_accuracy: 0.7022\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7595 - val_loss: 0.5727 - val_accuracy: 0.7079\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7574 - val_loss: 0.5711 - val_accuracy: 0.7135\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7616 - val_loss: 0.5693 - val_accuracy: 0.7135\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7616 - val_loss: 0.5673 - val_accuracy: 0.7191\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7616 - val_loss: 0.5658 - val_accuracy: 0.7247\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7658 - val_loss: 0.5641 - val_accuracy: 0.7247\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7658 - val_loss: 0.5626 - val_accuracy: 0.7247\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7637 - val_loss: 0.5607 - val_accuracy: 0.7360\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7806 - val_loss: 0.5592 - val_accuracy: 0.7303\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7890 - val_loss: 0.5574 - val_accuracy: 0.7303\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7890 - val_loss: 0.5560 - val_accuracy: 0.7303\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7890 - val_loss: 0.5547 - val_accuracy: 0.7360\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7869 - val_loss: 0.5531 - val_accuracy: 0.7360\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7869 - val_loss: 0.5517 - val_accuracy: 0.7360\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7848 - val_loss: 0.5503 - val_accuracy: 0.7360\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7848 - val_loss: 0.5490 - val_accuracy: 0.7416\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7869 - val_loss: 0.5475 - val_accuracy: 0.7416\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7869 - val_loss: 0.5465 - val_accuracy: 0.7360\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7890 - val_loss: 0.5452 - val_accuracy: 0.7472\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7911 - val_loss: 0.5439 - val_accuracy: 0.7472\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7954 - val_loss: 0.5427 - val_accuracy: 0.7472\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7954 - val_loss: 0.5413 - val_accuracy: 0.7472\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7996 - val_loss: 0.5403 - val_accuracy: 0.7472\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7996 - val_loss: 0.5392 - val_accuracy: 0.7472\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8017 - val_loss: 0.5378 - val_accuracy: 0.7472\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8038 - val_loss: 0.5369 - val_accuracy: 0.7472\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8080 - val_loss: 0.5359 - val_accuracy: 0.7528\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8101 - val_loss: 0.5344 - val_accuracy: 0.7472\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8080 - val_loss: 0.5332 - val_accuracy: 0.7472\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8080 - val_loss: 0.5322 - val_accuracy: 0.7472\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8101 - val_loss: 0.5312 - val_accuracy: 0.7528\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8080 - val_loss: 0.5305 - val_accuracy: 0.7528\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8080 - val_loss: 0.5296 - val_accuracy: 0.7528\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8080 - val_loss: 0.5286 - val_accuracy: 0.7528\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8122 - val_loss: 0.5278 - val_accuracy: 0.7584\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8122 - val_loss: 0.5269 - val_accuracy: 0.7584\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8143 - val_loss: 0.5260 - val_accuracy: 0.7584\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8143 - val_loss: 0.5251 - val_accuracy: 0.7584\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.8143 - val_loss: 0.5243 - val_accuracy: 0.7584\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.8143 - val_loss: 0.5236 - val_accuracy: 0.7528\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.8143 - val_loss: 0.5227 - val_accuracy: 0.7640\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.8143 - val_loss: 0.5218 - val_accuracy: 0.7640\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8143 - val_loss: 0.5209 - val_accuracy: 0.7640\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.8143 - val_loss: 0.5202 - val_accuracy: 0.7640\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8143 - val_loss: 0.5193 - val_accuracy: 0.7640\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8165 - val_loss: 0.5185 - val_accuracy: 0.7640\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8143 - val_loss: 0.5180 - val_accuracy: 0.7640\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8186 - val_loss: 0.5174 - val_accuracy: 0.7584\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8165 - val_loss: 0.5166 - val_accuracy: 0.7640\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8165 - val_loss: 0.5160 - val_accuracy: 0.7640\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8165 - val_loss: 0.5152 - val_accuracy: 0.7697\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8165 - val_loss: 0.5145 - val_accuracy: 0.7697\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8186 - val_loss: 0.5137 - val_accuracy: 0.7640\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8186 - val_loss: 0.5133 - val_accuracy: 0.7753\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8186 - val_loss: 0.5127 - val_accuracy: 0.7753\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8186 - val_loss: 0.5119 - val_accuracy: 0.7809\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8186 - val_loss: 0.5112 - val_accuracy: 0.7753\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8186 - val_loss: 0.5106 - val_accuracy: 0.7753\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8186 - val_loss: 0.5104 - val_accuracy: 0.7697\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8186 - val_loss: 0.5097 - val_accuracy: 0.7753\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8186 - val_loss: 0.5092 - val_accuracy: 0.7753\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8186 - val_loss: 0.5084 - val_accuracy: 0.7753\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8186 - val_loss: 0.5079 - val_accuracy: 0.7753\n",
      "8/8 [==============================] - 0s 833us/step - loss: 0.4987 - accuracy: 0.7764\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_990 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.7997 - accuracy: 0.3692 - val_loss: 0.7705 - val_accuracy: 0.4101\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7780 - accuracy: 0.3797 - val_loss: 0.7515 - val_accuracy: 0.4607\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7577 - accuracy: 0.4810 - val_loss: 0.7343 - val_accuracy: 0.5562\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7396 - accuracy: 0.5253 - val_loss: 0.7180 - val_accuracy: 0.5506\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7228 - accuracy: 0.5338 - val_loss: 0.7031 - val_accuracy: 0.5393\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7071 - accuracy: 0.5338 - val_loss: 0.6902 - val_accuracy: 0.5393\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5380 - val_loss: 0.6783 - val_accuracy: 0.5393\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6799 - accuracy: 0.6350 - val_loss: 0.6672 - val_accuracy: 0.6685\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.6709 - val_loss: 0.6574 - val_accuracy: 0.6798\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6857 - val_loss: 0.6478 - val_accuracy: 0.6854\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6857 - val_loss: 0.6394 - val_accuracy: 0.6854\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6899 - val_loss: 0.6317 - val_accuracy: 0.7135\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.7089 - val_loss: 0.6249 - val_accuracy: 0.7303\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.7152 - val_loss: 0.6184 - val_accuracy: 0.7303\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.7131 - val_loss: 0.6125 - val_accuracy: 0.7360\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.7215 - val_loss: 0.6070 - val_accuracy: 0.7360\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.7321 - val_loss: 0.6017 - val_accuracy: 0.7360\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.7426 - val_loss: 0.5970 - val_accuracy: 0.7416\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.7426 - val_loss: 0.5927 - val_accuracy: 0.7416\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7426 - val_loss: 0.5884 - val_accuracy: 0.7416\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7447 - val_loss: 0.5845 - val_accuracy: 0.7416\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7489 - val_loss: 0.5810 - val_accuracy: 0.7416\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7511 - val_loss: 0.5773 - val_accuracy: 0.7416\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7532 - val_loss: 0.5742 - val_accuracy: 0.7416\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7553 - val_loss: 0.5712 - val_accuracy: 0.7416\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7553 - val_loss: 0.5682 - val_accuracy: 0.7360\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7553 - val_loss: 0.5654 - val_accuracy: 0.7360\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7595 - val_loss: 0.5628 - val_accuracy: 0.7416\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7637 - val_loss: 0.5603 - val_accuracy: 0.7472\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7616 - val_loss: 0.5579 - val_accuracy: 0.7528\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7679 - val_loss: 0.5556 - val_accuracy: 0.7528\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7743 - val_loss: 0.5535 - val_accuracy: 0.7416\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7785 - val_loss: 0.5512 - val_accuracy: 0.7416\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7806 - val_loss: 0.5491 - val_accuracy: 0.7472\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7827 - val_loss: 0.5472 - val_accuracy: 0.7472\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7848 - val_loss: 0.5452 - val_accuracy: 0.7528\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7869 - val_loss: 0.5432 - val_accuracy: 0.7528\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7911 - val_loss: 0.5415 - val_accuracy: 0.7528\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7911 - val_loss: 0.5399 - val_accuracy: 0.7528\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7932 - val_loss: 0.5383 - val_accuracy: 0.7472\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7932 - val_loss: 0.5366 - val_accuracy: 0.7472\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7932 - val_loss: 0.5351 - val_accuracy: 0.7472\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7932 - val_loss: 0.5336 - val_accuracy: 0.7416\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7932 - val_loss: 0.5321 - val_accuracy: 0.7472\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7975 - val_loss: 0.5307 - val_accuracy: 0.7472\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7996 - val_loss: 0.5295 - val_accuracy: 0.7528\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.8017 - val_loss: 0.5282 - val_accuracy: 0.7528\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8038 - val_loss: 0.5269 - val_accuracy: 0.7584\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.8038 - val_loss: 0.5257 - val_accuracy: 0.7584\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.8038 - val_loss: 0.5245 - val_accuracy: 0.7584\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.8038 - val_loss: 0.5234 - val_accuracy: 0.7584\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8038 - val_loss: 0.5222 - val_accuracy: 0.7584\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8038 - val_loss: 0.5212 - val_accuracy: 0.7584\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8038 - val_loss: 0.5201 - val_accuracy: 0.7584\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8059 - val_loss: 0.5191 - val_accuracy: 0.7584\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8059 - val_loss: 0.5181 - val_accuracy: 0.7584\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.8059 - val_loss: 0.5171 - val_accuracy: 0.7584\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.8059 - val_loss: 0.5162 - val_accuracy: 0.7584\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.8059 - val_loss: 0.5153 - val_accuracy: 0.7584\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8059 - val_loss: 0.5144 - val_accuracy: 0.7584\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8059 - val_loss: 0.5135 - val_accuracy: 0.7584\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8059 - val_loss: 0.5126 - val_accuracy: 0.7584\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.8059 - val_loss: 0.5119 - val_accuracy: 0.7584\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8059 - val_loss: 0.5112 - val_accuracy: 0.7584\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8101 - val_loss: 0.5104 - val_accuracy: 0.7584\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8101 - val_loss: 0.5097 - val_accuracy: 0.7584\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8101 - val_loss: 0.5089 - val_accuracy: 0.7584\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.8122 - val_loss: 0.5082 - val_accuracy: 0.7584\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8122 - val_loss: 0.5074 - val_accuracy: 0.7584\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8122 - val_loss: 0.5068 - val_accuracy: 0.7528\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.8101 - val_loss: 0.5060 - val_accuracy: 0.7528\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.8122 - val_loss: 0.5055 - val_accuracy: 0.7528\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.8101 - val_loss: 0.5048 - val_accuracy: 0.7528\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.8101 - val_loss: 0.5043 - val_accuracy: 0.7528\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.8101 - val_loss: 0.5037 - val_accuracy: 0.7528\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.8101 - val_loss: 0.5030 - val_accuracy: 0.7584\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.8143 - val_loss: 0.5024 - val_accuracy: 0.7584\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8143 - val_loss: 0.5019 - val_accuracy: 0.7584\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8143 - val_loss: 0.5014 - val_accuracy: 0.7584\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8143 - val_loss: 0.5009 - val_accuracy: 0.7584\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8143 - val_loss: 0.5004 - val_accuracy: 0.7584\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.8186 - val_loss: 0.4998 - val_accuracy: 0.7584\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8165 - val_loss: 0.4993 - val_accuracy: 0.7584\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8165 - val_loss: 0.4988 - val_accuracy: 0.7584\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8165 - val_loss: 0.4984 - val_accuracy: 0.7584\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.8143 - val_loss: 0.4980 - val_accuracy: 0.7584\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8143 - val_loss: 0.4975 - val_accuracy: 0.7584\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8143 - val_loss: 0.4970 - val_accuracy: 0.7584\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8165 - val_loss: 0.4966 - val_accuracy: 0.7584\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8143 - val_loss: 0.4962 - val_accuracy: 0.7584\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8143 - val_loss: 0.4957 - val_accuracy: 0.7584\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8143 - val_loss: 0.4954 - val_accuracy: 0.7584\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8143 - val_loss: 0.4950 - val_accuracy: 0.7584\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8143 - val_loss: 0.4945 - val_accuracy: 0.7697\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8122 - val_loss: 0.4942 - val_accuracy: 0.7697\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.8122 - val_loss: 0.4938 - val_accuracy: 0.7697\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8122 - val_loss: 0.4934 - val_accuracy: 0.7697\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8122 - val_loss: 0.4930 - val_accuracy: 0.7697\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8143 - val_loss: 0.4927 - val_accuracy: 0.7697\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8122 - val_loss: 0.4923 - val_accuracy: 0.7697\n",
      "8/8 [==============================] - 0s 724us/step - loss: 0.4516 - accuracy: 0.7932\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_991 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.7320 - accuracy: 0.5527 - val_loss: 0.7793 - val_accuracy: 0.4944\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7142 - accuracy: 0.5907 - val_loss: 0.7626 - val_accuracy: 0.5281\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.6055 - val_loss: 0.7479 - val_accuracy: 0.5562\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.6181 - val_loss: 0.7342 - val_accuracy: 0.5955\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6224 - val_loss: 0.7223 - val_accuracy: 0.5955\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6371 - val_loss: 0.7114 - val_accuracy: 0.5843\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.6498 - val_loss: 0.7013 - val_accuracy: 0.5899\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6646 - val_loss: 0.6919 - val_accuracy: 0.6124\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.6793 - val_loss: 0.6835 - val_accuracy: 0.6180\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6793 - val_loss: 0.6762 - val_accuracy: 0.6236\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.6857 - val_loss: 0.6696 - val_accuracy: 0.6067\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.6983 - val_loss: 0.6635 - val_accuracy: 0.6124\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.7046 - val_loss: 0.6578 - val_accuracy: 0.6011\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.7046 - val_loss: 0.6528 - val_accuracy: 0.6067\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7110 - val_loss: 0.6480 - val_accuracy: 0.6180\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7131 - val_loss: 0.6436 - val_accuracy: 0.6292\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.7278 - val_loss: 0.6394 - val_accuracy: 0.6292\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7342 - val_loss: 0.6357 - val_accuracy: 0.6292\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7363 - val_loss: 0.6322 - val_accuracy: 0.6292\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7405 - val_loss: 0.6286 - val_accuracy: 0.6292\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7405 - val_loss: 0.6255 - val_accuracy: 0.6404\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7384 - val_loss: 0.6225 - val_accuracy: 0.6404\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7447 - val_loss: 0.6197 - val_accuracy: 0.6404\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7468 - val_loss: 0.6170 - val_accuracy: 0.6404\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7468 - val_loss: 0.6144 - val_accuracy: 0.6404\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7468 - val_loss: 0.6119 - val_accuracy: 0.6348\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7426 - val_loss: 0.6096 - val_accuracy: 0.6348\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7468 - val_loss: 0.6074 - val_accuracy: 0.6461\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7447 - val_loss: 0.6049 - val_accuracy: 0.6573\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7447 - val_loss: 0.6029 - val_accuracy: 0.6573\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7384 - val_loss: 0.6006 - val_accuracy: 0.6573\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7426 - val_loss: 0.5985 - val_accuracy: 0.6573\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7447 - val_loss: 0.5964 - val_accuracy: 0.6573\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7447 - val_loss: 0.5943 - val_accuracy: 0.6573\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7489 - val_loss: 0.5924 - val_accuracy: 0.6573\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7511 - val_loss: 0.5906 - val_accuracy: 0.6573\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7553 - val_loss: 0.5886 - val_accuracy: 0.6629\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7553 - val_loss: 0.5868 - val_accuracy: 0.6629\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7574 - val_loss: 0.5851 - val_accuracy: 0.6629\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7574 - val_loss: 0.5836 - val_accuracy: 0.6685\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7595 - val_loss: 0.5818 - val_accuracy: 0.6685\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7595 - val_loss: 0.5802 - val_accuracy: 0.6685\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7574 - val_loss: 0.5786 - val_accuracy: 0.6742\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7574 - val_loss: 0.5769 - val_accuracy: 0.6854\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7532 - val_loss: 0.5755 - val_accuracy: 0.6854\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7553 - val_loss: 0.5739 - val_accuracy: 0.6854\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7595 - val_loss: 0.5723 - val_accuracy: 0.6966\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7637 - val_loss: 0.5708 - val_accuracy: 0.6966\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7658 - val_loss: 0.5695 - val_accuracy: 0.6966\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7679 - val_loss: 0.5680 - val_accuracy: 0.7022\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7700 - val_loss: 0.5668 - val_accuracy: 0.7022\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.7700 - val_loss: 0.5654 - val_accuracy: 0.7079\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7700 - val_loss: 0.5641 - val_accuracy: 0.7079\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7764 - val_loss: 0.5629 - val_accuracy: 0.7135\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7764 - val_loss: 0.5616 - val_accuracy: 0.7191\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7743 - val_loss: 0.5602 - val_accuracy: 0.7079\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7764 - val_loss: 0.5591 - val_accuracy: 0.7191\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7764 - val_loss: 0.5580 - val_accuracy: 0.7191\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7785 - val_loss: 0.5568 - val_accuracy: 0.7191\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7827 - val_loss: 0.5557 - val_accuracy: 0.7191\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7827 - val_loss: 0.5545 - val_accuracy: 0.7191\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7869 - val_loss: 0.5532 - val_accuracy: 0.7191\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7890 - val_loss: 0.5524 - val_accuracy: 0.7191\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7932 - val_loss: 0.5513 - val_accuracy: 0.7191\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7911 - val_loss: 0.5503 - val_accuracy: 0.7247\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7911 - val_loss: 0.5494 - val_accuracy: 0.7303\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7932 - val_loss: 0.5484 - val_accuracy: 0.7303\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7954 - val_loss: 0.5472 - val_accuracy: 0.7360\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7954 - val_loss: 0.5465 - val_accuracy: 0.7360\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7954 - val_loss: 0.5455 - val_accuracy: 0.7360\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7932 - val_loss: 0.5446 - val_accuracy: 0.7416\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7996 - val_loss: 0.5436 - val_accuracy: 0.7472\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7996 - val_loss: 0.5427 - val_accuracy: 0.7472\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7996 - val_loss: 0.5422 - val_accuracy: 0.7584\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7996 - val_loss: 0.5411 - val_accuracy: 0.7584\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7975 - val_loss: 0.5403 - val_accuracy: 0.7584\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7954 - val_loss: 0.5394 - val_accuracy: 0.7584\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7954 - val_loss: 0.5385 - val_accuracy: 0.7584\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7954 - val_loss: 0.5379 - val_accuracy: 0.7584\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7954 - val_loss: 0.5372 - val_accuracy: 0.7584\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7932 - val_loss: 0.5365 - val_accuracy: 0.7584\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7932 - val_loss: 0.5357 - val_accuracy: 0.7640\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7932 - val_loss: 0.5347 - val_accuracy: 0.7640\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7932 - val_loss: 0.5341 - val_accuracy: 0.7640\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7932 - val_loss: 0.5335 - val_accuracy: 0.7640\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7932 - val_loss: 0.5326 - val_accuracy: 0.7640\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7932 - val_loss: 0.5319 - val_accuracy: 0.7640\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7932 - val_loss: 0.5312 - val_accuracy: 0.7640\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7911 - val_loss: 0.5305 - val_accuracy: 0.7640\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7911 - val_loss: 0.5300 - val_accuracy: 0.7640\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7911 - val_loss: 0.5291 - val_accuracy: 0.7697\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7911 - val_loss: 0.5283 - val_accuracy: 0.7697\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7911 - val_loss: 0.5277 - val_accuracy: 0.7697\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7911 - val_loss: 0.5273 - val_accuracy: 0.7697\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7911 - val_loss: 0.5267 - val_accuracy: 0.7697\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7911 - val_loss: 0.5261 - val_accuracy: 0.7753\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7911 - val_loss: 0.5256 - val_accuracy: 0.7753\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7932 - val_loss: 0.5250 - val_accuracy: 0.7753\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7932 - val_loss: 0.5246 - val_accuracy: 0.7753\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7932 - val_loss: 0.5242 - val_accuracy: 0.7753\n",
      "8/8 [==============================] - 0s 759us/step - loss: 0.4449 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_992 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5342 - accuracy: 0.7511 - val_loss: 0.5839 - val_accuracy: 0.6742\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7553 - val_loss: 0.5810 - val_accuracy: 0.6798\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7574 - val_loss: 0.5784 - val_accuracy: 0.6910\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7616 - val_loss: 0.5754 - val_accuracy: 0.6966\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7616 - val_loss: 0.5729 - val_accuracy: 0.6966\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7637 - val_loss: 0.5705 - val_accuracy: 0.7022\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7637 - val_loss: 0.5680 - val_accuracy: 0.7022\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7637 - val_loss: 0.5655 - val_accuracy: 0.7079\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7637 - val_loss: 0.5629 - val_accuracy: 0.7079\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7679 - val_loss: 0.5605 - val_accuracy: 0.7079\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7700 - val_loss: 0.5579 - val_accuracy: 0.7079\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7722 - val_loss: 0.5558 - val_accuracy: 0.7247\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7743 - val_loss: 0.5535 - val_accuracy: 0.7191\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7764 - val_loss: 0.5515 - val_accuracy: 0.7360\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7743 - val_loss: 0.5492 - val_accuracy: 0.7360\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7764 - val_loss: 0.5472 - val_accuracy: 0.7416\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7806 - val_loss: 0.5454 - val_accuracy: 0.7472\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7806 - val_loss: 0.5435 - val_accuracy: 0.7472\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7806 - val_loss: 0.5413 - val_accuracy: 0.7528\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7848 - val_loss: 0.5396 - val_accuracy: 0.7640\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7848 - val_loss: 0.5379 - val_accuracy: 0.7697\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7848 - val_loss: 0.5363 - val_accuracy: 0.7697\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7848 - val_loss: 0.5347 - val_accuracy: 0.7697\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7911 - val_loss: 0.5329 - val_accuracy: 0.7697\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7932 - val_loss: 0.5313 - val_accuracy: 0.7697\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7932 - val_loss: 0.5299 - val_accuracy: 0.7697\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7954 - val_loss: 0.5283 - val_accuracy: 0.7697\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7975 - val_loss: 0.5266 - val_accuracy: 0.7697\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7975 - val_loss: 0.5253 - val_accuracy: 0.7640\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7975 - val_loss: 0.5240 - val_accuracy: 0.7697\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7975 - val_loss: 0.5227 - val_accuracy: 0.7753\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8017 - val_loss: 0.5214 - val_accuracy: 0.7753\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.8080 - val_loss: 0.5200 - val_accuracy: 0.7753\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.8080 - val_loss: 0.5189 - val_accuracy: 0.7753\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8080 - val_loss: 0.5176 - val_accuracy: 0.7697\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.8080 - val_loss: 0.5166 - val_accuracy: 0.7697\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8080 - val_loss: 0.5155 - val_accuracy: 0.7697\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.8101 - val_loss: 0.5144 - val_accuracy: 0.7809\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8101 - val_loss: 0.5134 - val_accuracy: 0.7809\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8143 - val_loss: 0.5123 - val_accuracy: 0.7809\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8143 - val_loss: 0.5114 - val_accuracy: 0.7809\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8122 - val_loss: 0.5105 - val_accuracy: 0.7809\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8122 - val_loss: 0.5095 - val_accuracy: 0.7809\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8143 - val_loss: 0.5086 - val_accuracy: 0.7809\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8122 - val_loss: 0.5078 - val_accuracy: 0.7809\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8122 - val_loss: 0.5070 - val_accuracy: 0.7809\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8122 - val_loss: 0.5062 - val_accuracy: 0.7865\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8165 - val_loss: 0.5057 - val_accuracy: 0.7865\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8143 - val_loss: 0.5048 - val_accuracy: 0.7921\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8143 - val_loss: 0.5042 - val_accuracy: 0.7921\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8122 - val_loss: 0.5033 - val_accuracy: 0.7921\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8122 - val_loss: 0.5029 - val_accuracy: 0.7921\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.8080 - val_loss: 0.5019 - val_accuracy: 0.7921\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8080 - val_loss: 0.5013 - val_accuracy: 0.7921\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8101 - val_loss: 0.5007 - val_accuracy: 0.7921\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8101 - val_loss: 0.5001 - val_accuracy: 0.7921\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8122 - val_loss: 0.4996 - val_accuracy: 0.7978\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8228 - val_loss: 0.4989 - val_accuracy: 0.7978\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8249 - val_loss: 0.4985 - val_accuracy: 0.7978\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8270 - val_loss: 0.4981 - val_accuracy: 0.7978\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8270 - val_loss: 0.4975 - val_accuracy: 0.7978\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8270 - val_loss: 0.4970 - val_accuracy: 0.7978\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8270 - val_loss: 0.4966 - val_accuracy: 0.7978\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8291 - val_loss: 0.4961 - val_accuracy: 0.7978\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8270 - val_loss: 0.4955 - val_accuracy: 0.7978\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8270 - val_loss: 0.4951 - val_accuracy: 0.7978\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8228 - val_loss: 0.4943 - val_accuracy: 0.8034\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8249 - val_loss: 0.4941 - val_accuracy: 0.8090\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8270 - val_loss: 0.4939 - val_accuracy: 0.8090\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8270 - val_loss: 0.4937 - val_accuracy: 0.8146\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8270 - val_loss: 0.4931 - val_accuracy: 0.8146\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8270 - val_loss: 0.4927 - val_accuracy: 0.8146\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8270 - val_loss: 0.4922 - val_accuracy: 0.8146\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8270 - val_loss: 0.4922 - val_accuracy: 0.8146\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8249 - val_loss: 0.4915 - val_accuracy: 0.8146\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8228 - val_loss: 0.4913 - val_accuracy: 0.8146\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8228 - val_loss: 0.4908 - val_accuracy: 0.8146\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8228 - val_loss: 0.4906 - val_accuracy: 0.8146\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8228 - val_loss: 0.4903 - val_accuracy: 0.8146\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8270 - val_loss: 0.4899 - val_accuracy: 0.8146\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8270 - val_loss: 0.4895 - val_accuracy: 0.8146\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8291 - val_loss: 0.4891 - val_accuracy: 0.8146\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8333 - val_loss: 0.4888 - val_accuracy: 0.8146\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8333 - val_loss: 0.4890 - val_accuracy: 0.8146\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8333 - val_loss: 0.4884 - val_accuracy: 0.8146\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8333 - val_loss: 0.4882 - val_accuracy: 0.8146\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8354 - val_loss: 0.4876 - val_accuracy: 0.8146\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8354 - val_loss: 0.4878 - val_accuracy: 0.8146\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8312 - val_loss: 0.4872 - val_accuracy: 0.8146\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8312 - val_loss: 0.4871 - val_accuracy: 0.8146\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8291 - val_loss: 0.4869 - val_accuracy: 0.8146\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8291 - val_loss: 0.4866 - val_accuracy: 0.8146\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8291 - val_loss: 0.4868 - val_accuracy: 0.8146\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8291 - val_loss: 0.4863 - val_accuracy: 0.8146\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8291 - val_loss: 0.4860 - val_accuracy: 0.8146\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8291 - val_loss: 0.4859 - val_accuracy: 0.8146\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8270 - val_loss: 0.4855 - val_accuracy: 0.8146\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8270 - val_loss: 0.4853 - val_accuracy: 0.8146\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8270 - val_loss: 0.4855 - val_accuracy: 0.8146\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8270 - val_loss: 0.4852 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 774us/step - loss: 0.4728 - accuracy: 0.7848\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_993 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.7306 - accuracy: 0.5506 - val_loss: 0.6927 - val_accuracy: 0.6124\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7189 - accuracy: 0.5675 - val_loss: 0.6829 - val_accuracy: 0.6180\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7081 - accuracy: 0.5823 - val_loss: 0.6739 - val_accuracy: 0.6292\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.5844 - val_loss: 0.6655 - val_accuracy: 0.6236\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5865 - val_loss: 0.6575 - val_accuracy: 0.6404\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.6055 - val_loss: 0.6503 - val_accuracy: 0.6404\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.6076 - val_loss: 0.6431 - val_accuracy: 0.6404\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.6055 - val_loss: 0.6364 - val_accuracy: 0.6404\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6097 - val_loss: 0.6299 - val_accuracy: 0.6461\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.6097 - val_loss: 0.6242 - val_accuracy: 0.6517\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.6097 - val_loss: 0.6184 - val_accuracy: 0.6573\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.6118 - val_loss: 0.6128 - val_accuracy: 0.6573\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6160 - val_loss: 0.6077 - val_accuracy: 0.6573\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6160 - val_loss: 0.6027 - val_accuracy: 0.6573\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6203 - val_loss: 0.5979 - val_accuracy: 0.6573\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6245 - val_loss: 0.5935 - val_accuracy: 0.6629\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6245 - val_loss: 0.5891 - val_accuracy: 0.6685\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6329 - val_loss: 0.5849 - val_accuracy: 0.6685\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.6435 - val_loss: 0.5809 - val_accuracy: 0.6742\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.6519 - val_loss: 0.5769 - val_accuracy: 0.6742\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.6582 - val_loss: 0.5732 - val_accuracy: 0.6742\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.6646 - val_loss: 0.5696 - val_accuracy: 0.6742\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.6667 - val_loss: 0.5663 - val_accuracy: 0.6742\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.6751 - val_loss: 0.5627 - val_accuracy: 0.6742\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.6835 - val_loss: 0.5596 - val_accuracy: 0.6685\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.6878 - val_loss: 0.5566 - val_accuracy: 0.6854\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7025 - val_loss: 0.5537 - val_accuracy: 0.6854\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7110 - val_loss: 0.5510 - val_accuracy: 0.6854\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7215 - val_loss: 0.5482 - val_accuracy: 0.6966\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7342 - val_loss: 0.5456 - val_accuracy: 0.6910\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7363 - val_loss: 0.5431 - val_accuracy: 0.6966\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7447 - val_loss: 0.5407 - val_accuracy: 0.7247\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7532 - val_loss: 0.5383 - val_accuracy: 0.7191\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7574 - val_loss: 0.5360 - val_accuracy: 0.7191\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7658 - val_loss: 0.5336 - val_accuracy: 0.7247\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7637 - val_loss: 0.5318 - val_accuracy: 0.7303\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7679 - val_loss: 0.5298 - val_accuracy: 0.7360\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7637 - val_loss: 0.5279 - val_accuracy: 0.7360\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7658 - val_loss: 0.5259 - val_accuracy: 0.7416\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7679 - val_loss: 0.5241 - val_accuracy: 0.7416\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7700 - val_loss: 0.5224 - val_accuracy: 0.7528\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7722 - val_loss: 0.5207 - val_accuracy: 0.7584\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7700 - val_loss: 0.5189 - val_accuracy: 0.7697\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7743 - val_loss: 0.5173 - val_accuracy: 0.7753\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7722 - val_loss: 0.5158 - val_accuracy: 0.7809\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7764 - val_loss: 0.5144 - val_accuracy: 0.7809\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7785 - val_loss: 0.5128 - val_accuracy: 0.7809\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7806 - val_loss: 0.5116 - val_accuracy: 0.7809\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7848 - val_loss: 0.5102 - val_accuracy: 0.7865\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7890 - val_loss: 0.5090 - val_accuracy: 0.7809\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7869 - val_loss: 0.5076 - val_accuracy: 0.7809\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7932 - val_loss: 0.5066 - val_accuracy: 0.7809\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7975 - val_loss: 0.5054 - val_accuracy: 0.7865\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7954 - val_loss: 0.5042 - val_accuracy: 0.7865\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7954 - val_loss: 0.5032 - val_accuracy: 0.7865\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7975 - val_loss: 0.5021 - val_accuracy: 0.7921\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7996 - val_loss: 0.5011 - val_accuracy: 0.7978\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.8059 - val_loss: 0.5001 - val_accuracy: 0.8090\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8186 - val_loss: 0.4991 - val_accuracy: 0.8146\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8207 - val_loss: 0.4982 - val_accuracy: 0.8146\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8207 - val_loss: 0.4973 - val_accuracy: 0.8146\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.8228 - val_loss: 0.4964 - val_accuracy: 0.8146\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8228 - val_loss: 0.4956 - val_accuracy: 0.8146\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8270 - val_loss: 0.4946 - val_accuracy: 0.8090\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.8249 - val_loss: 0.4939 - val_accuracy: 0.8090\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8228 - val_loss: 0.4931 - val_accuracy: 0.8090\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.8207 - val_loss: 0.4924 - val_accuracy: 0.8090\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.8207 - val_loss: 0.4916 - val_accuracy: 0.8090\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.8228 - val_loss: 0.4908 - val_accuracy: 0.8090\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.8228 - val_loss: 0.4902 - val_accuracy: 0.8202\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.8228 - val_loss: 0.4895 - val_accuracy: 0.8202\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.8249 - val_loss: 0.4889 - val_accuracy: 0.8202\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.8228 - val_loss: 0.4883 - val_accuracy: 0.8202\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.8228 - val_loss: 0.4878 - val_accuracy: 0.8202\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.8228 - val_loss: 0.4871 - val_accuracy: 0.8202\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8207 - val_loss: 0.4866 - val_accuracy: 0.8202\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8207 - val_loss: 0.4860 - val_accuracy: 0.8202\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.8207 - val_loss: 0.4855 - val_accuracy: 0.8202\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8270 - val_loss: 0.4850 - val_accuracy: 0.8202\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8249 - val_loss: 0.4845 - val_accuracy: 0.8202\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8249 - val_loss: 0.4840 - val_accuracy: 0.8202\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8249 - val_loss: 0.4835 - val_accuracy: 0.8202\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8249 - val_loss: 0.4831 - val_accuracy: 0.8202\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8270 - val_loss: 0.4826 - val_accuracy: 0.8202\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8270 - val_loss: 0.4821 - val_accuracy: 0.8202\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.8270 - val_loss: 0.4817 - val_accuracy: 0.8202\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.8270 - val_loss: 0.4813 - val_accuracy: 0.8146\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8270 - val_loss: 0.4810 - val_accuracy: 0.8146\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8270 - val_loss: 0.4805 - val_accuracy: 0.8146\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8270 - val_loss: 0.4802 - val_accuracy: 0.8146\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8270 - val_loss: 0.4798 - val_accuracy: 0.8146\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8270 - val_loss: 0.4795 - val_accuracy: 0.8146\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8249 - val_loss: 0.4792 - val_accuracy: 0.8146\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8249 - val_loss: 0.4788 - val_accuracy: 0.8146\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8249 - val_loss: 0.4785 - val_accuracy: 0.8146\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.8270 - val_loss: 0.4782 - val_accuracy: 0.8146\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8249 - val_loss: 0.4779 - val_accuracy: 0.8146\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8249 - val_loss: 0.4776 - val_accuracy: 0.8146\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8249 - val_loss: 0.4772 - val_accuracy: 0.8146\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8228 - val_loss: 0.4771 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 800us/step - loss: 0.4339 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_994 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.6827 - accuracy: 0.6055 - val_loss: 0.6787 - val_accuracy: 0.5955\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.6034 - val_loss: 0.6655 - val_accuracy: 0.6067\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6245 - val_loss: 0.6529 - val_accuracy: 0.6067\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6751 - val_loss: 0.6416 - val_accuracy: 0.6854\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.7194 - val_loss: 0.6317 - val_accuracy: 0.6854\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.7447 - val_loss: 0.6231 - val_accuracy: 0.6966\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.7511 - val_loss: 0.6152 - val_accuracy: 0.6910\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.7532 - val_loss: 0.6081 - val_accuracy: 0.6854\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.7595 - val_loss: 0.6020 - val_accuracy: 0.6854\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7658 - val_loss: 0.5966 - val_accuracy: 0.6854\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7616 - val_loss: 0.5915 - val_accuracy: 0.7022\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7637 - val_loss: 0.5873 - val_accuracy: 0.7135\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7637 - val_loss: 0.5831 - val_accuracy: 0.7191\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7553 - val_loss: 0.5795 - val_accuracy: 0.7247\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7553 - val_loss: 0.5762 - val_accuracy: 0.7247\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7574 - val_loss: 0.5732 - val_accuracy: 0.7247\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7574 - val_loss: 0.5705 - val_accuracy: 0.7303\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7574 - val_loss: 0.5680 - val_accuracy: 0.7360\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7553 - val_loss: 0.5655 - val_accuracy: 0.7360\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7595 - val_loss: 0.5633 - val_accuracy: 0.7360\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7616 - val_loss: 0.5610 - val_accuracy: 0.7360\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7658 - val_loss: 0.5590 - val_accuracy: 0.7360\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7679 - val_loss: 0.5570 - val_accuracy: 0.7360\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7679 - val_loss: 0.5551 - val_accuracy: 0.7360\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7658 - val_loss: 0.5533 - val_accuracy: 0.7360\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7679 - val_loss: 0.5515 - val_accuracy: 0.7416\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7700 - val_loss: 0.5498 - val_accuracy: 0.7416\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7700 - val_loss: 0.5482 - val_accuracy: 0.7360\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7722 - val_loss: 0.5465 - val_accuracy: 0.7360\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7722 - val_loss: 0.5449 - val_accuracy: 0.7360\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7764 - val_loss: 0.5436 - val_accuracy: 0.7360\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7785 - val_loss: 0.5420 - val_accuracy: 0.7360\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7785 - val_loss: 0.5408 - val_accuracy: 0.7360\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7806 - val_loss: 0.5395 - val_accuracy: 0.7360\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7806 - val_loss: 0.5382 - val_accuracy: 0.7360\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7806 - val_loss: 0.5368 - val_accuracy: 0.7360\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7806 - val_loss: 0.5356 - val_accuracy: 0.7360\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7806 - val_loss: 0.5344 - val_accuracy: 0.7360\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7848 - val_loss: 0.5332 - val_accuracy: 0.7360\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7869 - val_loss: 0.5320 - val_accuracy: 0.7360\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7911 - val_loss: 0.5309 - val_accuracy: 0.7416\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8080 - val_loss: 0.5299 - val_accuracy: 0.7416\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.8080 - val_loss: 0.5288 - val_accuracy: 0.7528\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8143 - val_loss: 0.5278 - val_accuracy: 0.7640\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8143 - val_loss: 0.5267 - val_accuracy: 0.7697\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.8143 - val_loss: 0.5257 - val_accuracy: 0.7697\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.8165 - val_loss: 0.5249 - val_accuracy: 0.7697\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.8143 - val_loss: 0.5242 - val_accuracy: 0.7753\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8186 - val_loss: 0.5230 - val_accuracy: 0.7753\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8186 - val_loss: 0.5223 - val_accuracy: 0.7753\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.8165 - val_loss: 0.5211 - val_accuracy: 0.7753\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8207 - val_loss: 0.5206 - val_accuracy: 0.7753\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.8186 - val_loss: 0.5197 - val_accuracy: 0.7865\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8186 - val_loss: 0.5189 - val_accuracy: 0.7921\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8228 - val_loss: 0.5181 - val_accuracy: 0.7978\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8228 - val_loss: 0.5175 - val_accuracy: 0.7978\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8186 - val_loss: 0.5167 - val_accuracy: 0.7978\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8186 - val_loss: 0.5161 - val_accuracy: 0.7978\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8165 - val_loss: 0.5154 - val_accuracy: 0.7978\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8186 - val_loss: 0.5146 - val_accuracy: 0.7978\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8207 - val_loss: 0.5139 - val_accuracy: 0.7978\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8207 - val_loss: 0.5134 - val_accuracy: 0.7978\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.8207 - val_loss: 0.5127 - val_accuracy: 0.7978\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8165 - val_loss: 0.5120 - val_accuracy: 0.7978\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8165 - val_loss: 0.5114 - val_accuracy: 0.7978\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.8186 - val_loss: 0.5109 - val_accuracy: 0.7978\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8165 - val_loss: 0.5104 - val_accuracy: 0.7978\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.8122 - val_loss: 0.5098 - val_accuracy: 0.7978\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.8101 - val_loss: 0.5092 - val_accuracy: 0.7978\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.8101 - val_loss: 0.5088 - val_accuracy: 0.7921\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.8080 - val_loss: 0.5083 - val_accuracy: 0.7921\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.8080 - val_loss: 0.5079 - val_accuracy: 0.7921\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.8080 - val_loss: 0.5073 - val_accuracy: 0.7921\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.8080 - val_loss: 0.5070 - val_accuracy: 0.7921\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.8101 - val_loss: 0.5064 - val_accuracy: 0.7978\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.8101 - val_loss: 0.5060 - val_accuracy: 0.7978\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.8101 - val_loss: 0.5055 - val_accuracy: 0.8034\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.8101 - val_loss: 0.5049 - val_accuracy: 0.8034\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.8101 - val_loss: 0.5046 - val_accuracy: 0.8034\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8101 - val_loss: 0.5042 - val_accuracy: 0.8034\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.8080 - val_loss: 0.5036 - val_accuracy: 0.8034\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8101 - val_loss: 0.5034 - val_accuracy: 0.8034\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8101 - val_loss: 0.5031 - val_accuracy: 0.8034\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8059 - val_loss: 0.5025 - val_accuracy: 0.8034\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.8059 - val_loss: 0.5023 - val_accuracy: 0.8034\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8059 - val_loss: 0.5020 - val_accuracy: 0.8034\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8059 - val_loss: 0.5016 - val_accuracy: 0.8034\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8059 - val_loss: 0.5012 - val_accuracy: 0.8034\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8059 - val_loss: 0.5009 - val_accuracy: 0.8034\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.8059 - val_loss: 0.5005 - val_accuracy: 0.8034\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8059 - val_loss: 0.5001 - val_accuracy: 0.8034\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8080 - val_loss: 0.5000 - val_accuracy: 0.8034\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8059 - val_loss: 0.4997 - val_accuracy: 0.8034\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8059 - val_loss: 0.4995 - val_accuracy: 0.8034\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8080 - val_loss: 0.4990 - val_accuracy: 0.8034\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8080 - val_loss: 0.4988 - val_accuracy: 0.8034\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8080 - val_loss: 0.4982 - val_accuracy: 0.8034\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8080 - val_loss: 0.4980 - val_accuracy: 0.8034\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.8080 - val_loss: 0.4978 - val_accuracy: 0.8034\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8080 - val_loss: 0.4977 - val_accuracy: 0.8034\n",
      "8/8 [==============================] - 0s 782us/step - loss: 0.4267 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_995 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.8699 - accuracy: 0.3460 - val_loss: 0.8385 - val_accuracy: 0.4157\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8473 - accuracy: 0.3671 - val_loss: 0.8204 - val_accuracy: 0.4270\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8262 - accuracy: 0.3882 - val_loss: 0.8030 - val_accuracy: 0.4494\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8069 - accuracy: 0.4093 - val_loss: 0.7867 - val_accuracy: 0.4663\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7886 - accuracy: 0.4346 - val_loss: 0.7719 - val_accuracy: 0.4719\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7718 - accuracy: 0.4451 - val_loss: 0.7583 - val_accuracy: 0.4831\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7559 - accuracy: 0.4831 - val_loss: 0.7459 - val_accuracy: 0.5112\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.4979 - val_loss: 0.7343 - val_accuracy: 0.5225\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7282 - accuracy: 0.5063 - val_loss: 0.7235 - val_accuracy: 0.5056\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7150 - accuracy: 0.5232 - val_loss: 0.7139 - val_accuracy: 0.5169\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.5485 - val_loss: 0.7045 - val_accuracy: 0.5449\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5633 - val_loss: 0.6961 - val_accuracy: 0.5674\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5696 - val_loss: 0.6882 - val_accuracy: 0.5730\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.5907 - val_loss: 0.6808 - val_accuracy: 0.5843\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.5970 - val_loss: 0.6740 - val_accuracy: 0.5843\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6034 - val_loss: 0.6672 - val_accuracy: 0.5787\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6181 - val_loss: 0.6616 - val_accuracy: 0.6011\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6392 - val_loss: 0.6559 - val_accuracy: 0.6124\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6456 - val_loss: 0.6506 - val_accuracy: 0.6180\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.6498 - val_loss: 0.6454 - val_accuracy: 0.6236\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6561 - val_loss: 0.6406 - val_accuracy: 0.6236\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.6624 - val_loss: 0.6360 - val_accuracy: 0.6292\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6709 - val_loss: 0.6315 - val_accuracy: 0.6236\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.6793 - val_loss: 0.6273 - val_accuracy: 0.6236\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.6814 - val_loss: 0.6233 - val_accuracy: 0.6348\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.6835 - val_loss: 0.6195 - val_accuracy: 0.6404\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.6878 - val_loss: 0.6158 - val_accuracy: 0.6461\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.6920 - val_loss: 0.6121 - val_accuracy: 0.6461\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.6920 - val_loss: 0.6087 - val_accuracy: 0.6517\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.6962 - val_loss: 0.6056 - val_accuracy: 0.6461\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.6962 - val_loss: 0.6024 - val_accuracy: 0.6461\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.6941 - val_loss: 0.5992 - val_accuracy: 0.6517\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.7025 - val_loss: 0.5961 - val_accuracy: 0.6629\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7110 - val_loss: 0.5933 - val_accuracy: 0.6629\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7173 - val_loss: 0.5905 - val_accuracy: 0.6685\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7173 - val_loss: 0.5876 - val_accuracy: 0.6685\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7194 - val_loss: 0.5850 - val_accuracy: 0.6742\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7215 - val_loss: 0.5824 - val_accuracy: 0.6742\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7300 - val_loss: 0.5799 - val_accuracy: 0.6685\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7321 - val_loss: 0.5777 - val_accuracy: 0.6685\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7342 - val_loss: 0.5752 - val_accuracy: 0.6685\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7363 - val_loss: 0.5726 - val_accuracy: 0.6685\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7363 - val_loss: 0.5705 - val_accuracy: 0.6742\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7384 - val_loss: 0.5684 - val_accuracy: 0.6742\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7468 - val_loss: 0.5662 - val_accuracy: 0.6742\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7553 - val_loss: 0.5642 - val_accuracy: 0.6742\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7574 - val_loss: 0.5621 - val_accuracy: 0.6742\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7574 - val_loss: 0.5601 - val_accuracy: 0.6742\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7595 - val_loss: 0.5582 - val_accuracy: 0.6742\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7637 - val_loss: 0.5564 - val_accuracy: 0.6798\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7616 - val_loss: 0.5546 - val_accuracy: 0.6798\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7595 - val_loss: 0.5528 - val_accuracy: 0.6910\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7637 - val_loss: 0.5510 - val_accuracy: 0.6966\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7722 - val_loss: 0.5493 - val_accuracy: 0.6910\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7700 - val_loss: 0.5478 - val_accuracy: 0.6910\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7722 - val_loss: 0.5462 - val_accuracy: 0.6910\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7722 - val_loss: 0.5446 - val_accuracy: 0.6966\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7722 - val_loss: 0.5432 - val_accuracy: 0.7022\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7743 - val_loss: 0.5416 - val_accuracy: 0.7022\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7785 - val_loss: 0.5402 - val_accuracy: 0.7079\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7785 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7848 - val_loss: 0.5374 - val_accuracy: 0.7079\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7827 - val_loss: 0.5361 - val_accuracy: 0.7191\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7827 - val_loss: 0.5350 - val_accuracy: 0.7191\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7827 - val_loss: 0.5337 - val_accuracy: 0.7191\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7806 - val_loss: 0.5322 - val_accuracy: 0.7247\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7848 - val_loss: 0.5311 - val_accuracy: 0.7247\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7827 - val_loss: 0.5300 - val_accuracy: 0.7303\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7869 - val_loss: 0.5287 - val_accuracy: 0.7303\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7890 - val_loss: 0.5277 - val_accuracy: 0.7303\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7911 - val_loss: 0.5267 - val_accuracy: 0.7303\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7911 - val_loss: 0.5255 - val_accuracy: 0.7360\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7954 - val_loss: 0.5246 - val_accuracy: 0.7360\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7954 - val_loss: 0.5236 - val_accuracy: 0.7360\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7996 - val_loss: 0.5226 - val_accuracy: 0.7360\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7996 - val_loss: 0.5215 - val_accuracy: 0.7360\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7996 - val_loss: 0.5208 - val_accuracy: 0.7472\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7996 - val_loss: 0.5199 - val_accuracy: 0.7472\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7996 - val_loss: 0.5190 - val_accuracy: 0.7472\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7996 - val_loss: 0.5180 - val_accuracy: 0.7472\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7996 - val_loss: 0.5172 - val_accuracy: 0.7528\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7996 - val_loss: 0.5164 - val_accuracy: 0.7528\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8017 - val_loss: 0.5152 - val_accuracy: 0.7584\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.8038 - val_loss: 0.5147 - val_accuracy: 0.7584\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8038 - val_loss: 0.5140 - val_accuracy: 0.7584\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8059 - val_loss: 0.5133 - val_accuracy: 0.7697\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8059 - val_loss: 0.5125 - val_accuracy: 0.7697\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8059 - val_loss: 0.5117 - val_accuracy: 0.7697\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8101 - val_loss: 0.5110 - val_accuracy: 0.7697\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8122 - val_loss: 0.5105 - val_accuracy: 0.7697\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8165 - val_loss: 0.5096 - val_accuracy: 0.7753\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8186 - val_loss: 0.5089 - val_accuracy: 0.7809\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8186 - val_loss: 0.5083 - val_accuracy: 0.7865\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8249 - val_loss: 0.5077 - val_accuracy: 0.7921\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8270 - val_loss: 0.5071 - val_accuracy: 0.7921\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8291 - val_loss: 0.5063 - val_accuracy: 0.7921\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8270 - val_loss: 0.5057 - val_accuracy: 0.8034\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8270 - val_loss: 0.5052 - val_accuracy: 0.8034\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8270 - val_loss: 0.5048 - val_accuracy: 0.8034\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8270 - val_loss: 0.5042 - val_accuracy: 0.8034\n",
      "8/8 [==============================] - 0s 837us/step - loss: 0.5157 - accuracy: 0.7679\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_996 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.0995 - accuracy: 0.3376 - val_loss: 1.0210 - val_accuracy: 0.3876\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0696 - accuracy: 0.3397 - val_loss: 0.9932 - val_accuracy: 0.3933\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0403 - accuracy: 0.3397 - val_loss: 0.9669 - val_accuracy: 0.3933\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0126 - accuracy: 0.3397 - val_loss: 0.9418 - val_accuracy: 0.3989\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9857 - accuracy: 0.3460 - val_loss: 0.9185 - val_accuracy: 0.4045\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9611 - accuracy: 0.3460 - val_loss: 0.8958 - val_accuracy: 0.3989\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9372 - accuracy: 0.3439 - val_loss: 0.8746 - val_accuracy: 0.4101\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9151 - accuracy: 0.3481 - val_loss: 0.8541 - val_accuracy: 0.4045\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8935 - accuracy: 0.3608 - val_loss: 0.8357 - val_accuracy: 0.4045\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8738 - accuracy: 0.3650 - val_loss: 0.8182 - val_accuracy: 0.4101\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8555 - accuracy: 0.3713 - val_loss: 0.8012 - val_accuracy: 0.4157\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8370 - accuracy: 0.3755 - val_loss: 0.7865 - val_accuracy: 0.4157\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8210 - accuracy: 0.3755 - val_loss: 0.7719 - val_accuracy: 0.4438\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8050 - accuracy: 0.4008 - val_loss: 0.7586 - val_accuracy: 0.4438\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7904 - accuracy: 0.4409 - val_loss: 0.7459 - val_accuracy: 0.5169\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7766 - accuracy: 0.4747 - val_loss: 0.7336 - val_accuracy: 0.5169\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7632 - accuracy: 0.4705 - val_loss: 0.7225 - val_accuracy: 0.5112\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7510 - accuracy: 0.4705 - val_loss: 0.7117 - val_accuracy: 0.5225\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7391 - accuracy: 0.4684 - val_loss: 0.7019 - val_accuracy: 0.5225\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7279 - accuracy: 0.4958 - val_loss: 0.6928 - val_accuracy: 0.6292\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7176 - accuracy: 0.5970 - val_loss: 0.6839 - val_accuracy: 0.6461\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7073 - accuracy: 0.6034 - val_loss: 0.6759 - val_accuracy: 0.6461\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.6076 - val_loss: 0.6677 - val_accuracy: 0.6517\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.6118 - val_loss: 0.6601 - val_accuracy: 0.6517\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.6139 - val_loss: 0.6529 - val_accuracy: 0.6517\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.6139 - val_loss: 0.6461 - val_accuracy: 0.6573\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.6181 - val_loss: 0.6399 - val_accuracy: 0.6573\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6566 - accuracy: 0.6203 - val_loss: 0.6337 - val_accuracy: 0.6573\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.6245 - val_loss: 0.6280 - val_accuracy: 0.6573\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6350 - val_loss: 0.6224 - val_accuracy: 0.6910\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.6519 - val_loss: 0.6169 - val_accuracy: 0.6854\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.6730 - val_loss: 0.6118 - val_accuracy: 0.7079\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.6793 - val_loss: 0.6070 - val_accuracy: 0.7022\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.6814 - val_loss: 0.6021 - val_accuracy: 0.7022\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.6835 - val_loss: 0.5978 - val_accuracy: 0.7135\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.6857 - val_loss: 0.5936 - val_accuracy: 0.7191\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.6857 - val_loss: 0.5893 - val_accuracy: 0.7191\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.6835 - val_loss: 0.5851 - val_accuracy: 0.7191\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.6857 - val_loss: 0.5815 - val_accuracy: 0.7191\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.6920 - val_loss: 0.5779 - val_accuracy: 0.7360\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7025 - val_loss: 0.5745 - val_accuracy: 0.7303\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7046 - val_loss: 0.5710 - val_accuracy: 0.7416\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7110 - val_loss: 0.5678 - val_accuracy: 0.7472\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7152 - val_loss: 0.5646 - val_accuracy: 0.7528\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7194 - val_loss: 0.5616 - val_accuracy: 0.7528\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7300 - val_loss: 0.5587 - val_accuracy: 0.7416\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7321 - val_loss: 0.5559 - val_accuracy: 0.7416\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7342 - val_loss: 0.5532 - val_accuracy: 0.7416\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7384 - val_loss: 0.5507 - val_accuracy: 0.7416\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7405 - val_loss: 0.5482 - val_accuracy: 0.7416\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7511 - val_loss: 0.5458 - val_accuracy: 0.7472\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7553 - val_loss: 0.5436 - val_accuracy: 0.7528\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7595 - val_loss: 0.5413 - val_accuracy: 0.7528\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7679 - val_loss: 0.5393 - val_accuracy: 0.7528\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7722 - val_loss: 0.5372 - val_accuracy: 0.7640\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7764 - val_loss: 0.5353 - val_accuracy: 0.7584\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7806 - val_loss: 0.5333 - val_accuracy: 0.7809\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7848 - val_loss: 0.5316 - val_accuracy: 0.7809\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7890 - val_loss: 0.5298 - val_accuracy: 0.7809\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7954 - val_loss: 0.5281 - val_accuracy: 0.7809\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7996 - val_loss: 0.5265 - val_accuracy: 0.7865\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.8017 - val_loss: 0.5249 - val_accuracy: 0.7865\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.8038 - val_loss: 0.5234 - val_accuracy: 0.7921\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8038 - val_loss: 0.5220 - val_accuracy: 0.7921\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8038 - val_loss: 0.5205 - val_accuracy: 0.7921\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.8059 - val_loss: 0.5192 - val_accuracy: 0.7921\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.8101 - val_loss: 0.5179 - val_accuracy: 0.7978\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8122 - val_loss: 0.5166 - val_accuracy: 0.7978\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.8122 - val_loss: 0.5154 - val_accuracy: 0.7978\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.8122 - val_loss: 0.5142 - val_accuracy: 0.8034\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.8122 - val_loss: 0.5130 - val_accuracy: 0.8034\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.8143 - val_loss: 0.5120 - val_accuracy: 0.8034\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.8143 - val_loss: 0.5109 - val_accuracy: 0.8034\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.8143 - val_loss: 0.5099 - val_accuracy: 0.8034\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.8165 - val_loss: 0.5089 - val_accuracy: 0.8090\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.8186 - val_loss: 0.5079 - val_accuracy: 0.8090\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8186 - val_loss: 0.5071 - val_accuracy: 0.8090\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.8186 - val_loss: 0.5062 - val_accuracy: 0.8090\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8186 - val_loss: 0.5053 - val_accuracy: 0.8034\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.8186 - val_loss: 0.5045 - val_accuracy: 0.8034\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.8186 - val_loss: 0.5037 - val_accuracy: 0.8034\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.8207 - val_loss: 0.5029 - val_accuracy: 0.8034\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8186 - val_loss: 0.5022 - val_accuracy: 0.8034\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8186 - val_loss: 0.5014 - val_accuracy: 0.8034\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8186 - val_loss: 0.5006 - val_accuracy: 0.8034\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.8186 - val_loss: 0.4999 - val_accuracy: 0.8034\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8186 - val_loss: 0.4992 - val_accuracy: 0.8034\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.8186 - val_loss: 0.4986 - val_accuracy: 0.8034\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8165 - val_loss: 0.4979 - val_accuracy: 0.8034\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.8165 - val_loss: 0.4974 - val_accuracy: 0.8034\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8186 - val_loss: 0.4967 - val_accuracy: 0.8034\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8186 - val_loss: 0.4961 - val_accuracy: 0.8034\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8186 - val_loss: 0.4956 - val_accuracy: 0.8034\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8186 - val_loss: 0.4950 - val_accuracy: 0.8034\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.8186 - val_loss: 0.4945 - val_accuracy: 0.8034\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8186 - val_loss: 0.4940 - val_accuracy: 0.8034\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.8186 - val_loss: 0.4934 - val_accuracy: 0.8034\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8186 - val_loss: 0.4929 - val_accuracy: 0.8034\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8186 - val_loss: 0.4925 - val_accuracy: 0.8034\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8186 - val_loss: 0.4920 - val_accuracy: 0.8034\n",
      "8/8 [==============================] - 0s 729us/step - loss: 0.4588 - accuracy: 0.8017\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_997 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.8488 - accuracy: 0.4051 - val_loss: 0.8237 - val_accuracy: 0.4157\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8226 - accuracy: 0.4156 - val_loss: 0.8014 - val_accuracy: 0.4326\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7990 - accuracy: 0.4494 - val_loss: 0.7799 - val_accuracy: 0.4775\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7761 - accuracy: 0.4599 - val_loss: 0.7604 - val_accuracy: 0.4944\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7553 - accuracy: 0.4895 - val_loss: 0.7422 - val_accuracy: 0.5112\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.4895 - val_loss: 0.7259 - val_accuracy: 0.5225\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7181 - accuracy: 0.4873 - val_loss: 0.7108 - val_accuracy: 0.5337\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.5000 - val_loss: 0.6964 - val_accuracy: 0.5337\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.5084 - val_loss: 0.6845 - val_accuracy: 0.5337\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.5105 - val_loss: 0.6732 - val_accuracy: 0.5337\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.5781 - val_loss: 0.6623 - val_accuracy: 0.6292\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.6498 - val_loss: 0.6533 - val_accuracy: 0.6854\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6899 - val_loss: 0.6449 - val_accuracy: 0.7079\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.7025 - val_loss: 0.6368 - val_accuracy: 0.7135\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.7004 - val_loss: 0.6298 - val_accuracy: 0.7079\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.7046 - val_loss: 0.6232 - val_accuracy: 0.7079\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.7300 - val_loss: 0.6174 - val_accuracy: 0.7135\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.7405 - val_loss: 0.6121 - val_accuracy: 0.7079\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.7405 - val_loss: 0.6073 - val_accuracy: 0.7247\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7426 - val_loss: 0.6028 - val_accuracy: 0.7191\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7426 - val_loss: 0.5988 - val_accuracy: 0.7079\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7384 - val_loss: 0.5946 - val_accuracy: 0.7079\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7405 - val_loss: 0.5914 - val_accuracy: 0.7079\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7426 - val_loss: 0.5882 - val_accuracy: 0.7079\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7426 - val_loss: 0.5850 - val_accuracy: 0.7022\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7511 - val_loss: 0.5821 - val_accuracy: 0.7022\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7574 - val_loss: 0.5796 - val_accuracy: 0.7022\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7511 - val_loss: 0.5771 - val_accuracy: 0.7022\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7511 - val_loss: 0.5748 - val_accuracy: 0.7022\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7532 - val_loss: 0.5725 - val_accuracy: 0.7022\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7553 - val_loss: 0.5705 - val_accuracy: 0.7022\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7553 - val_loss: 0.5686 - val_accuracy: 0.7022\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7553 - val_loss: 0.5668 - val_accuracy: 0.7022\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7553 - val_loss: 0.5652 - val_accuracy: 0.7022\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7574 - val_loss: 0.5634 - val_accuracy: 0.6966\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7595 - val_loss: 0.5616 - val_accuracy: 0.6966\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7595 - val_loss: 0.5602 - val_accuracy: 0.6966\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7595 - val_loss: 0.5587 - val_accuracy: 0.6966\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7595 - val_loss: 0.5572 - val_accuracy: 0.6966\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7595 - val_loss: 0.5559 - val_accuracy: 0.6966\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7574 - val_loss: 0.5547 - val_accuracy: 0.6966\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7616 - val_loss: 0.5533 - val_accuracy: 0.7022\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7658 - val_loss: 0.5521 - val_accuracy: 0.7022\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7637 - val_loss: 0.5507 - val_accuracy: 0.7022\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7658 - val_loss: 0.5494 - val_accuracy: 0.7022\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7679 - val_loss: 0.5485 - val_accuracy: 0.7303\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7679 - val_loss: 0.5475 - val_accuracy: 0.7303\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7679 - val_loss: 0.5463 - val_accuracy: 0.7360\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7679 - val_loss: 0.5453 - val_accuracy: 0.7360\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7679 - val_loss: 0.5443 - val_accuracy: 0.7360\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7679 - val_loss: 0.5434 - val_accuracy: 0.7472\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7700 - val_loss: 0.5425 - val_accuracy: 0.7472\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7700 - val_loss: 0.5416 - val_accuracy: 0.7528\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7679 - val_loss: 0.5405 - val_accuracy: 0.7528\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7700 - val_loss: 0.5396 - val_accuracy: 0.7584\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7722 - val_loss: 0.5387 - val_accuracy: 0.7584\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7722 - val_loss: 0.5379 - val_accuracy: 0.7528\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7722 - val_loss: 0.5370 - val_accuracy: 0.7528\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7743 - val_loss: 0.5364 - val_accuracy: 0.7528\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7764 - val_loss: 0.5354 - val_accuracy: 0.7528\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7764 - val_loss: 0.5347 - val_accuracy: 0.7584\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7764 - val_loss: 0.5338 - val_accuracy: 0.7584\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7785 - val_loss: 0.5330 - val_accuracy: 0.7640\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7806 - val_loss: 0.5324 - val_accuracy: 0.7584\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7827 - val_loss: 0.5316 - val_accuracy: 0.7584\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7827 - val_loss: 0.5310 - val_accuracy: 0.7584\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7827 - val_loss: 0.5302 - val_accuracy: 0.7584\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7827 - val_loss: 0.5297 - val_accuracy: 0.7584\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7827 - val_loss: 0.5291 - val_accuracy: 0.7584\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7827 - val_loss: 0.5282 - val_accuracy: 0.7584\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7827 - val_loss: 0.5277 - val_accuracy: 0.7640\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7827 - val_loss: 0.5269 - val_accuracy: 0.7697\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7827 - val_loss: 0.5263 - val_accuracy: 0.7697\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7848 - val_loss: 0.5257 - val_accuracy: 0.7697\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7848 - val_loss: 0.5251 - val_accuracy: 0.7697\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7848 - val_loss: 0.5246 - val_accuracy: 0.7697\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7890 - val_loss: 0.5240 - val_accuracy: 0.7697\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7911 - val_loss: 0.5234 - val_accuracy: 0.7640\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7890 - val_loss: 0.5229 - val_accuracy: 0.7640\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7890 - val_loss: 0.5225 - val_accuracy: 0.7640\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7911 - val_loss: 0.5219 - val_accuracy: 0.7640\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7911 - val_loss: 0.5215 - val_accuracy: 0.7640\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7911 - val_loss: 0.5209 - val_accuracy: 0.7697\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7911 - val_loss: 0.5205 - val_accuracy: 0.7697\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7911 - val_loss: 0.5199 - val_accuracy: 0.7697\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7911 - val_loss: 0.5195 - val_accuracy: 0.7697\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7932 - val_loss: 0.5191 - val_accuracy: 0.7697\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7932 - val_loss: 0.5185 - val_accuracy: 0.7697\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7954 - val_loss: 0.5180 - val_accuracy: 0.7753\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7954 - val_loss: 0.5177 - val_accuracy: 0.7753\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7954 - val_loss: 0.5172 - val_accuracy: 0.7753\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7954 - val_loss: 0.5169 - val_accuracy: 0.7809\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7954 - val_loss: 0.5165 - val_accuracy: 0.7809\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7954 - val_loss: 0.5159 - val_accuracy: 0.7809\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7954 - val_loss: 0.5156 - val_accuracy: 0.7809\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7954 - val_loss: 0.5152 - val_accuracy: 0.7865\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7975 - val_loss: 0.5147 - val_accuracy: 0.7865\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7975 - val_loss: 0.5144 - val_accuracy: 0.7865\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7975 - val_loss: 0.5140 - val_accuracy: 0.7921\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7975 - val_loss: 0.5137 - val_accuracy: 0.7921\n",
      "8/8 [==============================] - 0s 737us/step - loss: 0.4474 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_998 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.0302 - accuracy: 0.3249 - val_loss: 1.0152 - val_accuracy: 0.3427\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9988 - accuracy: 0.3122 - val_loss: 0.9869 - val_accuracy: 0.3315\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9685 - accuracy: 0.3143 - val_loss: 0.9598 - val_accuracy: 0.3258\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9397 - accuracy: 0.3143 - val_loss: 0.9342 - val_accuracy: 0.3258\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9125 - accuracy: 0.3165 - val_loss: 0.9093 - val_accuracy: 0.3258\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8862 - accuracy: 0.3291 - val_loss: 0.8863 - val_accuracy: 0.3427\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8618 - accuracy: 0.3397 - val_loss: 0.8641 - val_accuracy: 0.3427\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8385 - accuracy: 0.3376 - val_loss: 0.8431 - val_accuracy: 0.3596\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8159 - accuracy: 0.3439 - val_loss: 0.8241 - val_accuracy: 0.3652\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7953 - accuracy: 0.3734 - val_loss: 0.8056 - val_accuracy: 0.3820\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7753 - accuracy: 0.4051 - val_loss: 0.7887 - val_accuracy: 0.3820\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7572 - accuracy: 0.4304 - val_loss: 0.7727 - val_accuracy: 0.3989\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7399 - accuracy: 0.4662 - val_loss: 0.7576 - val_accuracy: 0.4607\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7237 - accuracy: 0.5084 - val_loss: 0.7435 - val_accuracy: 0.4944\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7087 - accuracy: 0.5274 - val_loss: 0.7304 - val_accuracy: 0.5337\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5612 - val_loss: 0.7185 - val_accuracy: 0.5787\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.6034 - val_loss: 0.7071 - val_accuracy: 0.5787\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.6329 - val_loss: 0.6971 - val_accuracy: 0.5955\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.6414 - val_loss: 0.6874 - val_accuracy: 0.6292\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.6582 - val_loss: 0.6781 - val_accuracy: 0.6292\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.6688 - val_loss: 0.6699 - val_accuracy: 0.6461\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6730 - val_loss: 0.6621 - val_accuracy: 0.6573\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6772 - val_loss: 0.6545 - val_accuracy: 0.6966\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6899 - val_loss: 0.6480 - val_accuracy: 0.6910\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.7046 - val_loss: 0.6416 - val_accuracy: 0.6910\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.7152 - val_loss: 0.6354 - val_accuracy: 0.7022\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7236 - val_loss: 0.6298 - val_accuracy: 0.7022\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7300 - val_loss: 0.6247 - val_accuracy: 0.7022\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.7384 - val_loss: 0.6200 - val_accuracy: 0.7079\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7426 - val_loss: 0.6150 - val_accuracy: 0.7079\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7426 - val_loss: 0.6107 - val_accuracy: 0.7079\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7447 - val_loss: 0.6065 - val_accuracy: 0.7079\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7468 - val_loss: 0.6024 - val_accuracy: 0.7079\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7489 - val_loss: 0.5987 - val_accuracy: 0.7022\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7489 - val_loss: 0.5951 - val_accuracy: 0.7022\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7532 - val_loss: 0.5917 - val_accuracy: 0.7022\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7532 - val_loss: 0.5889 - val_accuracy: 0.7022\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7532 - val_loss: 0.5855 - val_accuracy: 0.7022\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7553 - val_loss: 0.5824 - val_accuracy: 0.7079\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7574 - val_loss: 0.5795 - val_accuracy: 0.7079\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7595 - val_loss: 0.5766 - val_accuracy: 0.7079\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7595 - val_loss: 0.5740 - val_accuracy: 0.7079\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7595 - val_loss: 0.5715 - val_accuracy: 0.7079\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7616 - val_loss: 0.5691 - val_accuracy: 0.7079\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7616 - val_loss: 0.5666 - val_accuracy: 0.7079\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7658 - val_loss: 0.5643 - val_accuracy: 0.7022\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7658 - val_loss: 0.5622 - val_accuracy: 0.7022\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7658 - val_loss: 0.5600 - val_accuracy: 0.7079\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7658 - val_loss: 0.5581 - val_accuracy: 0.7079\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7658 - val_loss: 0.5560 - val_accuracy: 0.7079\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7658 - val_loss: 0.5539 - val_accuracy: 0.7135\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7679 - val_loss: 0.5520 - val_accuracy: 0.7135\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7679 - val_loss: 0.5501 - val_accuracy: 0.7135\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7700 - val_loss: 0.5484 - val_accuracy: 0.7135\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7722 - val_loss: 0.5467 - val_accuracy: 0.7191\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7743 - val_loss: 0.5451 - val_accuracy: 0.7247\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7743 - val_loss: 0.5434 - val_accuracy: 0.7191\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7743 - val_loss: 0.5418 - val_accuracy: 0.7191\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7743 - val_loss: 0.5402 - val_accuracy: 0.7191\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7764 - val_loss: 0.5384 - val_accuracy: 0.7191\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7764 - val_loss: 0.5369 - val_accuracy: 0.7191\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7764 - val_loss: 0.5355 - val_accuracy: 0.7191\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7764 - val_loss: 0.5341 - val_accuracy: 0.7191\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7764 - val_loss: 0.5325 - val_accuracy: 0.7247\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7785 - val_loss: 0.5311 - val_accuracy: 0.7247\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7764 - val_loss: 0.5299 - val_accuracy: 0.7247\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7764 - val_loss: 0.5285 - val_accuracy: 0.7303\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7764 - val_loss: 0.5273 - val_accuracy: 0.7303\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7785 - val_loss: 0.5262 - val_accuracy: 0.7303\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7827 - val_loss: 0.5248 - val_accuracy: 0.7303\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7869 - val_loss: 0.5236 - val_accuracy: 0.7303\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7869 - val_loss: 0.5224 - val_accuracy: 0.7360\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7869 - val_loss: 0.5214 - val_accuracy: 0.7360\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7890 - val_loss: 0.5203 - val_accuracy: 0.7472\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7954 - val_loss: 0.5191 - val_accuracy: 0.7528\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7975 - val_loss: 0.5182 - val_accuracy: 0.7584\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7996 - val_loss: 0.5171 - val_accuracy: 0.7584\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7975 - val_loss: 0.5161 - val_accuracy: 0.7584\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7975 - val_loss: 0.5153 - val_accuracy: 0.7584\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7996 - val_loss: 0.5142 - val_accuracy: 0.7584\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7996 - val_loss: 0.5132 - val_accuracy: 0.7584\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7975 - val_loss: 0.5123 - val_accuracy: 0.7584\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7996 - val_loss: 0.5114 - val_accuracy: 0.7584\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7996 - val_loss: 0.5103 - val_accuracy: 0.7640\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7975 - val_loss: 0.5095 - val_accuracy: 0.7640\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.8017 - val_loss: 0.5088 - val_accuracy: 0.7640\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8017 - val_loss: 0.5079 - val_accuracy: 0.7697\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8038 - val_loss: 0.5072 - val_accuracy: 0.7697\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.8017 - val_loss: 0.5064 - val_accuracy: 0.7697\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8038 - val_loss: 0.5057 - val_accuracy: 0.7697\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8038 - val_loss: 0.5051 - val_accuracy: 0.7697\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8017 - val_loss: 0.5042 - val_accuracy: 0.7753\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8017 - val_loss: 0.5034 - val_accuracy: 0.7809\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8017 - val_loss: 0.5028 - val_accuracy: 0.7809\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8017 - val_loss: 0.5021 - val_accuracy: 0.7809\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.8038 - val_loss: 0.5016 - val_accuracy: 0.7809\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8059 - val_loss: 0.5009 - val_accuracy: 0.7809\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8122 - val_loss: 0.5003 - val_accuracy: 0.7865\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.8207 - val_loss: 0.4995 - val_accuracy: 0.7921\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8207 - val_loss: 0.4990 - val_accuracy: 0.7921\n",
      "8/8 [==============================] - 0s 788us/step - loss: 0.4916 - accuracy: 0.7848\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_999 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.0843 - accuracy: 0.2363 - val_loss: 1.0148 - val_accuracy: 0.2697\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0546 - accuracy: 0.2342 - val_loss: 0.9880 - val_accuracy: 0.2753\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0263 - accuracy: 0.2363 - val_loss: 0.9622 - val_accuracy: 0.2640\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9997 - accuracy: 0.2342 - val_loss: 0.9377 - val_accuracy: 0.2697\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9740 - accuracy: 0.2257 - val_loss: 0.9151 - val_accuracy: 0.2472\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9497 - accuracy: 0.2173 - val_loss: 0.8937 - val_accuracy: 0.2472\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9272 - accuracy: 0.2152 - val_loss: 0.8731 - val_accuracy: 0.2360\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9057 - accuracy: 0.2110 - val_loss: 0.8537 - val_accuracy: 0.2416\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8855 - accuracy: 0.2131 - val_loss: 0.8358 - val_accuracy: 0.2472\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8668 - accuracy: 0.2110 - val_loss: 0.8190 - val_accuracy: 0.2472\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8487 - accuracy: 0.2173 - val_loss: 0.8037 - val_accuracy: 0.2584\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8322 - accuracy: 0.2595 - val_loss: 0.7892 - val_accuracy: 0.3202\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8166 - accuracy: 0.2848 - val_loss: 0.7755 - val_accuracy: 0.3202\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8018 - accuracy: 0.2911 - val_loss: 0.7632 - val_accuracy: 0.3315\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7885 - accuracy: 0.3165 - val_loss: 0.7513 - val_accuracy: 0.3539\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7753 - accuracy: 0.3207 - val_loss: 0.7404 - val_accuracy: 0.3539\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7633 - accuracy: 0.3354 - val_loss: 0.7298 - val_accuracy: 0.3820\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.3755 - val_loss: 0.7204 - val_accuracy: 0.4551\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7412 - accuracy: 0.4494 - val_loss: 0.7111 - val_accuracy: 0.5225\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7308 - accuracy: 0.4873 - val_loss: 0.7029 - val_accuracy: 0.5337\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7215 - accuracy: 0.5169 - val_loss: 0.6946 - val_accuracy: 0.5955\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7126 - accuracy: 0.5591 - val_loss: 0.6870 - val_accuracy: 0.6124\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7038 - accuracy: 0.5675 - val_loss: 0.6800 - val_accuracy: 0.6461\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6957 - accuracy: 0.5844 - val_loss: 0.6736 - val_accuracy: 0.6404\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5865 - val_loss: 0.6673 - val_accuracy: 0.6404\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.5970 - val_loss: 0.6611 - val_accuracy: 0.6461\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6739 - accuracy: 0.6013 - val_loss: 0.6557 - val_accuracy: 0.6461\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.6076 - val_loss: 0.6502 - val_accuracy: 0.6461\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.6076 - val_loss: 0.6451 - val_accuracy: 0.6517\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6139 - val_loss: 0.6404 - val_accuracy: 0.6517\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6181 - val_loss: 0.6353 - val_accuracy: 0.6573\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.6224 - val_loss: 0.6309 - val_accuracy: 0.6629\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.6329 - val_loss: 0.6266 - val_accuracy: 0.6742\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.6392 - val_loss: 0.6227 - val_accuracy: 0.6742\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6477 - val_loss: 0.6184 - val_accuracy: 0.6742\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.6561 - val_loss: 0.6148 - val_accuracy: 0.6798\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6603 - val_loss: 0.6111 - val_accuracy: 0.6798\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6603 - val_loss: 0.6074 - val_accuracy: 0.6798\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.6603 - val_loss: 0.6039 - val_accuracy: 0.6854\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.6667 - val_loss: 0.6006 - val_accuracy: 0.6910\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.6709 - val_loss: 0.5973 - val_accuracy: 0.6910\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.6751 - val_loss: 0.5941 - val_accuracy: 0.6910\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6793 - val_loss: 0.5912 - val_accuracy: 0.6854\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6899 - val_loss: 0.5883 - val_accuracy: 0.6854\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.6920 - val_loss: 0.5852 - val_accuracy: 0.6854\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7068 - val_loss: 0.5826 - val_accuracy: 0.6966\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7131 - val_loss: 0.5798 - val_accuracy: 0.6966\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7131 - val_loss: 0.5771 - val_accuracy: 0.7022\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7152 - val_loss: 0.5745 - val_accuracy: 0.7022\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7173 - val_loss: 0.5722 - val_accuracy: 0.7022\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7278 - val_loss: 0.5699 - val_accuracy: 0.7079\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7300 - val_loss: 0.5674 - val_accuracy: 0.7135\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7321 - val_loss: 0.5650 - val_accuracy: 0.7135\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7300 - val_loss: 0.5628 - val_accuracy: 0.7135\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7300 - val_loss: 0.5607 - val_accuracy: 0.7191\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7278 - val_loss: 0.5585 - val_accuracy: 0.7247\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7321 - val_loss: 0.5564 - val_accuracy: 0.7247\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7321 - val_loss: 0.5543 - val_accuracy: 0.7303\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7321 - val_loss: 0.5523 - val_accuracy: 0.7303\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7363 - val_loss: 0.5503 - val_accuracy: 0.7303\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7426 - val_loss: 0.5484 - val_accuracy: 0.7360\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7426 - val_loss: 0.5465 - val_accuracy: 0.7360\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7426 - val_loss: 0.5447 - val_accuracy: 0.7360\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7447 - val_loss: 0.5429 - val_accuracy: 0.7360\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7468 - val_loss: 0.5413 - val_accuracy: 0.7360\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7489 - val_loss: 0.5397 - val_accuracy: 0.7472\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7511 - val_loss: 0.5379 - val_accuracy: 0.7528\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7532 - val_loss: 0.5361 - val_accuracy: 0.7640\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7574 - val_loss: 0.5347 - val_accuracy: 0.7640\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7637 - val_loss: 0.5332 - val_accuracy: 0.7697\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7658 - val_loss: 0.5316 - val_accuracy: 0.7697\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7658 - val_loss: 0.5302 - val_accuracy: 0.7697\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7658 - val_loss: 0.5288 - val_accuracy: 0.7640\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7658 - val_loss: 0.5274 - val_accuracy: 0.7697\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7679 - val_loss: 0.5260 - val_accuracy: 0.7809\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7679 - val_loss: 0.5247 - val_accuracy: 0.7809\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7700 - val_loss: 0.5233 - val_accuracy: 0.7865\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7700 - val_loss: 0.5221 - val_accuracy: 0.7865\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7764 - val_loss: 0.5209 - val_accuracy: 0.7865\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7785 - val_loss: 0.5196 - val_accuracy: 0.7865\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7785 - val_loss: 0.5184 - val_accuracy: 0.7921\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7785 - val_loss: 0.5173 - val_accuracy: 0.7978\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7806 - val_loss: 0.5161 - val_accuracy: 0.8034\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7806 - val_loss: 0.5151 - val_accuracy: 0.8034\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7806 - val_loss: 0.5140 - val_accuracy: 0.8090\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7869 - val_loss: 0.5129 - val_accuracy: 0.8034\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7890 - val_loss: 0.5119 - val_accuracy: 0.8090\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7911 - val_loss: 0.5109 - val_accuracy: 0.8146\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7954 - val_loss: 0.5098 - val_accuracy: 0.8090\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7975 - val_loss: 0.5089 - val_accuracy: 0.8090\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7975 - val_loss: 0.5079 - val_accuracy: 0.8090\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7996 - val_loss: 0.5070 - val_accuracy: 0.8146\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7975 - val_loss: 0.5061 - val_accuracy: 0.8090\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7996 - val_loss: 0.5052 - val_accuracy: 0.8090\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7975 - val_loss: 0.5043 - val_accuracy: 0.8090\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7996 - val_loss: 0.5035 - val_accuracy: 0.8090\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.8017 - val_loss: 0.5027 - val_accuracy: 0.8090\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7975 - val_loss: 0.5020 - val_accuracy: 0.8090\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.8017 - val_loss: 0.5011 - val_accuracy: 0.8090\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.8059 - val_loss: 0.5002 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 772us/step - loss: 0.4609 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1000 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.6700 - accuracy: 0.6266 - val_loss: 0.6222 - val_accuracy: 0.7022\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6329 - val_loss: 0.6131 - val_accuracy: 0.7135\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.6540 - val_loss: 0.6050 - val_accuracy: 0.7079\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6519 - val_loss: 0.5979 - val_accuracy: 0.7079\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6540 - val_loss: 0.5920 - val_accuracy: 0.6966\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6624 - val_loss: 0.5868 - val_accuracy: 0.6910\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.6646 - val_loss: 0.5825 - val_accuracy: 0.6966\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.6709 - val_loss: 0.5787 - val_accuracy: 0.6966\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.6772 - val_loss: 0.5753 - val_accuracy: 0.6966\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6835 - val_loss: 0.5719 - val_accuracy: 0.6966\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.6857 - val_loss: 0.5692 - val_accuracy: 0.7022\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.6857 - val_loss: 0.5665 - val_accuracy: 0.6966\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.6835 - val_loss: 0.5640 - val_accuracy: 0.6966\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.6835 - val_loss: 0.5619 - val_accuracy: 0.7022\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.6835 - val_loss: 0.5601 - val_accuracy: 0.7079\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.6857 - val_loss: 0.5580 - val_accuracy: 0.7191\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.6962 - val_loss: 0.5564 - val_accuracy: 0.7247\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7004 - val_loss: 0.5547 - val_accuracy: 0.7191\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7004 - val_loss: 0.5531 - val_accuracy: 0.7191\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7025 - val_loss: 0.5514 - val_accuracy: 0.7135\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7025 - val_loss: 0.5499 - val_accuracy: 0.7079\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7089 - val_loss: 0.5485 - val_accuracy: 0.7135\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7046 - val_loss: 0.5471 - val_accuracy: 0.7135\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7046 - val_loss: 0.5459 - val_accuracy: 0.7191\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7046 - val_loss: 0.5446 - val_accuracy: 0.7135\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7089 - val_loss: 0.5434 - val_accuracy: 0.7191\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7068 - val_loss: 0.5423 - val_accuracy: 0.7247\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7068 - val_loss: 0.5409 - val_accuracy: 0.7247\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7110 - val_loss: 0.5399 - val_accuracy: 0.7247\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7152 - val_loss: 0.5390 - val_accuracy: 0.7247\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7215 - val_loss: 0.5377 - val_accuracy: 0.7247\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7236 - val_loss: 0.5367 - val_accuracy: 0.7247\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7257 - val_loss: 0.5358 - val_accuracy: 0.7247\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7300 - val_loss: 0.5347 - val_accuracy: 0.7303\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7342 - val_loss: 0.5336 - val_accuracy: 0.7247\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7384 - val_loss: 0.5328 - val_accuracy: 0.7191\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7405 - val_loss: 0.5320 - val_accuracy: 0.7303\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7426 - val_loss: 0.5311 - val_accuracy: 0.7360\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7468 - val_loss: 0.5301 - val_accuracy: 0.7416\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7511 - val_loss: 0.5293 - val_accuracy: 0.7416\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7574 - val_loss: 0.5285 - val_accuracy: 0.7472\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7595 - val_loss: 0.5277 - val_accuracy: 0.7472\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7553 - val_loss: 0.5268 - val_accuracy: 0.7472\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7511 - val_loss: 0.5260 - val_accuracy: 0.7584\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7595 - val_loss: 0.5253 - val_accuracy: 0.7640\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7616 - val_loss: 0.5247 - val_accuracy: 0.7640\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7658 - val_loss: 0.5240 - val_accuracy: 0.7640\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7679 - val_loss: 0.5233 - val_accuracy: 0.7640\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7700 - val_loss: 0.5226 - val_accuracy: 0.7697\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7722 - val_loss: 0.5219 - val_accuracy: 0.7697\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7785 - val_loss: 0.5212 - val_accuracy: 0.7697\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7806 - val_loss: 0.5207 - val_accuracy: 0.7697\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7806 - val_loss: 0.5199 - val_accuracy: 0.7753\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7806 - val_loss: 0.5194 - val_accuracy: 0.7753\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7785 - val_loss: 0.5189 - val_accuracy: 0.7753\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7806 - val_loss: 0.5183 - val_accuracy: 0.7753\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7785 - val_loss: 0.5176 - val_accuracy: 0.7753\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7785 - val_loss: 0.5168 - val_accuracy: 0.7697\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7785 - val_loss: 0.5167 - val_accuracy: 0.7697\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7785 - val_loss: 0.5161 - val_accuracy: 0.7753\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7753\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7743 - val_loss: 0.5150 - val_accuracy: 0.7753\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7743 - val_loss: 0.5144 - val_accuracy: 0.7753\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7743 - val_loss: 0.5138 - val_accuracy: 0.7697\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7764 - val_loss: 0.5133 - val_accuracy: 0.7809\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7743 - val_loss: 0.5128 - val_accuracy: 0.7865\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7865\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7764 - val_loss: 0.5118 - val_accuracy: 0.7921\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7921\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7764 - val_loss: 0.5110 - val_accuracy: 0.7921\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7764 - val_loss: 0.5104 - val_accuracy: 0.7921\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7743 - val_loss: 0.5101 - val_accuracy: 0.7865\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7743 - val_loss: 0.5098 - val_accuracy: 0.7865\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7785 - val_loss: 0.5094 - val_accuracy: 0.7865\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7785 - val_loss: 0.5088 - val_accuracy: 0.7865\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7785 - val_loss: 0.5085 - val_accuracy: 0.7865\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7785 - val_loss: 0.5082 - val_accuracy: 0.7865\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7785 - val_loss: 0.5078 - val_accuracy: 0.7865\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7785 - val_loss: 0.5073 - val_accuracy: 0.7865\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7806 - val_loss: 0.5071 - val_accuracy: 0.7865\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7827 - val_loss: 0.5066 - val_accuracy: 0.7865\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7806 - val_loss: 0.5064 - val_accuracy: 0.7865\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7827 - val_loss: 0.5060 - val_accuracy: 0.7865\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7827 - val_loss: 0.5054 - val_accuracy: 0.7865\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7827 - val_loss: 0.5051 - val_accuracy: 0.7921\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7954 - val_loss: 0.5047 - val_accuracy: 0.7921\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7954 - val_loss: 0.5045 - val_accuracy: 0.7921\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7954 - val_loss: 0.5042 - val_accuracy: 0.7921\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7954 - val_loss: 0.5039 - val_accuracy: 0.7921\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7954 - val_loss: 0.5036 - val_accuracy: 0.7921\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7954 - val_loss: 0.5034 - val_accuracy: 0.7921\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7932 - val_loss: 0.5030 - val_accuracy: 0.7921\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7932 - val_loss: 0.5026 - val_accuracy: 0.7921\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7932 - val_loss: 0.5024 - val_accuracy: 0.7921\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7932 - val_loss: 0.5022 - val_accuracy: 0.7921\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7932 - val_loss: 0.5018 - val_accuracy: 0.7921\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7954 - val_loss: 0.5016 - val_accuracy: 0.7921\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7954 - val_loss: 0.5011 - val_accuracy: 0.7921\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7954 - val_loss: 0.5009 - val_accuracy: 0.7921\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7975 - val_loss: 0.5005 - val_accuracy: 0.7921\n",
      "8/8 [==============================] - 0s 756us/step - loss: 0.4299 - accuracy: 0.8354\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1001 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.8266 - accuracy: 0.3165 - val_loss: 0.7935 - val_accuracy: 0.3596\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7928 - accuracy: 0.3776 - val_loss: 0.7681 - val_accuracy: 0.3652\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7644 - accuracy: 0.4072 - val_loss: 0.7460 - val_accuracy: 0.4270\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.4409 - val_loss: 0.7266 - val_accuracy: 0.4663\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7187 - accuracy: 0.4662 - val_loss: 0.7099 - val_accuracy: 0.5393\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.5844 - val_loss: 0.6952 - val_accuracy: 0.6180\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.6203 - val_loss: 0.6818 - val_accuracy: 0.6292\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.6371 - val_loss: 0.6694 - val_accuracy: 0.6348\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.6540 - val_loss: 0.6585 - val_accuracy: 0.6573\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.6814 - val_loss: 0.6477 - val_accuracy: 0.6517\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.6835 - val_loss: 0.6371 - val_accuracy: 0.6573\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.7046 - val_loss: 0.6267 - val_accuracy: 0.6629\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.7194 - val_loss: 0.6165 - val_accuracy: 0.6629\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7342 - val_loss: 0.6061 - val_accuracy: 0.6798\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7489 - val_loss: 0.5957 - val_accuracy: 0.7079\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7637 - val_loss: 0.5858 - val_accuracy: 0.7191\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7743 - val_loss: 0.5753 - val_accuracy: 0.7247\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7848 - val_loss: 0.5659 - val_accuracy: 0.7247\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7996 - val_loss: 0.5572 - val_accuracy: 0.7360\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7996 - val_loss: 0.5476 - val_accuracy: 0.7472\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8017 - val_loss: 0.5390 - val_accuracy: 0.7640\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.8038 - val_loss: 0.5321 - val_accuracy: 0.7697\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.8080 - val_loss: 0.5252 - val_accuracy: 0.7697\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.8080 - val_loss: 0.5186 - val_accuracy: 0.7809\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.8122 - val_loss: 0.5141 - val_accuracy: 0.7753\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.8186 - val_loss: 0.5091 - val_accuracy: 0.7753\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.8228 - val_loss: 0.5046 - val_accuracy: 0.7697\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.8270 - val_loss: 0.5014 - val_accuracy: 0.7809\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8333 - val_loss: 0.4976 - val_accuracy: 0.7865\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8354 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8312 - val_loss: 0.4936 - val_accuracy: 0.7865\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8333 - val_loss: 0.4919 - val_accuracy: 0.7865\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8312 - val_loss: 0.4904 - val_accuracy: 0.7921\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8333 - val_loss: 0.4900 - val_accuracy: 0.7921\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8312 - val_loss: 0.4890 - val_accuracy: 0.7921\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8354 - val_loss: 0.4890 - val_accuracy: 0.7978\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8397 - val_loss: 0.4877 - val_accuracy: 0.8034\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8397 - val_loss: 0.4871 - val_accuracy: 0.8034\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8376 - val_loss: 0.4871 - val_accuracy: 0.8034\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8397 - val_loss: 0.4870 - val_accuracy: 0.8034\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8397 - val_loss: 0.4870 - val_accuracy: 0.8034\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8397 - val_loss: 0.4867 - val_accuracy: 0.8034\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8397 - val_loss: 0.4868 - val_accuracy: 0.7921\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8397 - val_loss: 0.4865 - val_accuracy: 0.7921\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8397 - val_loss: 0.4864 - val_accuracy: 0.7921\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8418 - val_loss: 0.4866 - val_accuracy: 0.7921\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8397 - val_loss: 0.4867 - val_accuracy: 0.7921\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8397 - val_loss: 0.4856 - val_accuracy: 0.7978\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8439 - val_loss: 0.4863 - val_accuracy: 0.7978\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8376 - val_loss: 0.4858 - val_accuracy: 0.7978\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8418 - val_loss: 0.4864 - val_accuracy: 0.7978\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8439 - val_loss: 0.4863 - val_accuracy: 0.7978\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8418 - val_loss: 0.4865 - val_accuracy: 0.7978\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8418 - val_loss: 0.4860 - val_accuracy: 0.7978\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8439 - val_loss: 0.4860 - val_accuracy: 0.7978\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8439 - val_loss: 0.4855 - val_accuracy: 0.7978\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8439 - val_loss: 0.4855 - val_accuracy: 0.7978\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8439 - val_loss: 0.4857 - val_accuracy: 0.7978\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8439 - val_loss: 0.4867 - val_accuracy: 0.7978\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8439 - val_loss: 0.4863 - val_accuracy: 0.7978\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8460 - val_loss: 0.4864 - val_accuracy: 0.7978\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8439 - val_loss: 0.4865 - val_accuracy: 0.7978\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8439 - val_loss: 0.4860 - val_accuracy: 0.7978\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8439 - val_loss: 0.4867 - val_accuracy: 0.7978\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8439 - val_loss: 0.4859 - val_accuracy: 0.7978\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8439 - val_loss: 0.4863 - val_accuracy: 0.7978\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.8460 - val_loss: 0.4865 - val_accuracy: 0.7978\n",
      "8/8 [==============================] - 0s 934us/step - loss: 0.4517 - accuracy: 0.8017\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1003 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.8432 - accuracy: 0.3966 - val_loss: 0.7999 - val_accuracy: 0.3933\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7841 - accuracy: 0.4430 - val_loss: 0.7530 - val_accuracy: 0.4551\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.5105 - val_loss: 0.7169 - val_accuracy: 0.5112\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7042 - accuracy: 0.5591 - val_loss: 0.6897 - val_accuracy: 0.5787\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.6076 - val_loss: 0.6677 - val_accuracy: 0.6011\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6456 - val_loss: 0.6490 - val_accuracy: 0.6573\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6751 - val_loss: 0.6340 - val_accuracy: 0.6854\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6835 - val_loss: 0.6216 - val_accuracy: 0.7191\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.7089 - val_loss: 0.6116 - val_accuracy: 0.7135\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.7173 - val_loss: 0.6021 - val_accuracy: 0.7135\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7257 - val_loss: 0.5939 - val_accuracy: 0.7135\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7342 - val_loss: 0.5865 - val_accuracy: 0.7247\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7447 - val_loss: 0.5793 - val_accuracy: 0.7360\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7489 - val_loss: 0.5732 - val_accuracy: 0.7360\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7532 - val_loss: 0.5667 - val_accuracy: 0.7416\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7637 - val_loss: 0.5608 - val_accuracy: 0.7303\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7637 - val_loss: 0.5542 - val_accuracy: 0.7303\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7743 - val_loss: 0.5484 - val_accuracy: 0.7360\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7827 - val_loss: 0.5424 - val_accuracy: 0.7360\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7911 - val_loss: 0.5368 - val_accuracy: 0.7247\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7975 - val_loss: 0.5313 - val_accuracy: 0.7303\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8038 - val_loss: 0.5262 - val_accuracy: 0.7247\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8059 - val_loss: 0.5208 - val_accuracy: 0.7247\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7416\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.8038 - val_loss: 0.5109 - val_accuracy: 0.7360\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8059 - val_loss: 0.5062 - val_accuracy: 0.7528\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8059 - val_loss: 0.5022 - val_accuracy: 0.7528\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8059 - val_loss: 0.4992 - val_accuracy: 0.7528\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8080 - val_loss: 0.4965 - val_accuracy: 0.7528\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8122 - val_loss: 0.4937 - val_accuracy: 0.7528\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8165 - val_loss: 0.4914 - val_accuracy: 0.7528\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8122 - val_loss: 0.4894 - val_accuracy: 0.7584\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8165 - val_loss: 0.4878 - val_accuracy: 0.7753\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8186 - val_loss: 0.4855 - val_accuracy: 0.7753\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8207 - val_loss: 0.4841 - val_accuracy: 0.7753\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8228 - val_loss: 0.4826 - val_accuracy: 0.7753\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8186 - val_loss: 0.4814 - val_accuracy: 0.7753\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8228 - val_loss: 0.4806 - val_accuracy: 0.7753\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8270 - val_loss: 0.4792 - val_accuracy: 0.7753\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8291 - val_loss: 0.4783 - val_accuracy: 0.7809\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8270 - val_loss: 0.4774 - val_accuracy: 0.7809\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8291 - val_loss: 0.4762 - val_accuracy: 0.7921\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8312 - val_loss: 0.4758 - val_accuracy: 0.7921\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8354 - val_loss: 0.4749 - val_accuracy: 0.7921\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8354 - val_loss: 0.4739 - val_accuracy: 0.7921\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8354 - val_loss: 0.4732 - val_accuracy: 0.7921\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8376 - val_loss: 0.4724 - val_accuracy: 0.7921\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8354 - val_loss: 0.4713 - val_accuracy: 0.7978\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8354 - val_loss: 0.4705 - val_accuracy: 0.7978\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8354 - val_loss: 0.4700 - val_accuracy: 0.7978\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8333 - val_loss: 0.4696 - val_accuracy: 0.8034\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8354 - val_loss: 0.4694 - val_accuracy: 0.8090\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8354 - val_loss: 0.4692 - val_accuracy: 0.8090\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8354 - val_loss: 0.4683 - val_accuracy: 0.8146\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8376 - val_loss: 0.4679 - val_accuracy: 0.8146\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8376 - val_loss: 0.4681 - val_accuracy: 0.8146\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8376 - val_loss: 0.4676 - val_accuracy: 0.8146\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8376 - val_loss: 0.4672 - val_accuracy: 0.8090\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8397 - val_loss: 0.4669 - val_accuracy: 0.8090\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8418 - val_loss: 0.4669 - val_accuracy: 0.8090\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8418 - val_loss: 0.4667 - val_accuracy: 0.8090\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8418 - val_loss: 0.4664 - val_accuracy: 0.8090\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8460 - val_loss: 0.4664 - val_accuracy: 0.8090\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.8418 - val_loss: 0.4663 - val_accuracy: 0.8090\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8481 - val_loss: 0.4662 - val_accuracy: 0.8090\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3946 - accuracy: 0.8502 - val_loss: 0.4658 - val_accuracy: 0.8090\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8481 - val_loss: 0.4660 - val_accuracy: 0.8090\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8502 - val_loss: 0.4659 - val_accuracy: 0.8090\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8502 - val_loss: 0.4660 - val_accuracy: 0.8090\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8502 - val_loss: 0.4658 - val_accuracy: 0.8090\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8523 - val_loss: 0.4665 - val_accuracy: 0.8090\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8502 - val_loss: 0.4665 - val_accuracy: 0.8090\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3916 - accuracy: 0.8502 - val_loss: 0.4657 - val_accuracy: 0.8090\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8523 - val_loss: 0.4660 - val_accuracy: 0.8090\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8523 - val_loss: 0.4660 - val_accuracy: 0.8090\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8502 - val_loss: 0.4666 - val_accuracy: 0.8090\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8523 - val_loss: 0.4661 - val_accuracy: 0.8090\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8544 - val_loss: 0.4661 - val_accuracy: 0.8090\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8544 - val_loss: 0.4663 - val_accuracy: 0.8090\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8544 - val_loss: 0.4664 - val_accuracy: 0.8090\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8523 - val_loss: 0.4662 - val_accuracy: 0.8090\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8523 - val_loss: 0.4656 - val_accuracy: 0.8090\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8565 - val_loss: 0.4663 - val_accuracy: 0.8090\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8565 - val_loss: 0.4662 - val_accuracy: 0.8090\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8565 - val_loss: 0.4662 - val_accuracy: 0.8090\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8544 - val_loss: 0.4658 - val_accuracy: 0.8090\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8544 - val_loss: 0.4659 - val_accuracy: 0.8090\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8565 - val_loss: 0.4659 - val_accuracy: 0.8090\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8565 - val_loss: 0.4662 - val_accuracy: 0.8090\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.8565 - val_loss: 0.4665 - val_accuracy: 0.8090\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8565 - val_loss: 0.4671 - val_accuracy: 0.8146\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8565 - val_loss: 0.4665 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 777us/step - loss: 0.3965 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1005 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6752 - accuracy: 0.5928 - val_loss: 0.6653 - val_accuracy: 0.6685\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6561 - val_loss: 0.6419 - val_accuracy: 0.6685\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6878 - val_loss: 0.6255 - val_accuracy: 0.6910\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.7004 - val_loss: 0.6134 - val_accuracy: 0.7079\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.6899 - val_loss: 0.6044 - val_accuracy: 0.6966\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.7025 - val_loss: 0.5975 - val_accuracy: 0.6966\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7068 - val_loss: 0.5906 - val_accuracy: 0.7022\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7194 - val_loss: 0.5839 - val_accuracy: 0.6966\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7215 - val_loss: 0.5776 - val_accuracy: 0.7079\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7257 - val_loss: 0.5709 - val_accuracy: 0.7135\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7489 - val_loss: 0.5652 - val_accuracy: 0.7079\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7574 - val_loss: 0.5594 - val_accuracy: 0.7135\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7637 - val_loss: 0.5541 - val_accuracy: 0.7079\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7700 - val_loss: 0.5491 - val_accuracy: 0.7247\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7722 - val_loss: 0.5435 - val_accuracy: 0.7247\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7722 - val_loss: 0.5392 - val_accuracy: 0.7303\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7743 - val_loss: 0.5346 - val_accuracy: 0.7247\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7806 - val_loss: 0.5304 - val_accuracy: 0.7360\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7869 - val_loss: 0.5270 - val_accuracy: 0.7360\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8059 - val_loss: 0.5236 - val_accuracy: 0.7584\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.8165 - val_loss: 0.5210 - val_accuracy: 0.7697\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.8228 - val_loss: 0.5188 - val_accuracy: 0.7697\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.8291 - val_loss: 0.5169 - val_accuracy: 0.7809\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8186 - val_loss: 0.5149 - val_accuracy: 0.7921\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8186 - val_loss: 0.5134 - val_accuracy: 0.8034\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8207 - val_loss: 0.5117 - val_accuracy: 0.8034\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8186 - val_loss: 0.5102 - val_accuracy: 0.7978\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8186 - val_loss: 0.5093 - val_accuracy: 0.8034\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8186 - val_loss: 0.5088 - val_accuracy: 0.7978\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8186 - val_loss: 0.5072 - val_accuracy: 0.7978\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8186 - val_loss: 0.5068 - val_accuracy: 0.7978\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8207 - val_loss: 0.5070 - val_accuracy: 0.7978\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8207 - val_loss: 0.5062 - val_accuracy: 0.7978\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8249 - val_loss: 0.5060 - val_accuracy: 0.7978\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8249 - val_loss: 0.5058 - val_accuracy: 0.7921\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8249 - val_loss: 0.5059 - val_accuracy: 0.7921\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8249 - val_loss: 0.5062 - val_accuracy: 0.7921\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8249 - val_loss: 0.5052 - val_accuracy: 0.7921\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8270 - val_loss: 0.5053 - val_accuracy: 0.7921\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8270 - val_loss: 0.5046 - val_accuracy: 0.7921\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8270 - val_loss: 0.5049 - val_accuracy: 0.7921\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8291 - val_loss: 0.5041 - val_accuracy: 0.7921\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8291 - val_loss: 0.5035 - val_accuracy: 0.7921\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8291 - val_loss: 0.5036 - val_accuracy: 0.7921\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8291 - val_loss: 0.5035 - val_accuracy: 0.7921\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8291 - val_loss: 0.5044 - val_accuracy: 0.7865\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8291 - val_loss: 0.5045 - val_accuracy: 0.7809\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8291 - val_loss: 0.5042 - val_accuracy: 0.7809\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8291 - val_loss: 0.5036 - val_accuracy: 0.7809\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8291 - val_loss: 0.5041 - val_accuracy: 0.7809\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8312 - val_loss: 0.5041 - val_accuracy: 0.7809\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8312 - val_loss: 0.5030 - val_accuracy: 0.7809\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8312 - val_loss: 0.5034 - val_accuracy: 0.7809\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8312 - val_loss: 0.5043 - val_accuracy: 0.7809\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8333 - val_loss: 0.5041 - val_accuracy: 0.7809\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8312 - val_loss: 0.5034 - val_accuracy: 0.7809\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8312 - val_loss: 0.5034 - val_accuracy: 0.7809\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8333 - val_loss: 0.5047 - val_accuracy: 0.7809\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8333 - val_loss: 0.5037 - val_accuracy: 0.7809\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8333 - val_loss: 0.5041 - val_accuracy: 0.7809\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8333 - val_loss: 0.5034 - val_accuracy: 0.7809\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8333 - val_loss: 0.5035 - val_accuracy: 0.7809\n",
      "8/8 [==============================] - 0s 798us/step - loss: 0.4220 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1007 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6702 - accuracy: 0.6013 - val_loss: 0.6585 - val_accuracy: 0.6854\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.7046 - val_loss: 0.6256 - val_accuracy: 0.6742\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7046 - val_loss: 0.6049 - val_accuracy: 0.6742\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7110 - val_loss: 0.5928 - val_accuracy: 0.6742\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7236 - val_loss: 0.5793 - val_accuracy: 0.6854\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7489 - val_loss: 0.5654 - val_accuracy: 0.6966\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7679 - val_loss: 0.5547 - val_accuracy: 0.7079\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7806 - val_loss: 0.5448 - val_accuracy: 0.7247\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.8059 - val_loss: 0.5355 - val_accuracy: 0.7360\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.8186 - val_loss: 0.5288 - val_accuracy: 0.7416\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.8186 - val_loss: 0.5222 - val_accuracy: 0.7472\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8270 - val_loss: 0.5167 - val_accuracy: 0.7584\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8333 - val_loss: 0.5110 - val_accuracy: 0.7753\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8249 - val_loss: 0.5072 - val_accuracy: 0.7753\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8207 - val_loss: 0.5049 - val_accuracy: 0.7809\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8249 - val_loss: 0.5010 - val_accuracy: 0.7809\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8207 - val_loss: 0.4991 - val_accuracy: 0.7865\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8249 - val_loss: 0.4968 - val_accuracy: 0.7865\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8291 - val_loss: 0.4941 - val_accuracy: 0.7753\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3946 - accuracy: 0.8291 - val_loss: 0.4925 - val_accuracy: 0.7753\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7865\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8354 - val_loss: 0.4898 - val_accuracy: 0.7921\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8354 - val_loss: 0.4880 - val_accuracy: 0.7921\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8397 - val_loss: 0.4862 - val_accuracy: 0.7921\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8376 - val_loss: 0.4856 - val_accuracy: 0.7978\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8354 - val_loss: 0.4840 - val_accuracy: 0.8034\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8376 - val_loss: 0.4823 - val_accuracy: 0.8034\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8418 - val_loss: 0.4831 - val_accuracy: 0.8090\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8418 - val_loss: 0.4821 - val_accuracy: 0.8146\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8439 - val_loss: 0.4818 - val_accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8460 - val_loss: 0.4818 - val_accuracy: 0.8146\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8418 - val_loss: 0.4809 - val_accuracy: 0.8146\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8439 - val_loss: 0.4808 - val_accuracy: 0.8090\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8439 - val_loss: 0.4798 - val_accuracy: 0.8146\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8481 - val_loss: 0.4764 - val_accuracy: 0.8202\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8460 - val_loss: 0.4782 - val_accuracy: 0.8258\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8481 - val_loss: 0.4788 - val_accuracy: 0.8258\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8460 - val_loss: 0.4789 - val_accuracy: 0.8202\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8481 - val_loss: 0.4788 - val_accuracy: 0.8202\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8523 - val_loss: 0.4783 - val_accuracy: 0.8202\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8544 - val_loss: 0.4771 - val_accuracy: 0.8202\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8565 - val_loss: 0.4755 - val_accuracy: 0.8315\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8565 - val_loss: 0.4763 - val_accuracy: 0.8258\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8544 - val_loss: 0.4792 - val_accuracy: 0.8146\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8586 - val_loss: 0.4762 - val_accuracy: 0.8202\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8565 - val_loss: 0.4789 - val_accuracy: 0.8146\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8565 - val_loss: 0.4780 - val_accuracy: 0.8202\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8565 - val_loss: 0.4770 - val_accuracy: 0.8146\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8565 - val_loss: 0.4771 - val_accuracy: 0.8258\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8565 - val_loss: 0.4771 - val_accuracy: 0.8202\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8629 - val_loss: 0.4768 - val_accuracy: 0.8146\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8586 - val_loss: 0.4780 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 841us/step - loss: 0.4393 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1009 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6463 - accuracy: 0.6624 - val_loss: 0.6402 - val_accuracy: 0.6461\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.6835 - val_loss: 0.6057 - val_accuracy: 0.6629\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7004 - val_loss: 0.5821 - val_accuracy: 0.7022\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7068 - val_loss: 0.5659 - val_accuracy: 0.7022\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7089 - val_loss: 0.5525 - val_accuracy: 0.7022\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7278 - val_loss: 0.5425 - val_accuracy: 0.7135\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7637 - val_loss: 0.5337 - val_accuracy: 0.7191\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7848 - val_loss: 0.5248 - val_accuracy: 0.7416\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7360\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.8059 - val_loss: 0.5123 - val_accuracy: 0.7303\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.8101 - val_loss: 0.5067 - val_accuracy: 0.7360\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8143 - val_loss: 0.5021 - val_accuracy: 0.7584\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.8228 - val_loss: 0.4985 - val_accuracy: 0.7753\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8207 - val_loss: 0.4945 - val_accuracy: 0.7753\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.8207 - val_loss: 0.4918 - val_accuracy: 0.7753\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8207 - val_loss: 0.4884 - val_accuracy: 0.7809\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8228 - val_loss: 0.4850 - val_accuracy: 0.7865\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8228 - val_loss: 0.4837 - val_accuracy: 0.7921\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8249 - val_loss: 0.4814 - val_accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8249 - val_loss: 0.4795 - val_accuracy: 0.7978\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8270 - val_loss: 0.4780 - val_accuracy: 0.7978\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8270 - val_loss: 0.4773 - val_accuracy: 0.7978\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8312 - val_loss: 0.4761 - val_accuracy: 0.8034\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8333 - val_loss: 0.4749 - val_accuracy: 0.8034\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8376 - val_loss: 0.4738 - val_accuracy: 0.8034\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8376 - val_loss: 0.4726 - val_accuracy: 0.8034\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8376 - val_loss: 0.4720 - val_accuracy: 0.8034\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8397 - val_loss: 0.4721 - val_accuracy: 0.8034\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8397 - val_loss: 0.4709 - val_accuracy: 0.8034\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8397 - val_loss: 0.4703 - val_accuracy: 0.8034\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8397 - val_loss: 0.4683 - val_accuracy: 0.8090\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8397 - val_loss: 0.4687 - val_accuracy: 0.8090\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8397 - val_loss: 0.4682 - val_accuracy: 0.8146\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8397 - val_loss: 0.4683 - val_accuracy: 0.8090\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8397 - val_loss: 0.4682 - val_accuracy: 0.8146\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8397 - val_loss: 0.4672 - val_accuracy: 0.8146\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8397 - val_loss: 0.4666 - val_accuracy: 0.8146\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8376 - val_loss: 0.4671 - val_accuracy: 0.8146\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8376 - val_loss: 0.4670 - val_accuracy: 0.8146\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8397 - val_loss: 0.4676 - val_accuracy: 0.8146\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8397 - val_loss: 0.4661 - val_accuracy: 0.8146\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8376 - val_loss: 0.4662 - val_accuracy: 0.8146\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8397 - val_loss: 0.4657 - val_accuracy: 0.8146\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8397 - val_loss: 0.4645 - val_accuracy: 0.8146\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8397 - val_loss: 0.4647 - val_accuracy: 0.8146\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8397 - val_loss: 0.4650 - val_accuracy: 0.8146\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8397 - val_loss: 0.4650 - val_accuracy: 0.8146\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8397 - val_loss: 0.4647 - val_accuracy: 0.8146\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8439 - val_loss: 0.4647 - val_accuracy: 0.8146\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8439 - val_loss: 0.4637 - val_accuracy: 0.8146\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8397 - val_loss: 0.4636 - val_accuracy: 0.8146\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8397 - val_loss: 0.4643 - val_accuracy: 0.8146\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8439 - val_loss: 0.4649 - val_accuracy: 0.8202\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8439 - val_loss: 0.4640 - val_accuracy: 0.8202\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8439 - val_loss: 0.4652 - val_accuracy: 0.8258\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8439 - val_loss: 0.4644 - val_accuracy: 0.8258\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8460 - val_loss: 0.4649 - val_accuracy: 0.8258\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8439 - val_loss: 0.4658 - val_accuracy: 0.8202\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8460 - val_loss: 0.4652 - val_accuracy: 0.8258\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8481 - val_loss: 0.4662 - val_accuracy: 0.8258\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8481 - val_loss: 0.4654 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 800us/step - loss: 0.4058 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1011 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7176 - accuracy: 0.4430 - val_loss: 0.6644 - val_accuracy: 0.6966\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.6498 - val_loss: 0.6212 - val_accuracy: 0.6966\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.7046 - val_loss: 0.5936 - val_accuracy: 0.6629\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.7173 - val_loss: 0.5759 - val_accuracy: 0.6854\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7215 - val_loss: 0.5635 - val_accuracy: 0.7079\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7363 - val_loss: 0.5539 - val_accuracy: 0.7079\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7447 - val_loss: 0.5445 - val_accuracy: 0.7022\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7468 - val_loss: 0.5367 - val_accuracy: 0.7191\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7574 - val_loss: 0.5293 - val_accuracy: 0.7360\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7743 - val_loss: 0.5233 - val_accuracy: 0.7528\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7848 - val_loss: 0.5173 - val_accuracy: 0.7584\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7753\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.8101 - val_loss: 0.5080 - val_accuracy: 0.7921\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.8186 - val_loss: 0.5042 - val_accuracy: 0.7809\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.8249 - val_loss: 0.5007 - val_accuracy: 0.7865\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.8270 - val_loss: 0.4982 - val_accuracy: 0.7921\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.8228 - val_loss: 0.4954 - val_accuracy: 0.7921\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.8228 - val_loss: 0.4945 - val_accuracy: 0.7921\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8228 - val_loss: 0.4918 - val_accuracy: 0.8034\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4909 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8228 - val_loss: 0.4894 - val_accuracy: 0.8034\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.8207 - val_loss: 0.4879 - val_accuracy: 0.8034\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8228 - val_loss: 0.4879 - val_accuracy: 0.8034\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8207 - val_loss: 0.4870 - val_accuracy: 0.7978\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8228 - val_loss: 0.4866 - val_accuracy: 0.8034\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8228 - val_loss: 0.4858 - val_accuracy: 0.7978\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8228 - val_loss: 0.4849 - val_accuracy: 0.8034\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8186 - val_loss: 0.4847 - val_accuracy: 0.7978\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8228 - val_loss: 0.4853 - val_accuracy: 0.7978\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8228 - val_loss: 0.4841 - val_accuracy: 0.7978\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8228 - val_loss: 0.4827 - val_accuracy: 0.8034\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8207 - val_loss: 0.4839 - val_accuracy: 0.8034\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8207 - val_loss: 0.4836 - val_accuracy: 0.8034\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8291 - val_loss: 0.4844 - val_accuracy: 0.7978\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8270 - val_loss: 0.4829 - val_accuracy: 0.8034\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8270 - val_loss: 0.4832 - val_accuracy: 0.8034\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.8270 - val_loss: 0.4829 - val_accuracy: 0.8034\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8270 - val_loss: 0.4843 - val_accuracy: 0.8034\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8270 - val_loss: 0.4835 - val_accuracy: 0.7978\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8270 - val_loss: 0.4844 - val_accuracy: 0.7978\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8270 - val_loss: 0.4841 - val_accuracy: 0.7978\n",
      "8/8 [==============================] - 0s 769us/step - loss: 0.4062 - accuracy: 0.8354\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1013 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6630 - accuracy: 0.6160 - val_loss: 0.6510 - val_accuracy: 0.6629\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7025 - val_loss: 0.6082 - val_accuracy: 0.6517\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7173 - val_loss: 0.5788 - val_accuracy: 0.6573\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7363 - val_loss: 0.5576 - val_accuracy: 0.6685\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7574 - val_loss: 0.5407 - val_accuracy: 0.7022\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7722 - val_loss: 0.5281 - val_accuracy: 0.7303\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.8143 - val_loss: 0.5161 - val_accuracy: 0.7640\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8312 - val_loss: 0.5078 - val_accuracy: 0.7809\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.8333 - val_loss: 0.5011 - val_accuracy: 0.7809\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8312 - val_loss: 0.4940 - val_accuracy: 0.7921\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8333 - val_loss: 0.4890 - val_accuracy: 0.7978\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8354 - val_loss: 0.4850 - val_accuracy: 0.7921\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8418 - val_loss: 0.4822 - val_accuracy: 0.7921\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8418 - val_loss: 0.4784 - val_accuracy: 0.7921\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8397 - val_loss: 0.4784 - val_accuracy: 0.8034\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8418 - val_loss: 0.4772 - val_accuracy: 0.8090\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8460 - val_loss: 0.4767 - val_accuracy: 0.8146\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8439 - val_loss: 0.4745 - val_accuracy: 0.8202\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8439 - val_loss: 0.4732 - val_accuracy: 0.8202\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8439 - val_loss: 0.4718 - val_accuracy: 0.8202\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8439 - val_loss: 0.4707 - val_accuracy: 0.8202\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8460 - val_loss: 0.4697 - val_accuracy: 0.8258\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8481 - val_loss: 0.4701 - val_accuracy: 0.8202\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8460 - val_loss: 0.4700 - val_accuracy: 0.8202\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8481 - val_loss: 0.4699 - val_accuracy: 0.8258\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8460 - val_loss: 0.4682 - val_accuracy: 0.8202\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8502 - val_loss: 0.4693 - val_accuracy: 0.8258\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8523 - val_loss: 0.4688 - val_accuracy: 0.8315\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8481 - val_loss: 0.4679 - val_accuracy: 0.8371\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8523 - val_loss: 0.4708 - val_accuracy: 0.8202\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8565 - val_loss: 0.4690 - val_accuracy: 0.8315\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8481 - val_loss: 0.4674 - val_accuracy: 0.8258\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8502 - val_loss: 0.4676 - val_accuracy: 0.8315\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8502 - val_loss: 0.4696 - val_accuracy: 0.8315\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8502 - val_loss: 0.4672 - val_accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8565 - val_loss: 0.4679 - val_accuracy: 0.8258\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8608 - val_loss: 0.4699 - val_accuracy: 0.8258\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8608 - val_loss: 0.4680 - val_accuracy: 0.8202\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8586 - val_loss: 0.4689 - val_accuracy: 0.8202\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8586 - val_loss: 0.4684 - val_accuracy: 0.8371\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8629 - val_loss: 0.4718 - val_accuracy: 0.8202\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8629 - val_loss: 0.4694 - val_accuracy: 0.8258\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8671 - val_loss: 0.4698 - val_accuracy: 0.8315\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.8692 - val_loss: 0.4696 - val_accuracy: 0.8315\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8692 - val_loss: 0.4711 - val_accuracy: 0.8315\n",
      "8/8 [==============================] - 0s 805us/step - loss: 0.4294 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1015 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6597 - accuracy: 0.6540 - val_loss: 0.6384 - val_accuracy: 0.6573\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6878 - val_loss: 0.6048 - val_accuracy: 0.6742\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7068 - val_loss: 0.5789 - val_accuracy: 0.6966\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7384 - val_loss: 0.5569 - val_accuracy: 0.7135\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7447 - val_loss: 0.5399 - val_accuracy: 0.7303\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7658 - val_loss: 0.5245 - val_accuracy: 0.7303\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7722 - val_loss: 0.5126 - val_accuracy: 0.7584\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7806 - val_loss: 0.5027 - val_accuracy: 0.7809\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7975 - val_loss: 0.4945 - val_accuracy: 0.7921\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.8101 - val_loss: 0.4888 - val_accuracy: 0.7865\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.8165 - val_loss: 0.4835 - val_accuracy: 0.7921\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8165 - val_loss: 0.4802 - val_accuracy: 0.8034\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8165 - val_loss: 0.4781 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.8143 - val_loss: 0.4764 - val_accuracy: 0.8034\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8186 - val_loss: 0.4733 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8207 - val_loss: 0.4721 - val_accuracy: 0.8146\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8186 - val_loss: 0.4728 - val_accuracy: 0.8090\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8249 - val_loss: 0.4694 - val_accuracy: 0.8146\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8291 - val_loss: 0.4689 - val_accuracy: 0.8146\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8291 - val_loss: 0.4689 - val_accuracy: 0.8202\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8354 - val_loss: 0.4684 - val_accuracy: 0.8146\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8333 - val_loss: 0.4671 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8354 - val_loss: 0.4673 - val_accuracy: 0.8202\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8354 - val_loss: 0.4669 - val_accuracy: 0.8202\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8376 - val_loss: 0.4657 - val_accuracy: 0.8202\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3916 - accuracy: 0.8376 - val_loss: 0.4659 - val_accuracy: 0.8146\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8376 - val_loss: 0.4665 - val_accuracy: 0.8146\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8354 - val_loss: 0.4665 - val_accuracy: 0.8202\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8376 - val_loss: 0.4662 - val_accuracy: 0.8146\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8376 - val_loss: 0.4658 - val_accuracy: 0.8146\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8418 - val_loss: 0.4664 - val_accuracy: 0.8146\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8439 - val_loss: 0.4664 - val_accuracy: 0.8146\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8376 - val_loss: 0.4647 - val_accuracy: 0.8146\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8439 - val_loss: 0.4652 - val_accuracy: 0.8146\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8460 - val_loss: 0.4657 - val_accuracy: 0.8146\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8460 - val_loss: 0.4653 - val_accuracy: 0.8146\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8460 - val_loss: 0.4655 - val_accuracy: 0.8146\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8460 - val_loss: 0.4657 - val_accuracy: 0.8146\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8460 - val_loss: 0.4646 - val_accuracy: 0.8146\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8460 - val_loss: 0.4646 - val_accuracy: 0.8146\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8481 - val_loss: 0.4647 - val_accuracy: 0.8146\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8460 - val_loss: 0.4661 - val_accuracy: 0.8146\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8460 - val_loss: 0.4664 - val_accuracy: 0.8146\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8460 - val_loss: 0.4673 - val_accuracy: 0.8146\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8481 - val_loss: 0.4655 - val_accuracy: 0.8202\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8481 - val_loss: 0.4661 - val_accuracy: 0.8202\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8481 - val_loss: 0.4668 - val_accuracy: 0.8146\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8481 - val_loss: 0.4666 - val_accuracy: 0.8202\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8502 - val_loss: 0.4672 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 826us/step - loss: 0.3981 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1017 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.8201 - accuracy: 0.3186 - val_loss: 0.7478 - val_accuracy: 0.3539\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7056 - accuracy: 0.4578 - val_loss: 0.6709 - val_accuracy: 0.6180\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.6329 - val_loss: 0.6249 - val_accuracy: 0.6404\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.6857 - val_loss: 0.5976 - val_accuracy: 0.6685\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7004 - val_loss: 0.5769 - val_accuracy: 0.6798\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7152 - val_loss: 0.5624 - val_accuracy: 0.6854\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7300 - val_loss: 0.5481 - val_accuracy: 0.7022\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7447 - val_loss: 0.5364 - val_accuracy: 0.7022\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7679 - val_loss: 0.5266 - val_accuracy: 0.7303\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7869 - val_loss: 0.5176 - val_accuracy: 0.7416\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8059 - val_loss: 0.5107 - val_accuracy: 0.7640\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.8249 - val_loss: 0.5041 - val_accuracy: 0.7865\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.8291 - val_loss: 0.4981 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.8312 - val_loss: 0.4943 - val_accuracy: 0.8034\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8291 - val_loss: 0.4919 - val_accuracy: 0.8034\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8270 - val_loss: 0.4880 - val_accuracy: 0.8090\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8207 - val_loss: 0.4867 - val_accuracy: 0.8202\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8165 - val_loss: 0.4844 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8186 - val_loss: 0.4831 - val_accuracy: 0.8034\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8207 - val_loss: 0.4832 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8228 - val_loss: 0.4825 - val_accuracy: 0.8034\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8228 - val_loss: 0.4817 - val_accuracy: 0.8034\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8249 - val_loss: 0.4824 - val_accuracy: 0.7978\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8228 - val_loss: 0.4814 - val_accuracy: 0.7978\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8207 - val_loss: 0.4821 - val_accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8270 - val_loss: 0.4822 - val_accuracy: 0.7978\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8270 - val_loss: 0.4816 - val_accuracy: 0.8034\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8291 - val_loss: 0.4834 - val_accuracy: 0.8034\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.8291 - val_loss: 0.4833 - val_accuracy: 0.8034\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8270 - val_loss: 0.4826 - val_accuracy: 0.7978\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8312 - val_loss: 0.4828 - val_accuracy: 0.8034\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3851 - accuracy: 0.8333 - val_loss: 0.4823 - val_accuracy: 0.8090\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8354 - val_loss: 0.4826 - val_accuracy: 0.8090\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8354 - val_loss: 0.4836 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 753us/step - loss: 0.4099 - accuracy: 0.8439\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1019 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6397 - accuracy: 0.6751 - val_loss: 0.6021 - val_accuracy: 0.7416\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7595 - val_loss: 0.5631 - val_accuracy: 0.7079\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7532 - val_loss: 0.5417 - val_accuracy: 0.7247\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7954 - val_loss: 0.5246 - val_accuracy: 0.7640\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.8101 - val_loss: 0.5092 - val_accuracy: 0.8090\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8249 - val_loss: 0.5014 - val_accuracy: 0.8146\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8228 - val_loss: 0.4952 - val_accuracy: 0.8034\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8249 - val_loss: 0.4899 - val_accuracy: 0.8034\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8270 - val_loss: 0.4871 - val_accuracy: 0.8034\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8312 - val_loss: 0.4854 - val_accuracy: 0.8034\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8333 - val_loss: 0.4814 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8312 - val_loss: 0.4785 - val_accuracy: 0.8034\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8312 - val_loss: 0.4799 - val_accuracy: 0.8090\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8376 - val_loss: 0.4805 - val_accuracy: 0.8146\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8418 - val_loss: 0.4749 - val_accuracy: 0.8146\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8439 - val_loss: 0.4746 - val_accuracy: 0.8146\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8481 - val_loss: 0.4741 - val_accuracy: 0.8090\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8354 - val_loss: 0.4711 - val_accuracy: 0.8202\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8418 - val_loss: 0.4728 - val_accuracy: 0.8202\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.8523 - val_loss: 0.4747 - val_accuracy: 0.8202\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8544 - val_loss: 0.4703 - val_accuracy: 0.8146\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8481 - val_loss: 0.4690 - val_accuracy: 0.8202\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8502 - val_loss: 0.4713 - val_accuracy: 0.8258\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8523 - val_loss: 0.4698 - val_accuracy: 0.8315\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8586 - val_loss: 0.4699 - val_accuracy: 0.8315\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8608 - val_loss: 0.4708 - val_accuracy: 0.8258\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3609 - accuracy: 0.8671 - val_loss: 0.4693 - val_accuracy: 0.8258\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8586 - val_loss: 0.4688 - val_accuracy: 0.8315\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8629 - val_loss: 0.4699 - val_accuracy: 0.8258\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8692 - val_loss: 0.4685 - val_accuracy: 0.8315\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8692 - val_loss: 0.4698 - val_accuracy: 0.8371\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8713 - val_loss: 0.4694 - val_accuracy: 0.8315\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8650 - val_loss: 0.4721 - val_accuracy: 0.8258\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8692 - val_loss: 0.4729 - val_accuracy: 0.8258\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8692 - val_loss: 0.4717 - val_accuracy: 0.8202\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8671 - val_loss: 0.4707 - val_accuracy: 0.8258\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8713 - val_loss: 0.4712 - val_accuracy: 0.8258\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8692 - val_loss: 0.4722 - val_accuracy: 0.8258\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8713 - val_loss: 0.4734 - val_accuracy: 0.8202\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8692 - val_loss: 0.4726 - val_accuracy: 0.8202\n",
      "8/8 [==============================] - 0s 823us/step - loss: 0.4309 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1021 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6461 - accuracy: 0.6287 - val_loss: 0.6180 - val_accuracy: 0.6348\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.6793 - val_loss: 0.5759 - val_accuracy: 0.6854\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7257 - val_loss: 0.5468 - val_accuracy: 0.7135\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7532 - val_loss: 0.5250 - val_accuracy: 0.7528\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7764 - val_loss: 0.5071 - val_accuracy: 0.7978\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.8080 - val_loss: 0.4954 - val_accuracy: 0.7809\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.8143 - val_loss: 0.4869 - val_accuracy: 0.7921\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8228 - val_loss: 0.4794 - val_accuracy: 0.7978\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8291 - val_loss: 0.4760 - val_accuracy: 0.7978\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8376 - val_loss: 0.4728 - val_accuracy: 0.8090\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8270 - val_loss: 0.4710 - val_accuracy: 0.7978\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8312 - val_loss: 0.4695 - val_accuracy: 0.8090\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8354 - val_loss: 0.4690 - val_accuracy: 0.8034\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8354 - val_loss: 0.4663 - val_accuracy: 0.8034\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8376 - val_loss: 0.4652 - val_accuracy: 0.8034\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8376 - val_loss: 0.4654 - val_accuracy: 0.8034\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8397 - val_loss: 0.4645 - val_accuracy: 0.8034\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8397 - val_loss: 0.4645 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8376 - val_loss: 0.4636 - val_accuracy: 0.8034\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8418 - val_loss: 0.4628 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8460 - val_loss: 0.4638 - val_accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8439 - val_loss: 0.4634 - val_accuracy: 0.8034\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8502 - val_loss: 0.4642 - val_accuracy: 0.8090\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3805 - accuracy: 0.8502 - val_loss: 0.4625 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8502 - val_loss: 0.4638 - val_accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8481 - val_loss: 0.4624 - val_accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8523 - val_loss: 0.4628 - val_accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8523 - val_loss: 0.4629 - val_accuracy: 0.8202\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8523 - val_loss: 0.4631 - val_accuracy: 0.8202\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8481 - val_loss: 0.4641 - val_accuracy: 0.8146\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8523 - val_loss: 0.4647 - val_accuracy: 0.8202\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8565 - val_loss: 0.4629 - val_accuracy: 0.8258\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8544 - val_loss: 0.4656 - val_accuracy: 0.8258\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8523 - val_loss: 0.4657 - val_accuracy: 0.8258\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8523 - val_loss: 0.4633 - val_accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8523 - val_loss: 0.4671 - val_accuracy: 0.8315\n",
      "8/8 [==============================] - 0s 889us/step - loss: 0.3973 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1023 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5969 - accuracy: 0.7152 - val_loss: 0.6007 - val_accuracy: 0.6629\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7257 - val_loss: 0.5752 - val_accuracy: 0.6629\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7257 - val_loss: 0.5559 - val_accuracy: 0.6854\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7637 - val_loss: 0.5397 - val_accuracy: 0.7191\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7806 - val_loss: 0.5301 - val_accuracy: 0.7303\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.8017 - val_loss: 0.5181 - val_accuracy: 0.7584\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8186 - val_loss: 0.5109 - val_accuracy: 0.7640\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8207 - val_loss: 0.5065 - val_accuracy: 0.7697\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8186 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8186 - val_loss: 0.4988 - val_accuracy: 0.7865\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8165 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8186 - val_loss: 0.4938 - val_accuracy: 0.7865\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8249 - val_loss: 0.4913 - val_accuracy: 0.7865\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8270 - val_loss: 0.4924 - val_accuracy: 0.7865\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8270 - val_loss: 0.4902 - val_accuracy: 0.7809\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8291 - val_loss: 0.4902 - val_accuracy: 0.7809\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8291 - val_loss: 0.4909 - val_accuracy: 0.7753\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.8291 - val_loss: 0.4892 - val_accuracy: 0.7809\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8333 - val_loss: 0.4891 - val_accuracy: 0.7809\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8354 - val_loss: 0.4859 - val_accuracy: 0.7809\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8354 - val_loss: 0.4908 - val_accuracy: 0.7753\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8397 - val_loss: 0.4921 - val_accuracy: 0.7809\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8376 - val_loss: 0.4909 - val_accuracy: 0.7809\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8397 - val_loss: 0.4924 - val_accuracy: 0.7809\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8376 - val_loss: 0.4912 - val_accuracy: 0.7809\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8439 - val_loss: 0.4930 - val_accuracy: 0.7809\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.8376 - val_loss: 0.4902 - val_accuracy: 0.7809\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8439 - val_loss: 0.4923 - val_accuracy: 0.7753\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8418 - val_loss: 0.4941 - val_accuracy: 0.7753\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8460 - val_loss: 0.4946 - val_accuracy: 0.7809\n",
      "8/8 [==============================] - 0s 817us/step - loss: 0.4123 - accuracy: 0.8354\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1025 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6735 - accuracy: 0.6308 - val_loss: 0.6034 - val_accuracy: 0.7584\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.7152 - val_loss: 0.5742 - val_accuracy: 0.7303\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.7342 - val_loss: 0.5605 - val_accuracy: 0.7191\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7447 - val_loss: 0.5523 - val_accuracy: 0.7135\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7384 - val_loss: 0.5470 - val_accuracy: 0.7191\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7553 - val_loss: 0.5422 - val_accuracy: 0.7191\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7679 - val_loss: 0.5376 - val_accuracy: 0.7360\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7764 - val_loss: 0.5329 - val_accuracy: 0.7472\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7932 - val_loss: 0.5283 - val_accuracy: 0.7528\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7932 - val_loss: 0.5227 - val_accuracy: 0.7640\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7911 - val_loss: 0.5183 - val_accuracy: 0.7640\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7975 - val_loss: 0.5143 - val_accuracy: 0.7697\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.8017 - val_loss: 0.5086 - val_accuracy: 0.7697\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7996 - val_loss: 0.5053 - val_accuracy: 0.7753\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.8017 - val_loss: 0.5013 - val_accuracy: 0.7753\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.8080 - val_loss: 0.4974 - val_accuracy: 0.7809\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.8101 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8101 - val_loss: 0.4930 - val_accuracy: 0.7809\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8143 - val_loss: 0.4897 - val_accuracy: 0.7865\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8122 - val_loss: 0.4902 - val_accuracy: 0.7865\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8165 - val_loss: 0.4876 - val_accuracy: 0.7921\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8101 - val_loss: 0.4851 - val_accuracy: 0.7978\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8165 - val_loss: 0.4831 - val_accuracy: 0.8034\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8228 - val_loss: 0.4825 - val_accuracy: 0.8034\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8228 - val_loss: 0.4810 - val_accuracy: 0.8034\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8270 - val_loss: 0.4803 - val_accuracy: 0.8034\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8249 - val_loss: 0.4794 - val_accuracy: 0.8034\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8291 - val_loss: 0.4786 - val_accuracy: 0.8090\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8354 - val_loss: 0.4782 - val_accuracy: 0.8090\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8354 - val_loss: 0.4771 - val_accuracy: 0.8146\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8333 - val_loss: 0.4783 - val_accuracy: 0.8090\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8354 - val_loss: 0.4790 - val_accuracy: 0.8090\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8418 - val_loss: 0.4740 - val_accuracy: 0.8202\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8439 - val_loss: 0.4760 - val_accuracy: 0.8146\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8418 - val_loss: 0.4741 - val_accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8460 - val_loss: 0.4740 - val_accuracy: 0.8258\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8460 - val_loss: 0.4730 - val_accuracy: 0.8202\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8502 - val_loss: 0.4747 - val_accuracy: 0.8202\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8439 - val_loss: 0.4746 - val_accuracy: 0.8202\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8481 - val_loss: 0.4723 - val_accuracy: 0.8258\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8460 - val_loss: 0.4717 - val_accuracy: 0.8202\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8460 - val_loss: 0.4732 - val_accuracy: 0.8258\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8460 - val_loss: 0.4724 - val_accuracy: 0.8258\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8502 - val_loss: 0.4738 - val_accuracy: 0.8258\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8481 - val_loss: 0.4713 - val_accuracy: 0.8202\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8481 - val_loss: 0.4710 - val_accuracy: 0.8202\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8481 - val_loss: 0.4717 - val_accuracy: 0.8202\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8481 - val_loss: 0.4739 - val_accuracy: 0.8315\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8502 - val_loss: 0.4727 - val_accuracy: 0.8202\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8523 - val_loss: 0.4735 - val_accuracy: 0.8258\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8502 - val_loss: 0.4718 - val_accuracy: 0.8202\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8502 - val_loss: 0.4726 - val_accuracy: 0.8202\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8502 - val_loss: 0.4722 - val_accuracy: 0.8202\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8544 - val_loss: 0.4728 - val_accuracy: 0.8202\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8502 - val_loss: 0.4731 - val_accuracy: 0.8258\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8565 - val_loss: 0.4732 - val_accuracy: 0.8202\n",
      "8/8 [==============================] - 0s 822us/step - loss: 0.4525 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1028 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6686 - accuracy: 0.6857 - val_loss: 0.6647 - val_accuracy: 0.6966\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.6962 - val_loss: 0.6522 - val_accuracy: 0.7022\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7068 - val_loss: 0.6343 - val_accuracy: 0.7135\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.7321 - val_loss: 0.6145 - val_accuracy: 0.7360\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7426 - val_loss: 0.5967 - val_accuracy: 0.7416\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7489 - val_loss: 0.5809 - val_accuracy: 0.7416\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7700 - val_loss: 0.5650 - val_accuracy: 0.7528\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7722 - val_loss: 0.5498 - val_accuracy: 0.7584\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7785 - val_loss: 0.5350 - val_accuracy: 0.7528\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7848 - val_loss: 0.5221 - val_accuracy: 0.7472\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7890 - val_loss: 0.5082 - val_accuracy: 0.7809\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7996 - val_loss: 0.4966 - val_accuracy: 0.7921\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.8059 - val_loss: 0.4869 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.8038 - val_loss: 0.4769 - val_accuracy: 0.8146\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8143 - val_loss: 0.4686 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8122 - val_loss: 0.4607 - val_accuracy: 0.8315\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8228 - val_loss: 0.4565 - val_accuracy: 0.8258\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8312 - val_loss: 0.4524 - val_accuracy: 0.8258\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8333 - val_loss: 0.4510 - val_accuracy: 0.8258\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8354 - val_loss: 0.4506 - val_accuracy: 0.8258\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8312 - val_loss: 0.4502 - val_accuracy: 0.8202\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8376 - val_loss: 0.4477 - val_accuracy: 0.8202\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8376 - val_loss: 0.4474 - val_accuracy: 0.8202\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8376 - val_loss: 0.4493 - val_accuracy: 0.8146\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8376 - val_loss: 0.4493 - val_accuracy: 0.8202\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8376 - val_loss: 0.4494 - val_accuracy: 0.8202\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8397 - val_loss: 0.4505 - val_accuracy: 0.8202\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8397 - val_loss: 0.4500 - val_accuracy: 0.8146\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8397 - val_loss: 0.4499 - val_accuracy: 0.8146\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8418 - val_loss: 0.4502 - val_accuracy: 0.8202\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8439 - val_loss: 0.4488 - val_accuracy: 0.8146\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8439 - val_loss: 0.4507 - val_accuracy: 0.8202\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8460 - val_loss: 0.4507 - val_accuracy: 0.8202\n",
      "8/8 [==============================] - 0s 734us/step - loss: 0.3964 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1031 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.8186 - accuracy: 0.2996 - val_loss: 0.7467 - val_accuracy: 0.3539\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.3671 - val_loss: 0.6900 - val_accuracy: 0.5225\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.6118 - val_loss: 0.6559 - val_accuracy: 0.6685\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.6624 - val_loss: 0.6348 - val_accuracy: 0.6573\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.6646 - val_loss: 0.6202 - val_accuracy: 0.6573\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6624 - val_loss: 0.6071 - val_accuracy: 0.6629\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.6646 - val_loss: 0.5943 - val_accuracy: 0.6685\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.6793 - val_loss: 0.5828 - val_accuracy: 0.6854\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5638 - accuracy: 0.7089 - val_loss: 0.5707 - val_accuracy: 0.6854\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7426 - val_loss: 0.5596 - val_accuracy: 0.7022\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7616 - val_loss: 0.5475 - val_accuracy: 0.7191\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7785 - val_loss: 0.5345 - val_accuracy: 0.7360\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7848 - val_loss: 0.5213 - val_accuracy: 0.7528\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7932 - val_loss: 0.5089 - val_accuracy: 0.7697\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.8059 - val_loss: 0.4992 - val_accuracy: 0.7865\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.8143 - val_loss: 0.4925 - val_accuracy: 0.7809\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.8059 - val_loss: 0.4869 - val_accuracy: 0.7978\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.8017 - val_loss: 0.4805 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.8017 - val_loss: 0.4782 - val_accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.8038 - val_loss: 0.4769 - val_accuracy: 0.8090\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8017 - val_loss: 0.4733 - val_accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8059 - val_loss: 0.4723 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8080 - val_loss: 0.4696 - val_accuracy: 0.8146\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8059 - val_loss: 0.4688 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8249 - val_loss: 0.4679 - val_accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8207 - val_loss: 0.4686 - val_accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8228 - val_loss: 0.4685 - val_accuracy: 0.7921\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8228 - val_loss: 0.4687 - val_accuracy: 0.7865\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8249 - val_loss: 0.4685 - val_accuracy: 0.7865\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8291 - val_loss: 0.4690 - val_accuracy: 0.7978\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8312 - val_loss: 0.4671 - val_accuracy: 0.7921\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8270 - val_loss: 0.4673 - val_accuracy: 0.8034\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8312 - val_loss: 0.4686 - val_accuracy: 0.7978\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8312 - val_loss: 0.4669 - val_accuracy: 0.7978\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8312 - val_loss: 0.4673 - val_accuracy: 0.8090\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.3932 - accuracy: 0.8270 - val_loss: 0.4663 - val_accuracy: 0.7978\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8291 - val_loss: 0.4695 - val_accuracy: 0.8034\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8270 - val_loss: 0.4691 - val_accuracy: 0.7978\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8270 - val_loss: 0.4666 - val_accuracy: 0.7978\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8207 - val_loss: 0.4674 - val_accuracy: 0.7921\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8228 - val_loss: 0.4669 - val_accuracy: 0.8034\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8207 - val_loss: 0.4667 - val_accuracy: 0.7921\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8249 - val_loss: 0.4683 - val_accuracy: 0.7978\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8249 - val_loss: 0.4682 - val_accuracy: 0.7921\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8270 - val_loss: 0.4683 - val_accuracy: 0.7921\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8249 - val_loss: 0.4668 - val_accuracy: 0.7978\n",
      "8/8 [==============================] - 0s 852us/step - loss: 0.4161 - accuracy: 0.8059\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1034 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6032 - accuracy: 0.6624 - val_loss: 0.6154 - val_accuracy: 0.6517\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7025 - val_loss: 0.5951 - val_accuracy: 0.6629\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7236 - val_loss: 0.5758 - val_accuracy: 0.6685\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7447 - val_loss: 0.5589 - val_accuracy: 0.6854\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7722 - val_loss: 0.5406 - val_accuracy: 0.7247\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7975 - val_loss: 0.5249 - val_accuracy: 0.7303\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8249 - val_loss: 0.5108 - val_accuracy: 0.7640\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.8354 - val_loss: 0.5017 - val_accuracy: 0.7809\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8333 - val_loss: 0.4972 - val_accuracy: 0.7809\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.8270 - val_loss: 0.4933 - val_accuracy: 0.7865\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8312 - val_loss: 0.4897 - val_accuracy: 0.7865\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8354 - val_loss: 0.4841 - val_accuracy: 0.7809\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8439 - val_loss: 0.4842 - val_accuracy: 0.8090\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8481 - val_loss: 0.4827 - val_accuracy: 0.7978\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8481 - val_loss: 0.4798 - val_accuracy: 0.7978\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8460 - val_loss: 0.4801 - val_accuracy: 0.8034\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8502 - val_loss: 0.4773 - val_accuracy: 0.8146\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8544 - val_loss: 0.4778 - val_accuracy: 0.8202\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8565 - val_loss: 0.4778 - val_accuracy: 0.8146\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8544 - val_loss: 0.4749 - val_accuracy: 0.8202\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 0.8565 - val_loss: 0.4725 - val_accuracy: 0.8202\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8608 - val_loss: 0.4782 - val_accuracy: 0.8034\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8523 - val_loss: 0.4750 - val_accuracy: 0.8202\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8608 - val_loss: 0.4718 - val_accuracy: 0.8146\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8671 - val_loss: 0.4742 - val_accuracy: 0.8146\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3419 - accuracy: 0.8629 - val_loss: 0.4739 - val_accuracy: 0.8146\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8671 - val_loss: 0.4746 - val_accuracy: 0.8146\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.8608 - val_loss: 0.4789 - val_accuracy: 0.8146\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8608 - val_loss: 0.4792 - val_accuracy: 0.8202\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8692 - val_loss: 0.4750 - val_accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.8671 - val_loss: 0.4779 - val_accuracy: 0.8090\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8692 - val_loss: 0.4773 - val_accuracy: 0.8146\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8650 - val_loss: 0.4772 - val_accuracy: 0.8146\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8650 - val_loss: 0.4803 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 840us/step - loss: 0.4244 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1037 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7047 - accuracy: 0.5127 - val_loss: 0.6625 - val_accuracy: 0.6798\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.6688 - val_loss: 0.6229 - val_accuracy: 0.6517\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.6878 - val_loss: 0.5921 - val_accuracy: 0.6854\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7363 - val_loss: 0.5655 - val_accuracy: 0.7022\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7848 - val_loss: 0.5399 - val_accuracy: 0.7472\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7954 - val_loss: 0.5178 - val_accuracy: 0.7584\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.8080 - val_loss: 0.5023 - val_accuracy: 0.7584\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8228 - val_loss: 0.4912 - val_accuracy: 0.7697\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8312 - val_loss: 0.4857 - val_accuracy: 0.7753\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8354 - val_loss: 0.4806 - val_accuracy: 0.7865\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8397 - val_loss: 0.4770 - val_accuracy: 0.7865\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8333 - val_loss: 0.4784 - val_accuracy: 0.7978\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8333 - val_loss: 0.4744 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8397 - val_loss: 0.4708 - val_accuracy: 0.7921\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8397 - val_loss: 0.4708 - val_accuracy: 0.7921\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8291 - val_loss: 0.4716 - val_accuracy: 0.7978\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8418 - val_loss: 0.4710 - val_accuracy: 0.7978\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8460 - val_loss: 0.4684 - val_accuracy: 0.7978\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8376 - val_loss: 0.4679 - val_accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8439 - val_loss: 0.4717 - val_accuracy: 0.7978\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8481 - val_loss: 0.4694 - val_accuracy: 0.7978\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8418 - val_loss: 0.4685 - val_accuracy: 0.7978\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8460 - val_loss: 0.4703 - val_accuracy: 0.8034\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8460 - val_loss: 0.4713 - val_accuracy: 0.7978\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8523 - val_loss: 0.4695 - val_accuracy: 0.7978\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8460 - val_loss: 0.4696 - val_accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8502 - val_loss: 0.4709 - val_accuracy: 0.7978\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8460 - val_loss: 0.4689 - val_accuracy: 0.8034\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8523 - val_loss: 0.4695 - val_accuracy: 0.7978\n",
      "8/8 [==============================] - 0s 728us/step - loss: 0.4070 - accuracy: 0.8059\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1040 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7570 - accuracy: 0.4304 - val_loss: 0.6894 - val_accuracy: 0.6124\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6920 - val_loss: 0.6303 - val_accuracy: 0.6966\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.7131 - val_loss: 0.6042 - val_accuracy: 0.6685\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.7257 - val_loss: 0.5899 - val_accuracy: 0.6854\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7363 - val_loss: 0.5785 - val_accuracy: 0.6966\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7384 - val_loss: 0.5680 - val_accuracy: 0.7022\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7785 - val_loss: 0.5595 - val_accuracy: 0.7247\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.8101 - val_loss: 0.5523 - val_accuracy: 0.7472\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.8101 - val_loss: 0.5430 - val_accuracy: 0.7528\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.8165 - val_loss: 0.5397 - val_accuracy: 0.7640\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8207 - val_loss: 0.5371 - val_accuracy: 0.7640\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8186 - val_loss: 0.5332 - val_accuracy: 0.7584\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.8186 - val_loss: 0.5326 - val_accuracy: 0.7640\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8207 - val_loss: 0.5316 - val_accuracy: 0.7640\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8228 - val_loss: 0.5317 - val_accuracy: 0.7640\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8270 - val_loss: 0.5315 - val_accuracy: 0.7640\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8228 - val_loss: 0.5290 - val_accuracy: 0.7697\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8291 - val_loss: 0.5326 - val_accuracy: 0.7640\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8270 - val_loss: 0.5297 - val_accuracy: 0.7697\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8291 - val_loss: 0.5308 - val_accuracy: 0.7809\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8333 - val_loss: 0.5307 - val_accuracy: 0.7809\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8376 - val_loss: 0.5290 - val_accuracy: 0.7809\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8312 - val_loss: 0.5328 - val_accuracy: 0.7753\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8354 - val_loss: 0.5318 - val_accuracy: 0.7809\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8333 - val_loss: 0.5321 - val_accuracy: 0.7865\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8397 - val_loss: 0.5313 - val_accuracy: 0.7865\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8439 - val_loss: 0.5384 - val_accuracy: 0.7697\n",
      "8/8 [==============================] - 0s 812us/step - loss: 0.4340 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1043 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6376 - accuracy: 0.6582 - val_loss: 0.6019 - val_accuracy: 0.6685\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7257 - val_loss: 0.5623 - val_accuracy: 0.6742\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7553 - val_loss: 0.5323 - val_accuracy: 0.7247\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.8101 - val_loss: 0.5108 - val_accuracy: 0.7753\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8080 - val_loss: 0.4936 - val_accuracy: 0.7753\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8228 - val_loss: 0.4871 - val_accuracy: 0.8090\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8249 - val_loss: 0.4828 - val_accuracy: 0.7809\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8333 - val_loss: 0.4785 - val_accuracy: 0.7978\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8333 - val_loss: 0.4732 - val_accuracy: 0.8146\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8333 - val_loss: 0.4681 - val_accuracy: 0.8202\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8418 - val_loss: 0.4699 - val_accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8397 - val_loss: 0.4649 - val_accuracy: 0.8202\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.8397 - val_loss: 0.4645 - val_accuracy: 0.8315\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8418 - val_loss: 0.4630 - val_accuracy: 0.8315\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8481 - val_loss: 0.4660 - val_accuracy: 0.8315\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8502 - val_loss: 0.4641 - val_accuracy: 0.8315\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8481 - val_loss: 0.4665 - val_accuracy: 0.8258\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8565 - val_loss: 0.4681 - val_accuracy: 0.8315\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8565 - val_loss: 0.4703 - val_accuracy: 0.8258\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8523 - val_loss: 0.4658 - val_accuracy: 0.8315\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8629 - val_loss: 0.4694 - val_accuracy: 0.8202\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8523 - val_loss: 0.4692 - val_accuracy: 0.8371\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3423 - accuracy: 0.8650 - val_loss: 0.4736 - val_accuracy: 0.8034\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.8671 - val_loss: 0.4717 - val_accuracy: 0.8202\n",
      "8/8 [==============================] - 0s 804us/step - loss: 0.4246 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1046 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6179 - accuracy: 0.6498 - val_loss: 0.6052 - val_accuracy: 0.6517\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7173 - val_loss: 0.5644 - val_accuracy: 0.7191\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7722 - val_loss: 0.5352 - val_accuracy: 0.7360\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7932 - val_loss: 0.5106 - val_accuracy: 0.7584\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.8122 - val_loss: 0.4959 - val_accuracy: 0.7640\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.8165 - val_loss: 0.4891 - val_accuracy: 0.7640\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8143 - val_loss: 0.4830 - val_accuracy: 0.7809\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8143 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8228 - val_loss: 0.4755 - val_accuracy: 0.7809\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8228 - val_loss: 0.4712 - val_accuracy: 0.7921\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8333 - val_loss: 0.4707 - val_accuracy: 0.7978\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8397 - val_loss: 0.4676 - val_accuracy: 0.8146\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8439 - val_loss: 0.4652 - val_accuracy: 0.8146\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8481 - val_loss: 0.4654 - val_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8397 - val_loss: 0.4661 - val_accuracy: 0.8146\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8481 - val_loss: 0.4646 - val_accuracy: 0.8202\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8502 - val_loss: 0.4609 - val_accuracy: 0.8258\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8481 - val_loss: 0.4611 - val_accuracy: 0.8258\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8523 - val_loss: 0.4608 - val_accuracy: 0.8258\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8481 - val_loss: 0.4615 - val_accuracy: 0.8258\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8608 - val_loss: 0.4615 - val_accuracy: 0.8258\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8544 - val_loss: 0.4627 - val_accuracy: 0.8258\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8608 - val_loss: 0.4671 - val_accuracy: 0.8258\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8586 - val_loss: 0.4609 - val_accuracy: 0.8258\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8565 - val_loss: 0.4649 - val_accuracy: 0.8258\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8586 - val_loss: 0.4651 - val_accuracy: 0.8258\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8544 - val_loss: 0.4675 - val_accuracy: 0.8315\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8544 - val_loss: 0.4693 - val_accuracy: 0.8258\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8608 - val_loss: 0.4727 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 788us/step - loss: 0.3880 - accuracy: 0.8439\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1049 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7062 - accuracy: 0.5316 - val_loss: 0.6489 - val_accuracy: 0.6629\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7215 - val_loss: 0.6098 - val_accuracy: 0.6742\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7278 - val_loss: 0.5818 - val_accuracy: 0.6742\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7616 - val_loss: 0.5530 - val_accuracy: 0.7247\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8059 - val_loss: 0.5318 - val_accuracy: 0.7247\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.8270 - val_loss: 0.5205 - val_accuracy: 0.7416\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8291 - val_loss: 0.5151 - val_accuracy: 0.7528\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8333 - val_loss: 0.5153 - val_accuracy: 0.7640\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8228 - val_loss: 0.5059 - val_accuracy: 0.7753\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8312 - val_loss: 0.5078 - val_accuracy: 0.7753\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8291 - val_loss: 0.5091 - val_accuracy: 0.7697\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.8376 - val_loss: 0.5045 - val_accuracy: 0.7753\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8354 - val_loss: 0.5041 - val_accuracy: 0.7753\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.8397 - val_loss: 0.5069 - val_accuracy: 0.7753\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.8397 - val_loss: 0.5139 - val_accuracy: 0.7697\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8291 - val_loss: 0.5117 - val_accuracy: 0.7697\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3623 - accuracy: 0.8502 - val_loss: 0.5180 - val_accuracy: 0.7753\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8502 - val_loss: 0.5149 - val_accuracy: 0.7697\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8565 - val_loss: 0.5200 - val_accuracy: 0.7697\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8544 - val_loss: 0.5197 - val_accuracy: 0.7809\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8586 - val_loss: 0.5262 - val_accuracy: 0.7809\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8586 - val_loss: 0.5338 - val_accuracy: 0.7584\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8629 - val_loss: 0.5350 - val_accuracy: 0.7697\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.4479 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1052 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5784 - accuracy: 0.6835 - val_loss: 0.5720 - val_accuracy: 0.6685\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7637 - val_loss: 0.5184 - val_accuracy: 0.7697\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8186 - val_loss: 0.4992 - val_accuracy: 0.7865\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8312 - val_loss: 0.4852 - val_accuracy: 0.8090\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8397 - val_loss: 0.4834 - val_accuracy: 0.8146\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8376 - val_loss: 0.4756 - val_accuracy: 0.8146\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8418 - val_loss: 0.4735 - val_accuracy: 0.8202\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8544 - val_loss: 0.4692 - val_accuracy: 0.8202\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8544 - val_loss: 0.4731 - val_accuracy: 0.8202\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8586 - val_loss: 0.4722 - val_accuracy: 0.8202\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8523 - val_loss: 0.4690 - val_accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8544 - val_loss: 0.4744 - val_accuracy: 0.8090\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8565 - val_loss: 0.4694 - val_accuracy: 0.8258\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8629 - val_loss: 0.4714 - val_accuracy: 0.8258\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8650 - val_loss: 0.4772 - val_accuracy: 0.8146\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8629 - val_loss: 0.4726 - val_accuracy: 0.8146\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8608 - val_loss: 0.4718 - val_accuracy: 0.8202\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8692 - val_loss: 0.4811 - val_accuracy: 0.8258\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8671 - val_loss: 0.4812 - val_accuracy: 0.8315\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8713 - val_loss: 0.4780 - val_accuracy: 0.8202\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8755 - val_loss: 0.4809 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 744us/step - loss: 0.4300 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1055 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6113 - accuracy: 0.6709 - val_loss: 0.5622 - val_accuracy: 0.7079\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7468 - val_loss: 0.5227 - val_accuracy: 0.7472\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.8165 - val_loss: 0.4992 - val_accuracy: 0.7697\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8101 - val_loss: 0.4885 - val_accuracy: 0.7921\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8207 - val_loss: 0.4746 - val_accuracy: 0.8034\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8228 - val_loss: 0.4776 - val_accuracy: 0.8202\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8207 - val_loss: 0.4693 - val_accuracy: 0.8258\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8460 - val_loss: 0.4710 - val_accuracy: 0.8258\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8376 - val_loss: 0.4694 - val_accuracy: 0.8258\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8523 - val_loss: 0.4639 - val_accuracy: 0.8258\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8460 - val_loss: 0.4771 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8481 - val_loss: 0.4722 - val_accuracy: 0.8146\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8565 - val_loss: 0.4736 - val_accuracy: 0.8202\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3590 - accuracy: 0.8439 - val_loss: 0.4718 - val_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8565 - val_loss: 0.4853 - val_accuracy: 0.8034\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3448 - accuracy: 0.8544 - val_loss: 0.4761 - val_accuracy: 0.8202\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8608 - val_loss: 0.4743 - val_accuracy: 0.8202\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8650 - val_loss: 0.4794 - val_accuracy: 0.8090\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8671 - val_loss: 0.4799 - val_accuracy: 0.8258\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8608 - val_loss: 0.4862 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 849us/step - loss: 0.4062 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1058 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5891 - accuracy: 0.6772 - val_loss: 0.5677 - val_accuracy: 0.6854\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7827 - val_loss: 0.5293 - val_accuracy: 0.7528\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7996 - val_loss: 0.5101 - val_accuracy: 0.7640\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7996 - val_loss: 0.5023 - val_accuracy: 0.7809\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8101 - val_loss: 0.4950 - val_accuracy: 0.7865\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8143 - val_loss: 0.5002 - val_accuracy: 0.7809\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8291 - val_loss: 0.5054 - val_accuracy: 0.7809\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8312 - val_loss: 0.5091 - val_accuracy: 0.7921\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8376 - val_loss: 0.5074 - val_accuracy: 0.7865\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8354 - val_loss: 0.5249 - val_accuracy: 0.7809\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8460 - val_loss: 0.5232 - val_accuracy: 0.7865\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8523 - val_loss: 0.5274 - val_accuracy: 0.7865\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8586 - val_loss: 0.5294 - val_accuracy: 0.7865\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8629 - val_loss: 0.5417 - val_accuracy: 0.7921\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8608 - val_loss: 0.5535 - val_accuracy: 0.7809\n",
      "8/8 [==============================] - 0s 862us/step - loss: 0.4398 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1061 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6593 - accuracy: 0.6983 - val_loss: 0.6523 - val_accuracy: 0.6685\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7278 - val_loss: 0.6352 - val_accuracy: 0.6629\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.7300 - val_loss: 0.6171 - val_accuracy: 0.6685\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.7215 - val_loss: 0.5980 - val_accuracy: 0.6742\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7236 - val_loss: 0.5818 - val_accuracy: 0.6742\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.7363 - val_loss: 0.5669 - val_accuracy: 0.6742\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7384 - val_loss: 0.5535 - val_accuracy: 0.6798\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7468 - val_loss: 0.5432 - val_accuracy: 0.6854\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7616 - val_loss: 0.5320 - val_accuracy: 0.7022\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7743 - val_loss: 0.5217 - val_accuracy: 0.7360\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.8059 - val_loss: 0.5133 - val_accuracy: 0.7640\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8101 - val_loss: 0.5065 - val_accuracy: 0.7809\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.8249 - val_loss: 0.4988 - val_accuracy: 0.7697\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8249 - val_loss: 0.4962 - val_accuracy: 0.7809\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8249 - val_loss: 0.4941 - val_accuracy: 0.7921\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8312 - val_loss: 0.4908 - val_accuracy: 0.8034\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8312 - val_loss: 0.4892 - val_accuracy: 0.7865\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8312 - val_loss: 0.4873 - val_accuracy: 0.7978\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8333 - val_loss: 0.4866 - val_accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8354 - val_loss: 0.4859 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8418 - val_loss: 0.4858 - val_accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8460 - val_loss: 0.4856 - val_accuracy: 0.8146\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8418 - val_loss: 0.4838 - val_accuracy: 0.8146\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8418 - val_loss: 0.4844 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8354 - val_loss: 0.4817 - val_accuracy: 0.7921\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8376 - val_loss: 0.4823 - val_accuracy: 0.8146\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8460 - val_loss: 0.4820 - val_accuracy: 0.8146\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8418 - val_loss: 0.4797 - val_accuracy: 0.8146\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8376 - val_loss: 0.4804 - val_accuracy: 0.8258\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8418 - val_loss: 0.4815 - val_accuracy: 0.8202\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8502 - val_loss: 0.4796 - val_accuracy: 0.8202\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8418 - val_loss: 0.4819 - val_accuracy: 0.8202\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8481 - val_loss: 0.4796 - val_accuracy: 0.8258\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8544 - val_loss: 0.4783 - val_accuracy: 0.8315\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8439 - val_loss: 0.4773 - val_accuracy: 0.8315\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8502 - val_loss: 0.4771 - val_accuracy: 0.8315\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8565 - val_loss: 0.4756 - val_accuracy: 0.8315\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3677 - accuracy: 0.8544 - val_loss: 0.4751 - val_accuracy: 0.8315\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8502 - val_loss: 0.4756 - val_accuracy: 0.8202\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8544 - val_loss: 0.4766 - val_accuracy: 0.8258\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8544 - val_loss: 0.4740 - val_accuracy: 0.8315\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8544 - val_loss: 0.4756 - val_accuracy: 0.8258\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8523 - val_loss: 0.4758 - val_accuracy: 0.8202\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8586 - val_loss: 0.4745 - val_accuracy: 0.8315\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8608 - val_loss: 0.4756 - val_accuracy: 0.8258\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8565 - val_loss: 0.4738 - val_accuracy: 0.8258\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8608 - val_loss: 0.4750 - val_accuracy: 0.8315\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8650 - val_loss: 0.4754 - val_accuracy: 0.8315\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8586 - val_loss: 0.4754 - val_accuracy: 0.8258\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8650 - val_loss: 0.4753 - val_accuracy: 0.8258\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8629 - val_loss: 0.4771 - val_accuracy: 0.8258\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8608 - val_loss: 0.4767 - val_accuracy: 0.8258\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8608 - val_loss: 0.4778 - val_accuracy: 0.8258\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8629 - val_loss: 0.4779 - val_accuracy: 0.8258\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8629 - val_loss: 0.4804 - val_accuracy: 0.8258\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8629 - val_loss: 0.4807 - val_accuracy: 0.8202\n",
      "8/8 [==============================] - 0s 830us/step - loss: 0.4374 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1065 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6757 - accuracy: 0.5970 - val_loss: 0.6697 - val_accuracy: 0.6067\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.6055 - val_loss: 0.6598 - val_accuracy: 0.6011\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6034 - val_loss: 0.6506 - val_accuracy: 0.6124\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.6055 - val_loss: 0.6416 - val_accuracy: 0.6124\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.6034 - val_loss: 0.6323 - val_accuracy: 0.6292\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.6160 - val_loss: 0.6223 - val_accuracy: 0.6292\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.6350 - val_loss: 0.6105 - val_accuracy: 0.6348\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.6582 - val_loss: 0.5966 - val_accuracy: 0.6798\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.6941 - val_loss: 0.5829 - val_accuracy: 0.6966\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7257 - val_loss: 0.5681 - val_accuracy: 0.7416\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7574 - val_loss: 0.5514 - val_accuracy: 0.7416\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7785 - val_loss: 0.5357 - val_accuracy: 0.7584\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.8080 - val_loss: 0.5208 - val_accuracy: 0.7809\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.8101 - val_loss: 0.5071 - val_accuracy: 0.7978\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.8143 - val_loss: 0.4954 - val_accuracy: 0.8034\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.8249 - val_loss: 0.4865 - val_accuracy: 0.7921\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.8228 - val_loss: 0.4788 - val_accuracy: 0.7921\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8186 - val_loss: 0.4739 - val_accuracy: 0.7921\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8186 - val_loss: 0.4707 - val_accuracy: 0.7921\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8207 - val_loss: 0.4676 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8249 - val_loss: 0.4655 - val_accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8249 - val_loss: 0.4647 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8249 - val_loss: 0.4622 - val_accuracy: 0.8090\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8270 - val_loss: 0.4600 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8333 - val_loss: 0.4576 - val_accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8291 - val_loss: 0.4581 - val_accuracy: 0.8146\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8312 - val_loss: 0.4560 - val_accuracy: 0.8202\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3865 - accuracy: 0.8333 - val_loss: 0.4548 - val_accuracy: 0.8090\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8354 - val_loss: 0.4531 - val_accuracy: 0.8258\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8376 - val_loss: 0.4530 - val_accuracy: 0.8258\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8418 - val_loss: 0.4524 - val_accuracy: 0.8258\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8397 - val_loss: 0.4489 - val_accuracy: 0.8258\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8354 - val_loss: 0.4512 - val_accuracy: 0.8202\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8376 - val_loss: 0.4488 - val_accuracy: 0.8258\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8418 - val_loss: 0.4478 - val_accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8397 - val_loss: 0.4492 - val_accuracy: 0.8202\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8376 - val_loss: 0.4493 - val_accuracy: 0.8202\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8354 - val_loss: 0.4474 - val_accuracy: 0.8202\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8439 - val_loss: 0.4472 - val_accuracy: 0.8258\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.8439 - val_loss: 0.4443 - val_accuracy: 0.8202\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8460 - val_loss: 0.4445 - val_accuracy: 0.8258\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8460 - val_loss: 0.4450 - val_accuracy: 0.8258\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8376 - val_loss: 0.4443 - val_accuracy: 0.8258\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8502 - val_loss: 0.4462 - val_accuracy: 0.8315\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8418 - val_loss: 0.4464 - val_accuracy: 0.8202\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8439 - val_loss: 0.4436 - val_accuracy: 0.8315\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8523 - val_loss: 0.4462 - val_accuracy: 0.8258\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8481 - val_loss: 0.4449 - val_accuracy: 0.8315\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8502 - val_loss: 0.4464 - val_accuracy: 0.8202\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8544 - val_loss: 0.4451 - val_accuracy: 0.8315\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8523 - val_loss: 0.4453 - val_accuracy: 0.8315\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8544 - val_loss: 0.4462 - val_accuracy: 0.8258\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8502 - val_loss: 0.4462 - val_accuracy: 0.8258\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8502 - val_loss: 0.4478 - val_accuracy: 0.8315\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8502 - val_loss: 0.4478 - val_accuracy: 0.8371\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.8544 - val_loss: 0.4471 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 813us/step - loss: 0.4084 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1069 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6970 - accuracy: 0.4451 - val_loss: 0.6915 - val_accuracy: 0.5843\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.6076 - val_loss: 0.6831 - val_accuracy: 0.5899\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.6287 - val_loss: 0.6734 - val_accuracy: 0.6067\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.6392 - val_loss: 0.6630 - val_accuracy: 0.6067\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.6582 - val_loss: 0.6528 - val_accuracy: 0.6124\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.6751 - val_loss: 0.6424 - val_accuracy: 0.6180\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.6983 - val_loss: 0.6311 - val_accuracy: 0.6292\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.7068 - val_loss: 0.6201 - val_accuracy: 0.6180\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.7194 - val_loss: 0.6098 - val_accuracy: 0.6292\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7321 - val_loss: 0.6005 - val_accuracy: 0.6292\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7447 - val_loss: 0.5905 - val_accuracy: 0.6685\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7595 - val_loss: 0.5792 - val_accuracy: 0.6798\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7827 - val_loss: 0.5690 - val_accuracy: 0.7191\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7954 - val_loss: 0.5614 - val_accuracy: 0.7472\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.8122 - val_loss: 0.5550 - val_accuracy: 0.7472\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.8165 - val_loss: 0.5493 - val_accuracy: 0.7584\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.8207 - val_loss: 0.5449 - val_accuracy: 0.7640\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8228 - val_loss: 0.5404 - val_accuracy: 0.7809\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.8186 - val_loss: 0.5367 - val_accuracy: 0.7921\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8207 - val_loss: 0.5382 - val_accuracy: 0.7753\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.8228 - val_loss: 0.5372 - val_accuracy: 0.7697\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8270 - val_loss: 0.5385 - val_accuracy: 0.7753\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8270 - val_loss: 0.5373 - val_accuracy: 0.7697\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8312 - val_loss: 0.5401 - val_accuracy: 0.7697\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8333 - val_loss: 0.5408 - val_accuracy: 0.7697\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8354 - val_loss: 0.5391 - val_accuracy: 0.7753\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8354 - val_loss: 0.5425 - val_accuracy: 0.7753\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8376 - val_loss: 0.5451 - val_accuracy: 0.7753\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8439 - val_loss: 0.5458 - val_accuracy: 0.7753\n",
      "8/8 [==============================] - 0s 829us/step - loss: 0.4561 - accuracy: 0.8397\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1073 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6215 - accuracy: 0.6519 - val_loss: 0.6078 - val_accuracy: 0.6517\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.6751 - val_loss: 0.5880 - val_accuracy: 0.6685\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7236 - val_loss: 0.5659 - val_accuracy: 0.6854\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7489 - val_loss: 0.5450 - val_accuracy: 0.7135\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7869 - val_loss: 0.5203 - val_accuracy: 0.7584\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.8101 - val_loss: 0.4964 - val_accuracy: 0.7865\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8333 - val_loss: 0.4817 - val_accuracy: 0.8034\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8376 - val_loss: 0.4763 - val_accuracy: 0.7978\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8439 - val_loss: 0.4648 - val_accuracy: 0.8258\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8397 - val_loss: 0.4651 - val_accuracy: 0.8315\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8502 - val_loss: 0.4700 - val_accuracy: 0.8258\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8481 - val_loss: 0.4638 - val_accuracy: 0.8315\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8523 - val_loss: 0.4697 - val_accuracy: 0.8315\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8544 - val_loss: 0.4641 - val_accuracy: 0.8258\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8608 - val_loss: 0.4653 - val_accuracy: 0.8371\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8565 - val_loss: 0.4645 - val_accuracy: 0.8371\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8650 - val_loss: 0.4714 - val_accuracy: 0.8371\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8565 - val_loss: 0.4676 - val_accuracy: 0.8146\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8629 - val_loss: 0.4678 - val_accuracy: 0.8371\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8629 - val_loss: 0.4680 - val_accuracy: 0.8258\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8650 - val_loss: 0.4770 - val_accuracy: 0.8146\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8608 - val_loss: 0.4687 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 848us/step - loss: 0.4254 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1077 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6495 - accuracy: 0.6730 - val_loss: 0.6354 - val_accuracy: 0.6685\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.7046 - val_loss: 0.5924 - val_accuracy: 0.6742\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7384 - val_loss: 0.5579 - val_accuracy: 0.6854\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.7532 - val_loss: 0.5372 - val_accuracy: 0.6742\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7722 - val_loss: 0.5194 - val_accuracy: 0.7079\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.8059 - val_loss: 0.5115 - val_accuracy: 0.7416\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8186 - val_loss: 0.5015 - val_accuracy: 0.7809\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8270 - val_loss: 0.4987 - val_accuracy: 0.7697\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8397 - val_loss: 0.4902 - val_accuracy: 0.7978\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8418 - val_loss: 0.4920 - val_accuracy: 0.8034\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.8354 - val_loss: 0.4854 - val_accuracy: 0.8034\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8397 - val_loss: 0.4901 - val_accuracy: 0.7978\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8418 - val_loss: 0.4858 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8481 - val_loss: 0.4866 - val_accuracy: 0.8034\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8565 - val_loss: 0.4899 - val_accuracy: 0.8146\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8418 - val_loss: 0.4880 - val_accuracy: 0.8090\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8565 - val_loss: 0.4909 - val_accuracy: 0.8146\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8523 - val_loss: 0.4864 - val_accuracy: 0.8090\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3624 - accuracy: 0.8502 - val_loss: 0.4966 - val_accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8502 - val_loss: 0.4931 - val_accuracy: 0.8090\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8544 - val_loss: 0.4912 - val_accuracy: 0.8202\n",
      "8/8 [==============================] - 0s 836us/step - loss: 0.4002 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1081 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6499 - accuracy: 0.6308 - val_loss: 0.6147 - val_accuracy: 0.6348\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.6414 - val_loss: 0.5776 - val_accuracy: 0.6461\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.6857 - val_loss: 0.5528 - val_accuracy: 0.6910\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7553 - val_loss: 0.5268 - val_accuracy: 0.7640\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7911 - val_loss: 0.5050 - val_accuracy: 0.7921\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.8080 - val_loss: 0.4892 - val_accuracy: 0.7978\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.8165 - val_loss: 0.4839 - val_accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8270 - val_loss: 0.4761 - val_accuracy: 0.8034\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8291 - val_loss: 0.4762 - val_accuracy: 0.8034\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8333 - val_loss: 0.4754 - val_accuracy: 0.7978\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8333 - val_loss: 0.4770 - val_accuracy: 0.8146\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8481 - val_loss: 0.4770 - val_accuracy: 0.7865\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8460 - val_loss: 0.4796 - val_accuracy: 0.8090\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8439 - val_loss: 0.4831 - val_accuracy: 0.8034\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.8354 - val_loss: 0.4772 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8481 - val_loss: 0.4835 - val_accuracy: 0.8034\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8418 - val_loss: 0.4929 - val_accuracy: 0.7921\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8544 - val_loss: 0.4920 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8523 - val_loss: 0.4979 - val_accuracy: 0.7921\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3397 - accuracy: 0.8544 - val_loss: 0.5034 - val_accuracy: 0.8034\n",
      "8/8 [==============================] - 0s 836us/step - loss: 0.4205 - accuracy: 0.8354\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1085 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.7110 - val_loss: 0.5740 - val_accuracy: 0.7191\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7553 - val_loss: 0.5194 - val_accuracy: 0.7584\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.8186 - val_loss: 0.4879 - val_accuracy: 0.7978\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8249 - val_loss: 0.4890 - val_accuracy: 0.8034\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8376 - val_loss: 0.4717 - val_accuracy: 0.8146\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8439 - val_loss: 0.4749 - val_accuracy: 0.8146\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8418 - val_loss: 0.4656 - val_accuracy: 0.8090\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8460 - val_loss: 0.4640 - val_accuracy: 0.8371\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8523 - val_loss: 0.4668 - val_accuracy: 0.8315\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8565 - val_loss: 0.4668 - val_accuracy: 0.8315\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8586 - val_loss: 0.4647 - val_accuracy: 0.8315\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8608 - val_loss: 0.4696 - val_accuracy: 0.8371\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8650 - val_loss: 0.4645 - val_accuracy: 0.8202\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8734 - val_loss: 0.4647 - val_accuracy: 0.8146\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3363 - accuracy: 0.8692 - val_loss: 0.4731 - val_accuracy: 0.8202\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8713 - val_loss: 0.4717 - val_accuracy: 0.8202\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8692 - val_loss: 0.4836 - val_accuracy: 0.8202\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3239 - accuracy: 0.8629 - val_loss: 0.4780 - val_accuracy: 0.8202\n",
      "8/8 [==============================] - 0s 818us/step - loss: 0.4268 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1089 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6313 - accuracy: 0.6118 - val_loss: 0.5914 - val_accuracy: 0.6461\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.6920 - val_loss: 0.5318 - val_accuracy: 0.7640\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.8038 - val_loss: 0.4948 - val_accuracy: 0.7753\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.8270 - val_loss: 0.4781 - val_accuracy: 0.7865\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8291 - val_loss: 0.4775 - val_accuracy: 0.7865\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8333 - val_loss: 0.4731 - val_accuracy: 0.8034\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8354 - val_loss: 0.4676 - val_accuracy: 0.8146\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8439 - val_loss: 0.4679 - val_accuracy: 0.8146\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8397 - val_loss: 0.4667 - val_accuracy: 0.8146\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8418 - val_loss: 0.4654 - val_accuracy: 0.8146\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8481 - val_loss: 0.4687 - val_accuracy: 0.8315\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.8481 - val_loss: 0.4673 - val_accuracy: 0.8258\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8502 - val_loss: 0.4707 - val_accuracy: 0.8258\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8544 - val_loss: 0.4689 - val_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3567 - accuracy: 0.8481 - val_loss: 0.4777 - val_accuracy: 0.8258\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8565 - val_loss: 0.4788 - val_accuracy: 0.8258\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8544 - val_loss: 0.4757 - val_accuracy: 0.8202\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8544 - val_loss: 0.4825 - val_accuracy: 0.8258\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3448 - accuracy: 0.8565 - val_loss: 0.4748 - val_accuracy: 0.8258\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8544 - val_loss: 0.4850 - val_accuracy: 0.8315\n",
      "8/8 [==============================] - 0s 812us/step - loss: 0.3869 - accuracy: 0.8397\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1093 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6014 - accuracy: 0.6835 - val_loss: 0.5776 - val_accuracy: 0.6685\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7278 - val_loss: 0.5355 - val_accuracy: 0.7528\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7954 - val_loss: 0.5202 - val_accuracy: 0.7697\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7996 - val_loss: 0.5156 - val_accuracy: 0.7697\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.8165 - val_loss: 0.5138 - val_accuracy: 0.7697\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8122 - val_loss: 0.5203 - val_accuracy: 0.7697\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8228 - val_loss: 0.5204 - val_accuracy: 0.7697\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8291 - val_loss: 0.5186 - val_accuracy: 0.7640\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8270 - val_loss: 0.5233 - val_accuracy: 0.7753\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8397 - val_loss: 0.5268 - val_accuracy: 0.7528\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8376 - val_loss: 0.5335 - val_accuracy: 0.7809\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3601 - accuracy: 0.8481 - val_loss: 0.5326 - val_accuracy: 0.7697\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8481 - val_loss: 0.5360 - val_accuracy: 0.7753\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8565 - val_loss: 0.5476 - val_accuracy: 0.7921\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3437 - accuracy: 0.8439 - val_loss: 0.5523 - val_accuracy: 0.7809\n",
      "8/8 [==============================] - 0s 798us/step - loss: 0.4427 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1097 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5904 - accuracy: 0.6920 - val_loss: 0.5584 - val_accuracy: 0.6910\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7679 - val_loss: 0.4997 - val_accuracy: 0.7921\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8270 - val_loss: 0.4954 - val_accuracy: 0.7921\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8291 - val_loss: 0.4756 - val_accuracy: 0.8146\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8397 - val_loss: 0.4632 - val_accuracy: 0.8202\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8460 - val_loss: 0.4663 - val_accuracy: 0.8258\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8608 - val_loss: 0.4584 - val_accuracy: 0.8371\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8565 - val_loss: 0.4793 - val_accuracy: 0.8090\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8608 - val_loss: 0.4740 - val_accuracy: 0.8202\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3397 - accuracy: 0.8692 - val_loss: 0.4727 - val_accuracy: 0.8090\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3291 - accuracy: 0.8692 - val_loss: 0.4865 - val_accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8692 - val_loss: 0.5049 - val_accuracy: 0.8034\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8755 - val_loss: 0.4970 - val_accuracy: 0.8146\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8755 - val_loss: 0.4909 - val_accuracy: 0.8034\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.8734 - val_loss: 0.5059 - val_accuracy: 0.8034\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8755 - val_loss: 0.5083 - val_accuracy: 0.8034\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8797 - val_loss: 0.5294 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 931us/step - loss: 0.4290 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1101 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5956 - accuracy: 0.7068 - val_loss: 0.5542 - val_accuracy: 0.7022\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7827 - val_loss: 0.5120 - val_accuracy: 0.7584\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8186 - val_loss: 0.4936 - val_accuracy: 0.7978\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8333 - val_loss: 0.4738 - val_accuracy: 0.8202\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8418 - val_loss: 0.4710 - val_accuracy: 0.8090\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3825 - accuracy: 0.8354 - val_loss: 0.4633 - val_accuracy: 0.8315\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8397 - val_loss: 0.4755 - val_accuracy: 0.8090\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8544 - val_loss: 0.4662 - val_accuracy: 0.8202\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8502 - val_loss: 0.4873 - val_accuracy: 0.8090\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8523 - val_loss: 0.4795 - val_accuracy: 0.8146\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8565 - val_loss: 0.4905 - val_accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8565 - val_loss: 0.4778 - val_accuracy: 0.8146\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8523 - val_loss: 0.4786 - val_accuracy: 0.8146\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8629 - val_loss: 0.5061 - val_accuracy: 0.8146\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8565 - val_loss: 0.5010 - val_accuracy: 0.8034\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3291 - accuracy: 0.8608 - val_loss: 0.4864 - val_accuracy: 0.8202\n",
      "8/8 [==============================] - 0s 781us/step - loss: 0.3913 - accuracy: 0.8354\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1105 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6147 - accuracy: 0.6181 - val_loss: 0.5727 - val_accuracy: 0.6798\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7932 - val_loss: 0.5291 - val_accuracy: 0.7528\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.8270 - val_loss: 0.5066 - val_accuracy: 0.7697\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8186 - val_loss: 0.5136 - val_accuracy: 0.7809\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8460 - val_loss: 0.4923 - val_accuracy: 0.7809\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8312 - val_loss: 0.5247 - val_accuracy: 0.7753\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8207 - val_loss: 0.5151 - val_accuracy: 0.7528\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8544 - val_loss: 0.5146 - val_accuracy: 0.7809\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3601 - accuracy: 0.8418 - val_loss: 0.5130 - val_accuracy: 0.7809\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8523 - val_loss: 0.5509 - val_accuracy: 0.7360\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.8544 - val_loss: 0.5458 - val_accuracy: 0.7753\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8544 - val_loss: 0.5521 - val_accuracy: 0.7640\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8671 - val_loss: 0.5878 - val_accuracy: 0.7416\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8418 - val_loss: 0.5849 - val_accuracy: 0.7528\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.8776 - val_loss: 0.6007 - val_accuracy: 0.7640\n",
      "8/8 [==============================] - 0s 876us/step - loss: 0.4718 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1109 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0269 - accuracy: 0.2532 - val_loss: 0.9999 - val_accuracy: 0.3034\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9975 - accuracy: 0.2532 - val_loss: 0.9732 - val_accuracy: 0.2921\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9695 - accuracy: 0.2595 - val_loss: 0.9479 - val_accuracy: 0.3034\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9434 - accuracy: 0.2743 - val_loss: 0.9239 - val_accuracy: 0.3034\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9184 - accuracy: 0.2806 - val_loss: 0.9011 - val_accuracy: 0.3034\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8947 - accuracy: 0.2869 - val_loss: 0.8803 - val_accuracy: 0.3090\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8728 - accuracy: 0.3101 - val_loss: 0.8606 - val_accuracy: 0.3258\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8521 - accuracy: 0.3418 - val_loss: 0.8422 - val_accuracy: 0.3146\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8324 - accuracy: 0.3544 - val_loss: 0.8252 - val_accuracy: 0.3371\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8146 - accuracy: 0.3544 - val_loss: 0.8089 - val_accuracy: 0.3427\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7968 - accuracy: 0.3692 - val_loss: 0.7945 - val_accuracy: 0.3427\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7815 - accuracy: 0.3987 - val_loss: 0.7801 - val_accuracy: 0.3989\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7662 - accuracy: 0.4536 - val_loss: 0.7669 - val_accuracy: 0.4607\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7517 - accuracy: 0.5105 - val_loss: 0.7549 - val_accuracy: 0.5056\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.5380 - val_loss: 0.7433 - val_accuracy: 0.5169\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7261 - accuracy: 0.5464 - val_loss: 0.7325 - val_accuracy: 0.5281\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7144 - accuracy: 0.5591 - val_loss: 0.7225 - val_accuracy: 0.5562\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7033 - accuracy: 0.5633 - val_loss: 0.7132 - val_accuracy: 0.5730\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5759 - val_loss: 0.7044 - val_accuracy: 0.5787\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5992 - val_loss: 0.6959 - val_accuracy: 0.6180\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.6203 - val_loss: 0.6882 - val_accuracy: 0.6292\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.6287 - val_loss: 0.6809 - val_accuracy: 0.6348\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6392 - val_loss: 0.6740 - val_accuracy: 0.6404\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6414 - val_loss: 0.6671 - val_accuracy: 0.6404\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.6435 - val_loss: 0.6608 - val_accuracy: 0.6348\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.6498 - val_loss: 0.6548 - val_accuracy: 0.6348\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6498 - val_loss: 0.6490 - val_accuracy: 0.6348\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6456 - val_loss: 0.6435 - val_accuracy: 0.6292\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.6477 - val_loss: 0.6382 - val_accuracy: 0.6292\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6498 - val_loss: 0.6330 - val_accuracy: 0.6461\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.6519 - val_loss: 0.6284 - val_accuracy: 0.6461\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6519 - val_loss: 0.6237 - val_accuracy: 0.6461\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.6561 - val_loss: 0.6189 - val_accuracy: 0.6517\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.6603 - val_loss: 0.6147 - val_accuracy: 0.6517\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.6688 - val_loss: 0.6104 - val_accuracy: 0.6573\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.6709 - val_loss: 0.6066 - val_accuracy: 0.6573\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.6730 - val_loss: 0.6028 - val_accuracy: 0.6629\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.6793 - val_loss: 0.5991 - val_accuracy: 0.6685\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.6814 - val_loss: 0.5953 - val_accuracy: 0.6685\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.6857 - val_loss: 0.5918 - val_accuracy: 0.6685\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.6941 - val_loss: 0.5884 - val_accuracy: 0.6742\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.6983 - val_loss: 0.5852 - val_accuracy: 0.6742\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7068 - val_loss: 0.5822 - val_accuracy: 0.6854\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7131 - val_loss: 0.5791 - val_accuracy: 0.6798\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7194 - val_loss: 0.5761 - val_accuracy: 0.6798\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7278 - val_loss: 0.5734 - val_accuracy: 0.6798\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7300 - val_loss: 0.5704 - val_accuracy: 0.6854\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7321 - val_loss: 0.5679 - val_accuracy: 0.6798\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7384 - val_loss: 0.5652 - val_accuracy: 0.6798\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7384 - val_loss: 0.5627 - val_accuracy: 0.6854\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7447 - val_loss: 0.5602 - val_accuracy: 0.7022\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7468 - val_loss: 0.5579 - val_accuracy: 0.7022\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7447 - val_loss: 0.5558 - val_accuracy: 0.7079\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7468 - val_loss: 0.5533 - val_accuracy: 0.7079\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7511 - val_loss: 0.5514 - val_accuracy: 0.7135\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7511 - val_loss: 0.5491 - val_accuracy: 0.7135\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7532 - val_loss: 0.5473 - val_accuracy: 0.7135\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7595 - val_loss: 0.5453 - val_accuracy: 0.7135\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7616 - val_loss: 0.5436 - val_accuracy: 0.7191\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7616 - val_loss: 0.5418 - val_accuracy: 0.7191\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7658 - val_loss: 0.5399 - val_accuracy: 0.7191\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7700 - val_loss: 0.5383 - val_accuracy: 0.7247\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7743 - val_loss: 0.5366 - val_accuracy: 0.7303\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7785 - val_loss: 0.5348 - val_accuracy: 0.7360\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7806 - val_loss: 0.5334 - val_accuracy: 0.7360\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7827 - val_loss: 0.5317 - val_accuracy: 0.7416\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7890 - val_loss: 0.5301 - val_accuracy: 0.7360\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7932 - val_loss: 0.5286 - val_accuracy: 0.7360\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7932 - val_loss: 0.5273 - val_accuracy: 0.7360\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7954 - val_loss: 0.5259 - val_accuracy: 0.7416\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7975 - val_loss: 0.5248 - val_accuracy: 0.7528\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7975 - val_loss: 0.5233 - val_accuracy: 0.7528\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7975 - val_loss: 0.5220 - val_accuracy: 0.7472\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7996 - val_loss: 0.5208 - val_accuracy: 0.7472\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8038 - val_loss: 0.5197 - val_accuracy: 0.7472\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8059 - val_loss: 0.5186 - val_accuracy: 0.7528\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8080 - val_loss: 0.5174 - val_accuracy: 0.7528\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8080 - val_loss: 0.5161 - val_accuracy: 0.7528\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.8101 - val_loss: 0.5151 - val_accuracy: 0.7472\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8080 - val_loss: 0.5139 - val_accuracy: 0.7528\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8080 - val_loss: 0.5132 - val_accuracy: 0.7528\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8101 - val_loss: 0.5119 - val_accuracy: 0.7697\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.8101 - val_loss: 0.5112 - val_accuracy: 0.7697\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8101 - val_loss: 0.5101 - val_accuracy: 0.7640\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8101 - val_loss: 0.5090 - val_accuracy: 0.7753\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8101 - val_loss: 0.5082 - val_accuracy: 0.7753\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8059 - val_loss: 0.5073 - val_accuracy: 0.7753\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8059 - val_loss: 0.5066 - val_accuracy: 0.7753\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8059 - val_loss: 0.5057 - val_accuracy: 0.7809\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8059 - val_loss: 0.5047 - val_accuracy: 0.7865\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8080 - val_loss: 0.5040 - val_accuracy: 0.7865\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8080 - val_loss: 0.5032 - val_accuracy: 0.7865\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8101 - val_loss: 0.5026 - val_accuracy: 0.7865\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8101 - val_loss: 0.5018 - val_accuracy: 0.7921\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8101 - val_loss: 0.5011 - val_accuracy: 0.7978\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8228 - val_loss: 0.5004 - val_accuracy: 0.8034\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8249 - val_loss: 0.4998 - val_accuracy: 0.8034\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8228 - val_loss: 0.4992 - val_accuracy: 0.8034\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.8249 - val_loss: 0.4985 - val_accuracy: 0.8034\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.4979 - val_accuracy: 0.8034\n",
      "8/8 [==============================] - 0s 783us/step - loss: 0.4925 - accuracy: 0.7848\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1110 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.8990 - accuracy: 0.3903 - val_loss: 0.8880 - val_accuracy: 0.3820\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8723 - accuracy: 0.3945 - val_loss: 0.8629 - val_accuracy: 0.3820\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8473 - accuracy: 0.3882 - val_loss: 0.8395 - val_accuracy: 0.3876\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8234 - accuracy: 0.3945 - val_loss: 0.8177 - val_accuracy: 0.3933\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8010 - accuracy: 0.3924 - val_loss: 0.7976 - val_accuracy: 0.3989\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7802 - accuracy: 0.3945 - val_loss: 0.7788 - val_accuracy: 0.3989\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7608 - accuracy: 0.3966 - val_loss: 0.7613 - val_accuracy: 0.3876\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7430 - accuracy: 0.4093 - val_loss: 0.7448 - val_accuracy: 0.4157\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7264 - accuracy: 0.4451 - val_loss: 0.7296 - val_accuracy: 0.4326\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7107 - accuracy: 0.4937 - val_loss: 0.7159 - val_accuracy: 0.5169\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6973 - accuracy: 0.5295 - val_loss: 0.7025 - val_accuracy: 0.5112\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5570 - val_loss: 0.6911 - val_accuracy: 0.5112\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.5633 - val_loss: 0.6806 - val_accuracy: 0.5169\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.5781 - val_loss: 0.6709 - val_accuracy: 0.5449\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.5992 - val_loss: 0.6621 - val_accuracy: 0.5955\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.6414 - val_loss: 0.6535 - val_accuracy: 0.6292\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6878 - val_loss: 0.6457 - val_accuracy: 0.6854\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.7405 - val_loss: 0.6387 - val_accuracy: 0.7135\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.7553 - val_loss: 0.6323 - val_accuracy: 0.7303\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.7616 - val_loss: 0.6263 - val_accuracy: 0.7247\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.7595 - val_loss: 0.6205 - val_accuracy: 0.7247\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7553 - val_loss: 0.6157 - val_accuracy: 0.7303\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.7553 - val_loss: 0.6107 - val_accuracy: 0.7191\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7553 - val_loss: 0.6061 - val_accuracy: 0.7247\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7553 - val_loss: 0.6020 - val_accuracy: 0.7247\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7532 - val_loss: 0.5982 - val_accuracy: 0.7247\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7532 - val_loss: 0.5944 - val_accuracy: 0.7247\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7553 - val_loss: 0.5910 - val_accuracy: 0.7247\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.7553 - val_loss: 0.5879 - val_accuracy: 0.7191\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7553 - val_loss: 0.5847 - val_accuracy: 0.7135\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7574 - val_loss: 0.5819 - val_accuracy: 0.7135\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7574 - val_loss: 0.5790 - val_accuracy: 0.7135\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7574 - val_loss: 0.5763 - val_accuracy: 0.7191\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7574 - val_loss: 0.5738 - val_accuracy: 0.7247\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7595 - val_loss: 0.5715 - val_accuracy: 0.7303\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7595 - val_loss: 0.5692 - val_accuracy: 0.7303\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7637 - val_loss: 0.5671 - val_accuracy: 0.7360\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7637 - val_loss: 0.5649 - val_accuracy: 0.7360\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7658 - val_loss: 0.5628 - val_accuracy: 0.7360\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7700 - val_loss: 0.5609 - val_accuracy: 0.7416\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7722 - val_loss: 0.5591 - val_accuracy: 0.7416\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7743 - val_loss: 0.5572 - val_accuracy: 0.7416\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7743 - val_loss: 0.5553 - val_accuracy: 0.7416\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7764 - val_loss: 0.5536 - val_accuracy: 0.7416\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7743 - val_loss: 0.5520 - val_accuracy: 0.7472\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7785 - val_loss: 0.5503 - val_accuracy: 0.7584\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7806 - val_loss: 0.5488 - val_accuracy: 0.7584\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7827 - val_loss: 0.5472 - val_accuracy: 0.7584\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7869 - val_loss: 0.5458 - val_accuracy: 0.7584\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7869 - val_loss: 0.5444 - val_accuracy: 0.7640\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7869 - val_loss: 0.5430 - val_accuracy: 0.7640\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7911 - val_loss: 0.5416 - val_accuracy: 0.7697\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7911 - val_loss: 0.5403 - val_accuracy: 0.7753\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7911 - val_loss: 0.5390 - val_accuracy: 0.7753\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7890 - val_loss: 0.5378 - val_accuracy: 0.7753\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7890 - val_loss: 0.5366 - val_accuracy: 0.7809\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7890 - val_loss: 0.5354 - val_accuracy: 0.7809\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7890 - val_loss: 0.5343 - val_accuracy: 0.7865\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7890 - val_loss: 0.5331 - val_accuracy: 0.7865\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7911 - val_loss: 0.5319 - val_accuracy: 0.7865\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7975 - val_loss: 0.5308 - val_accuracy: 0.7865\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7996 - val_loss: 0.5298 - val_accuracy: 0.7809\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7996 - val_loss: 0.5288 - val_accuracy: 0.7809\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7996 - val_loss: 0.5279 - val_accuracy: 0.7809\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7975 - val_loss: 0.5270 - val_accuracy: 0.7809\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7975 - val_loss: 0.5261 - val_accuracy: 0.7809\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7954 - val_loss: 0.5252 - val_accuracy: 0.7809\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7954 - val_loss: 0.5242 - val_accuracy: 0.7865\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7954 - val_loss: 0.5233 - val_accuracy: 0.7865\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7954 - val_loss: 0.5224 - val_accuracy: 0.7921\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7954 - val_loss: 0.5216 - val_accuracy: 0.7921\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7954 - val_loss: 0.5208 - val_accuracy: 0.7921\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7975 - val_loss: 0.5201 - val_accuracy: 0.7921\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7996 - val_loss: 0.5192 - val_accuracy: 0.7921\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7996 - val_loss: 0.5185 - val_accuracy: 0.7921\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7996 - val_loss: 0.5177 - val_accuracy: 0.7921\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7996 - val_loss: 0.5170 - val_accuracy: 0.7921\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7996 - val_loss: 0.5163 - val_accuracy: 0.7921\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7996 - val_loss: 0.5155 - val_accuracy: 0.7921\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7996 - val_loss: 0.5149 - val_accuracy: 0.7921\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8038 - val_loss: 0.5141 - val_accuracy: 0.7921\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8038 - val_loss: 0.5135 - val_accuracy: 0.7921\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8038 - val_loss: 0.5129 - val_accuracy: 0.7921\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7921\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7921\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.8038 - val_loss: 0.5109 - val_accuracy: 0.7921\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8038 - val_loss: 0.5103 - val_accuracy: 0.7921\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8038 - val_loss: 0.5098 - val_accuracy: 0.7921\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7921\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7921\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8038 - val_loss: 0.5080 - val_accuracy: 0.7921\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8038 - val_loss: 0.5074 - val_accuracy: 0.7921\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8038 - val_loss: 0.5070 - val_accuracy: 0.7921\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.8038 - val_loss: 0.5065 - val_accuracy: 0.7921\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.8059 - val_loss: 0.5059 - val_accuracy: 0.7921\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.8059 - val_loss: 0.5055 - val_accuracy: 0.7921\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8059 - val_loss: 0.5049 - val_accuracy: 0.7921\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.8059 - val_loss: 0.5044 - val_accuracy: 0.7978\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8059 - val_loss: 0.5040 - val_accuracy: 0.7978\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8059 - val_loss: 0.5034 - val_accuracy: 0.7978\n",
      "8/8 [==============================] - 0s 830us/step - loss: 0.4502 - accuracy: 0.8017\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1111 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.7607 - accuracy: 0.4557 - val_loss: 0.7294 - val_accuracy: 0.4888\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7405 - accuracy: 0.4662 - val_loss: 0.7131 - val_accuracy: 0.5506\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7227 - accuracy: 0.4768 - val_loss: 0.6981 - val_accuracy: 0.5562\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7051 - accuracy: 0.5148 - val_loss: 0.6854 - val_accuracy: 0.5730\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5443 - val_loss: 0.6734 - val_accuracy: 0.6067\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.5612 - val_loss: 0.6629 - val_accuracy: 0.6292\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.6034 - val_loss: 0.6536 - val_accuracy: 0.6573\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6350 - val_loss: 0.6451 - val_accuracy: 0.6742\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6414 - val_loss: 0.6376 - val_accuracy: 0.6742\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.6582 - val_loss: 0.6311 - val_accuracy: 0.6798\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6603 - val_loss: 0.6255 - val_accuracy: 0.6685\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.6730 - val_loss: 0.6201 - val_accuracy: 0.6798\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6920 - val_loss: 0.6156 - val_accuracy: 0.6742\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.6920 - val_loss: 0.6113 - val_accuracy: 0.6798\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.6983 - val_loss: 0.6076 - val_accuracy: 0.6742\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.7004 - val_loss: 0.6041 - val_accuracy: 0.6742\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.6941 - val_loss: 0.6012 - val_accuracy: 0.6742\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.6962 - val_loss: 0.5986 - val_accuracy: 0.6742\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7004 - val_loss: 0.5962 - val_accuracy: 0.6798\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7068 - val_loss: 0.5940 - val_accuracy: 0.6854\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7068 - val_loss: 0.5918 - val_accuracy: 0.6854\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7068 - val_loss: 0.5899 - val_accuracy: 0.6910\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7025 - val_loss: 0.5879 - val_accuracy: 0.6910\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7025 - val_loss: 0.5862 - val_accuracy: 0.6910\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7025 - val_loss: 0.5846 - val_accuracy: 0.6910\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7025 - val_loss: 0.5831 - val_accuracy: 0.6910\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7089 - val_loss: 0.5815 - val_accuracy: 0.6910\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7089 - val_loss: 0.5801 - val_accuracy: 0.6910\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7089 - val_loss: 0.5786 - val_accuracy: 0.6966\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7152 - val_loss: 0.5773 - val_accuracy: 0.7135\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7173 - val_loss: 0.5760 - val_accuracy: 0.7135\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7236 - val_loss: 0.5747 - val_accuracy: 0.7135\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7257 - val_loss: 0.5732 - val_accuracy: 0.7135\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7300 - val_loss: 0.5721 - val_accuracy: 0.7135\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7342 - val_loss: 0.5709 - val_accuracy: 0.7135\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7342 - val_loss: 0.5697 - val_accuracy: 0.7135\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7363 - val_loss: 0.5685 - val_accuracy: 0.7079\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7342 - val_loss: 0.5676 - val_accuracy: 0.7079\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7405 - val_loss: 0.5664 - val_accuracy: 0.7079\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7468 - val_loss: 0.5652 - val_accuracy: 0.7079\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7489 - val_loss: 0.5641 - val_accuracy: 0.7079\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7553 - val_loss: 0.5634 - val_accuracy: 0.7247\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7574 - val_loss: 0.5622 - val_accuracy: 0.7303\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7637 - val_loss: 0.5614 - val_accuracy: 0.7303\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7616 - val_loss: 0.5605 - val_accuracy: 0.7303\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7574 - val_loss: 0.5594 - val_accuracy: 0.7303\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7595 - val_loss: 0.5584 - val_accuracy: 0.7303\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7595 - val_loss: 0.5575 - val_accuracy: 0.7360\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7595 - val_loss: 0.5567 - val_accuracy: 0.7416\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7574 - val_loss: 0.5557 - val_accuracy: 0.7360\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7595 - val_loss: 0.5550 - val_accuracy: 0.7360\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7595 - val_loss: 0.5540 - val_accuracy: 0.7416\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7595 - val_loss: 0.5533 - val_accuracy: 0.7360\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7595 - val_loss: 0.5523 - val_accuracy: 0.7303\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7616 - val_loss: 0.5515 - val_accuracy: 0.7247\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7637 - val_loss: 0.5507 - val_accuracy: 0.7303\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7700 - val_loss: 0.5498 - val_accuracy: 0.7303\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7700 - val_loss: 0.5491 - val_accuracy: 0.7303\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7700 - val_loss: 0.5483 - val_accuracy: 0.7303\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7785 - val_loss: 0.5475 - val_accuracy: 0.7303\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7806 - val_loss: 0.5466 - val_accuracy: 0.7360\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7806 - val_loss: 0.5459 - val_accuracy: 0.7303\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7806 - val_loss: 0.5454 - val_accuracy: 0.7360\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7848 - val_loss: 0.5449 - val_accuracy: 0.7472\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7827 - val_loss: 0.5441 - val_accuracy: 0.7584\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7827 - val_loss: 0.5434 - val_accuracy: 0.7697\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7869 - val_loss: 0.5425 - val_accuracy: 0.7753\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7911 - val_loss: 0.5420 - val_accuracy: 0.7753\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7911 - val_loss: 0.5413 - val_accuracy: 0.7753\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.87 - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7911 - val_loss: 0.5406 - val_accuracy: 0.7753\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7932 - val_loss: 0.5399 - val_accuracy: 0.7753\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7911 - val_loss: 0.5393 - val_accuracy: 0.7753\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7890 - val_loss: 0.5387 - val_accuracy: 0.7865\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7911 - val_loss: 0.5381 - val_accuracy: 0.7865\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7911 - val_loss: 0.5375 - val_accuracy: 0.7865\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7911 - val_loss: 0.5369 - val_accuracy: 0.7865\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7911 - val_loss: 0.5362 - val_accuracy: 0.7865\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7911 - val_loss: 0.5358 - val_accuracy: 0.7865\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7911 - val_loss: 0.5354 - val_accuracy: 0.7865\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7911 - val_loss: 0.5347 - val_accuracy: 0.7865\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7932 - val_loss: 0.5339 - val_accuracy: 0.7865\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7932 - val_loss: 0.5334 - val_accuracy: 0.7865\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7932 - val_loss: 0.5329 - val_accuracy: 0.7865\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7932 - val_loss: 0.5325 - val_accuracy: 0.7809\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7954 - val_loss: 0.5318 - val_accuracy: 0.7809\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7954 - val_loss: 0.5312 - val_accuracy: 0.7865\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7954 - val_loss: 0.5308 - val_accuracy: 0.7865\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7954 - val_loss: 0.5305 - val_accuracy: 0.7865\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7954 - val_loss: 0.5299 - val_accuracy: 0.7865\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7954 - val_loss: 0.5295 - val_accuracy: 0.7865\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7954 - val_loss: 0.5290 - val_accuracy: 0.7865\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7954 - val_loss: 0.5283 - val_accuracy: 0.7865\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7954 - val_loss: 0.5278 - val_accuracy: 0.7921\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7954 - val_loss: 0.5274 - val_accuracy: 0.7921\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7954 - val_loss: 0.5272 - val_accuracy: 0.7921\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7954 - val_loss: 0.5267 - val_accuracy: 0.7921\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7954 - val_loss: 0.5261 - val_accuracy: 0.7921\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7954 - val_loss: 0.5256 - val_accuracy: 0.7921\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7954 - val_loss: 0.5253 - val_accuracy: 0.7921\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7954 - val_loss: 0.5249 - val_accuracy: 0.7921\n",
      "8/8 [==============================] - 0s 838us/step - loss: 0.4548 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1112 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6684 - accuracy: 0.6308 - val_loss: 0.6712 - val_accuracy: 0.6067\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6582 - val_loss: 0.6577 - val_accuracy: 0.6124\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6772 - val_loss: 0.6456 - val_accuracy: 0.6685\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6962 - val_loss: 0.6348 - val_accuracy: 0.6798\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.7194 - val_loss: 0.6252 - val_accuracy: 0.7079\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.7363 - val_loss: 0.6166 - val_accuracy: 0.7079\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.7468 - val_loss: 0.6089 - val_accuracy: 0.7135\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7574 - val_loss: 0.6018 - val_accuracy: 0.7416\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7658 - val_loss: 0.5954 - val_accuracy: 0.7472\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7679 - val_loss: 0.5897 - val_accuracy: 0.7360\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7658 - val_loss: 0.5846 - val_accuracy: 0.7360\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7658 - val_loss: 0.5797 - val_accuracy: 0.7360\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7616 - val_loss: 0.5754 - val_accuracy: 0.7303\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7595 - val_loss: 0.5715 - val_accuracy: 0.7247\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7658 - val_loss: 0.5675 - val_accuracy: 0.7247\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7764 - val_loss: 0.5641 - val_accuracy: 0.7247\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7764 - val_loss: 0.5608 - val_accuracy: 0.7247\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7806 - val_loss: 0.5576 - val_accuracy: 0.7247\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7806 - val_loss: 0.5545 - val_accuracy: 0.7303\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7848 - val_loss: 0.5516 - val_accuracy: 0.7303\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7932 - val_loss: 0.5489 - val_accuracy: 0.7303\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7975 - val_loss: 0.5462 - val_accuracy: 0.7472\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7975 - val_loss: 0.5439 - val_accuracy: 0.7528\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7975 - val_loss: 0.5415 - val_accuracy: 0.7528\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8017 - val_loss: 0.5390 - val_accuracy: 0.7584\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.8038 - val_loss: 0.5369 - val_accuracy: 0.7640\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.8101 - val_loss: 0.5347 - val_accuracy: 0.7640\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8122 - val_loss: 0.5327 - val_accuracy: 0.7697\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8122 - val_loss: 0.5306 - val_accuracy: 0.7753\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8122 - val_loss: 0.5287 - val_accuracy: 0.7753\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.8143 - val_loss: 0.5269 - val_accuracy: 0.7753\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8165 - val_loss: 0.5252 - val_accuracy: 0.7753\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8165 - val_loss: 0.5235 - val_accuracy: 0.7753\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8165 - val_loss: 0.5216 - val_accuracy: 0.7865\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.8165 - val_loss: 0.5201 - val_accuracy: 0.7921\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.8186 - val_loss: 0.5187 - val_accuracy: 0.7921\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8207 - val_loss: 0.5172 - val_accuracy: 0.7809\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8228 - val_loss: 0.5161 - val_accuracy: 0.7809\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8228 - val_loss: 0.5149 - val_accuracy: 0.7809\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.8249 - val_loss: 0.5134 - val_accuracy: 0.7809\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.8249 - val_loss: 0.5120 - val_accuracy: 0.7809\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8228 - val_loss: 0.5110 - val_accuracy: 0.7809\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8228 - val_loss: 0.5097 - val_accuracy: 0.7809\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8228 - val_loss: 0.5085 - val_accuracy: 0.7809\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.8207 - val_loss: 0.5074 - val_accuracy: 0.7809\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8207 - val_loss: 0.5064 - val_accuracy: 0.7809\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8207 - val_loss: 0.5053 - val_accuracy: 0.7865\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8207 - val_loss: 0.5044 - val_accuracy: 0.7865\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8207 - val_loss: 0.5034 - val_accuracy: 0.7865\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.8228 - val_loss: 0.5023 - val_accuracy: 0.7865\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.8249 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8249 - val_loss: 0.5008 - val_accuracy: 0.7921\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8249 - val_loss: 0.4998 - val_accuracy: 0.7921\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8291 - val_loss: 0.4990 - val_accuracy: 0.7921\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8291 - val_loss: 0.4982 - val_accuracy: 0.7921\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8312 - val_loss: 0.4977 - val_accuracy: 0.7921\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8333 - val_loss: 0.4967 - val_accuracy: 0.7921\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8354 - val_loss: 0.4961 - val_accuracy: 0.7921\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8354 - val_loss: 0.4956 - val_accuracy: 0.7921\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8354 - val_loss: 0.4948 - val_accuracy: 0.7921\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8333 - val_loss: 0.4942 - val_accuracy: 0.7921\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8333 - val_loss: 0.4936 - val_accuracy: 0.7921\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8333 - val_loss: 0.4929 - val_accuracy: 0.7809\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8354 - val_loss: 0.4924 - val_accuracy: 0.7809\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.8333 - val_loss: 0.4917 - val_accuracy: 0.7809\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8333 - val_loss: 0.4912 - val_accuracy: 0.7809\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8312 - val_loss: 0.4906 - val_accuracy: 0.7809\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8312 - val_loss: 0.4902 - val_accuracy: 0.7809\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8312 - val_loss: 0.4897 - val_accuracy: 0.7809\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8312 - val_loss: 0.4892 - val_accuracy: 0.7809\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8312 - val_loss: 0.4887 - val_accuracy: 0.7809\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8312 - val_loss: 0.4883 - val_accuracy: 0.7809\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8333 - val_loss: 0.4877 - val_accuracy: 0.7809\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8333 - val_loss: 0.4873 - val_accuracy: 0.7809\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8333 - val_loss: 0.4868 - val_accuracy: 0.7921\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8333 - val_loss: 0.4865 - val_accuracy: 0.7921\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8354 - val_loss: 0.4861 - val_accuracy: 0.7921\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8354 - val_loss: 0.4858 - val_accuracy: 0.7978\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8354 - val_loss: 0.4853 - val_accuracy: 0.7921\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8333 - val_loss: 0.4851 - val_accuracy: 0.7921\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8312 - val_loss: 0.4846 - val_accuracy: 0.7921\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8312 - val_loss: 0.4844 - val_accuracy: 0.7921\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8312 - val_loss: 0.4840 - val_accuracy: 0.7921\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8291 - val_loss: 0.4836 - val_accuracy: 0.7921\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8291 - val_loss: 0.4833 - val_accuracy: 0.7978\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8291 - val_loss: 0.4832 - val_accuracy: 0.7978\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8291 - val_loss: 0.4828 - val_accuracy: 0.7978\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8291 - val_loss: 0.4825 - val_accuracy: 0.7978\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8291 - val_loss: 0.4823 - val_accuracy: 0.7978\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8291 - val_loss: 0.4820 - val_accuracy: 0.7978\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8291 - val_loss: 0.4816 - val_accuracy: 0.7978\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8312 - val_loss: 0.4813 - val_accuracy: 0.7978\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8291 - val_loss: 0.4810 - val_accuracy: 0.7978\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8291 - val_loss: 0.4810 - val_accuracy: 0.7978\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8291 - val_loss: 0.4806 - val_accuracy: 0.7978\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8291 - val_loss: 0.4804 - val_accuracy: 0.7978\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8291 - val_loss: 0.4805 - val_accuracy: 0.7978\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8291 - val_loss: 0.4799 - val_accuracy: 0.7978\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8291 - val_loss: 0.4798 - val_accuracy: 0.7978\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8291 - val_loss: 0.4796 - val_accuracy: 0.7978\n",
      "8/8 [==============================] - 0s 831us/step - loss: 0.4629 - accuracy: 0.7848\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1113 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7234 - accuracy: 0.4705 - val_loss: 0.6898 - val_accuracy: 0.5787\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7099 - accuracy: 0.5802 - val_loss: 0.6786 - val_accuracy: 0.6348\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.6076 - val_loss: 0.6682 - val_accuracy: 0.6517\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.6224 - val_loss: 0.6589 - val_accuracy: 0.6461\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.6203 - val_loss: 0.6502 - val_accuracy: 0.6461\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.6224 - val_loss: 0.6422 - val_accuracy: 0.6517\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6224 - val_loss: 0.6351 - val_accuracy: 0.6461\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6224 - val_loss: 0.6283 - val_accuracy: 0.6461\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6266 - val_loss: 0.6223 - val_accuracy: 0.6517\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.6245 - val_loss: 0.6166 - val_accuracy: 0.6517\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6392 - val_loss: 0.6116 - val_accuracy: 0.6742\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.6603 - val_loss: 0.6069 - val_accuracy: 0.6798\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6730 - val_loss: 0.6021 - val_accuracy: 0.6854\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.6730 - val_loss: 0.5981 - val_accuracy: 0.6854\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.6772 - val_loss: 0.5941 - val_accuracy: 0.6854\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6772 - val_loss: 0.5899 - val_accuracy: 0.6910\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.6772 - val_loss: 0.5862 - val_accuracy: 0.6910\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.6814 - val_loss: 0.5828 - val_accuracy: 0.6854\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.6793 - val_loss: 0.5793 - val_accuracy: 0.6854\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.6793 - val_loss: 0.5761 - val_accuracy: 0.6910\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.6857 - val_loss: 0.5730 - val_accuracy: 0.7022\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.6878 - val_loss: 0.5700 - val_accuracy: 0.7079\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.6899 - val_loss: 0.5671 - val_accuracy: 0.7079\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.6983 - val_loss: 0.5643 - val_accuracy: 0.7022\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7068 - val_loss: 0.5616 - val_accuracy: 0.7022\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7110 - val_loss: 0.5591 - val_accuracy: 0.7079\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.7257 - val_loss: 0.5564 - val_accuracy: 0.7135\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7321 - val_loss: 0.5541 - val_accuracy: 0.7135\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7321 - val_loss: 0.5518 - val_accuracy: 0.7135\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7321 - val_loss: 0.5494 - val_accuracy: 0.7191\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7426 - val_loss: 0.5471 - val_accuracy: 0.7303\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7426 - val_loss: 0.5452 - val_accuracy: 0.7303\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7426 - val_loss: 0.5431 - val_accuracy: 0.7360\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7447 - val_loss: 0.5412 - val_accuracy: 0.7360\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7447 - val_loss: 0.5392 - val_accuracy: 0.7360\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7468 - val_loss: 0.5373 - val_accuracy: 0.7360\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7489 - val_loss: 0.5355 - val_accuracy: 0.7360\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7553 - val_loss: 0.5337 - val_accuracy: 0.7416\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7616 - val_loss: 0.5319 - val_accuracy: 0.7416\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7637 - val_loss: 0.5303 - val_accuracy: 0.7416\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7637 - val_loss: 0.5287 - val_accuracy: 0.7472\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7658 - val_loss: 0.5272 - val_accuracy: 0.7472\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7658 - val_loss: 0.5256 - val_accuracy: 0.7472\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7722 - val_loss: 0.5241 - val_accuracy: 0.7472\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7764 - val_loss: 0.5228 - val_accuracy: 0.7528\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7827 - val_loss: 0.5214 - val_accuracy: 0.7528\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7848 - val_loss: 0.5199 - val_accuracy: 0.7472\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7869 - val_loss: 0.5188 - val_accuracy: 0.7584\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7869 - val_loss: 0.5175 - val_accuracy: 0.7584\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7848 - val_loss: 0.5161 - val_accuracy: 0.7640\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7848 - val_loss: 0.5151 - val_accuracy: 0.7697\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7848 - val_loss: 0.5138 - val_accuracy: 0.7697\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7848 - val_loss: 0.5126 - val_accuracy: 0.7697\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7848 - val_loss: 0.5116 - val_accuracy: 0.7697\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7848 - val_loss: 0.5105 - val_accuracy: 0.7697\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7890 - val_loss: 0.5096 - val_accuracy: 0.7809\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7890 - val_loss: 0.5085 - val_accuracy: 0.7753\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7911 - val_loss: 0.5075 - val_accuracy: 0.7753\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7932 - val_loss: 0.5066 - val_accuracy: 0.7865\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8080 - val_loss: 0.5056 - val_accuracy: 0.7865\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8059 - val_loss: 0.5048 - val_accuracy: 0.7865\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8080 - val_loss: 0.5039 - val_accuracy: 0.7865\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8080 - val_loss: 0.5031 - val_accuracy: 0.7809\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8101 - val_loss: 0.5022 - val_accuracy: 0.7809\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8080 - val_loss: 0.5014 - val_accuracy: 0.7809\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8101 - val_loss: 0.5007 - val_accuracy: 0.7865\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.8101 - val_loss: 0.4999 - val_accuracy: 0.7921\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.8080 - val_loss: 0.4992 - val_accuracy: 0.7921\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8101 - val_loss: 0.4985 - val_accuracy: 0.7921\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8122 - val_loss: 0.4977 - val_accuracy: 0.7921\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8143 - val_loss: 0.4970 - val_accuracy: 0.7921\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.8143 - val_loss: 0.4965 - val_accuracy: 0.7921\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.8143 - val_loss: 0.4958 - val_accuracy: 0.7921\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.8143 - val_loss: 0.4951 - val_accuracy: 0.7921\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8165 - val_loss: 0.4945 - val_accuracy: 0.7921\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8165 - val_loss: 0.4939 - val_accuracy: 0.7921\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.8143 - val_loss: 0.4933 - val_accuracy: 0.7921\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8143 - val_loss: 0.4927 - val_accuracy: 0.7921\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8165 - val_loss: 0.4923 - val_accuracy: 0.7921\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8207 - val_loss: 0.4916 - val_accuracy: 0.7865\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8207 - val_loss: 0.4911 - val_accuracy: 0.7865\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8207 - val_loss: 0.4908 - val_accuracy: 0.7865\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8207 - val_loss: 0.4903 - val_accuracy: 0.7865\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8186 - val_loss: 0.4897 - val_accuracy: 0.7865\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8186 - val_loss: 0.4893 - val_accuracy: 0.7865\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8186 - val_loss: 0.4889 - val_accuracy: 0.7865\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8207 - val_loss: 0.4884 - val_accuracy: 0.7809\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8207 - val_loss: 0.4879 - val_accuracy: 0.7809\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8207 - val_loss: 0.4875 - val_accuracy: 0.7809\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8186 - val_loss: 0.4872 - val_accuracy: 0.7809\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8165 - val_loss: 0.4867 - val_accuracy: 0.7753\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8165 - val_loss: 0.4865 - val_accuracy: 0.7753\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8165 - val_loss: 0.4861 - val_accuracy: 0.7809\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8165 - val_loss: 0.4856 - val_accuracy: 0.7809\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8165 - val_loss: 0.4853 - val_accuracy: 0.7809\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.8143 - val_loss: 0.4849 - val_accuracy: 0.7753\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8143 - val_loss: 0.4845 - val_accuracy: 0.7753\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8143 - val_loss: 0.4844 - val_accuracy: 0.7809\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8143 - val_loss: 0.4839 - val_accuracy: 0.7809\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8165 - val_loss: 0.4836 - val_accuracy: 0.7809\n",
      "8/8 [==============================] - 0s 731us/step - loss: 0.4388 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1114 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.6678 - accuracy: 0.6350 - val_loss: 0.7368 - val_accuracy: 0.5506\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6582 - val_loss: 0.7228 - val_accuracy: 0.5843\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.6793 - val_loss: 0.7101 - val_accuracy: 0.5955\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6835 - val_loss: 0.6983 - val_accuracy: 0.6292\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.6920 - val_loss: 0.6884 - val_accuracy: 0.6517\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6941 - val_loss: 0.6791 - val_accuracy: 0.6573\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.7046 - val_loss: 0.6708 - val_accuracy: 0.6685\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.7194 - val_loss: 0.6631 - val_accuracy: 0.6573\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7278 - val_loss: 0.6563 - val_accuracy: 0.6798\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7300 - val_loss: 0.6499 - val_accuracy: 0.6629\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.7321 - val_loss: 0.6441 - val_accuracy: 0.6685\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7300 - val_loss: 0.6387 - val_accuracy: 0.6798\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7278 - val_loss: 0.6338 - val_accuracy: 0.6742\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7278 - val_loss: 0.6288 - val_accuracy: 0.6798\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7278 - val_loss: 0.6246 - val_accuracy: 0.6685\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7152 - val_loss: 0.6206 - val_accuracy: 0.6685\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7131 - val_loss: 0.6168 - val_accuracy: 0.6685\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7131 - val_loss: 0.6130 - val_accuracy: 0.6742\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7152 - val_loss: 0.6095 - val_accuracy: 0.6742\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7173 - val_loss: 0.6063 - val_accuracy: 0.6742\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7131 - val_loss: 0.6031 - val_accuracy: 0.6742\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7131 - val_loss: 0.6002 - val_accuracy: 0.6685\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7173 - val_loss: 0.5969 - val_accuracy: 0.6685\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7194 - val_loss: 0.5941 - val_accuracy: 0.6742\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7236 - val_loss: 0.5914 - val_accuracy: 0.6798\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7321 - val_loss: 0.5887 - val_accuracy: 0.6854\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7426 - val_loss: 0.5862 - val_accuracy: 0.6910\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7468 - val_loss: 0.5835 - val_accuracy: 0.6910\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7489 - val_loss: 0.5812 - val_accuracy: 0.6966\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7489 - val_loss: 0.5790 - val_accuracy: 0.6966\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7574 - val_loss: 0.5764 - val_accuracy: 0.7022\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7637 - val_loss: 0.5740 - val_accuracy: 0.7022\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7700 - val_loss: 0.5719 - val_accuracy: 0.7022\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7743 - val_loss: 0.5696 - val_accuracy: 0.7079\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7827 - val_loss: 0.5677 - val_accuracy: 0.7191\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7848 - val_loss: 0.5656 - val_accuracy: 0.7191\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7827 - val_loss: 0.5638 - val_accuracy: 0.7191\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7890 - val_loss: 0.5619 - val_accuracy: 0.7191\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7890 - val_loss: 0.5601 - val_accuracy: 0.7191\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7890 - val_loss: 0.5582 - val_accuracy: 0.7191\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7869 - val_loss: 0.5564 - val_accuracy: 0.7191\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7932 - val_loss: 0.5545 - val_accuracy: 0.7191\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7932 - val_loss: 0.5531 - val_accuracy: 0.7191\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8017 - val_loss: 0.5514 - val_accuracy: 0.7191\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8017 - val_loss: 0.5498 - val_accuracy: 0.7191\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7996 - val_loss: 0.5482 - val_accuracy: 0.7191\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7954 - val_loss: 0.5468 - val_accuracy: 0.7135\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7954 - val_loss: 0.5451 - val_accuracy: 0.7191\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7954 - val_loss: 0.5436 - val_accuracy: 0.7191\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7954 - val_loss: 0.5423 - val_accuracy: 0.7191\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7975 - val_loss: 0.5411 - val_accuracy: 0.7135\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7975 - val_loss: 0.5398 - val_accuracy: 0.7135\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7996 - val_loss: 0.5386 - val_accuracy: 0.7135\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8017 - val_loss: 0.5372 - val_accuracy: 0.7135\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.8017 - val_loss: 0.5360 - val_accuracy: 0.7135\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8017 - val_loss: 0.5349 - val_accuracy: 0.7135\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.8017 - val_loss: 0.5337 - val_accuracy: 0.7191\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.8017 - val_loss: 0.5326 - val_accuracy: 0.7135\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.8017 - val_loss: 0.5314 - val_accuracy: 0.7135\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.8017 - val_loss: 0.5304 - val_accuracy: 0.7135\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.8059 - val_loss: 0.5293 - val_accuracy: 0.7360\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8059 - val_loss: 0.5282 - val_accuracy: 0.7360\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8101 - val_loss: 0.5273 - val_accuracy: 0.7360\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8101 - val_loss: 0.5259 - val_accuracy: 0.7360\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8122 - val_loss: 0.5249 - val_accuracy: 0.7472\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.8122 - val_loss: 0.5240 - val_accuracy: 0.7472\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8101 - val_loss: 0.5232 - val_accuracy: 0.7472\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.8059 - val_loss: 0.5222 - val_accuracy: 0.7528\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.8059 - val_loss: 0.5212 - val_accuracy: 0.7584\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.8059 - val_loss: 0.5204 - val_accuracy: 0.7584\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.8059 - val_loss: 0.5195 - val_accuracy: 0.7584\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.8080 - val_loss: 0.5186 - val_accuracy: 0.7584\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8080 - val_loss: 0.5181 - val_accuracy: 0.7584\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8080 - val_loss: 0.5172 - val_accuracy: 0.7584\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8080 - val_loss: 0.5166 - val_accuracy: 0.7640\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8080 - val_loss: 0.5158 - val_accuracy: 0.7640\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8080 - val_loss: 0.5151 - val_accuracy: 0.7640\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8080 - val_loss: 0.5145 - val_accuracy: 0.7640\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8101 - val_loss: 0.5136 - val_accuracy: 0.7640\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.8101 - val_loss: 0.5129 - val_accuracy: 0.7584\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8101 - val_loss: 0.5123 - val_accuracy: 0.7584\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8080 - val_loss: 0.5117 - val_accuracy: 0.7640\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8101 - val_loss: 0.5110 - val_accuracy: 0.7640\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.8165 - val_loss: 0.5103 - val_accuracy: 0.7640\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8165 - val_loss: 0.5098 - val_accuracy: 0.7640\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8165 - val_loss: 0.5092 - val_accuracy: 0.7640\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8165 - val_loss: 0.5086 - val_accuracy: 0.7640\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8165 - val_loss: 0.5080 - val_accuracy: 0.7640\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8207 - val_loss: 0.5075 - val_accuracy: 0.7697\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8207 - val_loss: 0.5070 - val_accuracy: 0.7697\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8207 - val_loss: 0.5064 - val_accuracy: 0.7697\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8186 - val_loss: 0.5060 - val_accuracy: 0.7697\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8186 - val_loss: 0.5053 - val_accuracy: 0.7753\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8207 - val_loss: 0.5047 - val_accuracy: 0.7809\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8186 - val_loss: 0.5042 - val_accuracy: 0.7865\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8186 - val_loss: 0.5038 - val_accuracy: 0.7865\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8186 - val_loss: 0.5034 - val_accuracy: 0.7865\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8186 - val_loss: 0.5029 - val_accuracy: 0.7865\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8165 - val_loss: 0.5026 - val_accuracy: 0.7809\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8165 - val_loss: 0.5023 - val_accuracy: 0.7809\n",
      "8/8 [==============================] - 0s 780us/step - loss: 0.4328 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1115 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6686 - accuracy: 0.6097 - val_loss: 0.7003 - val_accuracy: 0.5955\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.6329 - val_loss: 0.6926 - val_accuracy: 0.6067\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6498 - val_loss: 0.6847 - val_accuracy: 0.6180\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.6519 - val_loss: 0.6774 - val_accuracy: 0.6236\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6582 - val_loss: 0.6704 - val_accuracy: 0.6236\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6688 - val_loss: 0.6635 - val_accuracy: 0.6292\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6793 - val_loss: 0.6573 - val_accuracy: 0.6348\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.6793 - val_loss: 0.6509 - val_accuracy: 0.6461\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6814 - val_loss: 0.6451 - val_accuracy: 0.6517\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6793 - val_loss: 0.6393 - val_accuracy: 0.6461\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.6835 - val_loss: 0.6338 - val_accuracy: 0.6461\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.6835 - val_loss: 0.6284 - val_accuracy: 0.6461\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.6857 - val_loss: 0.6230 - val_accuracy: 0.6461\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.6941 - val_loss: 0.6183 - val_accuracy: 0.6517\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7025 - val_loss: 0.6134 - val_accuracy: 0.6517\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7089 - val_loss: 0.6083 - val_accuracy: 0.6573\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7152 - val_loss: 0.6036 - val_accuracy: 0.6629\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7257 - val_loss: 0.5993 - val_accuracy: 0.6742\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7321 - val_loss: 0.5954 - val_accuracy: 0.6798\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7363 - val_loss: 0.5916 - val_accuracy: 0.6854\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7426 - val_loss: 0.5874 - val_accuracy: 0.6854\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7511 - val_loss: 0.5838 - val_accuracy: 0.6910\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7553 - val_loss: 0.5797 - val_accuracy: 0.7022\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7595 - val_loss: 0.5763 - val_accuracy: 0.7079\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7658 - val_loss: 0.5730 - val_accuracy: 0.7135\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7658 - val_loss: 0.5695 - val_accuracy: 0.7135\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7700 - val_loss: 0.5660 - val_accuracy: 0.7135\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7700 - val_loss: 0.5632 - val_accuracy: 0.7191\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7743 - val_loss: 0.5603 - val_accuracy: 0.7191\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7743 - val_loss: 0.5572 - val_accuracy: 0.7135\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7743 - val_loss: 0.5546 - val_accuracy: 0.7135\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7743 - val_loss: 0.5518 - val_accuracy: 0.7135\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7785 - val_loss: 0.5494 - val_accuracy: 0.7135\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7785 - val_loss: 0.5469 - val_accuracy: 0.7247\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7785 - val_loss: 0.5444 - val_accuracy: 0.7247\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7806 - val_loss: 0.5420 - val_accuracy: 0.7303\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7827 - val_loss: 0.5401 - val_accuracy: 0.7303\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7848 - val_loss: 0.5377 - val_accuracy: 0.7360\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7911 - val_loss: 0.5356 - val_accuracy: 0.7360\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7932 - val_loss: 0.5335 - val_accuracy: 0.7360\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7911 - val_loss: 0.5314 - val_accuracy: 0.7360\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7911 - val_loss: 0.5297 - val_accuracy: 0.7360\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7932 - val_loss: 0.5280 - val_accuracy: 0.7416\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7932 - val_loss: 0.5260 - val_accuracy: 0.7416\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7954 - val_loss: 0.5242 - val_accuracy: 0.7416\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7996 - val_loss: 0.5227 - val_accuracy: 0.7416\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8017 - val_loss: 0.5210 - val_accuracy: 0.7416\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7996 - val_loss: 0.5197 - val_accuracy: 0.7416\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8017 - val_loss: 0.5180 - val_accuracy: 0.7416\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8038 - val_loss: 0.5165 - val_accuracy: 0.7528\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8038 - val_loss: 0.5150 - val_accuracy: 0.7528\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8038 - val_loss: 0.5141 - val_accuracy: 0.7528\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.8059 - val_loss: 0.5125 - val_accuracy: 0.7528\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8038 - val_loss: 0.5112 - val_accuracy: 0.7697\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8059 - val_loss: 0.5101 - val_accuracy: 0.7697\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.8059 - val_loss: 0.5089 - val_accuracy: 0.7753\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8080 - val_loss: 0.5077 - val_accuracy: 0.7809\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8080 - val_loss: 0.5064 - val_accuracy: 0.7865\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8143 - val_loss: 0.5053 - val_accuracy: 0.7865\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8122 - val_loss: 0.5045 - val_accuracy: 0.7865\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8122 - val_loss: 0.5035 - val_accuracy: 0.7865\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8122 - val_loss: 0.5025 - val_accuracy: 0.7865\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8143 - val_loss: 0.5016 - val_accuracy: 0.7921\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8165 - val_loss: 0.5005 - val_accuracy: 0.7921\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8165 - val_loss: 0.4997 - val_accuracy: 0.7921\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8122 - val_loss: 0.4988 - val_accuracy: 0.7921\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8122 - val_loss: 0.4978 - val_accuracy: 0.7921\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8143 - val_loss: 0.4972 - val_accuracy: 0.7921\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8165 - val_loss: 0.4964 - val_accuracy: 0.7921\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8165 - val_loss: 0.4958 - val_accuracy: 0.7921\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8143 - val_loss: 0.4950 - val_accuracy: 0.7921\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8186 - val_loss: 0.4943 - val_accuracy: 0.7921\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8165 - val_loss: 0.4937 - val_accuracy: 0.7921\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8165 - val_loss: 0.4927 - val_accuracy: 0.7921\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8165 - val_loss: 0.4921 - val_accuracy: 0.7921\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8143 - val_loss: 0.4917 - val_accuracy: 0.7921\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8143 - val_loss: 0.4911 - val_accuracy: 0.7921\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8143 - val_loss: 0.4905 - val_accuracy: 0.7921\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8122 - val_loss: 0.4901 - val_accuracy: 0.7921\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8207 - val_loss: 0.4891 - val_accuracy: 0.7978\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8312 - val_loss: 0.4887 - val_accuracy: 0.7978\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8312 - val_loss: 0.4883 - val_accuracy: 0.7978\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8312 - val_loss: 0.4878 - val_accuracy: 0.7978\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8312 - val_loss: 0.4871 - val_accuracy: 0.7978\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8291 - val_loss: 0.4867 - val_accuracy: 0.7978\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8291 - val_loss: 0.4862 - val_accuracy: 0.8034\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8291 - val_loss: 0.4860 - val_accuracy: 0.8034\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8291 - val_loss: 0.4857 - val_accuracy: 0.8034\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8270 - val_loss: 0.4851 - val_accuracy: 0.8034\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8270 - val_loss: 0.4848 - val_accuracy: 0.8034\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8249 - val_loss: 0.4844 - val_accuracy: 0.8090\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8249 - val_loss: 0.4838 - val_accuracy: 0.8090\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8249 - val_loss: 0.4835 - val_accuracy: 0.8090\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8249 - val_loss: 0.4831 - val_accuracy: 0.8146\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8228 - val_loss: 0.4829 - val_accuracy: 0.8146\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8249 - val_loss: 0.4825 - val_accuracy: 0.8146\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8228 - val_loss: 0.4823 - val_accuracy: 0.8146\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8228 - val_loss: 0.4821 - val_accuracy: 0.8146\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8228 - val_loss: 0.4818 - val_accuracy: 0.8146\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8249 - val_loss: 0.4812 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 820us/step - loss: 0.4653 - accuracy: 0.7975\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1116 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.8604 - accuracy: 0.5464 - val_loss: 0.7979 - val_accuracy: 0.5674\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8472 - accuracy: 0.5485 - val_loss: 0.7876 - val_accuracy: 0.5674\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8353 - accuracy: 0.5527 - val_loss: 0.7772 - val_accuracy: 0.5730\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8229 - accuracy: 0.5633 - val_loss: 0.7673 - val_accuracy: 0.5674\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8113 - accuracy: 0.5633 - val_loss: 0.7577 - val_accuracy: 0.5730\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8000 - accuracy: 0.5633 - val_loss: 0.7484 - val_accuracy: 0.5730\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7889 - accuracy: 0.5654 - val_loss: 0.7394 - val_accuracy: 0.5730\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7783 - accuracy: 0.5696 - val_loss: 0.7304 - val_accuracy: 0.5787\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7675 - accuracy: 0.5781 - val_loss: 0.7220 - val_accuracy: 0.5899\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7574 - accuracy: 0.5823 - val_loss: 0.7136 - val_accuracy: 0.5955\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7476 - accuracy: 0.5886 - val_loss: 0.7054 - val_accuracy: 0.6011\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.5844 - val_loss: 0.6975 - val_accuracy: 0.6067\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7283 - accuracy: 0.5844 - val_loss: 0.6899 - val_accuracy: 0.6124\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7193 - accuracy: 0.5886 - val_loss: 0.6827 - val_accuracy: 0.6124\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7105 - accuracy: 0.5928 - val_loss: 0.6755 - val_accuracy: 0.6236\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.5949 - val_loss: 0.6686 - val_accuracy: 0.6292\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5970 - val_loss: 0.6619 - val_accuracy: 0.6236\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.6034 - val_loss: 0.6555 - val_accuracy: 0.6236\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.6118 - val_loss: 0.6492 - val_accuracy: 0.6292\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.6118 - val_loss: 0.6432 - val_accuracy: 0.6292\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.6160 - val_loss: 0.6372 - val_accuracy: 0.6517\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6224 - val_loss: 0.6317 - val_accuracy: 0.6517\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6245 - val_loss: 0.6264 - val_accuracy: 0.6517\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.6329 - val_loss: 0.6211 - val_accuracy: 0.6517\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.6329 - val_loss: 0.6162 - val_accuracy: 0.6517\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.6392 - val_loss: 0.6113 - val_accuracy: 0.6461\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6414 - val_loss: 0.6066 - val_accuracy: 0.6461\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6456 - val_loss: 0.6021 - val_accuracy: 0.6685\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6519 - val_loss: 0.5977 - val_accuracy: 0.6742\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.6540 - val_loss: 0.5937 - val_accuracy: 0.6742\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.6561 - val_loss: 0.5897 - val_accuracy: 0.6742\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6582 - val_loss: 0.5859 - val_accuracy: 0.6685\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.6603 - val_loss: 0.5821 - val_accuracy: 0.6742\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.6709 - val_loss: 0.5785 - val_accuracy: 0.6742\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.6793 - val_loss: 0.5752 - val_accuracy: 0.6742\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.6857 - val_loss: 0.5719 - val_accuracy: 0.6798\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.6899 - val_loss: 0.5686 - val_accuracy: 0.6854\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.6941 - val_loss: 0.5654 - val_accuracy: 0.6966\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7025 - val_loss: 0.5627 - val_accuracy: 0.7022\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7131 - val_loss: 0.5598 - val_accuracy: 0.7079\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7173 - val_loss: 0.5570 - val_accuracy: 0.7135\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7215 - val_loss: 0.5542 - val_accuracy: 0.7135\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7257 - val_loss: 0.5518 - val_accuracy: 0.7191\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7257 - val_loss: 0.5494 - val_accuracy: 0.7247\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7257 - val_loss: 0.5470 - val_accuracy: 0.7247\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7300 - val_loss: 0.5445 - val_accuracy: 0.7303\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7342 - val_loss: 0.5423 - val_accuracy: 0.7303\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7405 - val_loss: 0.5401 - val_accuracy: 0.7472\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7384 - val_loss: 0.5380 - val_accuracy: 0.7472\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7426 - val_loss: 0.5359 - val_accuracy: 0.7472\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7447 - val_loss: 0.5340 - val_accuracy: 0.7472\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7447 - val_loss: 0.5321 - val_accuracy: 0.7528\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7468 - val_loss: 0.5301 - val_accuracy: 0.7584\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7468 - val_loss: 0.5284 - val_accuracy: 0.7584\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7511 - val_loss: 0.5267 - val_accuracy: 0.7584\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7532 - val_loss: 0.5250 - val_accuracy: 0.7697\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7532 - val_loss: 0.5235 - val_accuracy: 0.7753\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7553 - val_loss: 0.5218 - val_accuracy: 0.7753\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7574 - val_loss: 0.5203 - val_accuracy: 0.7809\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7658 - val_loss: 0.5189 - val_accuracy: 0.7865\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7658 - val_loss: 0.5174 - val_accuracy: 0.7865\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.7700 - val_loss: 0.5160 - val_accuracy: 0.7865\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7722 - val_loss: 0.5148 - val_accuracy: 0.7865\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7743 - val_loss: 0.5134 - val_accuracy: 0.7865\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7764 - val_loss: 0.5121 - val_accuracy: 0.7865\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7806 - val_loss: 0.5108 - val_accuracy: 0.7921\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7806 - val_loss: 0.5096 - val_accuracy: 0.8034\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7827 - val_loss: 0.5085 - val_accuracy: 0.8034\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7827 - val_loss: 0.5073 - val_accuracy: 0.8034\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7806 - val_loss: 0.5063 - val_accuracy: 0.7978\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7806 - val_loss: 0.5052 - val_accuracy: 0.7978\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7806 - val_loss: 0.5042 - val_accuracy: 0.7978\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7848 - val_loss: 0.5032 - val_accuracy: 0.7978\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7848 - val_loss: 0.5021 - val_accuracy: 0.7921\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7890 - val_loss: 0.5012 - val_accuracy: 0.7978\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7911 - val_loss: 0.5003 - val_accuracy: 0.7978\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7911 - val_loss: 0.4994 - val_accuracy: 0.7978\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7911 - val_loss: 0.4985 - val_accuracy: 0.7865\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7911 - val_loss: 0.4976 - val_accuracy: 0.7865\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7975 - val_loss: 0.4967 - val_accuracy: 0.7978\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7975 - val_loss: 0.4961 - val_accuracy: 0.7978\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7954 - val_loss: 0.4953 - val_accuracy: 0.7978\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7932 - val_loss: 0.4945 - val_accuracy: 0.7978\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7954 - val_loss: 0.4938 - val_accuracy: 0.7978\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7954 - val_loss: 0.4931 - val_accuracy: 0.7978\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8017 - val_loss: 0.4923 - val_accuracy: 0.8034\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8017 - val_loss: 0.4917 - val_accuracy: 0.8034\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.8017 - val_loss: 0.4910 - val_accuracy: 0.8090\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8122 - val_loss: 0.4904 - val_accuracy: 0.8090\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8080 - val_loss: 0.4897 - val_accuracy: 0.8034\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8080 - val_loss: 0.4891 - val_accuracy: 0.7978\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8080 - val_loss: 0.4885 - val_accuracy: 0.7978\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8059 - val_loss: 0.4880 - val_accuracy: 0.7978\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8038 - val_loss: 0.4875 - val_accuracy: 0.7978\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8017 - val_loss: 0.4870 - val_accuracy: 0.7978\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8038 - val_loss: 0.4863 - val_accuracy: 0.7978\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.8017 - val_loss: 0.4859 - val_accuracy: 0.7978\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8017 - val_loss: 0.4855 - val_accuracy: 0.7978\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8207 - val_loss: 0.4850 - val_accuracy: 0.8034\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8186 - val_loss: 0.4845 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 829us/step - loss: 0.4441 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1117 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6095 - accuracy: 0.7426 - val_loss: 0.6130 - val_accuracy: 0.7191\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.7511 - val_loss: 0.6044 - val_accuracy: 0.7191\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.7511 - val_loss: 0.5969 - val_accuracy: 0.7191\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7553 - val_loss: 0.5901 - val_accuracy: 0.7191\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7574 - val_loss: 0.5839 - val_accuracy: 0.7191\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.7595 - val_loss: 0.5785 - val_accuracy: 0.7191\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7616 - val_loss: 0.5738 - val_accuracy: 0.7247\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7595 - val_loss: 0.5695 - val_accuracy: 0.7191\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7553 - val_loss: 0.5654 - val_accuracy: 0.7135\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7574 - val_loss: 0.5617 - val_accuracy: 0.7191\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7574 - val_loss: 0.5586 - val_accuracy: 0.7191\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7595 - val_loss: 0.5557 - val_accuracy: 0.7247\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7616 - val_loss: 0.5529 - val_accuracy: 0.7191\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7616 - val_loss: 0.5502 - val_accuracy: 0.7191\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7616 - val_loss: 0.5479 - val_accuracy: 0.7247\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7637 - val_loss: 0.5456 - val_accuracy: 0.7247\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7637 - val_loss: 0.5437 - val_accuracy: 0.7247\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7637 - val_loss: 0.5416 - val_accuracy: 0.7247\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7658 - val_loss: 0.5397 - val_accuracy: 0.7247\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7679 - val_loss: 0.5378 - val_accuracy: 0.7360\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7700 - val_loss: 0.5362 - val_accuracy: 0.7360\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7743 - val_loss: 0.5344 - val_accuracy: 0.7360\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7764 - val_loss: 0.5328 - val_accuracy: 0.7360\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7785 - val_loss: 0.5313 - val_accuracy: 0.7360\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7785 - val_loss: 0.5298 - val_accuracy: 0.7360\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7806 - val_loss: 0.5284 - val_accuracy: 0.7360\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7827 - val_loss: 0.5271 - val_accuracy: 0.7360\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7848 - val_loss: 0.5256 - val_accuracy: 0.7416\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7827 - val_loss: 0.5245 - val_accuracy: 0.7416\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7827 - val_loss: 0.5234 - val_accuracy: 0.7416\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7827 - val_loss: 0.5224 - val_accuracy: 0.7416\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7827 - val_loss: 0.5210 - val_accuracy: 0.7416\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7806 - val_loss: 0.5201 - val_accuracy: 0.7416\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7869 - val_loss: 0.5191 - val_accuracy: 0.7416\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7869 - val_loss: 0.5180 - val_accuracy: 0.7416\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7869 - val_loss: 0.5171 - val_accuracy: 0.7416\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7869 - val_loss: 0.5162 - val_accuracy: 0.7416\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7869 - val_loss: 0.5153 - val_accuracy: 0.7472\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7869 - val_loss: 0.5145 - val_accuracy: 0.7472\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7869 - val_loss: 0.5136 - val_accuracy: 0.7528\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7911 - val_loss: 0.5127 - val_accuracy: 0.7584\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7911 - val_loss: 0.5122 - val_accuracy: 0.7584\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7911 - val_loss: 0.5113 - val_accuracy: 0.7584\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7911 - val_loss: 0.5105 - val_accuracy: 0.7584\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7911 - val_loss: 0.5099 - val_accuracy: 0.7640\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7932 - val_loss: 0.5091 - val_accuracy: 0.7640\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7932 - val_loss: 0.5085 - val_accuracy: 0.7753\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7954 - val_loss: 0.5079 - val_accuracy: 0.7865\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7954 - val_loss: 0.5073 - val_accuracy: 0.7865\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7975 - val_loss: 0.5067 - val_accuracy: 0.7865\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7975 - val_loss: 0.5061 - val_accuracy: 0.7865\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7975 - val_loss: 0.5056 - val_accuracy: 0.7865\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7975 - val_loss: 0.5048 - val_accuracy: 0.7865\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7975 - val_loss: 0.5044 - val_accuracy: 0.7865\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7954 - val_loss: 0.5038 - val_accuracy: 0.7865\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7954 - val_loss: 0.5034 - val_accuracy: 0.7921\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7954 - val_loss: 0.5030 - val_accuracy: 0.7978\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7954 - val_loss: 0.5024 - val_accuracy: 0.7978\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7954 - val_loss: 0.5020 - val_accuracy: 0.7978\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7954 - val_loss: 0.5015 - val_accuracy: 0.7978\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7996 - val_loss: 0.5011 - val_accuracy: 0.7978\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7996 - val_loss: 0.5008 - val_accuracy: 0.7978\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7996 - val_loss: 0.5003 - val_accuracy: 0.7978\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7996 - val_loss: 0.4997 - val_accuracy: 0.7978\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7996 - val_loss: 0.4995 - val_accuracy: 0.7978\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7996 - val_loss: 0.4991 - val_accuracy: 0.7978\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8017 - val_loss: 0.4986 - val_accuracy: 0.7978\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8017 - val_loss: 0.4982 - val_accuracy: 0.7978\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8017 - val_loss: 0.4980 - val_accuracy: 0.7978\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8017 - val_loss: 0.4976 - val_accuracy: 0.7978\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8038 - val_loss: 0.4973 - val_accuracy: 0.7978\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8038 - val_loss: 0.4969 - val_accuracy: 0.7978\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.8059 - val_loss: 0.4965 - val_accuracy: 0.7978\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8059 - val_loss: 0.4963 - val_accuracy: 0.7978\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8080 - val_loss: 0.4960 - val_accuracy: 0.7978\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8080 - val_loss: 0.4956 - val_accuracy: 0.7978\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8080 - val_loss: 0.4953 - val_accuracy: 0.7978\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8080 - val_loss: 0.4950 - val_accuracy: 0.7978\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8080 - val_loss: 0.4948 - val_accuracy: 0.7978\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8059 - val_loss: 0.4948 - val_accuracy: 0.7978\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8059 - val_loss: 0.4944 - val_accuracy: 0.8034\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.8080 - val_loss: 0.4942 - val_accuracy: 0.8034\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8080 - val_loss: 0.4939 - val_accuracy: 0.8034\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.8101 - val_loss: 0.4937 - val_accuracy: 0.8034\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8101 - val_loss: 0.4932 - val_accuracy: 0.8090\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8101 - val_loss: 0.4930 - val_accuracy: 0.8034\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8059 - val_loss: 0.4928 - val_accuracy: 0.8034\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8080 - val_loss: 0.4926 - val_accuracy: 0.8034\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8080 - val_loss: 0.4926 - val_accuracy: 0.8034\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8080 - val_loss: 0.4922 - val_accuracy: 0.8034\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8080 - val_loss: 0.4921 - val_accuracy: 0.8034\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.8080 - val_loss: 0.4919 - val_accuracy: 0.8034\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.8080 - val_loss: 0.4916 - val_accuracy: 0.8034\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8080 - val_loss: 0.4915 - val_accuracy: 0.8034\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8080 - val_loss: 0.4913 - val_accuracy: 0.8034\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8080 - val_loss: 0.4910 - val_accuracy: 0.8034\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8080 - val_loss: 0.4908 - val_accuracy: 0.8034\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8101 - val_loss: 0.4906 - val_accuracy: 0.8034\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8101 - val_loss: 0.4905 - val_accuracy: 0.8034\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8101 - val_loss: 0.4901 - val_accuracy: 0.8034\n",
      "8/8 [==============================] - 0s 764us/step - loss: 0.4138 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1118 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5742 - accuracy: 0.6920 - val_loss: 0.6334 - val_accuracy: 0.6573\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.6983 - val_loss: 0.6275 - val_accuracy: 0.6742\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7046 - val_loss: 0.6219 - val_accuracy: 0.6742\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7089 - val_loss: 0.6169 - val_accuracy: 0.6742\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7131 - val_loss: 0.6120 - val_accuracy: 0.6798\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7131 - val_loss: 0.6071 - val_accuracy: 0.6798\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7152 - val_loss: 0.6023 - val_accuracy: 0.6798\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7215 - val_loss: 0.5982 - val_accuracy: 0.6854\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7215 - val_loss: 0.5938 - val_accuracy: 0.6910\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7300 - val_loss: 0.5896 - val_accuracy: 0.6910\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7342 - val_loss: 0.5858 - val_accuracy: 0.6910\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7342 - val_loss: 0.5820 - val_accuracy: 0.6966\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7321 - val_loss: 0.5786 - val_accuracy: 0.6966\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7342 - val_loss: 0.5750 - val_accuracy: 0.6966\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7405 - val_loss: 0.5715 - val_accuracy: 0.7022\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7532 - val_loss: 0.5681 - val_accuracy: 0.7022\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7553 - val_loss: 0.5651 - val_accuracy: 0.7022\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7637 - val_loss: 0.5623 - val_accuracy: 0.7079\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7658 - val_loss: 0.5598 - val_accuracy: 0.7135\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7658 - val_loss: 0.5568 - val_accuracy: 0.7247\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7700 - val_loss: 0.5541 - val_accuracy: 0.7247\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7700 - val_loss: 0.5515 - val_accuracy: 0.7303\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7785 - val_loss: 0.5494 - val_accuracy: 0.7303\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7764 - val_loss: 0.5467 - val_accuracy: 0.7247\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7806 - val_loss: 0.5447 - val_accuracy: 0.7303\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7806 - val_loss: 0.5425 - val_accuracy: 0.7303\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7785 - val_loss: 0.5403 - val_accuracy: 0.7303\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7785 - val_loss: 0.5385 - val_accuracy: 0.7303\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7806 - val_loss: 0.5368 - val_accuracy: 0.7303\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7806 - val_loss: 0.5346 - val_accuracy: 0.7360\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7806 - val_loss: 0.5331 - val_accuracy: 0.7303\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7827 - val_loss: 0.5312 - val_accuracy: 0.7303\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7869 - val_loss: 0.5297 - val_accuracy: 0.7303\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7890 - val_loss: 0.5279 - val_accuracy: 0.7416\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7890 - val_loss: 0.5266 - val_accuracy: 0.7472\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7911 - val_loss: 0.5251 - val_accuracy: 0.7472\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7911 - val_loss: 0.5237 - val_accuracy: 0.7416\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7911 - val_loss: 0.5225 - val_accuracy: 0.7360\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7848 - val_loss: 0.5212 - val_accuracy: 0.7416\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7827 - val_loss: 0.5202 - val_accuracy: 0.7416\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7827 - val_loss: 0.5185 - val_accuracy: 0.7528\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7890 - val_loss: 0.5173 - val_accuracy: 0.7640\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7911 - val_loss: 0.5162 - val_accuracy: 0.7640\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7911 - val_loss: 0.5152 - val_accuracy: 0.7697\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7975 - val_loss: 0.5142 - val_accuracy: 0.7697\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8101 - val_loss: 0.5132 - val_accuracy: 0.7640\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8101 - val_loss: 0.5121 - val_accuracy: 0.7697\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.8122 - val_loss: 0.5113 - val_accuracy: 0.7697\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8080 - val_loss: 0.5102 - val_accuracy: 0.7697\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8059 - val_loss: 0.5094 - val_accuracy: 0.7809\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8080 - val_loss: 0.5085 - val_accuracy: 0.7809\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8101 - val_loss: 0.5080 - val_accuracy: 0.7809\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8122 - val_loss: 0.5069 - val_accuracy: 0.7809\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8143 - val_loss: 0.5059 - val_accuracy: 0.7809\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8143 - val_loss: 0.5053 - val_accuracy: 0.7809\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8143 - val_loss: 0.5046 - val_accuracy: 0.7809\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.8122 - val_loss: 0.5038 - val_accuracy: 0.7865\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8143 - val_loss: 0.5031 - val_accuracy: 0.7865\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8165 - val_loss: 0.5024 - val_accuracy: 0.7865\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8165 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8165 - val_loss: 0.5009 - val_accuracy: 0.7865\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8165 - val_loss: 0.5004 - val_accuracy: 0.7865\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8186 - val_loss: 0.4998 - val_accuracy: 0.7865\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.8186 - val_loss: 0.4991 - val_accuracy: 0.7865\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8165 - val_loss: 0.4984 - val_accuracy: 0.7921\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8165 - val_loss: 0.4982 - val_accuracy: 0.7921\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8165 - val_loss: 0.4976 - val_accuracy: 0.7978\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8186 - val_loss: 0.4972 - val_accuracy: 0.7978\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8186 - val_loss: 0.4967 - val_accuracy: 0.7978\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8186 - val_loss: 0.4962 - val_accuracy: 0.7978\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8186 - val_loss: 0.4954 - val_accuracy: 0.7978\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8186 - val_loss: 0.4953 - val_accuracy: 0.7978\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8186 - val_loss: 0.4945 - val_accuracy: 0.7921\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8249 - val_loss: 0.4941 - val_accuracy: 0.7921\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.8249 - val_loss: 0.4938 - val_accuracy: 0.7921\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8249 - val_loss: 0.4933 - val_accuracy: 0.7921\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8249 - val_loss: 0.4928 - val_accuracy: 0.7978\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8249 - val_loss: 0.4925 - val_accuracy: 0.8034\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8270 - val_loss: 0.4923 - val_accuracy: 0.8034\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8270 - val_loss: 0.4917 - val_accuracy: 0.8034\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8270 - val_loss: 0.4913 - val_accuracy: 0.8034\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8270 - val_loss: 0.4910 - val_accuracy: 0.8034\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8249 - val_loss: 0.4906 - val_accuracy: 0.8034\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8249 - val_loss: 0.4901 - val_accuracy: 0.8034\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8249 - val_loss: 0.4896 - val_accuracy: 0.8034\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8249 - val_loss: 0.4893 - val_accuracy: 0.8034\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8249 - val_loss: 0.4892 - val_accuracy: 0.8034\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8249 - val_loss: 0.4886 - val_accuracy: 0.8034\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8249 - val_loss: 0.4882 - val_accuracy: 0.8034\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8228 - val_loss: 0.4877 - val_accuracy: 0.8034\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8249 - val_loss: 0.4878 - val_accuracy: 0.8034\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8249 - val_loss: 0.4873 - val_accuracy: 0.8034\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8249 - val_loss: 0.4871 - val_accuracy: 0.8034\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8249 - val_loss: 0.4869 - val_accuracy: 0.8034\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8249 - val_loss: 0.4865 - val_accuracy: 0.8034\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8249 - val_loss: 0.4861 - val_accuracy: 0.8034\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8249 - val_loss: 0.4861 - val_accuracy: 0.8034\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8249 - val_loss: 0.4860 - val_accuracy: 0.8034\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8249 - val_loss: 0.4858 - val_accuracy: 0.8034\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8249 - val_loss: 0.4852 - val_accuracy: 0.8034\n",
      "8/8 [==============================] - 0s 742us/step - loss: 0.4864 - accuracy: 0.7848\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1119 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.6868 - accuracy: 0.5865 - val_loss: 0.6666 - val_accuracy: 0.6180\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.5886 - val_loss: 0.6598 - val_accuracy: 0.6180\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.5949 - val_loss: 0.6534 - val_accuracy: 0.6180\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.6055 - val_loss: 0.6475 - val_accuracy: 0.6180\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.6539 - accuracy: 0.6181 - val_loss: 0.6417 - val_accuracy: 0.6236\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6287 - val_loss: 0.6359 - val_accuracy: 0.6348\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.6519 - val_loss: 0.6309 - val_accuracy: 0.6348\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.6646 - val_loss: 0.6257 - val_accuracy: 0.6404\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6667 - val_loss: 0.6209 - val_accuracy: 0.6461\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6709 - val_loss: 0.6163 - val_accuracy: 0.6461\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6772 - val_loss: 0.6119 - val_accuracy: 0.6517\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6793 - val_loss: 0.6077 - val_accuracy: 0.6573\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.6878 - val_loss: 0.6034 - val_accuracy: 0.6629\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.6920 - val_loss: 0.5996 - val_accuracy: 0.6629\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.6920 - val_loss: 0.5958 - val_accuracy: 0.6629\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.6941 - val_loss: 0.5921 - val_accuracy: 0.6742\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.6941 - val_loss: 0.5886 - val_accuracy: 0.6742\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.6941 - val_loss: 0.5852 - val_accuracy: 0.6742\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7004 - val_loss: 0.5820 - val_accuracy: 0.6910\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.6983 - val_loss: 0.5788 - val_accuracy: 0.6854\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7046 - val_loss: 0.5758 - val_accuracy: 0.6966\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7110 - val_loss: 0.5729 - val_accuracy: 0.6966\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7152 - val_loss: 0.5701 - val_accuracy: 0.6910\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7152 - val_loss: 0.5675 - val_accuracy: 0.6910\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7152 - val_loss: 0.5649 - val_accuracy: 0.6966\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7173 - val_loss: 0.5623 - val_accuracy: 0.6910\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7194 - val_loss: 0.5598 - val_accuracy: 0.6798\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7194 - val_loss: 0.5575 - val_accuracy: 0.6854\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7278 - val_loss: 0.5554 - val_accuracy: 0.6854\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7300 - val_loss: 0.5532 - val_accuracy: 0.6854\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7363 - val_loss: 0.5511 - val_accuracy: 0.6966\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7405 - val_loss: 0.5490 - val_accuracy: 0.7022\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7426 - val_loss: 0.5471 - val_accuracy: 0.7079\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7447 - val_loss: 0.5452 - val_accuracy: 0.7079\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7468 - val_loss: 0.5433 - val_accuracy: 0.7079\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7511 - val_loss: 0.5415 - val_accuracy: 0.7079\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7511 - val_loss: 0.5398 - val_accuracy: 0.7079\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7532 - val_loss: 0.5381 - val_accuracy: 0.7079\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7553 - val_loss: 0.5366 - val_accuracy: 0.7079\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7595 - val_loss: 0.5350 - val_accuracy: 0.7079\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7616 - val_loss: 0.5335 - val_accuracy: 0.7079\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7616 - val_loss: 0.5320 - val_accuracy: 0.7079\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7616 - val_loss: 0.5307 - val_accuracy: 0.7079\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7616 - val_loss: 0.5294 - val_accuracy: 0.7079\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7616 - val_loss: 0.5279 - val_accuracy: 0.7079\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7616 - val_loss: 0.5266 - val_accuracy: 0.7135\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7637 - val_loss: 0.5254 - val_accuracy: 0.7135\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7637 - val_loss: 0.5239 - val_accuracy: 0.7135\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7658 - val_loss: 0.5229 - val_accuracy: 0.7135\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7658 - val_loss: 0.5219 - val_accuracy: 0.7135\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7658 - val_loss: 0.5207 - val_accuracy: 0.7135\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7658 - val_loss: 0.5195 - val_accuracy: 0.7135\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7679 - val_loss: 0.5187 - val_accuracy: 0.7135\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7658 - val_loss: 0.5175 - val_accuracy: 0.7135\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7700 - val_loss: 0.5165 - val_accuracy: 0.7191\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7722 - val_loss: 0.5156 - val_accuracy: 0.7191\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7764 - val_loss: 0.5146 - val_accuracy: 0.7247\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7827 - val_loss: 0.5137 - val_accuracy: 0.7303\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7848 - val_loss: 0.5128 - val_accuracy: 0.7303\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7890 - val_loss: 0.5120 - val_accuracy: 0.7303\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7932 - val_loss: 0.5111 - val_accuracy: 0.7247\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7954 - val_loss: 0.5103 - val_accuracy: 0.7247\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7975 - val_loss: 0.5094 - val_accuracy: 0.7191\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8017 - val_loss: 0.5087 - val_accuracy: 0.7191\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8017 - val_loss: 0.5079 - val_accuracy: 0.7191\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.8017 - val_loss: 0.5071 - val_accuracy: 0.7247\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8017 - val_loss: 0.5064 - val_accuracy: 0.7303\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.8017 - val_loss: 0.5056 - val_accuracy: 0.7303\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.8017 - val_loss: 0.5049 - val_accuracy: 0.7303\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8038 - val_loss: 0.5041 - val_accuracy: 0.7303\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8080 - val_loss: 0.5035 - val_accuracy: 0.7303\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8059 - val_loss: 0.5030 - val_accuracy: 0.7303\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8080 - val_loss: 0.5024 - val_accuracy: 0.7303\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8059 - val_loss: 0.5017 - val_accuracy: 0.7303\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8059 - val_loss: 0.5011 - val_accuracy: 0.7360\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8059 - val_loss: 0.5005 - val_accuracy: 0.7360\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.8080 - val_loss: 0.4999 - val_accuracy: 0.7360\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.8080 - val_loss: 0.4993 - val_accuracy: 0.7360\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.8080 - val_loss: 0.4988 - val_accuracy: 0.7360\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8101 - val_loss: 0.4982 - val_accuracy: 0.7360\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8101 - val_loss: 0.4978 - val_accuracy: 0.7360\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8122 - val_loss: 0.4972 - val_accuracy: 0.7360\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8122 - val_loss: 0.4967 - val_accuracy: 0.7472\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.8122 - val_loss: 0.4962 - val_accuracy: 0.7472\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.8143 - val_loss: 0.4958 - val_accuracy: 0.7528\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.8165 - val_loss: 0.4952 - val_accuracy: 0.7528\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8165 - val_loss: 0.4948 - val_accuracy: 0.7528\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.8165 - val_loss: 0.4943 - val_accuracy: 0.7472\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8165 - val_loss: 0.4939 - val_accuracy: 0.7528\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.8165 - val_loss: 0.4935 - val_accuracy: 0.7528\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8165 - val_loss: 0.4931 - val_accuracy: 0.7584\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8165 - val_loss: 0.4926 - val_accuracy: 0.7584\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8165 - val_loss: 0.4922 - val_accuracy: 0.7584\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.8165 - val_loss: 0.4918 - val_accuracy: 0.7584\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8165 - val_loss: 0.4915 - val_accuracy: 0.7584\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8165 - val_loss: 0.4911 - val_accuracy: 0.7584\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8186 - val_loss: 0.4907 - val_accuracy: 0.7584\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8186 - val_loss: 0.4904 - val_accuracy: 0.7584\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8165 - val_loss: 0.4900 - val_accuracy: 0.7584\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8186 - val_loss: 0.4897 - val_accuracy: 0.7584\n",
      "8/8 [==============================] - 0s 801us/step - loss: 0.4403 - accuracy: 0.8101\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1120 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.8003 - accuracy: 0.4979 - val_loss: 0.7585 - val_accuracy: 0.4888\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7843 - accuracy: 0.5169 - val_loss: 0.7453 - val_accuracy: 0.5337\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7697 - accuracy: 0.5316 - val_loss: 0.7334 - val_accuracy: 0.5562\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7566 - accuracy: 0.5380 - val_loss: 0.7217 - val_accuracy: 0.5843\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7438 - accuracy: 0.5612 - val_loss: 0.7115 - val_accuracy: 0.6180\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7325 - accuracy: 0.5823 - val_loss: 0.7020 - val_accuracy: 0.6292\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7213 - accuracy: 0.6034 - val_loss: 0.6938 - val_accuracy: 0.6404\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7117 - accuracy: 0.5970 - val_loss: 0.6857 - val_accuracy: 0.6461\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.6034 - val_loss: 0.6781 - val_accuracy: 0.6461\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.6076 - val_loss: 0.6715 - val_accuracy: 0.6517\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.6118 - val_loss: 0.6648 - val_accuracy: 0.6517\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6779 - accuracy: 0.6160 - val_loss: 0.6587 - val_accuracy: 0.6573\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.6203 - val_loss: 0.6526 - val_accuracy: 0.6517\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.6266 - val_loss: 0.6472 - val_accuracy: 0.6573\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.6287 - val_loss: 0.6419 - val_accuracy: 0.6573\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6329 - val_loss: 0.6369 - val_accuracy: 0.6573\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6371 - val_loss: 0.6317 - val_accuracy: 0.6573\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6371 - val_loss: 0.6270 - val_accuracy: 0.6685\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6414 - val_loss: 0.6221 - val_accuracy: 0.6629\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6435 - val_loss: 0.6177 - val_accuracy: 0.6685\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.6477 - val_loss: 0.6134 - val_accuracy: 0.6629\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6519 - val_loss: 0.6091 - val_accuracy: 0.6798\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6582 - val_loss: 0.6048 - val_accuracy: 0.6798\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.6667 - val_loss: 0.6011 - val_accuracy: 0.6742\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6751 - val_loss: 0.5971 - val_accuracy: 0.6742\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.6857 - val_loss: 0.5936 - val_accuracy: 0.6798\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6899 - val_loss: 0.5898 - val_accuracy: 0.6798\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.6920 - val_loss: 0.5862 - val_accuracy: 0.6798\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.6962 - val_loss: 0.5827 - val_accuracy: 0.6798\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7025 - val_loss: 0.5794 - val_accuracy: 0.6966\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7068 - val_loss: 0.5761 - val_accuracy: 0.7022\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7089 - val_loss: 0.5730 - val_accuracy: 0.7135\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7152 - val_loss: 0.5699 - val_accuracy: 0.7079\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5638 - accuracy: 0.7215 - val_loss: 0.5668 - val_accuracy: 0.7079\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7236 - val_loss: 0.5640 - val_accuracy: 0.7079\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7278 - val_loss: 0.5611 - val_accuracy: 0.7079\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7300 - val_loss: 0.5582 - val_accuracy: 0.7191\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7405 - val_loss: 0.5556 - val_accuracy: 0.7191\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7447 - val_loss: 0.5530 - val_accuracy: 0.7303\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7489 - val_loss: 0.5508 - val_accuracy: 0.7303\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7511 - val_loss: 0.5482 - val_accuracy: 0.7247\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7616 - val_loss: 0.5459 - val_accuracy: 0.7247\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7700 - val_loss: 0.5436 - val_accuracy: 0.7360\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7764 - val_loss: 0.5411 - val_accuracy: 0.7360\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7785 - val_loss: 0.5391 - val_accuracy: 0.7360\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7785 - val_loss: 0.5371 - val_accuracy: 0.7360\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7785 - val_loss: 0.5350 - val_accuracy: 0.7416\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7806 - val_loss: 0.5330 - val_accuracy: 0.7472\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7848 - val_loss: 0.5311 - val_accuracy: 0.7472\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7869 - val_loss: 0.5294 - val_accuracy: 0.7528\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7869 - val_loss: 0.5277 - val_accuracy: 0.7528\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7911 - val_loss: 0.5259 - val_accuracy: 0.7528\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7911 - val_loss: 0.5241 - val_accuracy: 0.7528\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7911 - val_loss: 0.5225 - val_accuracy: 0.7472\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7890 - val_loss: 0.5210 - val_accuracy: 0.7472\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7890 - val_loss: 0.5196 - val_accuracy: 0.7472\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7890 - val_loss: 0.5182 - val_accuracy: 0.7472\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7954 - val_loss: 0.5166 - val_accuracy: 0.7584\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8017 - val_loss: 0.5154 - val_accuracy: 0.7584\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8080 - val_loss: 0.5140 - val_accuracy: 0.7640\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.8122 - val_loss: 0.5126 - val_accuracy: 0.7640\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.8143 - val_loss: 0.5112 - val_accuracy: 0.7640\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.8143 - val_loss: 0.5102 - val_accuracy: 0.7697\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.8143 - val_loss: 0.5089 - val_accuracy: 0.7697\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.8186 - val_loss: 0.5078 - val_accuracy: 0.7697\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.8207 - val_loss: 0.5066 - val_accuracy: 0.7865\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.8165 - val_loss: 0.5056 - val_accuracy: 0.7865\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.8186 - val_loss: 0.5047 - val_accuracy: 0.7865\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8186 - val_loss: 0.5036 - val_accuracy: 0.7865\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8165 - val_loss: 0.5027 - val_accuracy: 0.7865\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8143 - val_loss: 0.5017 - val_accuracy: 0.7921\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.8165 - val_loss: 0.5006 - val_accuracy: 0.7921\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.8165 - val_loss: 0.4997 - val_accuracy: 0.7921\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.8165 - val_loss: 0.4991 - val_accuracy: 0.7921\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.8165 - val_loss: 0.4983 - val_accuracy: 0.7921\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.8165 - val_loss: 0.4974 - val_accuracy: 0.7921\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.8165 - val_loss: 0.4966 - val_accuracy: 0.7921\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.8165 - val_loss: 0.4958 - val_accuracy: 0.7921\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8165 - val_loss: 0.4950 - val_accuracy: 0.7921\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8165 - val_loss: 0.4943 - val_accuracy: 0.7978\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.8165 - val_loss: 0.4935 - val_accuracy: 0.8034\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.8165 - val_loss: 0.4929 - val_accuracy: 0.8034\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8165 - val_loss: 0.4924 - val_accuracy: 0.8034\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8165 - val_loss: 0.4916 - val_accuracy: 0.8090\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8165 - val_loss: 0.4912 - val_accuracy: 0.8090\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8101 - val_loss: 0.4906 - val_accuracy: 0.8090\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.8101 - val_loss: 0.4900 - val_accuracy: 0.8090\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8101 - val_loss: 0.4893 - val_accuracy: 0.8034\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8101 - val_loss: 0.4889 - val_accuracy: 0.8034\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8080 - val_loss: 0.4883 - val_accuracy: 0.8034\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.8080 - val_loss: 0.4878 - val_accuracy: 0.8034\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8059 - val_loss: 0.4873 - val_accuracy: 0.8034\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8080 - val_loss: 0.4869 - val_accuracy: 0.8034\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.8080 - val_loss: 0.4864 - val_accuracy: 0.8090\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8080 - val_loss: 0.4860 - val_accuracy: 0.8090\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8101 - val_loss: 0.4855 - val_accuracy: 0.8034\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.8101 - val_loss: 0.4851 - val_accuracy: 0.8034\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8080 - val_loss: 0.4846 - val_accuracy: 0.8034\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8059 - val_loss: 0.4844 - val_accuracy: 0.8034\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8059 - val_loss: 0.4839 - val_accuracy: 0.8034\n",
      "8/8 [==============================] - 0s 763us/step - loss: 0.4229 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1121 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5886 - accuracy: 0.6878 - val_loss: 0.6269 - val_accuracy: 0.6236\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.6962 - val_loss: 0.6178 - val_accuracy: 0.6517\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7004 - val_loss: 0.6096 - val_accuracy: 0.6573\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7068 - val_loss: 0.5996 - val_accuracy: 0.6629\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7194 - val_loss: 0.5903 - val_accuracy: 0.6629\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7384 - val_loss: 0.5799 - val_accuracy: 0.6910\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7384 - val_loss: 0.5696 - val_accuracy: 0.6910\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7532 - val_loss: 0.5612 - val_accuracy: 0.7022\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7700 - val_loss: 0.5518 - val_accuracy: 0.7135\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7700 - val_loss: 0.5423 - val_accuracy: 0.7079\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7743 - val_loss: 0.5349 - val_accuracy: 0.7135\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7785 - val_loss: 0.5278 - val_accuracy: 0.7247\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7890 - val_loss: 0.5229 - val_accuracy: 0.7303\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7869 - val_loss: 0.5181 - val_accuracy: 0.7528\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7911 - val_loss: 0.5126 - val_accuracy: 0.7472\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8122 - val_loss: 0.5077 - val_accuracy: 0.7697\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8228 - val_loss: 0.5046 - val_accuracy: 0.7809\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.8249 - val_loss: 0.5003 - val_accuracy: 0.7921\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8333 - val_loss: 0.4975 - val_accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8376 - val_loss: 0.4956 - val_accuracy: 0.7978\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8291 - val_loss: 0.4919 - val_accuracy: 0.7978\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8418 - val_loss: 0.4905 - val_accuracy: 0.7978\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8418 - val_loss: 0.4886 - val_accuracy: 0.8146\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8376 - val_loss: 0.4874 - val_accuracy: 0.8146\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8397 - val_loss: 0.4855 - val_accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8376 - val_loss: 0.4846 - val_accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8354 - val_loss: 0.4834 - val_accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8354 - val_loss: 0.4828 - val_accuracy: 0.8034\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8354 - val_loss: 0.4824 - val_accuracy: 0.8034\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8354 - val_loss: 0.4822 - val_accuracy: 0.8034\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8354 - val_loss: 0.4806 - val_accuracy: 0.8090\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8354 - val_loss: 0.4793 - val_accuracy: 0.8090\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8397 - val_loss: 0.4813 - val_accuracy: 0.8034\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8376 - val_loss: 0.4796 - val_accuracy: 0.8090\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8354 - val_loss: 0.4790 - val_accuracy: 0.8090\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8354 - val_loss: 0.4788 - val_accuracy: 0.8090\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8354 - val_loss: 0.4779 - val_accuracy: 0.8090\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8376 - val_loss: 0.4779 - val_accuracy: 0.8146\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8397 - val_loss: 0.4773 - val_accuracy: 0.8146\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8376 - val_loss: 0.4770 - val_accuracy: 0.8146\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8354 - val_loss: 0.4761 - val_accuracy: 0.8090\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3844 - accuracy: 0.8354 - val_loss: 0.4768 - val_accuracy: 0.8146\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8354 - val_loss: 0.4764 - val_accuracy: 0.8146\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8354 - val_loss: 0.4756 - val_accuracy: 0.8146\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8354 - val_loss: 0.4758 - val_accuracy: 0.8146\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8354 - val_loss: 0.4759 - val_accuracy: 0.8146\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8354 - val_loss: 0.4758 - val_accuracy: 0.8146\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8354 - val_loss: 0.4753 - val_accuracy: 0.8146\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8354 - val_loss: 0.4751 - val_accuracy: 0.8146\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8354 - val_loss: 0.4742 - val_accuracy: 0.8090\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8354 - val_loss: 0.4742 - val_accuracy: 0.8146\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8354 - val_loss: 0.4751 - val_accuracy: 0.8146\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8354 - val_loss: 0.4754 - val_accuracy: 0.8146\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8354 - val_loss: 0.4737 - val_accuracy: 0.8090\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8354 - val_loss: 0.4732 - val_accuracy: 0.8090\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8354 - val_loss: 0.4743 - val_accuracy: 0.8146\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8354 - val_loss: 0.4740 - val_accuracy: 0.8146\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8354 - val_loss: 0.4745 - val_accuracy: 0.8146\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8376 - val_loss: 0.4727 - val_accuracy: 0.8034\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8354 - val_loss: 0.4727 - val_accuracy: 0.8090\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8376 - val_loss: 0.4725 - val_accuracy: 0.8090\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8376 - val_loss: 0.4712 - val_accuracy: 0.8034\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8354 - val_loss: 0.4713 - val_accuracy: 0.8034\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8397 - val_loss: 0.4722 - val_accuracy: 0.8146\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8354 - val_loss: 0.4706 - val_accuracy: 0.8034\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8354 - val_loss: 0.4707 - val_accuracy: 0.8090\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8376 - val_loss: 0.4712 - val_accuracy: 0.8090\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8397 - val_loss: 0.4705 - val_accuracy: 0.8090\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8460 - val_loss: 0.4718 - val_accuracy: 0.8090\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8439 - val_loss: 0.4699 - val_accuracy: 0.8090\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8376 - val_loss: 0.4697 - val_accuracy: 0.8090\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8376 - val_loss: 0.4713 - val_accuracy: 0.8090\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8460 - val_loss: 0.4715 - val_accuracy: 0.8090\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8460 - val_loss: 0.4711 - val_accuracy: 0.8090\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8460 - val_loss: 0.4710 - val_accuracy: 0.8146\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8460 - val_loss: 0.4710 - val_accuracy: 0.8090\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8460 - val_loss: 0.4704 - val_accuracy: 0.8090\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8460 - val_loss: 0.4702 - val_accuracy: 0.8090\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8481 - val_loss: 0.4706 - val_accuracy: 0.8146\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8481 - val_loss: 0.4698 - val_accuracy: 0.8146\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8481 - val_loss: 0.4692 - val_accuracy: 0.8146\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8481 - val_loss: 0.4688 - val_accuracy: 0.8146\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8481 - val_loss: 0.4698 - val_accuracy: 0.8146\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8439 - val_loss: 0.4701 - val_accuracy: 0.8090\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8439 - val_loss: 0.4695 - val_accuracy: 0.8090\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8481 - val_loss: 0.4680 - val_accuracy: 0.8146\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8460 - val_loss: 0.4692 - val_accuracy: 0.8202\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8439 - val_loss: 0.4696 - val_accuracy: 0.8090\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3643 - accuracy: 0.8439 - val_loss: 0.4694 - val_accuracy: 0.8090\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8439 - val_loss: 0.4687 - val_accuracy: 0.8146\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8460 - val_loss: 0.4683 - val_accuracy: 0.8146\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8460 - val_loss: 0.4689 - val_accuracy: 0.8146\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8460 - val_loss: 0.4690 - val_accuracy: 0.8146\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8460 - val_loss: 0.4688 - val_accuracy: 0.8146\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8460 - val_loss: 0.4680 - val_accuracy: 0.8146\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8439 - val_loss: 0.4680 - val_accuracy: 0.8146\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3624 - accuracy: 0.8460 - val_loss: 0.4693 - val_accuracy: 0.8146\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8439 - val_loss: 0.4675 - val_accuracy: 0.8146\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8460 - val_loss: 0.4681 - val_accuracy: 0.8146\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8481 - val_loss: 0.4679 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 812us/step - loss: 0.4386 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1123 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7206 - accuracy: 0.5380 - val_loss: 0.7055 - val_accuracy: 0.5674\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5992 - val_loss: 0.6809 - val_accuracy: 0.6180\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6498 - val_loss: 0.6590 - val_accuracy: 0.6685\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6688 - val_loss: 0.6403 - val_accuracy: 0.6854\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6857 - val_loss: 0.6232 - val_accuracy: 0.6854\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.7068 - val_loss: 0.6064 - val_accuracy: 0.7079\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.7236 - val_loss: 0.5917 - val_accuracy: 0.7247\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7342 - val_loss: 0.5780 - val_accuracy: 0.7360\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7363 - val_loss: 0.5655 - val_accuracy: 0.7528\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7553 - val_loss: 0.5548 - val_accuracy: 0.7584\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7679 - val_loss: 0.5447 - val_accuracy: 0.7697\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7700 - val_loss: 0.5351 - val_accuracy: 0.7640\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7890 - val_loss: 0.5268 - val_accuracy: 0.7697\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7869 - val_loss: 0.5196 - val_accuracy: 0.7809\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8017 - val_loss: 0.5131 - val_accuracy: 0.7921\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.8080 - val_loss: 0.5076 - val_accuracy: 0.7921\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8165 - val_loss: 0.5026 - val_accuracy: 0.7921\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8101 - val_loss: 0.4983 - val_accuracy: 0.7921\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.8101 - val_loss: 0.4943 - val_accuracy: 0.7865\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.8080 - val_loss: 0.4915 - val_accuracy: 0.7865\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8165 - val_loss: 0.4890 - val_accuracy: 0.7865\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8186 - val_loss: 0.4862 - val_accuracy: 0.7865\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8207 - val_loss: 0.4843 - val_accuracy: 0.7921\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8270 - val_loss: 0.4827 - val_accuracy: 0.7921\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8270 - val_loss: 0.4813 - val_accuracy: 0.7865\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8270 - val_loss: 0.4799 - val_accuracy: 0.7978\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8270 - val_loss: 0.4786 - val_accuracy: 0.8034\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8270 - val_loss: 0.4778 - val_accuracy: 0.7978\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8312 - val_loss: 0.4767 - val_accuracy: 0.8090\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8312 - val_loss: 0.4761 - val_accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8312 - val_loss: 0.4758 - val_accuracy: 0.8090\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8312 - val_loss: 0.4751 - val_accuracy: 0.8146\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8376 - val_loss: 0.4752 - val_accuracy: 0.8090\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8376 - val_loss: 0.4744 - val_accuracy: 0.8146\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8376 - val_loss: 0.4743 - val_accuracy: 0.8146\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8376 - val_loss: 0.4738 - val_accuracy: 0.8146\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8397 - val_loss: 0.4737 - val_accuracy: 0.8146\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8376 - val_loss: 0.4734 - val_accuracy: 0.8146\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8397 - val_loss: 0.4735 - val_accuracy: 0.8146\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8397 - val_loss: 0.4731 - val_accuracy: 0.8202\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8397 - val_loss: 0.4728 - val_accuracy: 0.8202\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8397 - val_loss: 0.4726 - val_accuracy: 0.8202\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8397 - val_loss: 0.4726 - val_accuracy: 0.8202\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8418 - val_loss: 0.4723 - val_accuracy: 0.8202\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8418 - val_loss: 0.4722 - val_accuracy: 0.8202\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8418 - val_loss: 0.4717 - val_accuracy: 0.8202\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8418 - val_loss: 0.4717 - val_accuracy: 0.8202\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8418 - val_loss: 0.4715 - val_accuracy: 0.8202\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8439 - val_loss: 0.4717 - val_accuracy: 0.8202\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8418 - val_loss: 0.4716 - val_accuracy: 0.8202\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8439 - val_loss: 0.4712 - val_accuracy: 0.8202\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8439 - val_loss: 0.4711 - val_accuracy: 0.8146\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8439 - val_loss: 0.4710 - val_accuracy: 0.8202\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8439 - val_loss: 0.4707 - val_accuracy: 0.8202\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8439 - val_loss: 0.4710 - val_accuracy: 0.8202\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.8439 - val_loss: 0.4709 - val_accuracy: 0.8202\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8439 - val_loss: 0.4710 - val_accuracy: 0.8146\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8439 - val_loss: 0.4708 - val_accuracy: 0.8202\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3889 - accuracy: 0.8439 - val_loss: 0.4707 - val_accuracy: 0.8202\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8439 - val_loss: 0.4708 - val_accuracy: 0.8202\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8439 - val_loss: 0.4713 - val_accuracy: 0.8202\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8439 - val_loss: 0.4713 - val_accuracy: 0.8202\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8439 - val_loss: 0.4710 - val_accuracy: 0.8146\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8439 - val_loss: 0.4713 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 789us/step - loss: 0.4014 - accuracy: 0.8101\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1125 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5555 - accuracy: 0.7405 - val_loss: 0.5360 - val_accuracy: 0.7472\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7426 - val_loss: 0.5295 - val_accuracy: 0.7584\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7511 - val_loss: 0.5240 - val_accuracy: 0.7584\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7616 - val_loss: 0.5192 - val_accuracy: 0.7753\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7700 - val_loss: 0.5156 - val_accuracy: 0.7697\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7806 - val_loss: 0.5115 - val_accuracy: 0.7640\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7848 - val_loss: 0.5078 - val_accuracy: 0.7753\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7848 - val_loss: 0.5050 - val_accuracy: 0.7921\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7932 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7932 - val_loss: 0.4993 - val_accuracy: 0.7978\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8017 - val_loss: 0.4963 - val_accuracy: 0.7921\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8101 - val_loss: 0.4947 - val_accuracy: 0.7978\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.8143 - val_loss: 0.4929 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8165 - val_loss: 0.4915 - val_accuracy: 0.7978\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8186 - val_loss: 0.4897 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.8249 - val_loss: 0.4881 - val_accuracy: 0.8034\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8249 - val_loss: 0.4878 - val_accuracy: 0.8034\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8249 - val_loss: 0.4865 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.8228 - val_loss: 0.4860 - val_accuracy: 0.8034\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8228 - val_loss: 0.4854 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8207 - val_loss: 0.4848 - val_accuracy: 0.8034\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8186 - val_loss: 0.4847 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8186 - val_loss: 0.4831 - val_accuracy: 0.8034\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.8186 - val_loss: 0.4822 - val_accuracy: 0.8034\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8186 - val_loss: 0.4825 - val_accuracy: 0.8034\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8186 - val_loss: 0.4822 - val_accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8165 - val_loss: 0.4806 - val_accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8165 - val_loss: 0.4809 - val_accuracy: 0.8090\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8165 - val_loss: 0.4805 - val_accuracy: 0.8146\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8165 - val_loss: 0.4805 - val_accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8165 - val_loss: 0.4792 - val_accuracy: 0.8090\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8228 - val_loss: 0.4793 - val_accuracy: 0.8090\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8249 - val_loss: 0.4790 - val_accuracy: 0.8090\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8228 - val_loss: 0.4793 - val_accuracy: 0.8090\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8228 - val_loss: 0.4790 - val_accuracy: 0.8090\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8228 - val_loss: 0.4791 - val_accuracy: 0.8090\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8207 - val_loss: 0.4783 - val_accuracy: 0.8034\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8228 - val_loss: 0.4784 - val_accuracy: 0.8034\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8249 - val_loss: 0.4778 - val_accuracy: 0.7978\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8228 - val_loss: 0.4779 - val_accuracy: 0.7978\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8249 - val_loss: 0.4783 - val_accuracy: 0.8034\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8291 - val_loss: 0.4782 - val_accuracy: 0.7978\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8291 - val_loss: 0.4787 - val_accuracy: 0.7978\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8291 - val_loss: 0.4782 - val_accuracy: 0.7978\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8291 - val_loss: 0.4784 - val_accuracy: 0.7921\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8270 - val_loss: 0.4779 - val_accuracy: 0.7921\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8291 - val_loss: 0.4786 - val_accuracy: 0.7921\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8291 - val_loss: 0.4781 - val_accuracy: 0.7921\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8270 - val_loss: 0.4790 - val_accuracy: 0.7921\n",
      "8/8 [==============================] - 0s 765us/step - loss: 0.4018 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1127 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6453 - accuracy: 0.6899 - val_loss: 0.6387 - val_accuracy: 0.6854\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.7489 - val_loss: 0.6037 - val_accuracy: 0.6798\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7489 - val_loss: 0.5811 - val_accuracy: 0.6798\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7447 - val_loss: 0.5655 - val_accuracy: 0.6798\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7553 - val_loss: 0.5518 - val_accuracy: 0.6910\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7679 - val_loss: 0.5401 - val_accuracy: 0.7079\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7869 - val_loss: 0.5302 - val_accuracy: 0.7247\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7954 - val_loss: 0.5200 - val_accuracy: 0.7528\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8143 - val_loss: 0.5116 - val_accuracy: 0.7809\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.8207 - val_loss: 0.5066 - val_accuracy: 0.7978\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8165 - val_loss: 0.5022 - val_accuracy: 0.7921\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.8291 - val_loss: 0.4965 - val_accuracy: 0.7753\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8228 - val_loss: 0.4945 - val_accuracy: 0.7921\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8228 - val_loss: 0.4904 - val_accuracy: 0.7921\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8270 - val_loss: 0.4877 - val_accuracy: 0.7921\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8270 - val_loss: 0.4866 - val_accuracy: 0.7978\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8354 - val_loss: 0.4838 - val_accuracy: 0.7978\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8354 - val_loss: 0.4819 - val_accuracy: 0.7921\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8333 - val_loss: 0.4808 - val_accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8354 - val_loss: 0.4791 - val_accuracy: 0.7978\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8354 - val_loss: 0.4789 - val_accuracy: 0.7978\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8333 - val_loss: 0.4778 - val_accuracy: 0.7978\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8312 - val_loss: 0.4751 - val_accuracy: 0.8090\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8312 - val_loss: 0.4745 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8333 - val_loss: 0.4725 - val_accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8354 - val_loss: 0.4718 - val_accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8354 - val_loss: 0.4715 - val_accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8354 - val_loss: 0.4691 - val_accuracy: 0.8090\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8354 - val_loss: 0.4707 - val_accuracy: 0.8146\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8376 - val_loss: 0.4690 - val_accuracy: 0.8146\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8376 - val_loss: 0.4689 - val_accuracy: 0.8146\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8376 - val_loss: 0.4687 - val_accuracy: 0.8258\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8397 - val_loss: 0.4670 - val_accuracy: 0.8146\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8418 - val_loss: 0.4681 - val_accuracy: 0.8315\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8439 - val_loss: 0.4668 - val_accuracy: 0.8315\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8439 - val_loss: 0.4661 - val_accuracy: 0.8315\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8418 - val_loss: 0.4661 - val_accuracy: 0.8315\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8439 - val_loss: 0.4663 - val_accuracy: 0.8371\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8523 - val_loss: 0.4667 - val_accuracy: 0.8371\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8502 - val_loss: 0.4656 - val_accuracy: 0.8371\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8523 - val_loss: 0.4659 - val_accuracy: 0.8371\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3643 - accuracy: 0.8481 - val_loss: 0.4640 - val_accuracy: 0.8315\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8502 - val_loss: 0.4647 - val_accuracy: 0.8371\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.8502 - val_loss: 0.4646 - val_accuracy: 0.8371\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8502 - val_loss: 0.4653 - val_accuracy: 0.8371\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8523 - val_loss: 0.4648 - val_accuracy: 0.8371\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8502 - val_loss: 0.4644 - val_accuracy: 0.8371\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8481 - val_loss: 0.4648 - val_accuracy: 0.8371\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8481 - val_loss: 0.4642 - val_accuracy: 0.8371\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8523 - val_loss: 0.4655 - val_accuracy: 0.8371\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8502 - val_loss: 0.4650 - val_accuracy: 0.8371\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8523 - val_loss: 0.4647 - val_accuracy: 0.8371\n",
      "8/8 [==============================] - 0s 802us/step - loss: 0.4255 - accuracy: 0.8101\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1129 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6919 - accuracy: 0.5717 - val_loss: 0.6618 - val_accuracy: 0.7079\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.6646 - val_loss: 0.6239 - val_accuracy: 0.6910\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.6751 - val_loss: 0.5954 - val_accuracy: 0.6966\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7025 - val_loss: 0.5731 - val_accuracy: 0.7191\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7384 - val_loss: 0.5539 - val_accuracy: 0.7360\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7700 - val_loss: 0.5364 - val_accuracy: 0.7528\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7743 - val_loss: 0.5224 - val_accuracy: 0.7921\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8143 - val_loss: 0.5113 - val_accuracy: 0.7809\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.8207 - val_loss: 0.5014 - val_accuracy: 0.8146\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.8270 - val_loss: 0.4942 - val_accuracy: 0.8202\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.8291 - val_loss: 0.4887 - val_accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.8270 - val_loss: 0.4846 - val_accuracy: 0.8258\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.8312 - val_loss: 0.4806 - val_accuracy: 0.8146\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8333 - val_loss: 0.4779 - val_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8354 - val_loss: 0.4768 - val_accuracy: 0.8202\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8333 - val_loss: 0.4751 - val_accuracy: 0.8146\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8354 - val_loss: 0.4736 - val_accuracy: 0.8202\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8354 - val_loss: 0.4732 - val_accuracy: 0.8146\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8376 - val_loss: 0.4723 - val_accuracy: 0.8146\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8376 - val_loss: 0.4719 - val_accuracy: 0.8146\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8376 - val_loss: 0.4718 - val_accuracy: 0.8202\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8376 - val_loss: 0.4706 - val_accuracy: 0.8202\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8376 - val_loss: 0.4706 - val_accuracy: 0.8202\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8376 - val_loss: 0.4708 - val_accuracy: 0.8202\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8397 - val_loss: 0.4693 - val_accuracy: 0.8202\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8397 - val_loss: 0.4696 - val_accuracy: 0.8202\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8397 - val_loss: 0.4693 - val_accuracy: 0.8258\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8418 - val_loss: 0.4683 - val_accuracy: 0.8258\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8397 - val_loss: 0.4694 - val_accuracy: 0.8202\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8397 - val_loss: 0.4682 - val_accuracy: 0.8258\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8418 - val_loss: 0.4680 - val_accuracy: 0.8258\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8418 - val_loss: 0.4678 - val_accuracy: 0.8258\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3892 - accuracy: 0.8418 - val_loss: 0.4676 - val_accuracy: 0.8258\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8418 - val_loss: 0.4693 - val_accuracy: 0.8258\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8418 - val_loss: 0.4683 - val_accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8418 - val_loss: 0.4677 - val_accuracy: 0.8258\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8418 - val_loss: 0.4676 - val_accuracy: 0.8258\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8418 - val_loss: 0.4673 - val_accuracy: 0.8258\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8418 - val_loss: 0.4675 - val_accuracy: 0.8258\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8439 - val_loss: 0.4680 - val_accuracy: 0.8258\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8439 - val_loss: 0.4673 - val_accuracy: 0.8258\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8439 - val_loss: 0.4672 - val_accuracy: 0.8258\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8439 - val_loss: 0.4674 - val_accuracy: 0.8258\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8460 - val_loss: 0.4673 - val_accuracy: 0.8258\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8460 - val_loss: 0.4671 - val_accuracy: 0.8258\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8439 - val_loss: 0.4671 - val_accuracy: 0.8258\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8481 - val_loss: 0.4671 - val_accuracy: 0.8258\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8481 - val_loss: 0.4664 - val_accuracy: 0.8258\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8481 - val_loss: 0.4690 - val_accuracy: 0.8258\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8481 - val_loss: 0.4673 - val_accuracy: 0.8258\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8481 - val_loss: 0.4670 - val_accuracy: 0.8258\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3737 - accuracy: 0.8460 - val_loss: 0.4682 - val_accuracy: 0.8202\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8460 - val_loss: 0.4685 - val_accuracy: 0.8202\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8460 - val_loss: 0.4686 - val_accuracy: 0.8258\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8481 - val_loss: 0.4687 - val_accuracy: 0.8258\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8460 - val_loss: 0.4686 - val_accuracy: 0.8258\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8460 - val_loss: 0.4694 - val_accuracy: 0.8202\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8460 - val_loss: 0.4692 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 772us/step - loss: 0.4113 - accuracy: 0.8059\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1131 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6474 - accuracy: 0.6414 - val_loss: 0.6515 - val_accuracy: 0.6404\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.6730 - val_loss: 0.6242 - val_accuracy: 0.6348\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.6835 - val_loss: 0.6044 - val_accuracy: 0.6404\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.7004 - val_loss: 0.5875 - val_accuracy: 0.6685\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7215 - val_loss: 0.5734 - val_accuracy: 0.6742\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7363 - val_loss: 0.5612 - val_accuracy: 0.6966\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7595 - val_loss: 0.5510 - val_accuracy: 0.7135\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7764 - val_loss: 0.5424 - val_accuracy: 0.7079\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7700 - val_loss: 0.5352 - val_accuracy: 0.7360\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7869 - val_loss: 0.5280 - val_accuracy: 0.7360\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7890 - val_loss: 0.5233 - val_accuracy: 0.7640\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7890 - val_loss: 0.5193 - val_accuracy: 0.7640\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7932 - val_loss: 0.5161 - val_accuracy: 0.7640\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7911 - val_loss: 0.5109 - val_accuracy: 0.7640\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7975 - val_loss: 0.5080 - val_accuracy: 0.7697\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.8017 - val_loss: 0.5051 - val_accuracy: 0.7753\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.8059 - val_loss: 0.5043 - val_accuracy: 0.7697\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8080 - val_loss: 0.5007 - val_accuracy: 0.7809\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8080 - val_loss: 0.4995 - val_accuracy: 0.7809\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8122 - val_loss: 0.4977 - val_accuracy: 0.7921\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8122 - val_loss: 0.4950 - val_accuracy: 0.7978\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.8122 - val_loss: 0.4940 - val_accuracy: 0.7978\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8143 - val_loss: 0.4921 - val_accuracy: 0.7978\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8186 - val_loss: 0.4908 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8186 - val_loss: 0.4892 - val_accuracy: 0.8034\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8186 - val_loss: 0.4885 - val_accuracy: 0.8034\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8186 - val_loss: 0.4890 - val_accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8186 - val_loss: 0.4869 - val_accuracy: 0.8034\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8186 - val_loss: 0.4864 - val_accuracy: 0.8034\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8186 - val_loss: 0.4845 - val_accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8207 - val_loss: 0.4861 - val_accuracy: 0.7978\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8228 - val_loss: 0.4856 - val_accuracy: 0.7978\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8207 - val_loss: 0.4854 - val_accuracy: 0.7978\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8228 - val_loss: 0.4835 - val_accuracy: 0.8034\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8228 - val_loss: 0.4843 - val_accuracy: 0.7978\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8249 - val_loss: 0.4847 - val_accuracy: 0.7978\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8270 - val_loss: 0.4847 - val_accuracy: 0.7978\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8249 - val_loss: 0.4823 - val_accuracy: 0.7978\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8228 - val_loss: 0.4812 - val_accuracy: 0.8034\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8228 - val_loss: 0.4836 - val_accuracy: 0.7978\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8249 - val_loss: 0.4831 - val_accuracy: 0.7978\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8249 - val_loss: 0.4814 - val_accuracy: 0.7978\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8249 - val_loss: 0.4821 - val_accuracy: 0.7978\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8249 - val_loss: 0.4817 - val_accuracy: 0.7978\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3876 - accuracy: 0.8270 - val_loss: 0.4818 - val_accuracy: 0.7978\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8270 - val_loss: 0.4819 - val_accuracy: 0.7921\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.8270 - val_loss: 0.4819 - val_accuracy: 0.7921\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8291 - val_loss: 0.4804 - val_accuracy: 0.7978\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8333 - val_loss: 0.4814 - val_accuracy: 0.7865\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8291 - val_loss: 0.4817 - val_accuracy: 0.7865\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8270 - val_loss: 0.4819 - val_accuracy: 0.7921\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8333 - val_loss: 0.4825 - val_accuracy: 0.7978\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8333 - val_loss: 0.4813 - val_accuracy: 0.8090\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8376 - val_loss: 0.4820 - val_accuracy: 0.7978\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8376 - val_loss: 0.4826 - val_accuracy: 0.7978\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8312 - val_loss: 0.4815 - val_accuracy: 0.8034\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8312 - val_loss: 0.4807 - val_accuracy: 0.8034\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8397 - val_loss: 0.4818 - val_accuracy: 0.8034\n",
      "8/8 [==============================] - 0s 789us/step - loss: 0.4093 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1133 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6011 - accuracy: 0.6751 - val_loss: 0.6207 - val_accuracy: 0.6573\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7152 - val_loss: 0.5935 - val_accuracy: 0.6742\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7489 - val_loss: 0.5726 - val_accuracy: 0.7079\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7489 - val_loss: 0.5526 - val_accuracy: 0.7191\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7679 - val_loss: 0.5374 - val_accuracy: 0.7416\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7911 - val_loss: 0.5213 - val_accuracy: 0.7640\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.8017 - val_loss: 0.5122 - val_accuracy: 0.7809\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.8228 - val_loss: 0.5022 - val_accuracy: 0.7865\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.8291 - val_loss: 0.4934 - val_accuracy: 0.8034\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8291 - val_loss: 0.4878 - val_accuracy: 0.7978\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8312 - val_loss: 0.4846 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8312 - val_loss: 0.4834 - val_accuracy: 0.8034\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8333 - val_loss: 0.4815 - val_accuracy: 0.8034\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8333 - val_loss: 0.4787 - val_accuracy: 0.8034\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8376 - val_loss: 0.4771 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8376 - val_loss: 0.4767 - val_accuracy: 0.8146\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8397 - val_loss: 0.4763 - val_accuracy: 0.8146\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8376 - val_loss: 0.4752 - val_accuracy: 0.8146\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8397 - val_loss: 0.4722 - val_accuracy: 0.8146\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8397 - val_loss: 0.4736 - val_accuracy: 0.8146\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8439 - val_loss: 0.4745 - val_accuracy: 0.8146\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8418 - val_loss: 0.4714 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8397 - val_loss: 0.4700 - val_accuracy: 0.8090\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8418 - val_loss: 0.4725 - val_accuracy: 0.8146\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8439 - val_loss: 0.4699 - val_accuracy: 0.8146\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8460 - val_loss: 0.4717 - val_accuracy: 0.8146\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8460 - val_loss: 0.4708 - val_accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8439 - val_loss: 0.4694 - val_accuracy: 0.8090\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8460 - val_loss: 0.4702 - val_accuracy: 0.8146\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8481 - val_loss: 0.4683 - val_accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8439 - val_loss: 0.4713 - val_accuracy: 0.8146\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8523 - val_loss: 0.4693 - val_accuracy: 0.8090\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8481 - val_loss: 0.4681 - val_accuracy: 0.8146\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8502 - val_loss: 0.4691 - val_accuracy: 0.8146\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8481 - val_loss: 0.4706 - val_accuracy: 0.8202\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8523 - val_loss: 0.4687 - val_accuracy: 0.8146\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8629 - val_loss: 0.4696 - val_accuracy: 0.8202\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8544 - val_loss: 0.4683 - val_accuracy: 0.8146\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8608 - val_loss: 0.4700 - val_accuracy: 0.8202\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8608 - val_loss: 0.4688 - val_accuracy: 0.8202\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8502 - val_loss: 0.4683 - val_accuracy: 0.8202\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8565 - val_loss: 0.4669 - val_accuracy: 0.8202\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8608 - val_loss: 0.4702 - val_accuracy: 0.8202\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8629 - val_loss: 0.4706 - val_accuracy: 0.8202\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8629 - val_loss: 0.4679 - val_accuracy: 0.8202\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8650 - val_loss: 0.4685 - val_accuracy: 0.8202\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8650 - val_loss: 0.4686 - val_accuracy: 0.8258\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8586 - val_loss: 0.4677 - val_accuracy: 0.8202\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8608 - val_loss: 0.4694 - val_accuracy: 0.8202\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8671 - val_loss: 0.4697 - val_accuracy: 0.8202\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3550 - accuracy: 0.8608 - val_loss: 0.4684 - val_accuracy: 0.8258\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8650 - val_loss: 0.4707 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 809us/step - loss: 0.4380 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1135 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7190 - accuracy: 0.3903 - val_loss: 0.6902 - val_accuracy: 0.5337\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.6582 - val_loss: 0.6373 - val_accuracy: 0.6966\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.7089 - val_loss: 0.6018 - val_accuracy: 0.7022\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7194 - val_loss: 0.5763 - val_accuracy: 0.7079\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7257 - val_loss: 0.5556 - val_accuracy: 0.7303\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7511 - val_loss: 0.5385 - val_accuracy: 0.7472\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7532 - val_loss: 0.5240 - val_accuracy: 0.7584\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7743 - val_loss: 0.5131 - val_accuracy: 0.7640\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7827 - val_loss: 0.5031 - val_accuracy: 0.7809\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.8017 - val_loss: 0.4945 - val_accuracy: 0.7921\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8186 - val_loss: 0.4888 - val_accuracy: 0.7978\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8207 - val_loss: 0.4836 - val_accuracy: 0.7921\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8312 - val_loss: 0.4791 - val_accuracy: 0.8034\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8312 - val_loss: 0.4776 - val_accuracy: 0.8034\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8291 - val_loss: 0.4759 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8312 - val_loss: 0.4729 - val_accuracy: 0.8034\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8354 - val_loss: 0.4711 - val_accuracy: 0.8146\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8354 - val_loss: 0.4707 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8354 - val_loss: 0.4688 - val_accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8354 - val_loss: 0.4688 - val_accuracy: 0.8090\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8376 - val_loss: 0.4675 - val_accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8376 - val_loss: 0.4669 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8397 - val_loss: 0.4675 - val_accuracy: 0.8202\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8376 - val_loss: 0.4666 - val_accuracy: 0.8146\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8397 - val_loss: 0.4661 - val_accuracy: 0.8146\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8397 - val_loss: 0.4654 - val_accuracy: 0.8258\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8418 - val_loss: 0.4651 - val_accuracy: 0.8202\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3868 - accuracy: 0.8418 - val_loss: 0.4638 - val_accuracy: 0.8202\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8418 - val_loss: 0.4642 - val_accuracy: 0.8202\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8418 - val_loss: 0.4639 - val_accuracy: 0.8258\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8418 - val_loss: 0.4636 - val_accuracy: 0.8258\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8418 - val_loss: 0.4645 - val_accuracy: 0.8202\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8460 - val_loss: 0.4645 - val_accuracy: 0.8315\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8460 - val_loss: 0.4641 - val_accuracy: 0.8258\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8460 - val_loss: 0.4635 - val_accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8460 - val_loss: 0.4640 - val_accuracy: 0.8258\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8439 - val_loss: 0.4633 - val_accuracy: 0.8258\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8460 - val_loss: 0.4644 - val_accuracy: 0.8315\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8439 - val_loss: 0.4649 - val_accuracy: 0.8315\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8460 - val_loss: 0.4639 - val_accuracy: 0.8315\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8460 - val_loss: 0.4646 - val_accuracy: 0.8315\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8460 - val_loss: 0.4655 - val_accuracy: 0.8258\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8460 - val_loss: 0.4652 - val_accuracy: 0.8371\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8481 - val_loss: 0.4658 - val_accuracy: 0.8315\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8460 - val_loss: 0.4647 - val_accuracy: 0.8371\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8481 - val_loss: 0.4672 - val_accuracy: 0.8427\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8460 - val_loss: 0.4669 - val_accuracy: 0.8315\n",
      "8/8 [==============================] - 0s 764us/step - loss: 0.4026 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1137 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7319 - accuracy: 0.4325 - val_loss: 0.6752 - val_accuracy: 0.6461\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7363 - val_loss: 0.6111 - val_accuracy: 0.6854\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7173 - val_loss: 0.5806 - val_accuracy: 0.6966\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7300 - val_loss: 0.5621 - val_accuracy: 0.7022\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7489 - val_loss: 0.5469 - val_accuracy: 0.7191\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7722 - val_loss: 0.5370 - val_accuracy: 0.7191\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7954 - val_loss: 0.5268 - val_accuracy: 0.7416\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.8122 - val_loss: 0.5185 - val_accuracy: 0.7584\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.8080 - val_loss: 0.5140 - val_accuracy: 0.7697\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.8101 - val_loss: 0.5071 - val_accuracy: 0.7921\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.8165 - val_loss: 0.5019 - val_accuracy: 0.8146\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8165 - val_loss: 0.4994 - val_accuracy: 0.8034\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.8143 - val_loss: 0.4955 - val_accuracy: 0.8034\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8143 - val_loss: 0.4945 - val_accuracy: 0.7978\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8122 - val_loss: 0.4910 - val_accuracy: 0.7978\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8165 - val_loss: 0.4892 - val_accuracy: 0.7978\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8165 - val_loss: 0.4890 - val_accuracy: 0.7978\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8207 - val_loss: 0.4874 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8165 - val_loss: 0.4871 - val_accuracy: 0.8034\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8228 - val_loss: 0.4846 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8207 - val_loss: 0.4833 - val_accuracy: 0.8034\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8228 - val_loss: 0.4842 - val_accuracy: 0.8034\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8228 - val_loss: 0.4828 - val_accuracy: 0.8034\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8249 - val_loss: 0.4832 - val_accuracy: 0.8034\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8249 - val_loss: 0.4823 - val_accuracy: 0.8034\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8270 - val_loss: 0.4821 - val_accuracy: 0.8034\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.8270 - val_loss: 0.4823 - val_accuracy: 0.7921\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8270 - val_loss: 0.4834 - val_accuracy: 0.7921\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8291 - val_loss: 0.4832 - val_accuracy: 0.7921\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8312 - val_loss: 0.4829 - val_accuracy: 0.7978\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8291 - val_loss: 0.4817 - val_accuracy: 0.7921\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8291 - val_loss: 0.4816 - val_accuracy: 0.7921\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8312 - val_loss: 0.4821 - val_accuracy: 0.8034\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8354 - val_loss: 0.4820 - val_accuracy: 0.8034\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8354 - val_loss: 0.4800 - val_accuracy: 0.7978\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8397 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8376 - val_loss: 0.4852 - val_accuracy: 0.7978\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8418 - val_loss: 0.4827 - val_accuracy: 0.7978\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8418 - val_loss: 0.4810 - val_accuracy: 0.7978\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8397 - val_loss: 0.4819 - val_accuracy: 0.7978\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8439 - val_loss: 0.4821 - val_accuracy: 0.7978\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8418 - val_loss: 0.4822 - val_accuracy: 0.7921\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8502 - val_loss: 0.4848 - val_accuracy: 0.7921\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8481 - val_loss: 0.4841 - val_accuracy: 0.7921\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8502 - val_loss: 0.4853 - val_accuracy: 0.7921\n",
      "8/8 [==============================] - 0s 755us/step - loss: 0.4058 - accuracy: 0.8397\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1139 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7779 - accuracy: 0.4030 - val_loss: 0.6785 - val_accuracy: 0.6629\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.7574 - val_loss: 0.6015 - val_accuracy: 0.6854\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7363 - val_loss: 0.5664 - val_accuracy: 0.7079\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7595 - val_loss: 0.5491 - val_accuracy: 0.7247\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7806 - val_loss: 0.5326 - val_accuracy: 0.7416\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7932 - val_loss: 0.5163 - val_accuracy: 0.7921\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8186 - val_loss: 0.5048 - val_accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8333 - val_loss: 0.4961 - val_accuracy: 0.8034\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8270 - val_loss: 0.4884 - val_accuracy: 0.7978\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8291 - val_loss: 0.4877 - val_accuracy: 0.7978\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8270 - val_loss: 0.4878 - val_accuracy: 0.8034\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.8333 - val_loss: 0.4811 - val_accuracy: 0.8034\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8376 - val_loss: 0.4796 - val_accuracy: 0.8034\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8376 - val_loss: 0.4760 - val_accuracy: 0.8090\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8376 - val_loss: 0.4800 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8354 - val_loss: 0.4736 - val_accuracy: 0.8090\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8354 - val_loss: 0.4743 - val_accuracy: 0.8090\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8397 - val_loss: 0.4738 - val_accuracy: 0.8090\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8418 - val_loss: 0.4725 - val_accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8418 - val_loss: 0.4735 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8418 - val_loss: 0.4719 - val_accuracy: 0.8034\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8439 - val_loss: 0.4707 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8460 - val_loss: 0.4741 - val_accuracy: 0.8090\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8439 - val_loss: 0.4705 - val_accuracy: 0.8146\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8502 - val_loss: 0.4701 - val_accuracy: 0.8146\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8502 - val_loss: 0.4707 - val_accuracy: 0.8202\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8502 - val_loss: 0.4695 - val_accuracy: 0.8202\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8523 - val_loss: 0.4703 - val_accuracy: 0.8202\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8481 - val_loss: 0.4675 - val_accuracy: 0.8202\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8481 - val_loss: 0.4712 - val_accuracy: 0.8202\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8544 - val_loss: 0.4714 - val_accuracy: 0.8202\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8481 - val_loss: 0.4691 - val_accuracy: 0.8258\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8565 - val_loss: 0.4702 - val_accuracy: 0.8202\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8565 - val_loss: 0.4723 - val_accuracy: 0.8202\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 0.8544 - val_loss: 0.4731 - val_accuracy: 0.8202\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8544 - val_loss: 0.4707 - val_accuracy: 0.8258\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8586 - val_loss: 0.4723 - val_accuracy: 0.8258\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8629 - val_loss: 0.4708 - val_accuracy: 0.8258\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8586 - val_loss: 0.4711 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 850us/step - loss: 0.4264 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1141 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7243 - accuracy: 0.4473 - val_loss: 0.6590 - val_accuracy: 0.6180\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.6519 - val_loss: 0.6009 - val_accuracy: 0.6573\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.6962 - val_loss: 0.5698 - val_accuracy: 0.6854\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7131 - val_loss: 0.5435 - val_accuracy: 0.7247\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7574 - val_loss: 0.5205 - val_accuracy: 0.7697\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.8207 - val_loss: 0.5030 - val_accuracy: 0.8090\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.8165 - val_loss: 0.4905 - val_accuracy: 0.7753\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8249 - val_loss: 0.4815 - val_accuracy: 0.7921\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4985 - accuracy: 0.78 - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8249 - val_loss: 0.4759 - val_accuracy: 0.7921\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8228 - val_loss: 0.4736 - val_accuracy: 0.7978\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8249 - val_loss: 0.4717 - val_accuracy: 0.7978\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8312 - val_loss: 0.4693 - val_accuracy: 0.7978\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8312 - val_loss: 0.4678 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8333 - val_loss: 0.4685 - val_accuracy: 0.7978\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8376 - val_loss: 0.4654 - val_accuracy: 0.8034\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8397 - val_loss: 0.4655 - val_accuracy: 0.8034\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8354 - val_loss: 0.4676 - val_accuracy: 0.8090\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8397 - val_loss: 0.4654 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3874 - accuracy: 0.8376 - val_loss: 0.4650 - val_accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3868 - accuracy: 0.8397 - val_loss: 0.4653 - val_accuracy: 0.8090\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8418 - val_loss: 0.4633 - val_accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8397 - val_loss: 0.4653 - val_accuracy: 0.8090\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3805 - accuracy: 0.8439 - val_loss: 0.4659 - val_accuracy: 0.8090\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8460 - val_loss: 0.4649 - val_accuracy: 0.8034\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8460 - val_loss: 0.4641 - val_accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8481 - val_loss: 0.4634 - val_accuracy: 0.8146\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8481 - val_loss: 0.4669 - val_accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8481 - val_loss: 0.4657 - val_accuracy: 0.8090\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8481 - val_loss: 0.4648 - val_accuracy: 0.8146\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8523 - val_loss: 0.4648 - val_accuracy: 0.8146\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8523 - val_loss: 0.4652 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 797us/step - loss: 0.4003 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1143 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7089 - accuracy: 0.4641 - val_loss: 0.6537 - val_accuracy: 0.6742\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.7131 - val_loss: 0.5988 - val_accuracy: 0.6517\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7194 - val_loss: 0.5682 - val_accuracy: 0.6685\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7300 - val_loss: 0.5481 - val_accuracy: 0.6742\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7595 - val_loss: 0.5307 - val_accuracy: 0.7360\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7890 - val_loss: 0.5158 - val_accuracy: 0.7809\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.8122 - val_loss: 0.5074 - val_accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.8186 - val_loss: 0.5024 - val_accuracy: 0.7978\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8122 - val_loss: 0.4946 - val_accuracy: 0.7921\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8186 - val_loss: 0.4913 - val_accuracy: 0.7921\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8207 - val_loss: 0.4896 - val_accuracy: 0.7978\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8165 - val_loss: 0.4856 - val_accuracy: 0.7978\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8228 - val_loss: 0.4847 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8228 - val_loss: 0.4848 - val_accuracy: 0.7921\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8207 - val_loss: 0.4847 - val_accuracy: 0.7978\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8312 - val_loss: 0.4841 - val_accuracy: 0.7921\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8291 - val_loss: 0.4838 - val_accuracy: 0.7865\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8312 - val_loss: 0.4814 - val_accuracy: 0.7921\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8333 - val_loss: 0.4862 - val_accuracy: 0.7865\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8333 - val_loss: 0.4826 - val_accuracy: 0.7809\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8354 - val_loss: 0.4832 - val_accuracy: 0.7809\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8397 - val_loss: 0.4864 - val_accuracy: 0.7865\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8333 - val_loss: 0.4864 - val_accuracy: 0.7809\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8312 - val_loss: 0.4845 - val_accuracy: 0.7809\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8418 - val_loss: 0.4844 - val_accuracy: 0.7865\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8376 - val_loss: 0.4843 - val_accuracy: 0.7809\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8418 - val_loss: 0.4829 - val_accuracy: 0.7809\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8460 - val_loss: 0.4879 - val_accuracy: 0.7809\n",
      "8/8 [==============================] - 0s 837us/step - loss: 0.4030 - accuracy: 0.8397\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1145 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6152 - accuracy: 0.6582 - val_loss: 0.6093 - val_accuracy: 0.6685\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.6772 - val_loss: 0.5961 - val_accuracy: 0.6629\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.6878 - val_loss: 0.5866 - val_accuracy: 0.6798\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7004 - val_loss: 0.5787 - val_accuracy: 0.6742\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7257 - val_loss: 0.5711 - val_accuracy: 0.6854\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7321 - val_loss: 0.5639 - val_accuracy: 0.6966\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7405 - val_loss: 0.5556 - val_accuracy: 0.7079\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7447 - val_loss: 0.5480 - val_accuracy: 0.7191\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7574 - val_loss: 0.5417 - val_accuracy: 0.7247\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7658 - val_loss: 0.5351 - val_accuracy: 0.7135\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7827 - val_loss: 0.5287 - val_accuracy: 0.7303\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7890 - val_loss: 0.5243 - val_accuracy: 0.7360\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7932 - val_loss: 0.5172 - val_accuracy: 0.7472\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7996 - val_loss: 0.5143 - val_accuracy: 0.7472\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.8165 - val_loss: 0.5085 - val_accuracy: 0.7753\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8207 - val_loss: 0.5053 - val_accuracy: 0.7865\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.8291 - val_loss: 0.5012 - val_accuracy: 0.7921\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8354 - val_loss: 0.4987 - val_accuracy: 0.7978\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8376 - val_loss: 0.4962 - val_accuracy: 0.8034\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8439 - val_loss: 0.4923 - val_accuracy: 0.8090\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8418 - val_loss: 0.4923 - val_accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8397 - val_loss: 0.4902 - val_accuracy: 0.8034\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8397 - val_loss: 0.4873 - val_accuracy: 0.8146\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8439 - val_loss: 0.4867 - val_accuracy: 0.8146\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8418 - val_loss: 0.4867 - val_accuracy: 0.8202\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8439 - val_loss: 0.4832 - val_accuracy: 0.8202\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8418 - val_loss: 0.4836 - val_accuracy: 0.8202\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8460 - val_loss: 0.4829 - val_accuracy: 0.8202\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8439 - val_loss: 0.4815 - val_accuracy: 0.8202\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8460 - val_loss: 0.4791 - val_accuracy: 0.8202\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8460 - val_loss: 0.4796 - val_accuracy: 0.8202\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8460 - val_loss: 0.4784 - val_accuracy: 0.8202\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8502 - val_loss: 0.4759 - val_accuracy: 0.8202\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8502 - val_loss: 0.4768 - val_accuracy: 0.8202\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8460 - val_loss: 0.4752 - val_accuracy: 0.8202\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8481 - val_loss: 0.4743 - val_accuracy: 0.8202\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8481 - val_loss: 0.4768 - val_accuracy: 0.8258\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8502 - val_loss: 0.4737 - val_accuracy: 0.8258\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8481 - val_loss: 0.4739 - val_accuracy: 0.8258\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8439 - val_loss: 0.4739 - val_accuracy: 0.8315\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8481 - val_loss: 0.4718 - val_accuracy: 0.8258\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8481 - val_loss: 0.4728 - val_accuracy: 0.8315\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8481 - val_loss: 0.4744 - val_accuracy: 0.8258\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8523 - val_loss: 0.4735 - val_accuracy: 0.8315\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8523 - val_loss: 0.4730 - val_accuracy: 0.8315\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8502 - val_loss: 0.4727 - val_accuracy: 0.8315\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8523 - val_loss: 0.4720 - val_accuracy: 0.8315\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8523 - val_loss: 0.4720 - val_accuracy: 0.8315\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8544 - val_loss: 0.4729 - val_accuracy: 0.8315\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8565 - val_loss: 0.4733 - val_accuracy: 0.8315\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8586 - val_loss: 0.4732 - val_accuracy: 0.8315\n",
      "8/8 [==============================] - 0s 812us/step - loss: 0.4449 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1148 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7261 - accuracy: 0.5485 - val_loss: 0.6777 - val_accuracy: 0.6180\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.5907 - val_loss: 0.6445 - val_accuracy: 0.6573\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.6034 - val_loss: 0.6232 - val_accuracy: 0.6461\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.6267 - accuracy: 0.6013 - val_loss: 0.6059 - val_accuracy: 0.6404\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6072 - accuracy: 0.6181 - val_loss: 0.5920 - val_accuracy: 0.6573\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.6414 - val_loss: 0.5784 - val_accuracy: 0.6910\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.6730 - val_loss: 0.5663 - val_accuracy: 0.7022\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7089 - val_loss: 0.5559 - val_accuracy: 0.7247\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7468 - val_loss: 0.5460 - val_accuracy: 0.7472\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7658 - val_loss: 0.5362 - val_accuracy: 0.7472\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7827 - val_loss: 0.5256 - val_accuracy: 0.7584\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7954 - val_loss: 0.5164 - val_accuracy: 0.7697\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7890 - val_loss: 0.5090 - val_accuracy: 0.7753\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7975 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.8080 - val_loss: 0.4957 - val_accuracy: 0.7921\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.8186 - val_loss: 0.4903 - val_accuracy: 0.7865\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.8186 - val_loss: 0.4863 - val_accuracy: 0.7978\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.8165 - val_loss: 0.4833 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8207 - val_loss: 0.4798 - val_accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8207 - val_loss: 0.4760 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8207 - val_loss: 0.4729 - val_accuracy: 0.8146\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.8228 - val_loss: 0.4718 - val_accuracy: 0.8146\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8165 - val_loss: 0.4706 - val_accuracy: 0.8202\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8228 - val_loss: 0.4694 - val_accuracy: 0.8315\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8249 - val_loss: 0.4684 - val_accuracy: 0.8258\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8249 - val_loss: 0.4666 - val_accuracy: 0.8315\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8249 - val_loss: 0.4657 - val_accuracy: 0.8315\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8249 - val_loss: 0.4651 - val_accuracy: 0.8258\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8333 - val_loss: 0.4649 - val_accuracy: 0.8258\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8312 - val_loss: 0.4641 - val_accuracy: 0.8202\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8312 - val_loss: 0.4634 - val_accuracy: 0.8258\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8354 - val_loss: 0.4637 - val_accuracy: 0.8202\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8333 - val_loss: 0.4624 - val_accuracy: 0.8258\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8333 - val_loss: 0.4618 - val_accuracy: 0.8202\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8354 - val_loss: 0.4628 - val_accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8354 - val_loss: 0.4622 - val_accuracy: 0.8202\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8333 - val_loss: 0.4628 - val_accuracy: 0.8202\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8376 - val_loss: 0.4620 - val_accuracy: 0.8202\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8354 - val_loss: 0.4609 - val_accuracy: 0.8202\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8354 - val_loss: 0.4621 - val_accuracy: 0.8146\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.8397 - val_loss: 0.4618 - val_accuracy: 0.8146\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8376 - val_loss: 0.4626 - val_accuracy: 0.8146\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8418 - val_loss: 0.4625 - val_accuracy: 0.8090\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8354 - val_loss: 0.4627 - val_accuracy: 0.8146\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8376 - val_loss: 0.4625 - val_accuracy: 0.8146\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8418 - val_loss: 0.4633 - val_accuracy: 0.8090\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8397 - val_loss: 0.4627 - val_accuracy: 0.8146\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8376 - val_loss: 0.4632 - val_accuracy: 0.8146\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8439 - val_loss: 0.4640 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 806us/step - loss: 0.4006 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1151 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6255 - accuracy: 0.6920 - val_loss: 0.6357 - val_accuracy: 0.6236\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.6941 - val_loss: 0.6219 - val_accuracy: 0.6348\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.7025 - val_loss: 0.6084 - val_accuracy: 0.6517\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7152 - val_loss: 0.5954 - val_accuracy: 0.6573\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7215 - val_loss: 0.5831 - val_accuracy: 0.6629\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7321 - val_loss: 0.5708 - val_accuracy: 0.6629\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7384 - val_loss: 0.5588 - val_accuracy: 0.6910\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7489 - val_loss: 0.5463 - val_accuracy: 0.7022\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7616 - val_loss: 0.5353 - val_accuracy: 0.7303\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.7764 - val_loss: 0.5238 - val_accuracy: 0.7472\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7890 - val_loss: 0.5154 - val_accuracy: 0.7584\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7996 - val_loss: 0.5090 - val_accuracy: 0.7753\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.8101 - val_loss: 0.5043 - val_accuracy: 0.7697\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.8038 - val_loss: 0.4996 - val_accuracy: 0.7809\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7954 - val_loss: 0.4929 - val_accuracy: 0.8034\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.8038 - val_loss: 0.4902 - val_accuracy: 0.8034\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.8080 - val_loss: 0.4887 - val_accuracy: 0.8034\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.8165 - val_loss: 0.4869 - val_accuracy: 0.8090\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8165 - val_loss: 0.4841 - val_accuracy: 0.8034\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8165 - val_loss: 0.4826 - val_accuracy: 0.8034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8207 - val_loss: 0.4826 - val_accuracy: 0.8090\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8207 - val_loss: 0.4812 - val_accuracy: 0.7978\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8228 - val_loss: 0.4811 - val_accuracy: 0.8034\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8249 - val_loss: 0.4816 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8291 - val_loss: 0.4806 - val_accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8228 - val_loss: 0.4795 - val_accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.8270 - val_loss: 0.4799 - val_accuracy: 0.8090\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8291 - val_loss: 0.4795 - val_accuracy: 0.8090\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8312 - val_loss: 0.4812 - val_accuracy: 0.8090\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8291 - val_loss: 0.4803 - val_accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8312 - val_loss: 0.4812 - val_accuracy: 0.8090\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8354 - val_loss: 0.4804 - val_accuracy: 0.8090\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8333 - val_loss: 0.4802 - val_accuracy: 0.8090\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8354 - val_loss: 0.4800 - val_accuracy: 0.8146\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8312 - val_loss: 0.4804 - val_accuracy: 0.8090\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8376 - val_loss: 0.4804 - val_accuracy: 0.8090\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8312 - val_loss: 0.4809 - val_accuracy: 0.8090\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8291 - val_loss: 0.4816 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 807us/step - loss: 0.4039 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1154 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6920 - accuracy: 0.5506 - val_loss: 0.6609 - val_accuracy: 0.6629\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.7025 - val_loss: 0.6197 - val_accuracy: 0.7022\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.7384 - val_loss: 0.5829 - val_accuracy: 0.7022\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7553 - val_loss: 0.5517 - val_accuracy: 0.7191\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7869 - val_loss: 0.5269 - val_accuracy: 0.7640\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.8017 - val_loss: 0.5079 - val_accuracy: 0.7865\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.8122 - val_loss: 0.4936 - val_accuracy: 0.7921\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8186 - val_loss: 0.4863 - val_accuracy: 0.8034\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8228 - val_loss: 0.4790 - val_accuracy: 0.8034\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8312 - val_loss: 0.4768 - val_accuracy: 0.8090\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8312 - val_loss: 0.4742 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8312 - val_loss: 0.4739 - val_accuracy: 0.8202\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8354 - val_loss: 0.4746 - val_accuracy: 0.8202\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.8333 - val_loss: 0.4736 - val_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8333 - val_loss: 0.4719 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8333 - val_loss: 0.4745 - val_accuracy: 0.8202\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8354 - val_loss: 0.4721 - val_accuracy: 0.8202\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8354 - val_loss: 0.4696 - val_accuracy: 0.8146\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8376 - val_loss: 0.4700 - val_accuracy: 0.8258\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8523 - val_loss: 0.4737 - val_accuracy: 0.8315\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8460 - val_loss: 0.4672 - val_accuracy: 0.8146\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.8418 - val_loss: 0.4691 - val_accuracy: 0.8258\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8502 - val_loss: 0.4711 - val_accuracy: 0.8258\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8481 - val_loss: 0.4693 - val_accuracy: 0.8315\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8565 - val_loss: 0.4696 - val_accuracy: 0.8258\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8608 - val_loss: 0.4691 - val_accuracy: 0.8258\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8608 - val_loss: 0.4709 - val_accuracy: 0.8258\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8586 - val_loss: 0.4728 - val_accuracy: 0.8202\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8565 - val_loss: 0.4695 - val_accuracy: 0.8258\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.8586 - val_loss: 0.4679 - val_accuracy: 0.8202\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8608 - val_loss: 0.4734 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 819us/step - loss: 0.4410 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1157 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5964 - accuracy: 0.6118 - val_loss: 0.5788 - val_accuracy: 0.6517\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.6540 - val_loss: 0.5498 - val_accuracy: 0.7191\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7743 - val_loss: 0.5273 - val_accuracy: 0.7640\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.8122 - val_loss: 0.5126 - val_accuracy: 0.7697\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.8207 - val_loss: 0.5008 - val_accuracy: 0.7697\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.8186 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.8228 - val_loss: 0.4856 - val_accuracy: 0.7809\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8249 - val_loss: 0.4803 - val_accuracy: 0.8090\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8249 - val_loss: 0.4770 - val_accuracy: 0.7978\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8270 - val_loss: 0.4745 - val_accuracy: 0.8090\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8312 - val_loss: 0.4718 - val_accuracy: 0.8146\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8333 - val_loss: 0.4694 - val_accuracy: 0.8090\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8333 - val_loss: 0.4676 - val_accuracy: 0.8202\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8376 - val_loss: 0.4679 - val_accuracy: 0.8146\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8376 - val_loss: 0.4671 - val_accuracy: 0.8202\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8397 - val_loss: 0.4631 - val_accuracy: 0.8258\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8354 - val_loss: 0.4627 - val_accuracy: 0.8146\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8397 - val_loss: 0.4645 - val_accuracy: 0.8146\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8439 - val_loss: 0.4610 - val_accuracy: 0.8202\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8418 - val_loss: 0.4614 - val_accuracy: 0.8202\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8439 - val_loss: 0.4623 - val_accuracy: 0.8146\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8460 - val_loss: 0.4617 - val_accuracy: 0.8146\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8439 - val_loss: 0.4615 - val_accuracy: 0.8258\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8460 - val_loss: 0.4588 - val_accuracy: 0.8258\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8481 - val_loss: 0.4623 - val_accuracy: 0.8315\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8502 - val_loss: 0.4633 - val_accuracy: 0.8202\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8523 - val_loss: 0.4619 - val_accuracy: 0.8258\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8544 - val_loss: 0.4610 - val_accuracy: 0.8258\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8481 - val_loss: 0.4636 - val_accuracy: 0.8258\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8523 - val_loss: 0.4616 - val_accuracy: 0.8258\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8523 - val_loss: 0.4647 - val_accuracy: 0.8202\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8502 - val_loss: 0.4640 - val_accuracy: 0.8202\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8544 - val_loss: 0.4651 - val_accuracy: 0.8202\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8544 - val_loss: 0.4634 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 825us/step - loss: 0.4062 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1160 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7011 - accuracy: 0.5359 - val_loss: 0.6464 - val_accuracy: 0.6629\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.6603 - val_loss: 0.6076 - val_accuracy: 0.6910\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.7173 - val_loss: 0.5774 - val_accuracy: 0.6854\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.7468 - val_loss: 0.5534 - val_accuracy: 0.7416\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7806 - val_loss: 0.5347 - val_accuracy: 0.7640\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7848 - val_loss: 0.5198 - val_accuracy: 0.7640\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7975 - val_loss: 0.5117 - val_accuracy: 0.7640\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.8143 - val_loss: 0.5037 - val_accuracy: 0.7809\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.8080 - val_loss: 0.4981 - val_accuracy: 0.8090\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.8165 - val_loss: 0.4949 - val_accuracy: 0.8090\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8228 - val_loss: 0.4934 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8207 - val_loss: 0.4906 - val_accuracy: 0.8034\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8165 - val_loss: 0.4897 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8165 - val_loss: 0.4861 - val_accuracy: 0.7978\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8228 - val_loss: 0.4858 - val_accuracy: 0.7921\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8249 - val_loss: 0.4870 - val_accuracy: 0.7978\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8333 - val_loss: 0.4872 - val_accuracy: 0.8034\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8354 - val_loss: 0.4863 - val_accuracy: 0.7921\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8291 - val_loss: 0.4858 - val_accuracy: 0.7865\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8291 - val_loss: 0.4850 - val_accuracy: 0.7865\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8333 - val_loss: 0.4852 - val_accuracy: 0.7978\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8460 - val_loss: 0.4890 - val_accuracy: 0.7809\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8439 - val_loss: 0.4885 - val_accuracy: 0.7865\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8439 - val_loss: 0.4900 - val_accuracy: 0.7865\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8439 - val_loss: 0.4867 - val_accuracy: 0.7809\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8481 - val_loss: 0.4898 - val_accuracy: 0.7865\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8523 - val_loss: 0.4906 - val_accuracy: 0.7753\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8502 - val_loss: 0.4946 - val_accuracy: 0.7584\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8502 - val_loss: 0.4940 - val_accuracy: 0.7809\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8544 - val_loss: 0.4958 - val_accuracy: 0.7809\n",
      "8/8 [==============================] - 0s 809us/step - loss: 0.3997 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1163 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7296 - accuracy: 0.4494 - val_loss: 0.6562 - val_accuracy: 0.6854\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.7152 - val_loss: 0.6009 - val_accuracy: 0.6348\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7173 - val_loss: 0.5670 - val_accuracy: 0.6966\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7342 - val_loss: 0.5390 - val_accuracy: 0.7247\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7764 - val_loss: 0.5143 - val_accuracy: 0.7809\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8122 - val_loss: 0.5009 - val_accuracy: 0.7978\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8249 - val_loss: 0.4878 - val_accuracy: 0.7865\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8270 - val_loss: 0.4831 - val_accuracy: 0.7978\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8354 - val_loss: 0.4793 - val_accuracy: 0.8034\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8376 - val_loss: 0.4743 - val_accuracy: 0.8090\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8397 - val_loss: 0.4755 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8439 - val_loss: 0.4713 - val_accuracy: 0.8090\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8439 - val_loss: 0.4689 - val_accuracy: 0.8258\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8460 - val_loss: 0.4699 - val_accuracy: 0.8258\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8481 - val_loss: 0.4679 - val_accuracy: 0.8258\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8523 - val_loss: 0.4711 - val_accuracy: 0.8258\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8565 - val_loss: 0.4668 - val_accuracy: 0.8258\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3550 - accuracy: 0.8544 - val_loss: 0.4679 - val_accuracy: 0.8258\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8608 - val_loss: 0.4692 - val_accuracy: 0.8202\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8671 - val_loss: 0.4739 - val_accuracy: 0.8202\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8523 - val_loss: 0.4692 - val_accuracy: 0.8258\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8608 - val_loss: 0.4780 - val_accuracy: 0.8202\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8671 - val_loss: 0.4713 - val_accuracy: 0.8202\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8629 - val_loss: 0.4786 - val_accuracy: 0.8202\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8650 - val_loss: 0.4737 - val_accuracy: 0.8258\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8629 - val_loss: 0.4763 - val_accuracy: 0.8202\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 0.8629 - val_loss: 0.4786 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 795us/step - loss: 0.4261 - accuracy: 0.8397\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1166 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7049 - accuracy: 0.4810 - val_loss: 0.6627 - val_accuracy: 0.6685\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6709 - val_loss: 0.6172 - val_accuracy: 0.6404\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7004 - val_loss: 0.5773 - val_accuracy: 0.6854\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7764 - val_loss: 0.5368 - val_accuracy: 0.7753\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.8186 - val_loss: 0.5048 - val_accuracy: 0.7865\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.8376 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8312 - val_loss: 0.4748 - val_accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8354 - val_loss: 0.4663 - val_accuracy: 0.7978\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8354 - val_loss: 0.4655 - val_accuracy: 0.8146\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8376 - val_loss: 0.4587 - val_accuracy: 0.8146\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8397 - val_loss: 0.4578 - val_accuracy: 0.8146\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8439 - val_loss: 0.4532 - val_accuracy: 0.8090\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8439 - val_loss: 0.4531 - val_accuracy: 0.8034\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8460 - val_loss: 0.4545 - val_accuracy: 0.8146\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8439 - val_loss: 0.4556 - val_accuracy: 0.8146\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8460 - val_loss: 0.4574 - val_accuracy: 0.8202\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8481 - val_loss: 0.4588 - val_accuracy: 0.8202\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8502 - val_loss: 0.4568 - val_accuracy: 0.8258\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.8502 - val_loss: 0.4594 - val_accuracy: 0.8258\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8502 - val_loss: 0.4569 - val_accuracy: 0.8202\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8565 - val_loss: 0.4599 - val_accuracy: 0.8258\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.8565 - val_loss: 0.4611 - val_accuracy: 0.8315\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8481 - val_loss: 0.4648 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 773us/step - loss: 0.3896 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1169 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6161 - accuracy: 0.7004 - val_loss: 0.6088 - val_accuracy: 0.6629\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7278 - val_loss: 0.5732 - val_accuracy: 0.6685\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7743 - val_loss: 0.5494 - val_accuracy: 0.7191\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7996 - val_loss: 0.5256 - val_accuracy: 0.7640\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7869 - val_loss: 0.5123 - val_accuracy: 0.7865\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7869 - val_loss: 0.5066 - val_accuracy: 0.7865\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8165 - val_loss: 0.5032 - val_accuracy: 0.7865\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8207 - val_loss: 0.4998 - val_accuracy: 0.7865\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8186 - val_loss: 0.5005 - val_accuracy: 0.7865\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8270 - val_loss: 0.4935 - val_accuracy: 0.7978\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8270 - val_loss: 0.4955 - val_accuracy: 0.7921\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8291 - val_loss: 0.4969 - val_accuracy: 0.7865\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8249 - val_loss: 0.4930 - val_accuracy: 0.7921\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8354 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8418 - val_loss: 0.4939 - val_accuracy: 0.7697\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8354 - val_loss: 0.4985 - val_accuracy: 0.7753\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8460 - val_loss: 0.4972 - val_accuracy: 0.7809\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8523 - val_loss: 0.4981 - val_accuracy: 0.7753\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8523 - val_loss: 0.5039 - val_accuracy: 0.7697\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8523 - val_loss: 0.5074 - val_accuracy: 0.7809\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8586 - val_loss: 0.5097 - val_accuracy: 0.7753\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8544 - val_loss: 0.5101 - val_accuracy: 0.7753\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8629 - val_loss: 0.5141 - val_accuracy: 0.7753\n",
      "8/8 [==============================] - 0s 803us/step - loss: 0.4456 - accuracy: 0.8354\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1172 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5786 - accuracy: 0.6751 - val_loss: 0.5780 - val_accuracy: 0.6461\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7321 - val_loss: 0.5284 - val_accuracy: 0.7135\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8354 - val_loss: 0.4973 - val_accuracy: 0.8034\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8333 - val_loss: 0.4888 - val_accuracy: 0.8034\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8354 - val_loss: 0.4814 - val_accuracy: 0.8146\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8460 - val_loss: 0.4688 - val_accuracy: 0.8146\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8439 - val_loss: 0.4758 - val_accuracy: 0.8202\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8565 - val_loss: 0.4766 - val_accuracy: 0.8315\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8502 - val_loss: 0.4730 - val_accuracy: 0.8202\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8586 - val_loss: 0.4709 - val_accuracy: 0.8258\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8565 - val_loss: 0.4808 - val_accuracy: 0.8034\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8650 - val_loss: 0.4757 - val_accuracy: 0.8202\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8650 - val_loss: 0.4773 - val_accuracy: 0.8258\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.8755 - val_loss: 0.4806 - val_accuracy: 0.8146\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8713 - val_loss: 0.4886 - val_accuracy: 0.7978\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8671 - val_loss: 0.4858 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 836us/step - loss: 0.4341 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1175 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6437 - accuracy: 0.5865 - val_loss: 0.5842 - val_accuracy: 0.6742\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7236 - val_loss: 0.5257 - val_accuracy: 0.7640\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.8165 - val_loss: 0.4957 - val_accuracy: 0.7753\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.8207 - val_loss: 0.4893 - val_accuracy: 0.7865\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8270 - val_loss: 0.4757 - val_accuracy: 0.7978\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8354 - val_loss: 0.4742 - val_accuracy: 0.8146\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8354 - val_loss: 0.4761 - val_accuracy: 0.8090\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.8418 - val_loss: 0.4704 - val_accuracy: 0.8202\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8376 - val_loss: 0.4791 - val_accuracy: 0.8146\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8481 - val_loss: 0.4719 - val_accuracy: 0.8090\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8460 - val_loss: 0.4739 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8418 - val_loss: 0.4762 - val_accuracy: 0.8090\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8544 - val_loss: 0.4811 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8523 - val_loss: 0.4771 - val_accuracy: 0.8090\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8439 - val_loss: 0.4806 - val_accuracy: 0.8146\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8586 - val_loss: 0.4854 - val_accuracy: 0.7978\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8481 - val_loss: 0.4862 - val_accuracy: 0.8034\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8544 - val_loss: 0.4882 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.4083 - accuracy: 0.8186\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1178 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5879 - accuracy: 0.6920 - val_loss: 0.5744 - val_accuracy: 0.6910\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7468 - val_loss: 0.5398 - val_accuracy: 0.7247\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.8038 - val_loss: 0.5084 - val_accuracy: 0.7584\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.8228 - val_loss: 0.4992 - val_accuracy: 0.7753\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8207 - val_loss: 0.4977 - val_accuracy: 0.7809\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8291 - val_loss: 0.4972 - val_accuracy: 0.7697\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8312 - val_loss: 0.4910 - val_accuracy: 0.7809\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8312 - val_loss: 0.4903 - val_accuracy: 0.7809\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8376 - val_loss: 0.4964 - val_accuracy: 0.7865\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8312 - val_loss: 0.4961 - val_accuracy: 0.7809\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8502 - val_loss: 0.5038 - val_accuracy: 0.7865\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8502 - val_loss: 0.5107 - val_accuracy: 0.7753\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8502 - val_loss: 0.5146 - val_accuracy: 0.7865\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8523 - val_loss: 0.5201 - val_accuracy: 0.7921\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8502 - val_loss: 0.5329 - val_accuracy: 0.7865\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8565 - val_loss: 0.5349 - val_accuracy: 0.7921\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8608 - val_loss: 0.5447 - val_accuracy: 0.7921\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8671 - val_loss: 0.5600 - val_accuracy: 0.7865\n",
      "8/8 [==============================] - 0s 804us/step - loss: 0.4536 - accuracy: 0.8481\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1181 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7190 - accuracy: 0.3544 - val_loss: 0.7041 - val_accuracy: 0.3933\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.4641 - val_loss: 0.6863 - val_accuracy: 0.6292\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.6835 - val_loss: 0.6729 - val_accuracy: 0.6910\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.7215 - val_loss: 0.6620 - val_accuracy: 0.6629\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7236 - val_loss: 0.6527 - val_accuracy: 0.6629\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.7257 - val_loss: 0.6433 - val_accuracy: 0.6629\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.7342 - val_loss: 0.6329 - val_accuracy: 0.6629\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7300 - val_loss: 0.6210 - val_accuracy: 0.6573\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7300 - val_loss: 0.6073 - val_accuracy: 0.6629\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.7447 - val_loss: 0.5916 - val_accuracy: 0.6573\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7574 - val_loss: 0.5780 - val_accuracy: 0.6742\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7764 - val_loss: 0.5661 - val_accuracy: 0.6966\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7764 - val_loss: 0.5588 - val_accuracy: 0.7079\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7932 - val_loss: 0.5528 - val_accuracy: 0.7360\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8017 - val_loss: 0.5452 - val_accuracy: 0.7528\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.8186 - val_loss: 0.5393 - val_accuracy: 0.7528\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8186 - val_loss: 0.5360 - val_accuracy: 0.7640\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8186 - val_loss: 0.5302 - val_accuracy: 0.7640\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8143 - val_loss: 0.5254 - val_accuracy: 0.7697\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8228 - val_loss: 0.5214 - val_accuracy: 0.7809\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8207 - val_loss: 0.5166 - val_accuracy: 0.7809\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8249 - val_loss: 0.5117 - val_accuracy: 0.7865\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8354 - val_loss: 0.5120 - val_accuracy: 0.7921\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8333 - val_loss: 0.5071 - val_accuracy: 0.7865\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8397 - val_loss: 0.5035 - val_accuracy: 0.7921\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8397 - val_loss: 0.5022 - val_accuracy: 0.7921\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.8397 - val_loss: 0.5023 - val_accuracy: 0.7978\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8397 - val_loss: 0.5015 - val_accuracy: 0.7921\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8418 - val_loss: 0.4991 - val_accuracy: 0.8034\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8397 - val_loss: 0.4976 - val_accuracy: 0.8034\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8439 - val_loss: 0.4973 - val_accuracy: 0.7921\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8460 - val_loss: 0.4951 - val_accuracy: 0.8090\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8418 - val_loss: 0.4939 - val_accuracy: 0.7921\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8439 - val_loss: 0.4948 - val_accuracy: 0.8146\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8460 - val_loss: 0.4972 - val_accuracy: 0.8034\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8460 - val_loss: 0.4937 - val_accuracy: 0.8146\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8460 - val_loss: 0.4924 - val_accuracy: 0.8146\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8481 - val_loss: 0.4929 - val_accuracy: 0.8034\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8439 - val_loss: 0.4919 - val_accuracy: 0.8034\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8481 - val_loss: 0.4904 - val_accuracy: 0.8202\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8460 - val_loss: 0.4932 - val_accuracy: 0.8034\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8460 - val_loss: 0.4926 - val_accuracy: 0.8090\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8439 - val_loss: 0.4905 - val_accuracy: 0.8202\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8481 - val_loss: 0.4900 - val_accuracy: 0.8146\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8439 - val_loss: 0.4917 - val_accuracy: 0.8090\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8481 - val_loss: 0.4908 - val_accuracy: 0.8202\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8460 - val_loss: 0.4913 - val_accuracy: 0.8202\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8460 - val_loss: 0.4895 - val_accuracy: 0.8202\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8460 - val_loss: 0.4911 - val_accuracy: 0.8146\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8481 - val_loss: 0.4921 - val_accuracy: 0.8202\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8460 - val_loss: 0.4943 - val_accuracy: 0.8146\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.8481 - val_loss: 0.4924 - val_accuracy: 0.8202\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8502 - val_loss: 0.4915 - val_accuracy: 0.8202\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3609 - accuracy: 0.8502 - val_loss: 0.4906 - val_accuracy: 0.8202\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8502 - val_loss: 0.4909 - val_accuracy: 0.8146\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8523 - val_loss: 0.4916 - val_accuracy: 0.8202\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8523 - val_loss: 0.4913 - val_accuracy: 0.8202\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8544 - val_loss: 0.4900 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.4530 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1185 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7049 - accuracy: 0.3924 - val_loss: 0.6898 - val_accuracy: 0.5393\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.6414 - val_loss: 0.6653 - val_accuracy: 0.6854\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.6814 - val_loss: 0.6435 - val_accuracy: 0.6854\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.6941 - val_loss: 0.6231 - val_accuracy: 0.6966\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.7046 - val_loss: 0.6023 - val_accuracy: 0.7079\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7110 - val_loss: 0.5803 - val_accuracy: 0.7247\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7215 - val_loss: 0.5595 - val_accuracy: 0.7191\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7616 - val_loss: 0.5424 - val_accuracy: 0.7753\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7890 - val_loss: 0.5309 - val_accuracy: 0.7753\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.8080 - val_loss: 0.5224 - val_accuracy: 0.7809\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.8143 - val_loss: 0.5162 - val_accuracy: 0.7753\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.8228 - val_loss: 0.5127 - val_accuracy: 0.7809\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.8249 - val_loss: 0.5104 - val_accuracy: 0.7865\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8291 - val_loss: 0.5086 - val_accuracy: 0.7865\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8270 - val_loss: 0.5062 - val_accuracy: 0.7865\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8207 - val_loss: 0.5071 - val_accuracy: 0.7865\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8270 - val_loss: 0.5058 - val_accuracy: 0.7865\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8249 - val_loss: 0.5045 - val_accuracy: 0.7865\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8249 - val_loss: 0.5044 - val_accuracy: 0.7809\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8270 - val_loss: 0.5061 - val_accuracy: 0.7809\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8291 - val_loss: 0.5054 - val_accuracy: 0.7921\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8312 - val_loss: 0.5035 - val_accuracy: 0.7809\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8270 - val_loss: 0.5051 - val_accuracy: 0.7809\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8312 - val_loss: 0.5020 - val_accuracy: 0.7809\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8312 - val_loss: 0.5022 - val_accuracy: 0.7809\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8312 - val_loss: 0.5021 - val_accuracy: 0.7753\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8397 - val_loss: 0.5009 - val_accuracy: 0.7921\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8397 - val_loss: 0.5015 - val_accuracy: 0.7809\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8418 - val_loss: 0.4992 - val_accuracy: 0.7865\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8397 - val_loss: 0.4990 - val_accuracy: 0.7753\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8376 - val_loss: 0.4991 - val_accuracy: 0.7809\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8418 - val_loss: 0.4994 - val_accuracy: 0.7753\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8376 - val_loss: 0.4984 - val_accuracy: 0.7809\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8418 - val_loss: 0.4978 - val_accuracy: 0.7753\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8439 - val_loss: 0.4975 - val_accuracy: 0.7865\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8418 - val_loss: 0.4996 - val_accuracy: 0.7865\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8439 - val_loss: 0.4975 - val_accuracy: 0.7921\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8418 - val_loss: 0.4993 - val_accuracy: 0.7921\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8418 - val_loss: 0.4986 - val_accuracy: 0.7865\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8460 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8439 - val_loss: 0.4976 - val_accuracy: 0.7865\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8439 - val_loss: 0.4961 - val_accuracy: 0.7865\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8439 - val_loss: 0.4953 - val_accuracy: 0.7921\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8439 - val_loss: 0.4940 - val_accuracy: 0.7978\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8439 - val_loss: 0.4930 - val_accuracy: 0.7921\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8460 - val_loss: 0.4913 - val_accuracy: 0.7921\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8460 - val_loss: 0.4920 - val_accuracy: 0.7921\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8460 - val_loss: 0.4917 - val_accuracy: 0.7978\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8523 - val_loss: 0.4884 - val_accuracy: 0.7978\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8481 - val_loss: 0.4860 - val_accuracy: 0.8034\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 0.8502 - val_loss: 0.4857 - val_accuracy: 0.8034\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8502 - val_loss: 0.4897 - val_accuracy: 0.8034\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8502 - val_loss: 0.4910 - val_accuracy: 0.8034\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8523 - val_loss: 0.4883 - val_accuracy: 0.8034\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8460 - val_loss: 0.4913 - val_accuracy: 0.8034\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8565 - val_loss: 0.4869 - val_accuracy: 0.8090\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8502 - val_loss: 0.4906 - val_accuracy: 0.8034\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8502 - val_loss: 0.4924 - val_accuracy: 0.8034\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8460 - val_loss: 0.4905 - val_accuracy: 0.8090\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8523 - val_loss: 0.4913 - val_accuracy: 0.8090\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8502 - val_loss: 0.4900 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 837us/step - loss: 0.3790 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1189 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.5527 - val_loss: 0.6818 - val_accuracy: 0.6966\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.6603 - val_loss: 0.6730 - val_accuracy: 0.6798\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.6835 - val_loss: 0.6634 - val_accuracy: 0.6854\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.7004 - val_loss: 0.6527 - val_accuracy: 0.6798\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.7152 - val_loss: 0.6385 - val_accuracy: 0.7079\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.7384 - val_loss: 0.6210 - val_accuracy: 0.7191\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7532 - val_loss: 0.6009 - val_accuracy: 0.7360\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7616 - val_loss: 0.5808 - val_accuracy: 0.7528\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7827 - val_loss: 0.5599 - val_accuracy: 0.7584\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7911 - val_loss: 0.5376 - val_accuracy: 0.7640\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7954 - val_loss: 0.5218 - val_accuracy: 0.7921\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.8017 - val_loss: 0.5109 - val_accuracy: 0.7978\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7996 - val_loss: 0.5046 - val_accuracy: 0.7865\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.8038 - val_loss: 0.5006 - val_accuracy: 0.7921\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8080 - val_loss: 0.4991 - val_accuracy: 0.7921\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8101 - val_loss: 0.4988 - val_accuracy: 0.7921\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8207 - val_loss: 0.4985 - val_accuracy: 0.7865\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8249 - val_loss: 0.5007 - val_accuracy: 0.7865\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8249 - val_loss: 0.4975 - val_accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8291 - val_loss: 0.4965 - val_accuracy: 0.7978\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8312 - val_loss: 0.4949 - val_accuracy: 0.7921\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8312 - val_loss: 0.4937 - val_accuracy: 0.8034\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8376 - val_loss: 0.4946 - val_accuracy: 0.8034\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8376 - val_loss: 0.4929 - val_accuracy: 0.8034\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8397 - val_loss: 0.4900 - val_accuracy: 0.8034\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8397 - val_loss: 0.4919 - val_accuracy: 0.7865\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8418 - val_loss: 0.4918 - val_accuracy: 0.7921\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8439 - val_loss: 0.4937 - val_accuracy: 0.7865\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3737 - accuracy: 0.8460 - val_loss: 0.4928 - val_accuracy: 0.7978\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8439 - val_loss: 0.4929 - val_accuracy: 0.7921\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8460 - val_loss: 0.4929 - val_accuracy: 0.7978\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8523 - val_loss: 0.4966 - val_accuracy: 0.7921\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8502 - val_loss: 0.4986 - val_accuracy: 0.7921\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8502 - val_loss: 0.4993 - val_accuracy: 0.7921\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8502 - val_loss: 0.5004 - val_accuracy: 0.7921\n",
      "8/8 [==============================] - 0s 849us/step - loss: 0.4124 - accuracy: 0.8312\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1193 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6814 - accuracy: 0.5781 - val_loss: 0.6535 - val_accuracy: 0.6461\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6920 - val_loss: 0.6262 - val_accuracy: 0.6461\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7068 - val_loss: 0.6005 - val_accuracy: 0.6685\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7468 - val_loss: 0.5641 - val_accuracy: 0.7135\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7806 - val_loss: 0.5343 - val_accuracy: 0.7416\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7954 - val_loss: 0.5117 - val_accuracy: 0.7640\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8101 - val_loss: 0.5044 - val_accuracy: 0.7753\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8312 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8333 - val_loss: 0.4907 - val_accuracy: 0.7978\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8397 - val_loss: 0.4869 - val_accuracy: 0.7978\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8291 - val_loss: 0.4815 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8418 - val_loss: 0.4733 - val_accuracy: 0.7978\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8418 - val_loss: 0.4792 - val_accuracy: 0.8202\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8354 - val_loss: 0.4707 - val_accuracy: 0.8090\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3623 - accuracy: 0.8523 - val_loss: 0.4743 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8544 - val_loss: 0.4704 - val_accuracy: 0.8258\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8439 - val_loss: 0.4673 - val_accuracy: 0.8146\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8481 - val_loss: 0.4722 - val_accuracy: 0.8146\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8544 - val_loss: 0.4715 - val_accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8629 - val_loss: 0.4676 - val_accuracy: 0.8146\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8523 - val_loss: 0.4683 - val_accuracy: 0.8034\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8734 - val_loss: 0.4703 - val_accuracy: 0.7978\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3327 - accuracy: 0.8608 - val_loss: 0.4690 - val_accuracy: 0.8202\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.8523 - val_loss: 0.4682 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.8650 - val_loss: 0.4685 - val_accuracy: 0.7978\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8713 - val_loss: 0.4675 - val_accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8734 - val_loss: 0.4759 - val_accuracy: 0.7921\n",
      "8/8 [==============================] - 0s 849us/step - loss: 0.4452 - accuracy: 0.8354\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1197 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6478 - accuracy: 0.6414 - val_loss: 0.6258 - val_accuracy: 0.6517\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.6688 - val_loss: 0.5936 - val_accuracy: 0.6685\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7194 - val_loss: 0.5624 - val_accuracy: 0.7079\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7806 - val_loss: 0.5339 - val_accuracy: 0.7472\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.8186 - val_loss: 0.5102 - val_accuracy: 0.7528\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.8354 - val_loss: 0.4996 - val_accuracy: 0.7528\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.8312 - val_loss: 0.4956 - val_accuracy: 0.7528\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8291 - val_loss: 0.4899 - val_accuracy: 0.7697\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8376 - val_loss: 0.4838 - val_accuracy: 0.7640\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8333 - val_loss: 0.4778 - val_accuracy: 0.7921\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8354 - val_loss: 0.4792 - val_accuracy: 0.7921\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8418 - val_loss: 0.4787 - val_accuracy: 0.7865\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8460 - val_loss: 0.4703 - val_accuracy: 0.8146\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8481 - val_loss: 0.4778 - val_accuracy: 0.7865\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8544 - val_loss: 0.4754 - val_accuracy: 0.8034\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8523 - val_loss: 0.4785 - val_accuracy: 0.7865\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8565 - val_loss: 0.4753 - val_accuracy: 0.7978\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8502 - val_loss: 0.4795 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8544 - val_loss: 0.4737 - val_accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8544 - val_loss: 0.4794 - val_accuracy: 0.8146\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8502 - val_loss: 0.4756 - val_accuracy: 0.8146\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8544 - val_loss: 0.4757 - val_accuracy: 0.8146\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8439 - val_loss: 0.4791 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 838us/step - loss: 0.3992 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1201 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7867 - accuracy: 0.3819 - val_loss: 0.7120 - val_accuracy: 0.3876\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.5654 - val_loss: 0.6589 - val_accuracy: 0.6910\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.7342 - val_loss: 0.6198 - val_accuracy: 0.6910\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7700 - val_loss: 0.5862 - val_accuracy: 0.7022\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7848 - val_loss: 0.5585 - val_accuracy: 0.7191\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7975 - val_loss: 0.5353 - val_accuracy: 0.7640\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.8101 - val_loss: 0.5165 - val_accuracy: 0.7865\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.8376 - val_loss: 0.5066 - val_accuracy: 0.7809\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8376 - val_loss: 0.4999 - val_accuracy: 0.7865\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8439 - val_loss: 0.4981 - val_accuracy: 0.7921\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8439 - val_loss: 0.5092 - val_accuracy: 0.7697\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8586 - val_loss: 0.5085 - val_accuracy: 0.7809\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8544 - val_loss: 0.5092 - val_accuracy: 0.7865\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8565 - val_loss: 0.5109 - val_accuracy: 0.7809\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8608 - val_loss: 0.5123 - val_accuracy: 0.7809\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8544 - val_loss: 0.5190 - val_accuracy: 0.7865\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8586 - val_loss: 0.5248 - val_accuracy: 0.7697\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8586 - val_loss: 0.5332 - val_accuracy: 0.7753\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8713 - val_loss: 0.5372 - val_accuracy: 0.7753\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8650 - val_loss: 0.5390 - val_accuracy: 0.7865\n",
      "8/8 [==============================] - 0s 870us/step - loss: 0.4342 - accuracy: 0.8270\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1205 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6459 - accuracy: 0.6203 - val_loss: 0.6140 - val_accuracy: 0.6348\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7046 - val_loss: 0.5738 - val_accuracy: 0.6629\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7468 - val_loss: 0.5397 - val_accuracy: 0.7135\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.8059 - val_loss: 0.5112 - val_accuracy: 0.7640\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8291 - val_loss: 0.4919 - val_accuracy: 0.7809\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8249 - val_loss: 0.4869 - val_accuracy: 0.7978\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8376 - val_loss: 0.4763 - val_accuracy: 0.8090\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8439 - val_loss: 0.4732 - val_accuracy: 0.8258\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8460 - val_loss: 0.4668 - val_accuracy: 0.8202\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8608 - val_loss: 0.4682 - val_accuracy: 0.8258\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8608 - val_loss: 0.4690 - val_accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8671 - val_loss: 0.4703 - val_accuracy: 0.8202\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8650 - val_loss: 0.4705 - val_accuracy: 0.8202\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8692 - val_loss: 0.4725 - val_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8586 - val_loss: 0.4736 - val_accuracy: 0.8202\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8608 - val_loss: 0.4813 - val_accuracy: 0.8146\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8713 - val_loss: 0.4881 - val_accuracy: 0.8202\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8608 - val_loss: 0.4890 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.8776 - val_loss: 0.4999 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.4287 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1209 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.6184 - accuracy: 0.6350 - val_loss: 0.5783 - val_accuracy: 0.6966\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7342 - val_loss: 0.5260 - val_accuracy: 0.7584\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.8101 - val_loss: 0.4879 - val_accuracy: 0.7865\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.8333 - val_loss: 0.4731 - val_accuracy: 0.7978\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8333 - val_loss: 0.4728 - val_accuracy: 0.8034\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8291 - val_loss: 0.4683 - val_accuracy: 0.8090\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8397 - val_loss: 0.4624 - val_accuracy: 0.8202\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8418 - val_loss: 0.4736 - val_accuracy: 0.8090\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8418 - val_loss: 0.4637 - val_accuracy: 0.8202\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8523 - val_loss: 0.4660 - val_accuracy: 0.8146\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8523 - val_loss: 0.4710 - val_accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8565 - val_loss: 0.4744 - val_accuracy: 0.8146\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8565 - val_loss: 0.4706 - val_accuracy: 0.8146\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8523 - val_loss: 0.4697 - val_accuracy: 0.8258\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8586 - val_loss: 0.4727 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.8502 - val_loss: 0.4865 - val_accuracy: 0.8202\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8586 - val_loss: 0.4770 - val_accuracy: 0.8090\n",
      "8/8 [==============================] - 0s 802us/step - loss: 0.4059 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1213 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6097 - accuracy: 0.6624 - val_loss: 0.5876 - val_accuracy: 0.6629\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7257 - val_loss: 0.5466 - val_accuracy: 0.7022\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7679 - val_loss: 0.5206 - val_accuracy: 0.7360\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.8143 - val_loss: 0.5013 - val_accuracy: 0.7697\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8101 - val_loss: 0.4986 - val_accuracy: 0.7753\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8207 - val_loss: 0.4949 - val_accuracy: 0.7809\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8333 - val_loss: 0.4901 - val_accuracy: 0.7640\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8249 - val_loss: 0.4880 - val_accuracy: 0.7697\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8354 - val_loss: 0.5018 - val_accuracy: 0.7584\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8439 - val_loss: 0.4952 - val_accuracy: 0.7528\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8502 - val_loss: 0.4996 - val_accuracy: 0.7584\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8418 - val_loss: 0.5129 - val_accuracy: 0.7753\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8629 - val_loss: 0.5232 - val_accuracy: 0.7640\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8586 - val_loss: 0.5294 - val_accuracy: 0.7753\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3350 - accuracy: 0.8650 - val_loss: 0.5434 - val_accuracy: 0.7697\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8586 - val_loss: 0.5448 - val_accuracy: 0.7584\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8586 - val_loss: 0.5669 - val_accuracy: 0.7360\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8692 - val_loss: 0.5689 - val_accuracy: 0.7584\n",
      "8/8 [==============================] - 0s 936us/step - loss: 0.4752 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1217 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5910 - accuracy: 0.6371 - val_loss: 0.5776 - val_accuracy: 0.6292\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7447 - val_loss: 0.5053 - val_accuracy: 0.7978\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.8291 - val_loss: 0.4895 - val_accuracy: 0.8202\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8376 - val_loss: 0.4713 - val_accuracy: 0.8315\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8460 - val_loss: 0.4703 - val_accuracy: 0.8371\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8544 - val_loss: 0.4667 - val_accuracy: 0.8258\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3609 - accuracy: 0.8481 - val_loss: 0.4694 - val_accuracy: 0.8258\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8650 - val_loss: 0.4718 - val_accuracy: 0.8371\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8586 - val_loss: 0.4774 - val_accuracy: 0.8371\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8692 - val_loss: 0.4749 - val_accuracy: 0.8371\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3297 - accuracy: 0.8671 - val_loss: 0.4837 - val_accuracy: 0.8258\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8692 - val_loss: 0.4825 - val_accuracy: 0.8258\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8713 - val_loss: 0.4962 - val_accuracy: 0.8202\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3109 - accuracy: 0.8797 - val_loss: 0.4920 - val_accuracy: 0.8315\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8819 - val_loss: 0.5240 - val_accuracy: 0.7921\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3067 - accuracy: 0.8692 - val_loss: 0.5202 - val_accuracy: 0.8146\n",
      "8/8 [==============================] - 0s 846us/step - loss: 0.4774 - accuracy: 0.8228\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1221 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5957 - accuracy: 0.6920 - val_loss: 0.5416 - val_accuracy: 0.7079\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.8080 - val_loss: 0.4884 - val_accuracy: 0.7865\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8207 - val_loss: 0.4793 - val_accuracy: 0.8034\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8333 - val_loss: 0.4738 - val_accuracy: 0.8090\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8460 - val_loss: 0.4649 - val_accuracy: 0.8090\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8481 - val_loss: 0.4693 - val_accuracy: 0.8090\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8418 - val_loss: 0.4720 - val_accuracy: 0.8034\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8460 - val_loss: 0.4727 - val_accuracy: 0.8090\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8523 - val_loss: 0.4805 - val_accuracy: 0.8202\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8523 - val_loss: 0.4890 - val_accuracy: 0.7978\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8502 - val_loss: 0.4882 - val_accuracy: 0.8146\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.8650 - val_loss: 0.4784 - val_accuracy: 0.8146\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8608 - val_loss: 0.5086 - val_accuracy: 0.8146\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8671 - val_loss: 0.4920 - val_accuracy: 0.8090\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8629 - val_loss: 0.4895 - val_accuracy: 0.8258\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.4063 - accuracy: 0.8354\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1225 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6282 - accuracy: 0.6793 - val_loss: 0.6004 - val_accuracy: 0.6573\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7405 - val_loss: 0.5426 - val_accuracy: 0.7640\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.8122 - val_loss: 0.5071 - val_accuracy: 0.7865\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.8122 - val_loss: 0.5224 - val_accuracy: 0.7416\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8249 - val_loss: 0.4947 - val_accuracy: 0.7809\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8333 - val_loss: 0.5036 - val_accuracy: 0.7753\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3779 - accuracy: 0.8249 - val_loss: 0.4997 - val_accuracy: 0.7809\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8481 - val_loss: 0.5136 - val_accuracy: 0.7753\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8460 - val_loss: 0.5150 - val_accuracy: 0.7809\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8502 - val_loss: 0.5285 - val_accuracy: 0.7921\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8608 - val_loss: 0.5476 - val_accuracy: 0.7809\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8650 - val_loss: 0.5592 - val_accuracy: 0.7809\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3300 - accuracy: 0.8608 - val_loss: 0.5693 - val_accuracy: 0.7697\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8629 - val_loss: 0.5792 - val_accuracy: 0.7697\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8755 - val_loss: 0.6064 - val_accuracy: 0.7528\n",
      "8/8 [==============================] - 0s 805us/step - loss: 0.4954 - accuracy: 0.8143\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_1229 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.6198 - accuracy: 0.7356 - val_loss: 0.5826 - val_accuracy: 0.6966\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7454 - val_loss: 0.5396 - val_accuracy: 0.7360\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8087 - val_loss: 0.5121 - val_accuracy: 0.7697\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8143 - val_loss: 0.5070 - val_accuracy: 0.7640\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8143 - val_loss: 0.4917 - val_accuracy: 0.7978\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8172 - val_loss: 0.4904 - val_accuracy: 0.8090\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8186 - val_loss: 0.4808 - val_accuracy: 0.8090\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8298 - val_loss: 0.4772 - val_accuracy: 0.8146\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8312 - val_loss: 0.4709 - val_accuracy: 0.8090\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8383 - val_loss: 0.4737 - val_accuracy: 0.8090\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8453 - val_loss: 0.4673 - val_accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8467 - val_loss: 0.4694 - val_accuracy: 0.8034\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8495 - val_loss: 0.4710 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8509 - val_loss: 0.4699 - val_accuracy: 0.8090\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8537 - val_loss: 0.4739 - val_accuracy: 0.8034\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8495 - val_loss: 0.4752 - val_accuracy: 0.8146\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8594 - val_loss: 0.4823 - val_accuracy: 0.7978\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8523 - val_loss: 0.4881 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8551 - val_loss: 0.4803 - val_accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8594 - val_loss: 0.4853 - val_accuracy: 0.7978\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8579 - val_loss: 0.4936 - val_accuracy: 0.7921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7feb61d0bc70>,\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.001, 0.002, 0.003],\n",
       "                         'n_hidden': [0, 1, 2, 3],\n",
       "                         'n_neurons': [10, 30, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": [10, 30, 50, 100],\n",
    "    \"learning_rate\": [1e-3, 2e-3, 3e-3]\n",
    "}\n",
    "\n",
    "grid_search_cv = GridSearchCV(keras_classifier, param_grid, cv=3)\n",
    "grid_search_cv.fit(X_train, y_train.values.ravel(), epochs=100, \n",
    "                  validation_data=(X_valid, y_valid.values.ravel()),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.001, 'n_hidden': 2, 'n_neurons': 50}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7921348314606742\n"
     ]
    }
   ],
   "source": [
    "model = grid_search_cv.best_estimator_.model\n",
    "predict = model.predict(X_valid)\n",
    "\n",
    "binary_predict = []\n",
    "for val in predict:\n",
    "    if val < 0.5:\n",
    "        binary_predict.append(0)\n",
    "    else:\n",
    "        binary_predict.append(1)\n",
    "        \n",
    "print(accuracy_score(y_valid, binary_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "honorifics = []\n",
    "\n",
    "for x in range(len(test_full_data['Name'])):\n",
    "    match = re.findall(\"([A-Za-z]+)\\.\", test_full_data['Name'].iloc[x])\n",
    "\n",
    "    if match[0] in ['Mr', 'Mrs', 'Miss', 'Master']:\n",
    "        honorifics.append(match[0])\n",
    "    else:\n",
    "        honorifics.append(\"Other\")\n",
    "        \n",
    "test_full_data['Honorifics'] = honorifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "LetterTicket = []\n",
    "\n",
    "for x in range(len(test_full_data['Ticket'])):\n",
    "    match = re.search(\"[A-Z]+\", test_full_data['Ticket'].iloc[x])\n",
    "\n",
    "    if match:\n",
    "        LetterTicket.append(1)\n",
    "    else:\n",
    "        LetterTicket.append(0)\n",
    "        \n",
    "test_full_data['LetterTicket'] = LetterTicket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Honorifics</th>\n",
       "      <th>LetterTicket</th>\n",
       "      <th>NumFamily</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked Honorifics  \\\n",
       "0  34.5      0      0   330911   7.8292   NaN        Q         Mr   \n",
       "1  47.0      1      0   363272   7.0000   NaN        S        Mrs   \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q         Mr   \n",
       "3  27.0      0      0   315154   8.6625   NaN        S         Mr   \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S        Mrs   \n",
       "\n",
       "   LetterTicket  NumFamily  \n",
       "0             0          0  \n",
       "1             0          1  \n",
       "2             0          0  \n",
       "3             0          0  \n",
       "4             0          2  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full_data['NumFamily'] = test_full_data['SibSp'] + test_full_data['Parch']\n",
    "test_full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 8 columns):\n",
      "Pclass          418 non-null int64\n",
      "Sex             418 non-null object\n",
      "Age             332 non-null float64\n",
      "Fare            417 non-null float64\n",
      "Embarked        418 non-null object\n",
      "Honorifics      418 non-null object\n",
      "LetterTicket    418 non-null int64\n",
      "NumFamily       418 non-null int64\n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 26.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data = test_full_data.drop(columns=['SibSp', 'Parch', 'Cabin', 'Name', 'Ticket', 'PassengerId'])\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = [\"Age\", \"Fare\", \"NumFamily\"]\n",
    "ord_enc = [\"Pclass\", \"Sex\", \"LetterTicket\"]\n",
    "one_hot_enc = [\"Embarked\", \"Honorifics\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num_column\", num_pipeline, num),\n",
    "    (\"ord_enc\", OrdinalEncoder(), ord_enc),\n",
    "    (\"one_hot_enc\", OneHotEncoder(), one_hot_enc),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.386231</td>\n",
       "      <td>-0.497413</td>\n",
       "      <td>-0.553443</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.371370</td>\n",
       "      <td>-0.512278</td>\n",
       "      <td>0.105643</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.553537</td>\n",
       "      <td>-0.464100</td>\n",
       "      <td>-0.553443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.204852</td>\n",
       "      <td>-0.482475</td>\n",
       "      <td>-0.553443</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.598908</td>\n",
       "      <td>-0.417492</td>\n",
       "      <td>0.764728</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2    3    4    5    6    7    8    9   10   11  \\\n",
       "0  0.386231 -0.497413 -0.553443  2.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0   \n",
       "1  1.371370 -0.512278  0.105643  2.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "2  2.553537 -0.464100 -0.553443  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0   \n",
       "3 -0.204852 -0.482475 -0.553443  2.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "4 -0.598908 -0.417492  0.764728  2.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "    12   13  \n",
       "0  0.0  0.0  \n",
       "1  1.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  1.0  0.0  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prepared = full_pipeline.fit_transform(test_data)\n",
    "titanic_test = pd.DataFrame(test_prepared)\n",
    "titanic_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'n_hidden': 2, 'n_neurons': 50}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_cv.best_params_)\n",
    "model = grid_search_cv.best_estimator_.model\n",
    "predict = model.predict(titanic_test)\n",
    "\n",
    "binary_predict = []\n",
    "for val in predict:\n",
    "    if val < 0.5:\n",
    "        binary_predict.append(0)\n",
    "    else:\n",
    "        binary_predict.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_pd = pd.DataFrame({'PassengerId': test_full_data['PassengerId'], 'Survived': binary_predict})\n",
    "submit_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_pd.to_csv('./Data/answer.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
